{
  "0": {
    "source_file": "aborting-a-build.txt",
    "text": "layout: section\ntitle: Aborting a build\n\n\nWhen you click that [x] icon from the UI, the following things happen:\n\nBrowser sends a request to the server.\nThe server interrupts (via Thread.interrupt()) the thread (AKA\nexecutor thread) that is responsible for carrying out a build.\nThe server returns\n\nAt this point, your browser is back, but the actual abort process\nhappens from here asynchronously.\n\n"
  },
  "1": {
    "source_file": "aborting-a-build.txt",
    "text": "le for carrying out a build.\nThe server returns\n\nAt this point, your browser is back, but the actual abort process\nhappens from here asynchronously.\n\nThe thread gets the interrupt signal. How quickly this happens depends\non what the executor is doing at the time of the interruption.\nSpecifically, an executor thread can only be interrupted in\n\"interruption points\" due to the Java design.\n* Waiting "
  },
  "2": {
    "source_file": "aborting-a-build.txt",
    "text": " at the time of the interruption.\nSpecifically, an executor thread can only be interrupted in\n\"interruption points\" due to the Java design.\n* Waiting for a completion of a child process (for example, maybe the\nbuild is running Ant) is an interruption point. That means if the\nexecutor was doing that, it gets interrupted instantaneously.\n* Waiting for a computation on an agent is an interruption poi"
  },
  "3": {
    "source_file": "aborting-a-build.txt",
    "text": " point. That means if the\nexecutor was doing that, it gets interrupted instantaneously.\n* Waiting for a computation on an agent is an interruption point.\n* Waiting for file or network I/O is not an interruption point. This\noften causes the problem where a build appears to be un-abortable. For\nexample, checking out a Subversion repository falls in this category.\n* Normal computation is also not an "
  },
  "4": {
    "source_file": "aborting-a-build.txt",
    "text": "ere a build appears to be un-abortable. For\nexample, checking out a Subversion repository falls in this category.\n* Normal computation is also not an interruption point.\nThe executor performs a clean up operation. This depends on what it\nwas doing by the time it noticed the interruption.\n* If it was waiting for a completion of a child process, Jenkins will\nsearch for all the descendant processes a"
  },
  "5": {
    "source_file": "aborting-a-build.txt",
    "text": " the time it noticed the interruption.\n* If it was waiting for a completion of a child process, Jenkins will\nsearch for all the descendant processes and kill them all. On Unix, this\nis done through `+java.lang.UnixProcess.destroyProcess+`, which sends\nhttp://en.wikipedia.org/wiki/SIGTERM[SIGTERM] on Unix-based JDK implementations. On Windows,\nthis is done through\nhttp://msdn.microsoft.com/en-us/li"
  },
  "6": {
    "source_file": "aborting-a-build.txt",
    "text": "s\nhttp://en.wikipedia.org/wiki/SIGTERM[SIGTERM] on Unix-based JDK implementations. On Windows,\nthis is done through\nhttp://msdn.microsoft.com/en-us/library/ms686714(VS.85).aspx[TerminateProcess]\nAPI.\n* If it was waiting for a completion of some computation in an agent, the\nthread that's performing the remote computation is interrupted\nasynchronously. How quickly that threads gets interrupted depen"
  },
  "7": {
    "source_file": "aborting-a-build.txt",
    "text": "tation in an agent, the\nthread that's performing the remote computation is interrupted\nasynchronously. How quickly that threads gets interrupted depends on\nwhat that thread is doing. See above.\nExecutor starts unwinding the stack, and eventually it finishes the\nunwinding. At this point, the build is marked as aborted and executor\nreturns to the idle status.\n\nPipeline jobs can be stopped by sending"
  },
  "8": {
    "source_file": "aborting-a-build.txt",
    "text": "inishes the\nunwinding. At this point, the build is marked as aborted and executor\nreturns to the idle status.\n\nPipeline jobs can be stopped by sending an HTTP POST request to URL\nendpoints of a build.\n\n* `+BUILD ID URL/stop+` - aborts a Pipeline.\n* `+BUILD ID URL/term+` - forcibly terminates a build (should only be\nused if `+stop+` does not work).\n* `+BUILD ID URL/kill+` - hard kill a pipeline. Th"
  },
  "9": {
    "source_file": "aborting-a-build.txt",
    "text": "+BUILD ID URL/term+` - forcibly terminates a build (should only be\nused if `+stop+` does not work).\n* `+BUILD ID URL/kill+` - hard kill a pipeline. This is the most\ndestructive way to stop a pipeline and should only be used as a last\nresort.\n\nCheck the thread dump `+http://yourserver/jenkins/threadDump+` and\nlook for the executor thread in question \u2014 they are named after the\nagent and executor num"
  },
  "10": {
    "source_file": "aborting-a-build.txt",
    "text": "he thread dump `+http://yourserver/jenkins/threadDump+` and\nlook for the executor thread in question \u2014 they are named after the\nagent and executor number. That'll normally tell you where the thread\nis, and often reveals why it's not responding to an interruption."
  },
  "11": {
    "source_file": "aborting-a-build.txt",
    "text": "interruption."
  },
  "12": {
    "source_file": "about-jenkins.txt",
    "text": "layout: section\n\n\nThe *Manage Jenkins >> About Jenkins* page shows\nthe current release of Jenkins on your system\nplus information about licenses for all components.\nThe top of the display shows the release and version of Jenkins that is running.\n\nThe following information about your Jenkins cluster is also provided:\n\n* List of all third-party libraries used for this release of Jenkins,\nwith links "
  },
  "13": {
    "source_file": "about-jenkins.txt",
    "text": " following information about your Jenkins cluster is also provided:\n\n* List of all third-party libraries used for this release of Jenkins,\nwith links to licensing details about each library.\n* List of static resources that are installed.\n* List of installed plugins, each of which includes a link to the page\nthat shows all third-party dependencies for each plugin\nwith a link to licensing details ab"
  },
  "14": {
    "source_file": "about-jenkins.txt",
    "text": "stalled plugins, each of which includes a link to the page\nthat shows all third-party dependencies for each plugin\nwith a link to licensing details about each library.\n\nThis video shares different methods to check the version of Jenkins being used.\n\n.What is the latest version of Jenkins?\nvideo::--uAoNOZtKo[youtube,width=800,height=420]"
  },
  "15": {
    "source_file": "about-jenkins.txt",
    "text": ".What is the latest version of Jenkins?\nvideo::--uAoNOZtKo[youtube,width=800,height=420]"
  },
  "16": {
    "source_file": "access-control.txt",
    "text": "title: Access Control\nlayout: section\n\n\nJenkins access control is split into two parts:\n\n* Authentication (users prove who they are) is done using a _security realm_.\n  The security realm determines user identity and group memberships.\n* Authorization (users are permitted to do something) is done by an _authorization strategy_.\n  This controls whether a user (directly or through group memberships)"
  },
  "17": {
    "source_file": "access-control.txt",
    "text": "n (users are permitted to do something) is done by an _authorization strategy_.\n  This controls whether a user (directly or through group memberships) has a permission.\n\nThese can be independent, or work in combination.\nAn independent configuration would be plugin:active-directory[Active Directory] or plugin:ldap[LDAP] as security realm, and something like plugin:matrix-auth[Matrix Authorization S"
  },
  "18": {
    "source_file": "access-control.txt",
    "text": "ould be plugin:active-directory[Active Directory] or plugin:ldap[LDAP] as security realm, and something like plugin:matrix-auth[Matrix Authorization Strategy] as authorization strategy.\nAn example for related security realm and authorization strategy configuration is plugin:github-oauth[GitHub Authentication]:\nWhile its security realm can be used with a generic authorization strategy, it also prov"
  },
  "19": {
    "source_file": "access-control.txt",
    "text": " configuration is plugin:github-oauth[GitHub Authentication]:\nWhile its security realm can be used with a generic authorization strategy, it also provides an authorization strategy that looks up a user's repository permissions on GitHub, and grants or denies permissions to related jobs in Jenkins based on that.\n\nJenkins could be set up to have basic access control happen outside of it.\nSome exampl"
  },
  "20": {
    "source_file": "access-control.txt",
    "text": "r denies permissions to related jobs in Jenkins based on that.\n\nJenkins could be set up to have basic access control happen outside of it.\nSome examples:\n\n* The built-in https://github.com/jenkinsci/winstone[Winstone/Jetty servlet container wrapper] provides options that implement a basic security realm outside Jenkins.\n* If Jenkins is running behind a reverse proxy like Nginx or Apache, those can"
  },
  "21": {
    "source_file": "access-control.txt",
    "text": "provides options that implement a basic security realm outside Jenkins.\n* If Jenkins is running behind a reverse proxy like Nginx or Apache, those can limit access to Jenkins.\n\nAn advantage of these approaches is that they do not allow any access to Jenkins unless a user is authorized, reducing the impact of security issues in Jenkins or plugins especially when accessible from the internet.\nA disa"
  },
  "22": {
    "source_file": "access-control.txt",
    "text": "Jenkins unless a user is authorized, reducing the impact of security issues in Jenkins or plugins especially when accessible from the internet.\nA disadvantage is the lack of integration with Jenkins access controls and potentially even interfering with it (e.g. when trying to authenticate scripted clients).\n\nWhen configuring authentication and authorization in Jenkins, it is easy to accidentally a"
  },
  "23": {
    "source_file": "access-control.txt",
    "text": "th it (e.g. when trying to authenticate scripted clients).\n\nWhen configuring authentication and authorization in Jenkins, it is easy to accidentally allow far more access than intended.\nSee  about the impact of unintentionally granting Administer permission.\n\nAnyone can do anything::\nThe *anyone can do anything* authorization strategy is very rarely a good choice, as it allows even anonymous users"
  },
  "24": {
    "source_file": "access-control.txt",
    "text": "mission.\n\nAnyone can do anything::\nThe *anyone can do anything* authorization strategy is very rarely a good choice, as it allows even anonymous users to administer Jenkins.\nAs a rule of thumb, it should not be used.\nNever rely on the Jenkins URL to not be known outside your team or organization alone for security.\n\nLogged-in users can do anything::\nUsing the *logged-in users can do anything* auth"
  },
  "25": {
    "source_file": "access-control.txt",
    "text": "not be known outside your team or organization alone for security.\n\nLogged-in users can do anything::\nUsing the *logged-in users can do anything* authorization strategy can be a sensible choice as long as only fully trusted users have accounts to access Jenkins.\nThis is the default with Jenkins's single admin user when setting up Jenkins with the setup wizard.\nSwitching to an authentication realm "
  },
  "26": {
    "source_file": "access-control.txt",
    "text": "ess Jenkins.\nThis is the default with Jenkins's single admin user when setting up Jenkins with the setup wizard.\nSwitching to an authentication realm that allows untrusted users to have an account later will result in those users getting administrative access to Jenkins if you keep this authorization strategy.\nExamples include enabling account signup for _Jenkins' own user database_, or various ot"
  },
  "27": {
    "source_file": "access-control.txt",
    "text": "ve access to Jenkins if you keep this authorization strategy.\nExamples include enabling account signup for _Jenkins' own user database_, or various other authorization realms, many of which (GitHub, Google, GitLab, etc.) allow anyone to sign up for an account.\n\nAnonymous and authenticated users::\nSimilar to the previous items, you should generally not grant significant permissions to `anonymous` ("
  },
  "28": {
    "source_file": "access-control.txt",
    "text": "n account.\n\nAnonymous and authenticated users::\nSimilar to the previous items, you should generally not grant significant permissions to `anonymous` (the anonymous user) or authenticated (any authenticated user) when using an authorization strategy that allows finer-grained control (like plugin:matrix-auth[Matrix Authorization Strategy]).\nGranting Overall/Administer permission to _anonymous_ is si"
  },
  "29": {
    "source_file": "access-control.txt",
    "text": "hat allows finer-grained control (like plugin:matrix-auth[Matrix Authorization Strategy]).\nGranting Overall/Administer permission to _anonymous_ is similar to _Anyone can do anything_, while granting that permission to _authenticated_ is essentially the same as _Logged-in users can do anything_.\n\nBuilt-in node::\nUsers with limited permissions .\nWhen setting up a new Jenkins instance, adding users "
  },
  "30": {
    "source_file": "access-control.txt",
    "text": "the same as _Logged-in users can do anything_.\n\nBuilt-in node::\nUsers with limited permissions .\nWhen setting up a new Jenkins instance, adding users and switching authorization strategies, it is important to also set up distributed builds and limit what jobs are able to run on the built-in node.\n\n//In addition to the above items that discuss who may (effectively) be granted administrative access "
  },
  "31": {
    "source_file": "access-control.txt",
    "text": "what jobs are able to run on the built-in node.\n\n//In addition to the above items that discuss who may (effectively) be granted administrative access to Jenkins, you should be careful who you give any read access to Jenkins.\n//See .\n\nAt a very basic level, the _Overall/Read_ permission provides users some basic access to Jenkins.\nThis permission is a prerequisite for more substantial access to Jen"
  },
  "32": {
    "source_file": "access-control.txt",
    "text": "level, the _Overall/Read_ permission provides users some basic access to Jenkins.\nThis permission is a prerequisite for more substantial access to Jenkins.\nWithout this permission, only very few features explicitly intended to be used without authentication are available.\n\nThe highest level of permissions is _Overall/Administer_.\nWith this permission, users can upload and install plugins and have "
  },
  "33": {
    "source_file": "access-control.txt",
    "text": "ication are available.\n\nThe highest level of permissions is _Overall/Administer_.\nWith this permission, users can upload and install plugins and have access to the .\n\nBetween these two extremes is finer-grained permission control involving other permissions.\nPermissions in Jenkins have a _scope_: They can be granted globally, on an item (like a folder or job), on a build, etc.\nWhenever a user atte"
  },
  "34": {
    "source_file": "access-control.txt",
    "text": "issions.\nPermissions in Jenkins have a _scope_: They can be granted globally, on an item (like a folder or job), on a build, etc.\nWhenever a user attempts to do something that is protected by permissions, the authorization strategy is checked for whether the current user has the specific permission (e.g., _Job/Read_) on the specific object (e.g., a job).\nExactly how permissions are assigned and wh"
  },
  "35": {
    "source_file": "access-control.txt",
    "text": "ther the current user has the specific permission (e.g., _Job/Read_) on the specific object (e.g., a job).\nExactly how permissions are assigned and whether and how they're inherited is controlled by the specific authorization strategy.\n\nAs an example, plugin:matrix-auth[Matrix Authorization Strategy] provides two different authorization strategies:\n\n* One provides a single global configuration of "
  },
  "36": {
    "source_file": "access-control.txt",
    "text": ", plugin:matrix-auth[Matrix Authorization Strategy] provides two different authorization strategies:\n\n* One provides a single global configuration of all permissions.\n  A user granted _Item/Read_ will be granted that permission everywhere.\n* One provides a project-based configuration.\n  In this model, permissions can be granted globally (as in the previous strategy), or only on specific folders, j"
  },
  "37": {
    "source_file": "access-control.txt",
    "text": "ides a project-based configuration.\n  In this model, permissions can be granted globally (as in the previous strategy), or only on specific folders, jobs, or agents.\n  Permissions are by default inherited, but that can be customized as well, so that users granted _Item/Read_ globally or on a parent folder may be excluded from access to a job.\n\nFor more details about the various permissions in Jenk"
  },
  "38": {
    "source_file": "access-control.txt",
    "text": "users granted _Item/Read_ globally or on a parent folder may be excluded from access to a job.\n\nFor more details about the various permissions in Jenkins and the level of access they grant, see .\n\nSee ."
  },
  "39": {
    "source_file": "access-modifier-annotation.txt",
    "text": "title: Access Modifier Annotation (@Restricted)\nlayout: developer\n\n\nAll public classes, as well as their public methods and fields are available to plugins with a dependency on the component defining a class (Jenkins core or a plugin).\nSometimes, these need to be public for technical reasons, but should not be available for other plugins to use.\nFor example, Stapler web methods (`#doConfigSubmit`,"
  },
  "40": {
    "source_file": "access-modifier-annotation.txt",
    "text": "se need to be public for technical reasons, but should not be available for other plugins to use.\nFor example, Stapler web methods (`#doConfigSubmit`, `doCheckName`, `doFillJobItems`, and similar) need to be public to be invoked by Stapler, but they're often not stable API -- parameters may be added or removed depending on the needs of the UI.\n\nThe access modifier annotation jenkinsdoc:component:a"
  },
  "41": {
    "source_file": "access-modifier-annotation.txt",
    "text": "re often not stable API -- parameters may be added or removed depending on the needs of the UI.\n\nThe access modifier annotation jenkinsdoc:component:access-modifier-annotation:org.kohsuke.accmod.Restricted[`@Restricted`] helps solve this problem, by preventing compliant plugins from calling methods annotated to be inaccessible by default.\nMultiple different modes are available, depending on the `v"
  },
  "42": {
    "source_file": "access-modifier-annotation.txt",
    "text": "preventing compliant plugins from calling methods annotated to be inaccessible by default.\nMultiple different modes are available, depending on the `value` of the annotation.\nThe most commonly modes are the following:\n\n* `@Restricted(NoExternalUse.class)` allows access to the annotated element from the same component, but not any others.\n  This is the most common way to use this annotation in Jenk"
  },
  "43": {
    "source_file": "access-modifier-annotation.txt",
    "text": "ass)` allows access to the annotated element from the same component, but not any others.\n  This is the most common way to use this annotation in Jenkins.\n* `@Restricted(DoNotUse.class)` prohibits all programmatic use. This could be used for code only reflectively invoked, e.g., from Jelly views.\n  As this reduces testability, `NoExternalUse.class` is often used instead, even if the only calls are"
  },
  "44": {
    "source_file": "access-modifier-annotation.txt",
    "text": "y reflectively invoked, e.g., from Jelly views.\n  As this reduces testability, `NoExternalUse.class` is often used instead, even if the only calls are from test code.\n// TODO Confirm that test code is affected by these annotations.\n* `@Restricted(Beta.class)` can be used to designate elements as being in _beta_.\n  What this means exactly is implementation-dependent, but the general idea is to ensu"
  },
  "45": {
    "source_file": "access-modifier-annotation.txt",
    "text": "a.class)` can be used to designate elements as being in _beta_.\n  What this means exactly is implementation-dependent, but the general idea is to ensure callers are prepared to quickly adapt to incompatible changes in the code.\n\nLook for jenkinsdoc:component:access-modifier-annotation:org.kohsuke.accmod.AccessRestriction[`AccessRestriction`] implementations for a complete list.\n\nAny calls to annot"
  },
  "46": {
    "source_file": "access-modifier-annotation.txt",
    "text": "omponent:access-modifier-annotation:org.kohsuke.accmod.AccessRestriction[`AccessRestriction`] implementations for a complete list.\n\nAny calls to annotated elements violating the access restrictions will result in compilation failures.\n\nSometimes it's necessary to suppress failures.\nThe most common reason is the intentional use of `@Restricted(Beta.class)` APIs.\nSupport for this is part of the plug"
  },
  "47": {
    "source_file": "access-modifier-annotation.txt",
    "text": " necessary to suppress failures.\nThe most common reason is the intentional use of `@Restricted(Beta.class)` APIs.\nSupport for this is part of the plugin parent POM: Set the property `useBeta` to `true` to allow use of `@Restricted(Beta.class)` annotated elements.\n\nNOTE: This will suppress failures for use of _any_ `Beta.class` API called in the project.\nAs a result, code changes may introduce more"
  },
  "48": {
    "source_file": "access-modifier-annotation.txt",
    "text": "ted elements.\n\nNOTE: This will suppress failures for use of _any_ `Beta.class` API called in the project.\nAs a result, code changes may introduce more uses of `Beta.class` APIs than intended.\n\nThere are multiple options to suppress other access modifier restrictions, from most to least responsible:\n\nYou can use the jenkinsdoc:component:access-modifier-suppressions:org.kohsuke.accmod.restrictions.s"
  },
  "49": {
    "source_file": "access-modifier-annotation.txt",
    "text": "ier restrictions, from most to least responsible:\n\nYou can use the jenkinsdoc:component:access-modifier-suppressions:org.kohsuke.accmod.restrictions.suppressions,SuppressRestrictedWarnings[`SuppressRestrictedWarnings`] annotation from the `access-modifier-suppressions` library to specifically declare which classes's restrictions should be suppressed.\nYou can set the property `access-modifier-check"
  },
  "50": {
    "source_file": "access-modifier-annotation.txt",
    "text": "ifier-suppressions` library to specifically declare which classes's restrictions should be suppressed.\nYou can set the property `access-modifier-checker.failOnError` in your `pom.xml` to check for violations, but not fail the build.\nYou can set the property `access-modifier-checker.skip` in your `pom.xml` to skip the checks altogether.\n\nWARNING: Code is usually annotated `@Restricted` for a reason"
  },
  "51": {
    "source_file": "access-modifier-annotation.txt",
    "text": "roperty `access-modifier-checker.skip` in your `pom.xml` to skip the checks altogether.\n\nWARNING: Code is usually annotated `@Restricted` for a reason.\nUse at your own risk!\n\nJenkins core and plugins have a dependency on `access-modifier-annotation`.\nThe jenkinsdoc:component:access-modifier-annotation:org.kohsuke.accmod.Restricted[`@Restricted`] annotation is itself annotated jenkinsdoc:component:"
  },
  "52": {
    "source_file": "access-modifier-annotation.txt",
    "text": "\nThe jenkinsdoc:component:access-modifier-annotation:org.kohsuke.accmod.Restricted[`@Restricted`] annotation is itself annotated jenkinsdoc:component:annotation-indexer:org.jvnet.hudson.annotation_indexer.Indexed[`@Indexed`], which means the https://javadoc.jenkins.io/component/annotation-indexer/org/jvnet/hudson/annotation_indexer/package-summary.html[Annotation Indexer] library will create a fil"
  },
  "53": {
    "source_file": "access-modifier-annotation.txt",
    "text": "javadoc.jenkins.io/component/annotation-indexer/org/jvnet/hudson/annotation_indexer/package-summary.html[Annotation Indexer] library will create a file listing all classes with a `@Restricted` annotated element in `META-INF/services/annotations/org.kohsuke.accmod.Restricted`.\n\nJenkins plugins are set up to run jenkinsdoc:component:access-modifier-checker:org.kohsuke.accmod.impl.EnforcerMojo[`Enfor"
  },
  "54": {
    "source_file": "access-modifier-annotation.txt",
    "text": "ohsuke.accmod.Restricted`.\n\nJenkins plugins are set up to run jenkinsdoc:component:access-modifier-checker:org.kohsuke.accmod.impl.EnforcerMojo[`EnforcerMojo`] during the build after compilation.\nThis reads all classes specified in the various `META-INF/services/annotations/org.kohsuke.accmod.Restricted` files in its dependencies and notes all annotated elements.\nThen, all generated class files ar"
  },
  "55": {
    "source_file": "access-modifier-annotation.txt",
    "text": "INF/services/annotations/org.kohsuke.accmod.Restricted` files in its dependencies and notes all annotated elements.\nThen, all generated class files are inspected for calls to prohibited elements from the previous step.\nIf any are are found, unless `access-modifier-checker.skip` is set, the build is failed."
  },
  "56": {
    "source_file": "access-modifier-annotation.txt",
    "text": "ccess-modifier-checker.skip` is set, the build is failed."
  },
  "57": {
    "source_file": "action-for-all-projects.txt",
    "text": "title: How to show a menu item on all projects\nlayout: developer\n\n\nThis guide will guide you through showing a menu item with associated URL and view on all projects' side panels, without requiring configuration in the job.\n\nThis could be used for example to show information about the job, such as statistics, without needing additional (persistently stored) data.\n\nIn this example, we'll add a link"
  },
  "58": {
    "source_file": "action-for-all-projects.txt",
    "text": "ample to show information about the job, such as statistics, without needing additional (persistently stored) data.\n\nIn this example, we'll add a link called _Statistics_ that will link to a page that shows some information about the project.\n\nThe action will be fairly basic: It will expect a reference to an `jenkinsdoc:Project[]` as constructor argument, and has getters returning the number of bu"
  },
  "59": {
    "source_file": "action-for-all-projects.txt",
    "text": "tion will be fairly basic: It will expect a reference to an `jenkinsdoc:Project[]` as constructor argument, and has getters returning the number of build steps and post-build steps this project has.\n\npackage org.jenkinsci.plugins.sample;\n\nimport hudson.model.Action;\nimport hudson.model.Project;\n\npublic class SampleAction implements Action {\n\n    private Project project;\n\n    public SampleAction(Pr"
  },
  "60": {
    "source_file": "action-for-all-projects.txt",
    "text": "on.model.Action;\nimport hudson.model.Project;\n\npublic class SampleAction implements Action {\n\n    private Project project;\n\n    public SampleAction(Project project) {\n        this.project = project;\n    }\n\n    public int getBuildStepsCount() {\n        return project.getBuilders().size();\n    }\n\n    public int getPostBuildStepsCount() {\n        return project.getPublishersList().size();\n    }\n\n    "
  },
  "61": {
    "source_file": "action-for-all-projects.txt",
    "text": "  return project.getBuilders().size();\n    }\n\n    public int getPostBuildStepsCount() {\n        return project.getPublishersList().size();\n    }\n\n    @Override\n    public String getIconFileName() {\n        return \"clipboard.png\";\n    }\n\n    @Override\n    public String getDisplayName() {\n        return \"Project Statistics\";\n    }\n\n    @Override\n    public String getUrlName() {\n        return \"stats"
  },
  "62": {
    "source_file": "action-for-all-projects.txt",
    "text": "\n    public String getDisplayName() {\n        return \"Project Statistics\";\n    }\n\n    @Override\n    public String getUrlName() {\n        return \"stats\";\n    }\n}\n\nSimilarly, the `index.jelly` view we create for it in the resource directory corresponding to this class -- `src/main/resources/org/jenkinsci/plugins/sample/SampleAction/` -- is very basic, just showing the information from the getters:\n\n"
  },
  "63": {
    "source_file": "action-for-all-projects.txt",
    "text": "ng to this class -- `src/main/resources/org/jenkinsci/plugins/sample/SampleAction/` -- is very basic, just showing the information from the getters:\n\n<?jelly escape-by-default='true'?>\n<j:jelly xmlns:j=\"jelly:core\" xmlns:l=\"/lib/layout\">\n    <l:layout title=\"Project Statistics\">\n        <l:main-panel>\n            <h1>\n                Project Statistics\n            </h1>\n            <ul>\n          "
  },
  "64": {
    "source_file": "action-for-all-projects.txt",
    "text": "t title=\"Project Statistics\">\n        <l:main-panel>\n            <h1>\n                Project Statistics\n            </h1>\n            <ul>\n                <li>\n                    Build Steps: ${it.buildStepsCount}\n                </li>\n                <li>\n                    Post-Build Steps: ${it.postBuildStepsCount}\n                </li>\n            </ul>\n        </l:main-panel>\n    </l:layou"
  },
  "65": {
    "source_file": "action-for-all-projects.txt",
    "text": "    <li>\n                    Post-Build Steps: ${it.postBuildStepsCount}\n                </li>\n            </ul>\n        </l:main-panel>\n    </l:layout>\n</j:jelly>\n\n`jenkinsdoc:TransientActionFactory[]` can be used to add any number of actions to a given instance of an `jenkinsdoc:Actionable[]` subtype. `TransientActionFactory` defines:\n\n1. Which subtype of `Actionable` it applies to\n2. Which kind"
  },
  "66": {
    "source_file": "action-for-all-projects.txt",
    "text": "iven instance of an `jenkinsdoc:Actionable[]` subtype. `TransientActionFactory` defines:\n\n1. Which subtype of `Actionable` it applies to\n2. Which kinds of `Action` it creates\n\nThe class will look like this:\n\n@Extension\npublic class SampleActionFactory extends TransientActionFactory<Project> {\n\n    @Override\n    public Class<Project> type() {\n        return Project.class; // <1> }\n\n    @NonNull\n   "
  },
  "67": {
    "source_file": "action-for-all-projects.txt",
    "text": "y extends TransientActionFactory<Project> {\n\n    @Override\n    public Class<Project> type() {\n        return Project.class; // <1> }\n\n    @NonNull\n    @Override\n    public Collection<? extends Action> createFor(@NonNull Project project) {\n        return Collections.singleton(new SampleAction(project)); // <2> }\n}\n\n<1> This will only apply to `Project` instances.\n<2> The factory could create differ"
  },
  "68": {
    "source_file": "action-for-all-projects.txt",
    "text": "urn Collections.singleton(new SampleAction(project)); // <2> }\n}\n\n<1> This will only apply to `Project` instances.\n<2> The factory could create different action depending on the `Project`, in this case, it is not needed.\n\nTo only show the project information to people who otherwise would be able to obtain it by viewing the job configuration, we can set up the action so the link is only shown to th"
  },
  "69": {
    "source_file": "action-for-all-projects.txt",
    "text": "ormation to people who otherwise would be able to obtain it by viewing the job configuration, we can set up the action so the link is only shown to those with the `Item.CONFIGURE` permission.footnote:[Another option would be to only create the action for those with the correct permission. That approach would currently work for Jobs, but other objects in Jenkins use caching for actions so the trans"
  },
  "70": {
    "source_file": "action-for-all-projects.txt",
    "text": " for those with the correct permission. That approach would currently work for Jobs, but other objects in Jenkins use caching for actions so the transient actions are not recreated on every request. Of course, the chosen approach requires more sophisticated permission checks.]\n\n(...)\n    @Override\n    public String getIconFileName() {\n        return this.project.hasPermission(Item.CONFIGURE) ? \"cl"
  },
  "71": {
    "source_file": "action-for-all-projects.txt",
    "text": "ticated permission checks.]\n\n(...)\n    @Override\n    public String getIconFileName() {\n        return this.project.hasPermission(Item.CONFIGURE) ? \"clipboard.png\" : null; // <1> }\n(...)\n\n<1> Returning `null` is a documented way for `getIconFileName` to make an action not appear in the side panel.\n\nThis will not prevent direct access via the URL however, so we need make sure to restrict who can acc"
  },
  "72": {
    "source_file": "action-for-all-projects.txt",
    "text": "to make an action not appear in the side panel.\n\nThis will not prevent direct access via the URL however, so we need make sure to restrict who can access the action.\n\nA reliable way to do this is to implement `staplerdoc:org.kohsuke.stapler.StaplerProxy[StaplerProxy]`, an interface intended to allow objects to forward HTTP request processing to another object. By implementing the `getTarget()` met"
  },
  "73": {
    "source_file": "action-for-all-projects.txt",
    "text": "oxy[StaplerProxy]`, an interface intended to allow objects to forward HTTP request processing to another object. By implementing the `getTarget()` method and returning `this`, the request will continue to be processed by the same object, but we're able to check user permissions before that happens.\n\n(...)\nimport org.kohsuke.stapler.StaplerProxy;\n\npublic class SampleAction implements Action, Staple"
  },
  "74": {
    "source_file": "action-for-all-projects.txt",
    "text": "le to check user permissions before that happens.\n\n(...)\nimport org.kohsuke.stapler.StaplerProxy;\n\npublic class SampleAction implements Action, StaplerProxy {\n    (...)\n\n    @Override\n    public Object getTarget() {\n        this.project.checkPermission(Item.CONFIGURE); // <1> return this;\n    }\n}\n\n<1> This throws an `AccessDeniedException` if the check fails, resulting in the user seeing an error "
  },
  "75": {
    "source_file": "action-for-all-projects.txt",
    "text": "on(Item.CONFIGURE); // <1> return this;\n    }\n}\n\n<1> This throws an `AccessDeniedException` if the check fails, resulting in the user seeing an error message (or, if not already logged in, a login screen)."
  },
  "76": {
    "source_file": "actions.txt",
    "text": "title: Web Methods\nlayout: developersection\nwip: true\nreferences:\n- title: Web Method\n  url: https://wiki.jenkins.io/display/JENKINS/Web+Method\n\n\nWeb methods need to provide some indication that they are intended for Stapler routing:\n\n* Any applicable annotation recognized by Stapler, e.g., `@RequirePOST`.\n* Any inferable parameter type, e.g., `StaplerRequest`.\n* Any applicable parameter annotatio"
  },
  "77": {
    "source_file": "actions.txt",
    "text": "e annotation recognized by Stapler, e.g., `@RequirePOST`.\n* Any inferable parameter type, e.g., `StaplerRequest`.\n* Any applicable parameter annotation, recognized by Stapler, e.g., `@AncestorInPath`.\n* Any declared exception type implementing `HttpResponse`, e.g., `HttpResponseException`.\n* A return type implementing `HttpResponse`.\n\nIf none of these indicators are present, the method will no lon"
  },
  "78": {
    "source_file": "actions.txt",
    "text": "esponse`, e.g., `HttpResponseException`.\n* A return type implementing `HttpResponse`.\n\nIf none of these indicators are present, the method will no longer be invoked by Stapler as a web method starting in Jenkins 2.138.4 and Jenkins 2.154.\nSome examples:\n\npublic void doRun()\npublic String doRun(String foo) throws Exception\n\nWhen the SECURITY-595 fix prevents access to a URL, a warning message is wr"
  },
  "79": {
    "source_file": "actions.txt",
    "text": "es:\n\npublic void doRun()\npublic String doRun(String foo) throws Exception\n\nWhen the SECURITY-595 fix prevents access to a URL, a warning message is written to the Jenkins log that looks similar to the following:\n\nWARNING: New Stapler routing rules result in the URL \"/example\" no longer being allowed. If you consider it safe to use, add the following to the whitelist: \"method hudson.model.Hudson do"
  },
  "80": {
    "source_file": "actions.txt",
    "text": "sult in the URL \"/example\" no longer being allowed. If you consider it safe to use, add the following to the whitelist: \"method hudson.model.Hudson doExample\". Learn more: https://www.jenkins.io/redirect/stapler-routing\n\nAdministrators can follow the instructions to make the method or field work on their specific controller, but ideally the component is changed to prevent the problem in the first "
  },
  "81": {
    "source_file": "actions.txt",
    "text": " instructions to make the method or field work on their specific controller, but ideally the component is changed to prevent the problem in the first place:\n\n* Add any of the indicators listed in the previous section that would make your method routable.\n* Annotate the web method `@StaplerDispatchable`.\n  You may need to add a dependency to the `io.jenkins.stapler:io.jenkins.stapler` library to ma"
  },
  "82": {
    "source_file": "actions.txt",
    "text": "ble.\n* Annotate the web method `@StaplerDispatchable`.\n  You may need to add a dependency to the `io.jenkins.stapler:io.jenkins.stapler` library to make this annotation available."
  },
  "83": {
    "source_file": "activity.txt",
    "text": "layout: section\ntitle: Activity View\nwip: false\n\n\nifdef::env-github[:imagesdir: ../resources]\nifndef::env-github[:imagesdir: ../../resources]\n\n// Show only 1/3 of the Blue ocean admonitions\n// :pipeline-visualization-admonition:\n// :pipeline-creation-admonition:\n\nThe Blue Ocean Activity view shows all activities related to one Pipeline.\n\nThe Activity view includes the <<getting-started#navigation-"
  },
  "84": {
    "source_file": "activity.txt",
    "text": "-admonition:\n\nThe Blue Ocean Activity view shows all activities related to one Pipeline.\n\nThe Activity view includes the <<getting-started#navigation-bar, standard navigation bar>> at the top and a local navigation bar below it.\n\nThe local navigation bar includes:\n\n* *Pipeline Name* - Selecting this displays the <<activity#, default Activity tab>>.\n* *Favorites Toggle* - Selecting the favorite ico"
  },
  "85": {
    "source_file": "activity.txt",
    "text": " bar includes:\n\n* *Pipeline Name* - Selecting this displays the <<activity#, default Activity tab>>.\n* *Favorites Toggle* - Selecting the favorite icon &#9734; to the right of the Pipeline name, adds a branch to the favorites list shown on the <<dashboard#favorites, dashboard's favorites list>>.\n* *Tabs* (<<activity, Activity>>, <<branches, Branches>> <<pull-requests, Pull Requests>>) - Selecting "
  },
  "86": {
    "source_file": "activity.txt",
    "text": "board#favorites, dashboard's favorites list>>.\n* *Tabs* (<<activity, Activity>>, <<branches, Branches>> <<pull-requests, Pull Requests>>) - Selecting one of these navigates to the corresponding information in the Activity view.\n\nThe default tab of the Activity view shows a list of the latest completed or active runs.\nEach line represents the <<dashboard#run-status, status>> of a run, run ID, commi"
  },
  "87": {
    "source_file": "activity.txt",
    "text": "e Activity view shows a list of the latest completed or active runs.\nEach line represents the <<dashboard#run-status, status>> of a run, run ID, commit information, and when the run completed.\n\n* Selecting a run will bring up the <<pipeline-run-details#, Pipeline run details>> to provide Pipeline visualization.\n* Active runs can be aborted from this list by selecting the *stop* icon, which is repr"
  },
  "88": {
    "source_file": "activity.txt",
    "text": "ls#, Pipeline run details>> to provide Pipeline visualization.\n* Active runs can be aborted from this list by selecting the *stop* icon, which is represented by a &#9726; within a circle.\n* Runs that have been completed can be re-run by selecting the\n*re-run* icon &#8634;.\n* The list can be filtered by branch using the \"Branch\" drop-down in the list header.\n\nThis view does not allow runs to be edi"
  },
  "89": {
    "source_file": "activity.txt",
    "text": "\n*re-run* icon &#8634;.\n* The list can be filtered by branch using the \"Branch\" drop-down in the list header.\n\nThis view does not allow runs to be edited or marked as favorites.\nTo perform these actions, select the *Branches* tab.\n\nThe *Branches* tab shows a list of all branches that have a completed or active run in the current Pipeline.\nEach line in the list corresponds to a branch in source con"
  },
  "90": {
    "source_file": "activity.txt",
    "text": " shows a list of all branches that have a completed or active run in the current Pipeline.\nEach line in the list corresponds to a branch in source control, displaying the <<dashboard#pipeline-health, overall health of the branch>> based on the status of the most recent run, branch name, commit information, and when the run completed.\n\nSelecting a branch brings up the <<pipeline-run-details#, Pipel"
  },
  "91": {
    "source_file": "activity.txt",
    "text": " of the most recent run, branch name, commit information, and when the run completed.\n\nSelecting a branch brings up the <<pipeline-run-details#, Pipeline run details>> for the latest completed or active run of that branch.\n\nPipelines where the latest run has been completed can be run again by selecting the *run* icon, represented by a icon:play[] in a circle.\n* Active runs can be aborted, and disp"
  },
  "92": {
    "source_file": "activity.txt",
    "text": " run has been completed can be run again by selecting the *run* icon, represented by a icon:play[] in a circle.\n* Active runs can be aborted, and display a *stop* icon, which is represented by a &#9726; within a circle.\nSelecting the *history* icon icon:history[] allows you to view the run history for that branch.\nThe *edit* icon, represented by a icon:pencil[], opens the <<pipeline-editor#, Pipel"
  },
  "93": {
    "source_file": "activity.txt",
    "text": "con:history[] allows you to view the run history for that branch.\nThe *edit* icon, represented by a icon:pencil[], opens the <<pipeline-editor#, Pipeline editor>> for that branch.\nThe *favorite* &#9734; icon adds a branch to your favorites list on the <<dashboard#favorites, dashboard>>.\nOn the dashboard a branch listed under favorites displays a solid star &#9733;.\nDeselecting the star removes the"
  },
  "94": {
    "source_file": "activity.txt",
    "text": "e <<dashboard#favorites, dashboard>>.\nOn the dashboard a branch listed under favorites displays a solid star &#9733;.\nDeselecting the star removes the branch from the favorites list.\n\nThe Pull Requests tab displays a list of all pull requests for the current Pipeline, that have a completed or active run.\nEach line in the list corresponds to a pull request in source control, which displays the stat"
  },
  "95": {
    "source_file": "activity.txt",
    "text": " current Pipeline, that have a completed or active run.\nEach line in the list corresponds to a pull request in source control, which displays the status of the most recent run, run ID, summary, author, and when the run completed.\n\nBlue Ocean displays pull requests and branches separately, but the lists behave similarly.\nSelecting a pull request in this list will bring up the <<pipeline-run-details"
  },
  "96": {
    "source_file": "activity.txt",
    "text": " pull requests and branches separately, but the lists behave similarly.\nSelecting a pull request in this list will bring up the <<pipeline-run-details#, Pipeline run details>> for the latest completed or active run of that pull request.\n\n* Active runs can be aborted from this list by selecting the *stop* icon, which is represented by a &#9726; within a circle.\n* Pull requests whose latest run has "
  },
  "97": {
    "source_file": "activity.txt",
    "text": "s can be aborted from this list by selecting the *stop* icon, which is represented by a &#9726; within a circle.\n* Pull requests whose latest run has been completed can be run again by selecting the *run* icon, represented by a icon:play[] in a circle.\n\nThe pull request list does not display <<dashboard#pipeline-health, health icons>>, and pull requests cannot be edited or marked as favorites.\n\nNO"
  },
  "98": {
    "source_file": "activity.txt",
    "text": "e.\n\nThe pull request list does not display <<dashboard#pipeline-health, health icons>>, and pull requests cannot be edited or marked as favorites.\n\nNOTE: By default, when a pull request is closed, Jenkins removes the Pipeline from Jenkins, and runs for that pull request are no longer accessible from Jenkins.\nThe Pipelines removed in this way will need to be cleaned up in the future.\nThis can be ch"
  },
  "99": {
    "source_file": "activity.txt",
    "text": "or that pull request are no longer accessible from Jenkins.\nThe Pipelines removed in this way will need to be cleaned up in the future.\nThis can be changed by adjusting the configuration of the underlying multi-branch Pipeline job."
  },
  "100": {
    "source_file": "add-a-configuration-as-code-automated-test.txt",
    "text": "layout: developersection\ntitle: Add a configuration as code automated test\n\n\nThe configuration as code plugin provides a test framework that allows a plugin to implement a round trip test of configuration as code with very little implementation code.\n\nInsert more details here"
  },
  "101": {
    "source_file": "add-a-configuration-as-code-automated-test.txt",
    "text": "\n\nInsert more details here"
  },
  "102": {
    "source_file": "add-a-contributing-guide.txt",
    "text": "layout: developersection\ntitle: Add a contributing guide\n\n\nIf the plugin does not already include a contributing guide and if it would benefit from more detail than is provided in the , add a contributing guide so that others understand how to help with plugin development.\nLook for existing contributing instructions in files like `README.md`.\nMove the content from the `README.md` file to the `CONT"
  },
  "103": {
    "source_file": "add-a-contributing-guide.txt",
    "text": "ith plugin development.\nLook for existing contributing instructions in files like `README.md`.\nMove the content from the `README.md` file to the `CONTRIBUTING.md` file so that the README file stays focused on user documentation.\n\n// Create the branch\n\nThe contributing guide often includes instructions to:\n\n* Compile and run automated tests\n* Run the plugin in a development environment\n* Report cod"
  },
  "104": {
    "source_file": "add-a-contributing-guide.txt",
    "text": "\n\nThe contributing guide often includes instructions to:\n\n* Compile and run automated tests\n* Run the plugin in a development environment\n* Report code coverage of the plugin and its tests\n* Report static analysis results\n\nRefer to the contributing guides of other plugins for common examples, like:\n\n*\n*\n*\n*\n*\n*\n\n// Create a pull request"
  },
  "105": {
    "source_file": "add-a-contributing-guide.txt",
    "text": "uides of other plugins for common examples, like:\n\n*\n*\n*\n*\n*\n*\n\n// Create a pull request"
  },
  "106": {
    "source_file": "add-a-jenkinsfile.txt",
    "text": "layout: developersection\ntitle: Add a Jenkinsfile\n\n\n.Add a Jenkinsfile to the repository\nvideo::Fev8KfFsPZE[youtube,width=800,height=420,start=807]\n\nIf the plugin repository does not already include a Jenkinsfile, add a `Jenkinsfile` so that  will automatically compile and test the plugin and any pull requests submitted to the plugin.\n\n// Create the branch\n\nCreate a file named `Jenkinsfile` with t"
  },
  "107": {
    "source_file": "add-a-jenkinsfile.txt",
    "text": "tomatically compile and test the plugin and any pull requests submitted to the plugin.\n\n// Create the branch\n\nCreate a file named `Jenkinsfile` with the content:\n\n``` groovy\nbuildPlugin(\n  useContainerAgent: true, // Set to `false` if you need to use Docker for containerized tests\n  configurations: [\n    [platform: 'linux', jdk: 21],\n    [platform: 'windows', jdk: 17],\n])\n```\nBe sure the configura"
  },
  "108": {
    "source_file": "add-a-jenkinsfile.txt",
    "text": " Docker for containerized tests\n  configurations: [\n    [platform: 'linux', jdk: 21],\n    [platform: 'windows', jdk: 17],\n])\n```\nBe sure the configuration platform is set correctly.\nBuilding with a `Jenkinsfile` configuration that includes Java 8 will result in a low-level class version error when using version 4.52 or later of the plugin parent POM.\n\n// Create a pull request\n\nA job will be automa"
  },
  "109": {
    "source_file": "add-a-jenkinsfile.txt",
    "text": "l result in a low-level class version error when using version 4.52 or later of the plugin parent POM.\n\n// Create a pull request\n\nA job will be automatically created in the  after the pull request is merged and the GitHub organization folder is scanned by ci.jenkins.io.\n\nFor more details, see the  page for Jenkins developers."
  },
  "110": {
    "source_file": "add-a-jenkinsfile.txt",
    "text": "ed by ci.jenkins.io.\n\nFor more details, see the  page for Jenkins developers."
  },
  "111": {
    "source_file": "add-a-link-to-report-an-issue.txt",
    "text": "layout: developersection\ntitle: Report an Issue\n\n\nThe plugins site  includes a \u201cReport an Issue\u201d link for each of the plugins.\nThe linked page guides the user to provide a better classified issue and leads them to the correct path to privately report security issues.\n\n// Create the branch\n\nAdd a heading in the plugin documentation that links to the specific \u201cReport an Issue\u201d link provided by the  "
  },
  "112": {
    "source_file": "add-a-link-to-report-an-issue.txt",
    "text": " security issues.\n\n// Create the branch\n\nAdd a heading in the plugin documentation that links to the specific \u201cReport an Issue\u201d link provided by the  site.\nSome plugins use GitHub issues.\nThe link from the  site is the correct link to use in that case as well.\n\nFor example, the link for the git plugin is , while the link for the elastic axis plugin is .\n\ndiff --git a/README.md b/README.md\n\nindex 4"
  },
  "113": {
    "source_file": "add-a-link-to-report-an-issue.txt",
    "text": "e as well.\n\nFor example, the link for the git plugin is , while the link for the elastic axis plugin is .\n\ndiff --git a/README.md b/README.md\n\nindex 41fad51..e4bc674 100644\n--- a/README.md\n++ b/README.md\n\n## Report an Issue\nPlease report issues and enhancements through the\n[Jenkins issue tracker](https://www.jenkins.io/participate/report-issue/redirect/#19326).\n// Create a pull request"
  },
  "114": {
    "source_file": "add-a-link-to-report-an-issue.txt",
    "text": "nhancements through the\n[Jenkins issue tracker](https://www.jenkins.io/participate/report-issue/redirect/#19326).\n// Create a pull request"
  },
  "115": {
    "source_file": "add-a-round-trip-test-for-configuration.txt",
    "text": "layout: developersection\ntitle: Add a round trip test for configuration\n\n\nThe Jenkins test harness provides convenience methods that make it relatively straightforward to create a round trip test of the configuration.\n\nInsert more details here"
  },
  "116": {
    "source_file": "add-more-spotbugs-checks.txt",
    "text": "layout: developersection\ntitle: Add more spotbugs checks\n\n\n.Add more thorough spotbugs checks\nvideo::2c8wK2jkcIA[youtube,width=800,height=420,start=255]\n\nThe Jenkins plugin pom enables static analysis with .\nPlugin maintenance can be improved in some cases by increasing the depth of spotbugs analysis.\n\n// Create the branch\n\nTo increase the spotbugs analysis checks, add the spotbugs properties entr"
  },
  "117": {
    "source_file": "add-more-spotbugs-checks.txt",
    "text": " cases by increasing the depth of spotbugs analysis.\n\n// Create the branch\n\nTo increase the spotbugs analysis checks, add the spotbugs properties entries in the properties section of the `pom.xml` file:\n\n   <properties>\n     <spotbugs.effort>Max</spotbugs.effort>\n     <spotbugs.threshold>Low</spotbugs.threshold>\n   </properties>\n\nWhen the spotbugs analysis checks are increased, they often report n"
  },
  "118": {
    "source_file": "add-more-spotbugs-checks.txt",
    "text": "tbugs.effort>\n     <spotbugs.threshold>Low</spotbugs.threshold>\n   </properties>\n\nWhen the spotbugs analysis checks are increased, they often report new issues that need to be resolved or suppressed.\nSpotbugs checks are included in the Apache Maven `verify` step.\nRun the spotbugs analysis checks as part of the Apache Maven `verify` step with the command:\n\n```\nmvn clean -DskipTests verify\n```\n\nIt i"
  },
  "119": {
    "source_file": "add-more-spotbugs-checks.txt",
    "text": "verify` step.\nRun the spotbugs analysis checks as part of the Apache Maven `verify` step with the command:\n\n```\nmvn clean -DskipTests verify\n```\n\nIt is generally preferred to fix a spotbugs warning rather than suppress the warning message.\nHowever, in those cases where a spotbugs message is incorrect or is infeasible to fix, it can be suppressed with the `SuppressFBWarnings` annotation.\nA suppress"
  },
  "120": {
    "source_file": "add-more-spotbugs-checks.txt",
    "text": "n those cases where a spotbugs message is incorrect or is infeasible to fix, it can be suppressed with the `SuppressFBWarnings` annotation.\nA suppression might look like this:\n\n```java\nimport edu.umd.cs.findbugs.annotations.SuppressFBWarnings;\n/* ... preceding a method that returns a Boolean and may return null */\n    @SuppressFBWarnings(\n            value = \"NP_BOOLEAN_RETURN_NULL\",\n            j"
  },
  "121": {
    "source_file": "add-more-spotbugs-checks.txt",
    "text": " preceding a method that returns a Boolean and may return null */\n    @SuppressFBWarnings(\n            value = \"NP_BOOLEAN_RETURN_NULL\",\n            justification = \"Null return indicates others should evaluate further\")\n```\n\nSometimes the number of spotbugs exclusions make it inconvenient or tedious to place the exclusions in the source files.\nIn those cases, a spotbugs exclusions file can be use"
  },
  "122": {
    "source_file": "add-more-spotbugs-checks.txt",
    "text": "spotbugs exclusions make it inconvenient or tedious to place the exclusions in the source files.\nIn those cases, a spotbugs exclusions file can be used to list the spotbugs warnings that are being excluded and the classes, methods, and fields involved.\n\nA good example of the spotbugs exclusions file and its configuration is available from Jenkins core.\nSee the  source file for examples.\nThe exclus"
  },
  "123": {
    "source_file": "add-more-spotbugs-checks.txt",
    "text": "d.\n\nA good example of the spotbugs exclusions file and its configuration is available from Jenkins core.\nSee the  source file for examples.\nThe exclusions in the filter file are enabled automatically with recent versions so long as the exclusion file is named `src/spotbugs/excludesFilter.xml`.\n\nAn example excludes filter file is also included here:\n\n<?xml version=\"1.0\"?>\n<FindBugsFilter>\n  <!--\n  "
  },
  "124": {
    "source_file": "add-more-spotbugs-checks.txt",
    "text": " is named `src/spotbugs/excludesFilter.xml`.\n\nAn example excludes filter file is also included here:\n\n<?xml version=\"1.0\"?>\n<FindBugsFilter>\n  <!--\n    Exclusions in this section have been triaged and determined to be\n    false positives.\n  -->\n\n  <!--\n    Here lies technical debt. Exclusions in this section have not yet\n    been triaged. When working on this section, pick an exclusion to\n    tria"
  },
  "125": {
    "source_file": "add-more-spotbugs-checks.txt",
    "text": "--\n    Here lies technical debt. Exclusions in this section have not yet\n    been triaged. When working on this section, pick an exclusion to\n    triage, then:\n\n    - Add a @SuppressFBWarnings(value = \"[...]\", justification = \"[...]\")\n      annotation if it is a false positive.  Indicate the reason why\n      it is a false positive, then remove the exclusion from this\n      section.\n\n    - If it is"
  },
  "126": {
    "source_file": "add-more-spotbugs-checks.txt",
    "text": "n if it is a false positive.  Indicate the reason why\n      it is a false positive, then remove the exclusion from this\n      section.\n\n    - If it is not a false positive, fix the bug, then remove the\n      exclusion from this section.\n   -->\n  <Match>\n    <Or>\n      <And>\n        <Bug pattern=\"ES_COMPARING_PARAMETER_STRING_WITH_EQ\"/>\n        <Class name=\"io.jenkins.plugin.example.ExampleAction\"/"
  },
  "127": {
    "source_file": "add-more-spotbugs-checks.txt",
    "text": "ch>\n    <Or>\n      <And>\n        <Bug pattern=\"ES_COMPARING_PARAMETER_STRING_WITH_EQ\"/>\n        <Class name=\"io.jenkins.plugin.example.ExampleAction\"/>\n      </And>\n      <And>\n        <Bug pattern=\"DM_BOXED_PRIMITIVE_FOR_PARSING\"/>\n        <Class name=\"io.jenkins.plugin.example.SomeFeature\"/>\n      </And>\n    </Or>\n  </Match>\n</FindBugsFilter>\n\n// Compile the plugin\n\nConfirm that no spotbugs warn"
  },
  "128": {
    "source_file": "add-more-spotbugs-checks.txt",
    "text": "me=\"io.jenkins.plugin.example.SomeFeature\"/>\n      </And>\n    </Or>\n  </Match>\n</FindBugsFilter>\n\n// Compile the plugin\n\nConfirm that no spotbugs warnings are reported.\nIf spotbugs warnings are reported, resolve t\n\n// Create a pull request"
  },
  "129": {
    "source_file": "adding-tool-tips.txt",
    "text": "layout: redirect\nredirect_url: \"https://weekly.ci.jenkins.io/design-library/tooltips/\""
  },
  "130": {
    "source_file": "admin-password-reset-instructions.txt",
    "text": "layout: section\n\n\nAs a system administrator, you can reset the Jenkins admin password.\nIn case you have forgotten or lost the password, this page provides instructions on how you can reset the admin password.\n\nvideo::_VhOMyWDIcY[youtube, width=640, height=360]\n\n1. Log in to your Jenkins controller.\n2. Stop the Jenkins process.\nYou may use this command: `systemctl stop jenkins`.\n3. Edit the Jenkins"
  },
  "131": {
    "source_file": "admin-password-reset-instructions.txt",
    "text": "eight=360]\n\n1. Log in to your Jenkins controller.\n2. Stop the Jenkins process.\nYou may use this command: `systemctl stop jenkins`.\n3. Edit the Jenkins configuration file (`config.xml`) inside your `jenkins/` or `$JENKINS_HOME` directory.\n4. Look for **useSecurity** and change it from *true* to *false* manually.\n5. Save your file and close it.\n6. Restart the Jenkins service to apply your changes.\nY"
  },
  "132": {
    "source_file": "admin-password-reset-instructions.txt",
    "text": "**useSecurity** and change it from *true* to *false* manually.\n5. Save your file and close it.\n6. Restart the Jenkins service to apply your changes.\nYou may use this command: `systemctl start jenkins`.\nAfter restarting Jenkins, navigate to your controller and sign in.\n7. On the dashboard, select *Manage Jenkins* in the navigation pane on the left side of the page.\n8. On the *Manage Jenkins* page, "
  },
  "133": {
    "source_file": "admin-password-reset-instructions.txt",
    "text": "oller and sign in.\n7. On the dashboard, select *Manage Jenkins* in the navigation pane on the left side of the page.\n8. On the *Manage Jenkins* page, under the *Security* section, select *Configure Global Security*.\n9. Under *Security Realm*, select *Jenkins' own user database* from the dropdown menu.\nEnsure the option *Allow users to sign up* is unchecked and save your changes.\nThis redirects you"
  },
  "134": {
    "source_file": "admin-password-reset-instructions.txt",
    "text": "*Jenkins' own user database* from the dropdown menu.\nEnsure the option *Allow users to sign up* is unchecked and save your changes.\nThis redirects you to the Manage Jenkins page.\n10. On the **Manage Jenkins** page, select **Users**.\n11. You will see a list showing User IDs.\nSelect the User ID that you want to change the password for.\n12. Select Configure using the gear icon or the dropdown menu fr"
  },
  "135": {
    "source_file": "admin-password-reset-instructions.txt",
    "text": "a list showing User IDs.\nSelect the User ID that you want to change the password for.\n12. Select Configure using the gear icon or the dropdown menu from the User ID.\nLocate the *Password* section to change your password.\n\nAfter changing the password, you will be able to log into your Jenkins controller again using the same username and the new password that you have just set.\n\nNOTE: Please ensure "
  },
  "136": {
    "source_file": "admin-password-reset-instructions.txt",
    "text": " you will be able to log into your Jenkins controller again using the same username and the new password that you have just set.\n\nNOTE: Please ensure not to leave the Jenkins controller insecure.\nSo, please re-enable the security by following these steps.\n\n1. Log in as your admin account.\n2. On the dashboard, select *Manage Jenkins* in the navigation pane on the left side of the page.\n3. On the *M"
  },
  "137": {
    "source_file": "admin-password-reset-instructions.txt",
    "text": "teps.\n\n1. Log in as your admin account.\n2. On the dashboard, select *Manage Jenkins* in the navigation pane on the left side of the page.\n3. On the *Manage Jenkins* page, under the *Security* section, select *Configure Global Security*.\n4. Set the *Authorization* to *Logged-in users can do anything*.\nUncheck the option *Allow anonymous read access*.\nSelect *Save*."
  },
  "138": {
    "source_file": "admin-password-reset-instructions.txt",
    "text": "uthorization* to *Logged-in users can do anything*.\nUncheck the option *Allow anonymous read access*.\nSelect *Save*."
  },
  "139": {
    "source_file": "administering-jenkins-on-kubernetes.txt",
    "text": "layout: section\nwip: true"
  },
  "140": {
    "source_file": "adopt-a-plugin.txt",
    "text": "layout: developersection\ntitle: Adopt a Plugin\nreferences:\n- url: ../managing-permissions\n  title: Managing plugin permissions\n\n\nWe're looking for new maintainers of existing plugins!\n\nThis page addresses cases when there is no active maintainer of a plugin:\n\n* **Adopting plugins marked for adoption.**\n  Plugin maintainers can mark plugins for adoption if they do not plan to maintain their plugins"
  },
  "141": {
    "source_file": "adopt-a-plugin.txt",
    "text": " plugin:\n\n* **Adopting plugins marked for adoption.**\n  Plugin maintainers can mark plugins for adoption if they do not plan to maintain their plugins anymore.\n  In such case we have a low-barrier process for taking over plugins.\n* **Adopting abandoned plugins.**\n  Sometimes plugin maintainers move on without marking plugins for adoption, due to various reasons.\n  In such case we can transfer owne"
  },
  "142": {
    "source_file": "adopt-a-plugin.txt",
    "text": "ed plugins.**\n  Sometimes plugin maintainers move on without marking plugins for adoption, due to various reasons.\n  In such case we can transfer ownership for plugins being hosted within the `jenkinsci` GitHub organization.\n  Such transfer may take a while. If a plugin has no maintainers listed then it follows the adoption process.\n\nThe procedure is two-fold:\n\n**Announce your adoption intention b"
  },
  "143": {
    "source_file": "adopt-a-plugin.txt",
    "text": "a while. If a plugin has no maintainers listed then it follows the adoption process.\n\nThe procedure is two-fold:\n\n**Announce your adoption intention by mail**\n\nSend the notification email to the https://groups.google.com/g/jenkinsci-dev[Jenkins Developers mailing list].\nBe sure to provide the following information:\n\n* Link to a plugin you want to adopt\n* The status of the plugin (`for adoption` or"
  },
  "144": {
    "source_file": "adopt-a-plugin.txt",
    "text": "opers mailing list].\nBe sure to provide the following information:\n\n* Link to a plugin you want to adopt\n* The status of the plugin (`for adoption` or `abandoned`)\n* Link(s) to pull requests you want to deliver, if applicable\n* Your GitHub username/id (e.g. oleg-nenashev for https://github.com/oleg-nenashev/)\n* Your Jenkins infrastructure account id.  if you don't have one.\n* The link to the \"Repo"
  },
  "145": {
    "source_file": "adopt-a-plugin.txt",
    "text": "d (e.g. oleg-nenashev for https://github.com/oleg-nenashev/)\n* Your Jenkins infrastructure account id.  if you don't have one.\n* The link to the \"Repository Permission Updater\" PR described below\n\nAn example request can look like this:\n\nHi,\nI would like to adopt a plugin:\n\n    Link: https://github.com/jenkinsci/<REPO>\n    Pull requests (optional): https://github.com/jenkinsci/<REPO>/pull/42\n    St"
  },
  "146": {
    "source_file": "adopt-a-plugin.txt",
    "text": "ike to adopt a plugin:\n\n    Link: https://github.com/jenkinsci/<REPO>\n    Pull requests (optional): https://github.com/jenkinsci/<REPO>/pull/42\n    Status: for adoption\n    GitHub Username: <YOUR GitHub USERNAME>\n    Jenkins Infrastructure ID: <YOUR Jenkins Infra ID>\n    Repository Permission Updater PR: https://github.com/jenkins-infra/repository-permissions-updater/pull/3758\n\n<Describe briefly w"
  },
  "147": {
    "source_file": "adopt-a-plugin.txt",
    "text": "Jenkins Infra ID>\n    Repository Permission Updater PR: https://github.com/jenkins-infra/repository-permissions-updater/pull/3758\n\n<Describe briefly what you plan to do>\n\nBest regards,\n\n**Submit a PR on the \"Repository Permission Updater\" repository**\n\nFile a pull request against  (RPU) to be able to deploy releases for your plugin.\nYou need to update the plugin's definition yaml file located in t"
  },
  "148": {
    "source_file": "adopt-a-plugin.txt",
    "text": "*\n\nFile a pull request against  (RPU) to be able to deploy releases for your plugin.\nYou need to update the plugin's definition yaml file located in the `permission` directory.\nAdd your Jenkins infrastructure account under the `developer` section.\nRefer to the  for detailed guidance.\n\nPing the current registered developers on the PR to inform them of your initiative (just in case they miss the not"
  },
  "149": {
    "source_file": "adopt-a-plugin.txt",
    "text": "fer to the  for detailed guidance.\n\nPing the current registered developers on the PR to inform them of your initiative (just in case they miss the notification on the Jenkins Dev List).\n\nOnce you have access to the plugin's GitHub repository, be sure to remove the `+adopt-this-plugin+` label.\nThis can be done by clicking on the gear wheel near the \"About\":\n\n**Note**: Membership of the `jenkinsci` "
  },
  "150": {
    "source_file": "adopt-a-plugin.txt",
    "text": " to remove the `+adopt-this-plugin+` label.\nThis can be done by clicking on the gear wheel near the \"About\":\n\n**Note**: Membership of the `jenkinsci` github organization is required.\nIf this is not the case yet, you will receive an invitation sent to your GitHub email account.\nYou can also accept it at https://github.com/jenkinsci if you can't find the invite.\nNote that the invitation is valid for"
  },
  "151": {
    "source_file": "adopt-a-plugin.txt",
    "text": " your GitHub email account.\nYou can also accept it at https://github.com/jenkinsci if you can't find the invite.\nNote that the invitation is valid for 7 days only.\n\nIf you need a new invitation because you missed it,\nreplying on the RPU pull request is the easiest way.\nYou can also create an  or email the .\n\nFor abandoned plugins, you are expected to try and reach out to existing maintainer(s) usi"
  },
  "152": {
    "source_file": "adopt-a-plugin.txt",
    "text": "is the easiest way.\nYou can also create an  or email the .\n\nFor abandoned plugins, you are expected to try and reach out to existing maintainer(s) using a best effort.\nThe typical way to do that is to ping in GitHub and to add her/his/their email addresses in CC (hint: Git commits should have this information).\nWe typically wait for about 2 weeks in normal work periods before proceeding, so please"
  },
  "153": {
    "source_file": "adopt-a-plugin.txt",
    "text": "resses in CC (hint: Git commits should have this information).\nWe typically wait for about 2 weeks in normal work periods before proceeding, so please be patient.\nHence, if you can prove the existing maintainer already agrees, and you explicitly asked about taking over (e.g. in a PR discussion), the process can be faster.\n\nOnce the situation is clarified, proceed as for an \"adoptable\" plugins (see"
  },
  "154": {
    "source_file": "adopt-a-plugin.txt",
    "text": "d about taking over (e.g. in a PR discussion), the process can be faster.\n\nOnce the situation is clarified, proceed as for an \"adoptable\" plugins (see above).\nOn the notification email, add information about the steps taken to contact the existing maintainers.\n\nIf there are no maintainers listed in the \"Repository Permission Updater\" repository then there is no need to wait 2 weeks and it can proc"
  },
  "155": {
    "source_file": "adopt-a-plugin.txt",
    "text": "intainers.\n\nIf there are no maintainers listed in the \"Repository Permission Updater\" repository then there is no need to wait 2 weeks and it can proceed immediately.\n\n*No.* Jenkins is designed with backward compatibility in mind, so it's rare that a plugin stops working.\nAnd even then there's often someone who can fix the bug and release a new version even if they wouldn't be considered a maintai"
  },
  "156": {
    "source_file": "adopt-a-plugin.txt",
    "text": " plugin stops working.\nAnd even then there's often someone who can fix the bug and release a new version even if they wouldn't be considered a maintainer of the plugin.\nSo if you're happy with what a plugin is offering, there's no reason not to use it just because it's up for adoption.\n\nCheck out the list of plugins up for adoption at the bottom of this page.\nIf you see a plugin you like, visit it"
  },
  "157": {
    "source_file": "adopt-a-plugin.txt",
    "text": "t just because it's up for adoption.\n\nCheck out the list of plugins up for adoption at the bottom of this page.\nIf you see a plugin you like, visit its wiki page as it may contain additional information about the adoption request.\n\nOnce you've chosen a plugin, review the documentation on plugin maintainership in the Jenkins project.\nThis is especially important if you're not currently a plugin dev"
  },
  "158": {
    "source_file": "adopt-a-plugin.txt",
    "text": " a plugin, review the documentation on plugin maintainership in the Jenkins project.\nThis is especially important if you're not currently a plugin developer.\n\nFirst, *make sure the plugin is not being actively maintained*.\nEven in actively maintained plugins, there may be periods of lower developer activity.\nDon't misinterpret failures to respond to questions or requests as the plugin being unmain"
  },
  "159": {
    "source_file": "adopt-a-plugin.txt",
    "text": " plugins, there may be periods of lower developer activity.\nDon't misinterpret failures to respond to questions or requests as the plugin being unmaintained!\n\nAs a new maintainer of a new plugin, you'll inherit its existing users, so be careful with breaking changes.\n, so any new releases should remain compatible with previous data and upgrade smoothly.\nIf you need help with this, don't hesitate t"
  },
  "160": {
    "source_file": "adopt-a-plugin.txt",
    "text": "breaking changes.\n, so any new releases should remain compatible with previous data and upgrade smoothly.\nIf you need help with this, don't hesitate to ask other Jenkins developers for help.\nAnd if all else fails,\n to warn users before they update.\n\nBefore marking a plugin for adoption,\nwe recommend to announce the incoming change in the  or in other appropriate channels.\nIt may help you find new "
  },
  "161": {
    "source_file": "adopt-a-plugin.txt",
    "text": "Before marking a plugin for adoption,\nwe recommend to announce the incoming change in the  or in other appropriate channels.\nIt may help you find new maintainers and, ideally, to establish a transition and knowledge transfer process.\n\nAdd the `+adopt-this-plugin+` label to the plugin. A plugin is marked for adoption in one of two ways:\n** Put an `+adopt-this-plugin+` topic in the plugin's GitHub r"
  },
  "162": {
    "source_file": "adopt-a-plugin.txt",
    "text": "-this-plugin+` label to the plugin. A plugin is marked for adoption in one of two ways:\n** Put an `+adopt-this-plugin+` topic in the plugin's GitHub repository.\n   If multiple plugins are maintained inside a single repository, the repository topic marks all of them for adoption.\n   This is the preferred method because the maintainer directly controls the topics assigned to the plugin repository\n**"
  },
  "163": {
    "source_file": "adopt-a-plugin.txt",
    "text": "rks all of them for adoption.\n   This is the preferred method because the maintainer directly controls the topics assigned to the plugin repository\n** Add an `+adopt-this-plugin+` label to the plugin entry in the Update Center's  file\n   If multiple plugins are maintained inside a single repository, an update center entry can mark a subset of the plugins for adoption.\n   This is not the preferred "
  },
  "164": {
    "source_file": "adopt-a-plugin.txt",
    "text": "plugins are maintained inside a single repository, an update center entry can mark a subset of the plugins for adoption.\n   This is not the preferred method because the maintainer does not directly control the Update Center file\nOptional: If you want to explain why you're marking that plugin as up for adoption,\n  add a section to the plugin's documentation.\n  You can also document your vision for "
  },
  "165": {
    "source_file": "adopt-a-plugin.txt",
    "text": " to explain why you're marking that plugin as up for adoption,\n  add a section to the plugin's documentation.\n  You can also document your vision for the plugin there so that new maintainers can take it into account.\n\nThis status is based on the `+adopt-this-plugin+` or `+jenkins-adopt-this-plugin+` label in the update center.\nSuch labels can come from the topics in the plugin's GitHub repository "
  },
  "166": {
    "source_file": "adopt-a-plugin.txt",
    "text": "opt-this-plugin+` or `+jenkins-adopt-this-plugin+` label in the update center.\nSuch labels can come from the topics in the plugin's GitHub repository or from\nthe Update Center's  file.\nIf you remove these topics/labels, the adoption notice will disappear after the repo synchronization.\n\nSee the list of plugin pages with the `+adopt-this-plugin+` label.\n\n*"
  },
  "167": {
    "source_file": "adopt-a-plugin.txt",
    "text": "pear after the repo synchronization.\n\nSee the list of plugin pages with the `+adopt-this-plugin+` label.\n\n*"
  },
  "168": {
    "source_file": "advanced-installation.txt",
    "text": "layout: redirect\nredirect_url: /doc/book/installing/"
  },
  "169": {
    "source_file": "advanced-localization.txt",
    "text": "title: Advanced Localization\nlayout: developersection\nreferences:\n- url: https://docs.oracle.com/javase/8/docs/api/java/text/MessageFormat.html\n  title: Javadoc for <tt>java.text.MessageFormat</tt>\n- url: https://docs.oracle.com/javase/8/docs/api/java/text/ChoiceFormat.html\n  title: Javadoc for <tt>java.text.ChoiceFormat</tt>\n- url: https://docs.oracle.com/javase/8/docs/api/java/text/SimpleDateFor"
  },
  "170": {
    "source_file": "advanced-localization.txt",
    "text": "a/text/ChoiceFormat.html\n  title: Javadoc for <tt>java.text.ChoiceFormat</tt>\n- url: https://docs.oracle.com/javase/8/docs/api/java/text/SimpleDateFormat.html\n  title: Javadoc for <tt>java.text.SimpleDateFormat</tt> explaining custom date format definitions\n\n\nPlaceholders in localized strings can support a range of flexible formatting options besides the basic `+{0}+` etc. that inserts the string "
  },
  "171": {
    "source_file": "advanced-localization.txt",
    "text": "nitions\n\n\nPlaceholders in localized strings can support a range of flexible formatting options besides the basic `+{0}+` etc. that inserts the string representation of whatever object is passed as argument.\n\nThis page provides an overview of the supported message formats.\nThe javadoc:java.text.MessageFormat[`MessageFormat` Javadoc] provides more details.\n\nIf numbers are passed as argument, they ar"
  },
  "172": {
    "source_file": "advanced-localization.txt",
    "text": "orted message formats.\nThe javadoc:java.text.MessageFormat[`MessageFormat` Javadoc] provides more details.\n\nIf numbers are passed as argument, they are typically printed without localized formatting.\n\nTo add locale-specific formatting, use the `number` format pattern:\n\n{0,number}          // <1> {0,number,integer}  // <2> {0,number,currency} // <3> {0,number,percent}  // <4> {0,number,0.###E0}  //"
  },
  "173": {
    "source_file": "advanced-localization.txt",
    "text": "r` format pattern:\n\n{0,number}          // <1> {0,number,integer}  // <2> {0,number,currency} // <3> {0,number,percent}  // <4> {0,number,0.###E0}  // <5> <1> Show a localized number, for example `1,234.56` (en_US), `1.234,56` (de_DE), or `1'234.5` (de_CH)\n<2> Number rounded to the nearest integer, e.g. `1,235` (en_US) or  `1.235` (de_DE)\n<3> Show as currency\n<4> Percentage, e.g. `0.12` could be f"
  },
  "174": {
    "source_file": "advanced-localization.txt",
    "text": "de_CH)\n<2> Number rounded to the nearest integer, e.g. `1,235` (en_US) or  `1.235` (de_DE)\n<3> Show as currency\n<4> Percentage, e.g. `0.12` could be formatted to `12%`\n<5> Arbitrary pattern can be defined as third argument as described on the javadoc:java.text.DecimalFormat[`DecimalFormat` Javadoc].\nThis example defines scientific notation, so `1234` would be shown as `1.234E3`.\n\nThis pattern is u"
  },
  "175": {
    "source_file": "advanced-localization.txt",
    "text": ":java.text.DecimalFormat[`DecimalFormat` Javadoc].\nThis example defines scientific notation, so `1234` would be shown as `1.234E3`.\n\nThis pattern is useful when the translation of a term depends on the value of a number.\nExample:\n\n{0,choice,0#No projects were|1#A project was|2<{0,number,integer} projects were} found.\n\nIn this example, the output depends on the value of the first parameter (index `"
  },
  "176": {
    "source_file": "advanced-localization.txt",
    "text": "ects were|1#A project was|2<{0,number,integer} projects were} found.\n\nIn this example, the output depends on the value of the first parameter (index `0`):\n\n- If it's zero, *No projects were found* is printed.\n- If it's one, *A project was found* is printed.\n- If it's two or more, *`N` projects were found* is printed, `N` being the localized representation of the parameter value.\n\nThis demonstrates"
  },
  "177": {
    "source_file": "advanced-localization.txt",
    "text": "rinted.\n- If it's two or more, *`N` projects were found* is printed, `N` being the localized representation of the parameter value.\n\nThis demonstrates that patterns can be nested, the localized `number` is nested inside the `choice` pattern.\n\nDate and time patterns can be used to display `Date` instances appropriate for the user's locale.\n\nThese either use the predefined date and time styles (`sho"
  },
  "178": {
    "source_file": "advanced-localization.txt",
    "text": "d time patterns can be used to display `Date` instances appropriate for the user's locale.\n\nThese either use the predefined date and time styles (`short`, `medium`, `long`, and `full`), or a custom format for the javadoc:java.text.SimpleDateFormat[`SimpleDateFormat`] class.\n\n{0,date}            // <1> {0,date,short}\n{0,date,medium}\n{0,date,long}\n{0,date,full}\n{0,date,yyyy-mm-dd} // <2> {0,time}   "
  },
  "179": {
    "source_file": "advanced-localization.txt",
    "text": "impleDateFormat`] class.\n\n{0,date}            // <1> {0,date,short}\n{0,date,medium}\n{0,date,long}\n{0,date,full}\n{0,date,yyyy-mm-dd} // <2> {0,time}            // <3> {0,time,short}\n{0,time,medium}\n{0,time,long}\n{0,time,full}\n{0,time,HH:mm:ss}   // <4> <1> Default (medium) date format\n<2> Custom date format, in this case a date like 2017-02-27\n<3> Default (medium) time format\n<4> Custom time format"
  },
  "180": {
    "source_file": "advanced-localization.txt",
    "text": "> <1> Default (medium) date format\n<2> Custom date format, in this case a date like 2017-02-27\n<3> Default (medium) time format\n<4> Custom time format, in this case a time like 17:45:32"
  },
  "181": {
    "source_file": "agent-to-controller.txt",
    "text": "title: Customizing Agent &rarr; Controller Security\nlayout: documentation\n\n\nifdef::env-github[:imagesdir: ../../resources]\nifndef::env-github[:imagesdir: ../../../resources]\n\nThis section describes how to customize the rules restricting agents' access to the Jenkins controller in Jenkins 2.325 and earlier.\n\n// TODO Also mention first LTS once it's known\nNOTE: In Jenkins 2.326, the ability to disab"
  },
  "182": {
    "source_file": "agent-to-controller.txt",
    "text": "s to the Jenkins controller in Jenkins 2.325 and earlier.\n\n// TODO Also mention first LTS once it's known\nNOTE: In Jenkins 2.326, the ability to disable or customize the agent-to-controller security system has been removed without replacement.\nThis documentation applies only to older releases of Jenkins.\nFor documentation specific to the change in Jenkins 2.326, see .\n\nSophisticated administrators"
  },
  "183": {
    "source_file": "agent-to-controller.txt",
    "text": "ocumentation applies only to older releases of Jenkins.\nFor documentation specific to the change in Jenkins 2.326, see .\n\nSophisticated administrators can use the built-in access control rules to create specific exemptions for certain access patterns from the agents to the Jenkins controller.\nThis should only be necessary when trying to run plugins that have not yet been adapted to be compatible.\n"
  },
  "184": {
    "source_file": "agent-to-controller.txt",
    "text": " from the agents to the Jenkins controller.\nThis should only be necessary when trying to run plugins that have not yet been adapted to be compatible.\n\nNOTE: For an introduction about the Agent &rarr; Controller Security system, see .\n\nBy following the link highlighted above, an administrator may edit *Commands* and *File Access* agent-to-controller access control rules.\n\n\"Commands\" in Jenkins and "
  },
  "185": {
    "source_file": "agent-to-controller.txt",
    "text": "e link highlighted above, an administrator may edit *Commands* and *File Access* agent-to-controller access control rules.\n\n\"Commands\" in Jenkins and its plugins are identified by their fully-qualified class names.\nThe majority of these commands are intended to be executed on agents by a request of a controller, but some of them are intended to be executed on a controller by a request of an agent."
  },
  "186": {
    "source_file": "agent-to-controller.txt",
    "text": "intended to be executed on agents by a request of a controller, but some of them are intended to be executed on a controller by a request of an agent.\n\nPlugins not yet updated for this subsystem may not classify which category each command falls into, such that when an agent requests that the controller execute a command which is not explicitly allowed, Jenkins will err on the side of caution and "
  },
  "187": {
    "source_file": "agent-to-controller.txt",
    "text": ", such that when an agent requests that the controller execute a command which is not explicitly allowed, Jenkins will err on the side of caution and refuse to execute the command.\n\nIn such cases, Jenkins administrators may allow certain commands as acceptable for execution on the controller.\n\n// TODO Terminology: Update image and label\n\nAdministrators may also allow classes by creating files with"
  },
  "188": {
    "source_file": "agent-to-controller.txt",
    "text": "acceptable for execution on the controller.\n\n// TODO Terminology: Update image and label\n\nAdministrators may also allow classes by creating files with the `.conf` extension in the directory `JENKINS_HOME/secrets/whitelisted-callables.d/`.\nThe contents of these `.conf` files should list command names on separate lines.\n\nThe contents of all the `.conf` files in the directory will be read by Jenkins "
  },
  "189": {
    "source_file": "agent-to-controller.txt",
    "text": "s of these `.conf` files should list command names on separate lines.\n\nThe contents of all the `.conf` files in the directory will be read by Jenkins and combined to create a `default.conf` file in the directory which lists all known safe commands.\nThe `default.conf` file will be re-written each time Jenkins boots.\n\nJenkins also manages a file named `gui.conf`, in the `whitelisted-callables.d` dir"
  },
  "190": {
    "source_file": "agent-to-controller.txt",
    "text": "he `default.conf` file will be re-written each time Jenkins boots.\n\nJenkins also manages a file named `gui.conf`, in the `whitelisted-callables.d` directory, where commands added via the web UI are written.\nIn order to disable the ability of administrators to change whitelisted commands from the web UI, place an empty `gui.conf` file in the directory and change its permissions such that is not wri"
  },
  "191": {
    "source_file": "agent-to-controller.txt",
    "text": "rators to change whitelisted commands from the web UI, place an empty `gui.conf` file in the directory and change its permissions such that is not writeable by the operating system user Jenkins run as.\n\nThe File Access Rules are used to validate file access requests made from agents to the controller.\nEach File Access Rule is a triplet which must contain each of the following elements:\n\n`allow` / "
  },
  "192": {
    "source_file": "agent-to-controller.txt",
    "text": " access requests made from agents to the controller.\nEach File Access Rule is a triplet which must contain each of the following elements:\n\n`allow` / `deny`: if the following two parameters match the current request being considered, an `allow` entry would allow the request to be carried out and a `deny` entry would deny the request to be rejected, regardless of what later rules might say.\n_operat"
  },
  "193": {
    "source_file": "agent-to-controller.txt",
    "text": " would allow the request to be carried out and a `deny` entry would deny the request to be rejected, regardless of what later rules might say.\n_operation_: Type of the operation requested.\n  The following 6 values exist.\n  The operations can also be combined by comma-separating the values.\n  The value of `all` indicates all the listed operations are allowed or denied.\n** `read`: read file content "
  },
  "194": {
    "source_file": "agent-to-controller.txt",
    "text": "combined by comma-separating the values.\n  The value of `all` indicates all the listed operations are allowed or denied.\n** `read`: read file content or list directory entries\n** `write`: write file content\n** `mkdirs`: create a new directory\n** `create`: create a file in an existing directory\n** `delete`: delete a file or directory\n** `stat`: read metadata of a file/directory, such as timestamp, "
  },
  "195": {
    "source_file": "agent-to-controller.txt",
    "text": "ate`: create a file in an existing directory\n** `delete`: delete a file or directory\n** `stat`: read metadata of a file/directory, such as timestamp, length, file access modes.\n_file path_: regular expression that specifies file paths that matches this rule.\n  In addition to the base regexp syntax, it supports the following tokens:\n** `<JENKINS_HOME>` can be used as a prefix to match the controlle"
  },
  "196": {
    "source_file": "agent-to-controller.txt",
    "text": "is rule.\n  In addition to the base regexp syntax, it supports the following tokens:\n** `<JENKINS_HOME>` can be used as a prefix to match the controller's `JENKINS_HOME` directory.\n** `<BUILDDIR>` can be used as a prefix to match the build record directory, such as `/var/lib/jenkins/job/foo/builds/12345`.\n** `<BUILDID>` matches the timestamp-formatted build IDs, like `12345`.\n\nThe rules are ordered"
  },
  "197": {
    "source_file": "agent-to-controller.txt",
    "text": "ctory, such as `/var/lib/jenkins/job/foo/builds/12345`.\n** `<BUILDID>` matches the timestamp-formatted build IDs, like `12345`.\n\nThe rules are ordered, and applied in that order.\nThe earliest match wins.\nFor example, the following rules allow access to all files in `JENKINS_HOME` except the `secrets` folders:\n\n# To avoid hassle of escaping every '\\' on Windows, you can use / even on Windows.\ndeny "
  },
  "198": {
    "source_file": "agent-to-controller.txt",
    "text": "to all files in `JENKINS_HOME` except the `secrets` folders:\n\n# To avoid hassle of escaping every '\\' on Windows, you can use / even on Windows.\ndeny all <JENKINS_HOME>/secrets/.*\nallow all <JENKINS_HOME>/.*\n\nOrdering is very important! The following rules are incorrectly written because the second rule will never match, and allow all agents to access all files and folders under `JENKINS_HOME`:\n\na"
  },
  "199": {
    "source_file": "agent-to-controller.txt",
    "text": " rules are incorrectly written because the second rule will never match, and allow all agents to access all files and folders under `JENKINS_HOME`:\n\nallow all <JENKINS_HOME>/.*\ndeny all <JENKINS_HOME>/secrets/.*\n\nAdministrators may also add File Access Rules by creating files with the `.conf.` extension in the directory `JENKINS_HOME/secrets/filepath-filters.d/`.\nJenkins itself generates the `30-d"
  },
  "200": {
    "source_file": "agent-to-controller.txt",
    "text": "ss Rules by creating files with the `.conf.` extension in the directory `JENKINS_HOME/secrets/filepath-filters.d/`.\nJenkins itself generates the `30-default.conf` file on boot in this directory which contains defaults considered the best balance between compatibility and security by the Jenkins project.\nIn order to disable these built-in defaults, replace `30-default.conf` with an empty file which"
  },
  "201": {
    "source_file": "agent-to-controller.txt",
    "text": "een compatibility and security by the Jenkins project.\nIn order to disable these built-in defaults, replace `30-default.conf` with an empty file which is not writable by the operating system user Jenkins run as.\n\nOn each startup, Jenkins will read all `.conf` files in the `filepath-filters.d` directory in alphabetical order, therefore it is good practice to name files in a manner which indicates t"
  },
  "202": {
    "source_file": "agent-to-controller.txt",
    "text": "l `.conf` files in the `filepath-filters.d` directory in alphabetical order, therefore it is good practice to name files in a manner which indicates their load order.\n\nJenkins also manages `50-gui.conf`, in the `filepath-filters/` directory, where File Access Rules added via the web UI are written.\nIn order to disable the ability of administrators to change the File Access Rules from the web UI, p"
  },
  "203": {
    "source_file": "agent-to-controller.txt",
    "text": "le Access Rules added via the web UI are written.\nIn order to disable the ability of administrators to change the File Access Rules from the web UI, place an empty `50-gui.conf` file in the directory and change its permissions such that is not writeable by the operating system user Jenkins run as.\n\nWhile it is not recommended, if all agents in a Jenkins environment can be considered \"trusted\" to t"
  },
  "204": {
    "source_file": "agent-to-controller.txt",
    "text": "ble by the operating system user Jenkins run as.\n\nWhile it is not recommended, if all agents in a Jenkins environment can be considered \"trusted\" to the same degree that the controller is trusted, the Agent/Master Access Control feature may be disabled.\n\nAdditionally, all the users in the Jenkins environment should have the same level of access to all configured projects.\n\nAn administrator can dis"
  },
  "205": {
    "source_file": "agent-to-controller.txt",
    "text": "ed.\n\nAdditionally, all the users in the Jenkins environment should have the same level of access to all configured projects.\n\nAn administrator can disable Agent to Controller Access Control in the web UI by un-checking the box on the *Security* page.\nAlternatively an administrator may create a file in `JENKINS_HOME/secrets` named `slave-to-master-security-kill-switch` with the contents of `true` a"
  },
  "206": {
    "source_file": "agent-to-controller.txt",
    "text": "\nAlternatively an administrator may create a file in `JENKINS_HOME/secrets` named `slave-to-master-security-kill-switch` with the contents of `true` and restart Jenkins.\n\n[CAUTION]\n\nMost Jenkins environments grow over time requiring their trust models to evolve as the environment grows.\nPlease consider scheduling regular \"check-ups\" to review whether any disabled security settings should be re-ena"
  },
  "207": {
    "source_file": "agent-to-controller.txt",
    "text": "s to evolve as the environment grows.\nPlease consider scheduling regular \"check-ups\" to review whether any disabled security settings should be re-enabled."
  },
  "208": {
    "source_file": "agents.txt",
    "text": "layout: documentation\ntitle: Defining execution environments\n\n\nIn the\n\nyou may have noticed the `agent` directive in each of the examples. The\n`agent` directive tells Jenkins where and how to execute the Pipeline, or\nsubset thereof. As you might expect, the `agent` is required for all Pipelines.\n\nUnderneath the hood, there are a few things `agent` causes to happen:\n\n* All the steps contained withi"
  },
  "209": {
    "source_file": "agents.txt",
    "text": "ct, the `agent` is required for all Pipelines.\n\nUnderneath the hood, there are a few things `agent` causes to happen:\n\n* All the steps contained within the block are queued for execution by Jenkins.\n  As soon as an <<../../book/glossary/#executor, executor>> is available, the\n  steps will begin to execute.\n* A <<../../book/glossary/#workspace, workspace>> is allocated which will\n  contain files ch"
  },
  "210": {
    "source_file": "agents.txt",
    "text": "ecutor>> is available, the\n  steps will begin to execute.\n* A <<../../book/glossary/#workspace, workspace>> is allocated which will\n  contain files checked out from source control as well as any additional\n  working files for the Pipeline.\n\nThere are several\n\nfor use in Pipeline, for this tour we will only focus on using an ephemeral\nDocker container.\n\nPipeline is designed to easily use\n\nimages an"
  },
  "211": {
    "source_file": "agents.txt",
    "text": " several\n\nfor use in Pipeline, for this tour we will only focus on using an ephemeral\nDocker container.\n\nPipeline is designed to easily use\n\nimages and containers to\nrun inside. This allows the Pipeline to define the environment\nand tools required without having to configure various system tools\nand dependencies on agents manually. This approach allows you to use\npractically any tool which can be\n"
  },
  "212": {
    "source_file": "agents.txt",
    "text": "thout having to configure various system tools\nand dependencies on agents manually. This approach allows you to use\npractically any tool which can be\nFor more agent specification options, consult the\n[pipeline]\n\n// Declarative //\npipeline {\n    agent {\n        docker { image 'node:24.11.1-alpine3.22' }\n    }\n    stages {\n        stage('Test') {\n            steps {\n                sh 'node --eval \""
  },
  "213": {
    "source_file": "agents.txt",
    "text": " {\n        docker { image 'node:24.11.1-alpine3.22' }\n    }\n    stages {\n        stage('Test') {\n            steps {\n                sh 'node --eval \"console.log(process.arch,process.platform)\"'\n            }\n        }\n    }\n}\n// Script //\nnode {\n    /* Requires the Docker Pipeline plugin to be installed */\n    docker.image('node:24.11.1-alpine3.22').inside {\n        stage('Test') {\n            sh"
  },
  "214": {
    "source_file": "agents.txt",
    "text": " /* Requires the Docker Pipeline plugin to be installed */\n    docker.image('node:24.11.1-alpine3.22').inside {\n        stage('Test') {\n            sh 'node --eval \"console.log(process.arch,process.platform)\"'\n        }\n    }\n}\n\nWhen the Pipeline executes, Jenkins will automatically start the specified\ncontainer and execute the defined steps within it:\n\n[Pipeline] stage\n[Pipeline] { (Test)\n[Pipeli"
  },
  "215": {
    "source_file": "agents.txt",
    "text": "cutes, Jenkins will automatically start the specified\ncontainer and execute the defined steps within it:\n\n[Pipeline] stage\n[Pipeline] { (Test)\n[Pipeline] sh\n[guided-tour] Running shell script\nnode --eval 'console.log(process.platform,process.env.CI)'\nlinux true\n[Pipeline] }\n[Pipeline] // stage\n[Pipeline] }\n\nMixing and matching different containers, or other agents, allows quite a lot\nof flexibilit"
  },
  "216": {
    "source_file": "agents.txt",
    "text": "\nlinux true\n[Pipeline] }\n[Pipeline] // stage\n[Pipeline] }\n\nMixing and matching different containers, or other agents, allows quite a lot\nof flexibility when executing a Pipeline, for more configuration options,\n\n\n'''\n+++\n\n+++"
  },
  "217": {
    "source_file": "appendix.txt",
    "text": "layout: redirect\nredirect_url: /doc/book/installing/"
  },
  "218": {
    "source_file": "architecting-for-manageability.txt",
    "text": "layout: section\n\n\nWith over 2,000 plugins and countless versions of said plugins in the\nopen-source community, testing for all possible conflicts before upgrading one\nor more production Jenkins controllers is simply not feasible. While Jenkins\nitself will warn of potential incompatibility if it detects that a plugin\nrequires a newer version of the Jenkins core, there is no automatic way to\ndetect "
  },
  "219": {
    "source_file": "architecting-for-manageability.txt",
    "text": " will warn of potential incompatibility if it detects that a plugin\nrequires a newer version of the Jenkins core, there is no automatic way to\ndetect conflicts between plugins or to automatically quantify the impact of\nupgrading a plugin.\n\nJenkins administrators test plugin and core version updates before performing them on the production controller.\nThis kind of testing requires a copy or \"test d"
  },
  "220": {
    "source_file": "architecting-for-manageability.txt",
    "text": "ministrators test plugin and core version updates before performing them on the production controller.\nThis kind of testing requires a copy or \"test deployment\" of the production server to act as the sandbox for such tests.\nEffective upgrade testing can prevent production downtime.\n\nA test controller is a Jenkins controller used solely for testing configurations and\nplugins in a non-production env"
  },
  "221": {
    "source_file": "architecting-for-manageability.txt",
    "text": "can prevent production downtime.\n\nA test controller is a Jenkins controller used solely for testing configurations and\nplugins in a non-production environment.\nA test controller is highly recommended for organizations with a mission-critical Jenkins controller.\n\nUpgrading or downgrading either the Jenkins core or any plugins can sometimes\nhave the unintended side effect of crippling another plugin"
  },
  "222": {
    "source_file": "architecting-for-manageability.txt",
    "text": "controller.\n\nUpgrading or downgrading either the Jenkins core or any plugins can sometimes\nhave the unintended side effect of crippling another plugin's functionality or\neven crashing a controller. As of today, there is no better way to pre-test for\nsuch catastrophic conflicts than with a test controller.\n\nTest controllers should have identical configurations, jobs, and plugins as the\nproduction c"
  },
  "223": {
    "source_file": "architecting-for-manageability.txt",
    "text": "such catastrophic conflicts than with a test controller.\n\nTest controllers should have identical configurations, jobs, and plugins as the\nproduction controller so that test upgrades  will most closely resemble the\noutcomes of a similar change on your production controller. For example, installing\nthe Folders plugin while running a version of the Jenkins core older than\n1.554.1 will cause the contr"
  },
  "224": {
    "source_file": "architecting-for-manageability.txt",
    "text": " production controller. For example, installing\nthe Folders plugin while running a version of the Jenkins core older than\n1.554.1 will cause the controller crash and be inaccessible until the plugin is\nmanually uninstalled from the _plugin_ folder.\n\n[[setting-up-a-test-controller]]\n\nThere are many methods for setting up a test controller, but the commonality\nbetween them all is that the _$JENKINS_"
  },
  "225": {
    "source_file": "architecting-for-manageability.txt",
    "text": "[[setting-up-a-test-controller]]\n\nThere are many methods for setting up a test controller, but the commonality\nbetween them all is that the _$JENKINS_HOME_ between them is nearly identical.\nWhether this means that most all of the  _$JENKINS_HOME_\nfolders are version controlled in a service like GitHub and mounted manually or\nprogrammatically to a test server or Docker container, the result is near"
  },
  "226": {
    "source_file": "architecting-for-manageability.txt",
    "text": "ders are version controlled in a service like GitHub and mounted manually or\nprogrammatically to a test server or Docker container, the result is nearly the\nsame.\n\nIt is ideal to first ensure the controller is idle (no running or queued jobs)\nbefore attempting to create a test controller.\n\n*With GitHub + manual commands*\n\nYou will simply need to open up your command-line interface and \"cd\" to the\n"
  },
  "227": {
    "source_file": "architecting-for-manageability.txt",
    "text": "attempting to create a test controller.\n\n*With GitHub + manual commands*\n\nYou will simply need to open up your command-line interface and \"cd\" to the\nfolder that contains the _$JENKINS_HOME_ directory for your production controller\nand run the \"git init\" command. For the location of this folder, please refer\nto section 3.\n\nIt is recommended that before running the \"git add\" command that you create"
  },
  "228": {
    "source_file": "architecting-for-manageability.txt",
    "text": "nit\" command. For the location of this folder, please refer\nto section 3.\n\nIt is recommended that before running the \"git add\" command that you create a\ngood _.gitignore_ file. This file will prevent you from accidentally\nversion-controlling large binary files.\n\nHere is an example _.gitignore_ file for a Jenkins controller running on OS X:\n\n.DS_Store\n.AppleDouble\n.LSOverride\nIcon\n._*\n.Spotlight-V1"
  },
  "229": {
    "source_file": "architecting-for-manageability.txt",
    "text": "nary files.\n\nHere is an example _.gitignore_ file for a Jenkins controller running on OS X:\n\n.DS_Store\n.AppleDouble\n.LSOverride\nIcon\n._*\n.Spotlight-V100\n.Trashes\n.AppleDB\n.AppleDesktop\nNetwork Trash Folder\nTemporary Items\n.apdisk\n*.log\n*.tmp\n*.old\n*.jar\n*.son\n.Xauthority\n.bash_history\n.bash_profile\n.fontconfig\n.gitconfig\n.gem\n.lesshst\n.mysql_history\n.owner\n.ri\n.rvm\n.ssh\n.viminfo\n.vnc\nbin/\ntools/\n*"
  },
  "230": {
    "source_file": "architecting-for-manageability.txt",
    "text": "jar\n*.son\n.Xauthority\n.bash_history\n.bash_profile\n.fontconfig\n.gitconfig\n.gem\n.lesshst\n.mysql_history\n.owner\n.ri\n.rvm\n.ssh\n.viminfo\n.vnc\nbin/\ntools/\n**/.owner\n**/queue.xml\n**/fingerprints/\n**/shelvedProjects/\n**/updates/\n**/jobs/*/workspace/\n**/war/\n/tools/\n**/custom_deps/\n**/cache/\n**/caches/\nfingerprints/\n*.log\n*.zip\n*.rrd\n*.gz\n\nOnce you have a good _.gitignore_ file, you can run the following g"
  },
  "231": {
    "source_file": "architecting-for-manageability.txt",
    "text": "/tools/\n**/custom_deps/\n**/cache/\n**/caches/\nfingerprints/\n*.log\n*.zip\n*.rrd\n*.gz\n\nOnce you have a good _.gitignore_ file, you can run the following git commands to\ncommit your _$JENKINS_HOME_ to a git repository like GitHub:\n\ngit add -\u2014all\ngit commit -m \"first commit\"\ngit push\n\nNow you can install Jenkins to a fresh deployment and \"git clone\" this\n_$JENKINS_HOME_ from the git repository to your n"
  },
  "232": {
    "source_file": "architecting-for-manageability.txt",
    "text": "t -m \"first commit\"\ngit push\n\nNow you can install Jenkins to a fresh deployment and \"git clone\" this\n_$JENKINS_HOME_ from the git repository to your new controller. You will need to\nreplace the files in the new controller with your version-controlled files to\ncomplete the migration, whether through scripts or through a drag-and-drop\nprocess.\n\nOnce this is done, you will need to restart the new tes"
  },
  "233": {
    "source_file": "architecting-for-manageability.txt",
    "text": " files to\ncomplete the migration, whether through scripts or through a drag-and-drop\nprocess.\n\nOnce this is done, you will need to restart the new test Jenkins\nservice or reload its configuration from the Jenkins UI (\"Manage Jenkins\" >>\n\"Reload Configuration\").\n\n*With GitHub + Docker (Linux-only)*\n\nWhen it comes to version controlling your $JENKINS_HOME, just follow the\ninstructions in the previou"
  },
  "234": {
    "source_file": "architecting-for-manageability.txt",
    "text": "guration\").\n\n*With GitHub + Docker (Linux-only)*\n\nWhen it comes to version controlling your $JENKINS_HOME, just follow the\ninstructions in the previous section.\n\nThe next step will be to create a Docker image with identical configurations to\nyour production deployment's - operating system (Linux-only), installed\nlibraries/tools, and open ports. This can be accomplished through Dockerfiles.\n\nYou wi"
  },
  "235": {
    "source_file": "architecting-for-manageability.txt",
    "text": "duction deployment's - operating system (Linux-only), installed\nlibraries/tools, and open ports. This can be accomplished through Dockerfiles.\n\nYou will then just need to create mounted storage on your Docker server with a\nclone of your version-controlled _$JENKINS_HOME_ home and a simple image to\nclone the _$JENKINS_HOME_ into.\n\nFor example, we can create a Docker image called _jenkins-storage_ a"
  },
  "236": {
    "source_file": "architecting-for-manageability.txt",
    "text": "olled _$JENKINS_HOME_ home and a simple image to\nclone the _$JENKINS_HOME_ into.\n\nFor example, we can create a Docker image called _jenkins-storage_ and version\ncontrol our _$JENKINS_HOME_ in a Github repository known as \"demo-joc\". The\n\"jenkins-storage\" Docker image can be built from a Dockerfile similar to this:\n\nFROM eclipse-temurin:21-jdk-jammy\nSHELL [\"/bin/bash\", \"-o\", \"pipefail\", \"-c\"]\nRUN a"
  },
  "237": {
    "source_file": "architecting-for-manageability.txt",
    "text": "age\" Docker image can be built from a Dockerfile similar to this:\n\nFROM eclipse-temurin:21-jdk-jammy\nSHELL [\"/bin/bash\", \"-o\", \"pipefail\", \"-c\"]\nRUN apt-get update && \\\n    apt-get -y upgrade && \\\n    apt-get install -y --no-install-recommends \\\n    curl \\\n    git \\\n    git-lfs \\\n    gpg \\\n    less \\\n    maven \\\n    ntp \\\n    ntpdate \\\n    openssh-server \\\n    vim && \\\n    mkdir -p /etc/apt/keyrin"
  },
  "238": {
    "source_file": "architecting-for-manageability.txt",
    "text": "curl \\\n    git \\\n    git-lfs \\\n    gpg \\\n    less \\\n    maven \\\n    ntp \\\n    ntpdate \\\n    openssh-server \\\n    vim && \\\n    mkdir -p /etc/apt/keyrings && \\\n    curl -fsSL https://download.docker.com/linux/ubuntu/gpg | \\\n        gpg --dearmor -o /etc/apt/keyrings/docker.gpg && \\\n    echo \"deb [arch=amd64 signed-by=/etc/apt/keyrings/docker.gpg] \\\n        https://download.docker.com/linux/ubuntu ja"
  },
  "239": {
    "source_file": "architecting-for-manageability.txt",
    "text": "c/apt/keyrings/docker.gpg && \\\n    echo \"deb [arch=amd64 signed-by=/etc/apt/keyrings/docker.gpg] \\\n        https://download.docker.com/linux/ubuntu jammy stable\" \\\n        >> /etc/apt/sources.list.d/docker.list 2> /dev/null && \\\n    apt-get update && \\\n    apt-get install -y --no-install-recommends \\\n    containerd.io \\\n    docker-ce \\\n    docker-ce-cli \\\n    docker-compose-plugin && \\\n    apt-get"
  },
  "240": {
    "source_file": "architecting-for-manageability.txt",
    "text": " \\\n    apt-get install -y --no-install-recommends \\\n    containerd.io \\\n    docker-ce \\\n    docker-ce-cli \\\n    docker-compose-plugin && \\\n    apt-get clean && \\\n    rm -rf /var/lib/apt/lists/*\nRUN printf \"AddressFamily inet\" >> /etc/ssh/ssh_config\nENV MAVEN_HOME /usr/bin/mvn\nENV GIT_HOME /usr/bin/git\n# Create Jenkins user\nRUN useradd jenkins -d /home/jenkins\nRUN echo \"jenkins:jenkins\" | chpasswd\n"
  },
  "241": {
    "source_file": "architecting-for-manageability.txt",
    "text": "NV MAVEN_HOME /usr/bin/mvn\nENV GIT_HOME /usr/bin/git\n# Create Jenkins user\nRUN useradd jenkins -d /home/jenkins\nRUN echo \"jenkins:jenkins\" | chpasswd\n# Make directories for JENKINS_HOME, jenkins.war lib\n# and [agents] remote FS root, ssh privilege separation directory\nRUN mkdir /usr/lib/jenkins /var/lib/jenkins /home/jenkins /var/run/sshd\n# Set permissions\nRUN chown -R jenkins:jenkins /usr/lib/jen"
  },
  "242": {
    "source_file": "architecting-for-manageability.txt",
    "text": "paration directory\nRUN mkdir /usr/lib/jenkins /var/lib/jenkins /home/jenkins /var/run/sshd\n# Set permissions\nRUN chown -R jenkins:jenkins /usr/lib/jenkins /var/lib/jenkins /home/jenkins\n#create data folder for cloning\nRUN [\"mkdir\", \"/data\"]\nRUN [\"chown\", \"-R\", \"jenkins:jenkins\", \"/data\"]\nRUN usermod -a -G docker jenkins\nUSER jenkins\nVOLUME [\"/data\"]\nWORKDIR /data\n# USER jenkins\nCMD [\"git\", \"clone\""
  },
  "243": {
    "source_file": "architecting-for-manageability.txt",
    "text": "wn\", \"-R\", \"jenkins:jenkins\", \"/data\"]\nRUN usermod -a -G docker jenkins\nUSER jenkins\nVOLUME [\"/data\"]\nWORKDIR /data\n# USER jenkins\nCMD [\"git\", \"clone\", \"https://github.com/MarkEWaite/docker-jenkins-storage.git\", \".\"]\n\nCreating mounted storage for containers would just require something similar to\nthe following command:\n\ndocker run \\\n    --name storage \\\n    [your-dockerhub-id]/jenkins-storage \\\n  "
  },
  "244": {
    "source_file": "architecting-for-manageability.txt",
    "text": "tainers would just require something similar to\nthe following command:\n\ndocker run \\\n    --name storage \\\n    [your-dockerhub-id]/jenkins-storage \\\n    git clone https://github.com/[your-github-id]/docker-jenkins-storage.git .\n\nAnd Jenkins images that rely on the mounted storage for their _$JENKINS_HOME_\nwill then need to point to the mounted volume:\n\ndocker run -d \\\n       --dns=172.17.42.1 \\\n   "
  },
  "245": {
    "source_file": "architecting-for-manageability.txt",
    "text": "t rely on the mounted storage for their _$JENKINS_HOME_\nwill then need to point to the mounted volume:\n\ndocker run -d \\\n       --dns=172.17.42.1 \\\n       --name joc-1 \\\n       --volumes-from storage \\\n       -e JENKINS_HOME=/data/var/lib/jenkins/jenkins \\\n       [your-dockerhub-id]/jenkins \\\n       --prefix=\"\"\n\n[[test-master-agents]]\n.Test agents\n\nTest controllers can be connected to test agents, "
  },
  "246": {
    "source_file": "architecting-for-manageability.txt",
    "text": "ins \\\n       [your-dockerhub-id]/jenkins \\\n       --prefix=\"\"\n\n[[test-master-agents]]\n.Test agents\n\nTest controllers can be connected to test agents, but this will require further\nconfigurations. Depending on your implementation of a test controller, you will\neither need to create a Jenkins Docker agent image or an agent VM. Of course,\nopen-source plugins like the EC2 plugin also the option of spi"
  },
  "247": {
    "source_file": "architecting-for-manageability.txt",
    "text": " you will\neither need to create a Jenkins Docker agent image or an agent VM. Of course,\nopen-source plugins like the EC2 plugin also the option of spinning up new\nagents on-demand.\n\nThe agent connection information will also need to be edited in the config.xml\nlocated in your test _$JENKINS_HOME_.\n\n.Rolling back plugins that cause failures\n\nIf you discover that a plugin update is causing conflict "
  },
  "248": {
    "source_file": "architecting-for-manageability.txt",
    "text": "config.xml\nlocated in your test _$JENKINS_HOME_.\n\n.Rolling back plugins that cause failures\n\nIf you discover that a plugin update is causing conflict within the test\ncontroller, you can rollback in several ways:\n\n* For bad plugins, you can rollback the plugin from the UI by going to the\n  plugin manager (\"Manage Jenkins\" >> \"Plugins\") and going to the\n  \"Available\" tab. Jenkins will show a \"downgr"
  },
  "249": {
    "source_file": "architecting-for-manageability.txt",
    "text": "he plugin from the UI by going to the\n  plugin manager (\"Manage Jenkins\" >> \"Plugins\") and going to the\n  \"Available\" tab. Jenkins will show a \"downgrade\" button next to any plugins\n  that can be downgraded.\n\n* If the UI is unavailable, then enter your _$JENKINS_HOME_ folder and go to\n  the plugins folder. From there, delete the .hpi or .jpi file for the\n  offending plugin, then restart Jenkins. I"
  },
  "250": {
    "source_file": "architecting-for-manageability.txt",
    "text": "ur _$JENKINS_HOME_ folder and go to\n  the plugins folder. From there, delete the .hpi or .jpi file for the\n  offending plugin, then restart Jenkins. If you need to rollback to an older\n  version, you will need to manually copy in an older version of that .jpi or\n  .hpi. To do this, go to the plugin's page on the\n   and download one\n  of its archived versions.\n\nA Jenkins controller can suffer insta"
  },
  "251": {
    "source_file": "architecting-for-manageability.txt",
    "text": "that .jpi or\n  .hpi. To do this, go to the plugin's page on the\n   and download one\n  of its archived versions.\n\nA Jenkins controller can suffer instability problems when it is not properly\nsized for its hardware or when a buggy plugin wastes resources. To combat this,\nJenkins administrators should begin their troubleshooting by identifying which\ncomponents are behaving abnormally and which resour"
  },
  "252": {
    "source_file": "architecting-for-manageability.txt",
    "text": "es. To combat this,\nJenkins administrators should begin their troubleshooting by identifying which\ncomponents are behaving abnormally and which resources are insufficient. The\nadministrator can\n and heap dumps to get some of this information, but in some cases where\nthe controller has become non-operational and taking a thread dump is impossible,\nit is useful to have a persistent record outside of"
  },
  "253": {
    "source_file": "architecting-for-manageability.txt",
    "text": "some cases where\nthe controller has become non-operational and taking a thread dump is impossible,\nit is useful to have a persistent record outside of Jenkins itself to reference\nwhen such troubleshooting is required.\n\nThe plugin:metrics[metrics plugin] is an open-source plugin that exposed Jenkins metrics.\nMetrics are exposed using the\n\n.Metrics exposed\n\nThe exact list of exposed metrics varies d"
  },
  "254": {
    "source_file": "architecting-for-manageability.txt",
    "text": "in] is an open-source plugin that exposed Jenkins metrics.\nMetrics are exposed using the\n\n.Metrics exposed\n\nThe exact list of exposed metrics varies depending on your installed plugins.\nTo get a full list of available metrics for your controller, run the following\nscript on the\n:\n\nfor (j in Jenkins.instance.getExtensionList(jenkins.metrics.api.MetricProvider.class)) {\n     for (m in j.getMetricSet"
  },
  "255": {
    "source_file": "architecting-for-manageability.txt",
    "text": " the following\nscript on the\n:\n\nfor (j in Jenkins.instance.getExtensionList(jenkins.metrics.api.MetricProvider.class)) {\n     for (m in j.getMetricSet()) {\n          for (i in m.metrics)\n               { println i.getKey() }\n     }\n}\n\nThe plugin:metrics[metrics plugin] documentation describes the available metrics.\n\n.Metrics Usage\n\nMetrics are protected by a set of permissions for viewing, accessi"
  },
  "256": {
    "source_file": "architecting-for-manageability.txt",
    "text": "ics[metrics plugin] documentation describes the available metrics.\n\n.Metrics Usage\n\nMetrics are protected by a set of permissions for viewing, accessing the thread\ndump, and posting a health check. The Metrics Operational Menu can be accessed\nvia the web UI by visiting <jenkins-url>/metrics/currentUser, and the 4 menu\noptions (Metrics, Ping, Threads, Healthcheck) lead to a JSON string containing\nt"
  },
  "257": {
    "source_file": "architecting-for-manageability.txt",
    "text": " web UI by visiting <jenkins-url>/metrics/currentUser, and the 4 menu\noptions (Metrics, Ping, Threads, Healthcheck) lead to a JSON string containing\nthe requested metrics or thread dump.\n\nAccess to the Metrics Servlet can also be provided by issuing API keys. API\nkeys can be configured from the Jenkins global configuration screen\n(<jenkins-url>/configure) under the \"Metrics\" section. Multiple acce"
  },
  "258": {
    "source_file": "architecting-for-manageability.txt",
    "text": "API keys. API\nkeys can be configured from the Jenkins global configuration screen\n(<jenkins-url>/configure) under the \"Metrics\" section. Multiple access can be\ngenerated and permissions associated with those keys can also be restricted at\nthis level.\n\nAdditional information on hardware recommendations can be be found on the  page"
  },
  "259": {
    "source_file": "architecting-for-manageability.txt",
    "text": "\n\nAdditional information on hardware recommendations can be be found on the  page"
  },
  "260": {
    "source_file": "architecting-for-scale.txt",
    "text": "layout: section\n\n\nAs an organization matures from a continuous delivery standpoint, its Jenkins\nrequirements will similarly grow. This growth is often reflected in the Jenkins\narchitecture, whether that be \"vertical\" or \"horizontal\" growth.\n\n*Vertical growth* is when the load on a Jenkins controller load is increased by having more\nconfigured jobs or orchestrating more frequent builds. This may al"
  },
  "261": {
    "source_file": "architecting-for-scale.txt",
    "text": "l growth* is when the load on a Jenkins controller load is increased by having more\nconfigured jobs or orchestrating more frequent builds. This may also mean that\nmore teams are depending on that one controller.\n\n*Horizontal* growth is the creation of additional Jenkins controllers\nto accommodate new teams or projects, rather than adding new teams or projects\nto an existing controller.\n\nThere are "
  },
  "262": {
    "source_file": "architecting-for-scale.txt",
    "text": "f additional Jenkins controllers\nto accommodate new teams or projects, rather than adding new teams or projects\nto an existing controller.\n\nThere are potential pitfalls associated with each approach to scaling Jenkins,\nbut with careful planning, many of them can be avoided or managed. Here are\nsome things to consider when choosing a strategy for scaling your\norganization's Jenkins controllers:\n\n* "
  },
  "263": {
    "source_file": "architecting-for-scale.txt",
    "text": " of them can be avoided or managed. Here are\nsome things to consider when choosing a strategy for scaling your\norganization's Jenkins controllers:\n\n* **Do you have the resources to run a distributed build system?** If possible,\n  it is recommended set up dedicated build nodes that run separately from the\n  Jenkins controller. This frees up resources for the controller to improve its\n  scheduling p"
  },
  "264": {
    "source_file": "architecting-for-scale.txt",
    "text": "t up dedicated build nodes that run separately from the\n  Jenkins controller. This frees up resources for the controller to improve its\n  scheduling performance and prevents builds from being able to modify any\n  potentially sensitive data in the _$JENKINS_HOME_. This also allows\n  for a single controller to scale far more vertically than if that controller were\n  both the job builder and schedule"
  },
  "265": {
    "source_file": "architecting-for-scale.txt",
    "text": "ENKINS_HOME_. This also allows\n  for a single controller to scale far more vertically than if that controller were\n  both the job builder and scheduler.\n* **Do you have the resources to maintain multiple controllers?** Jenkins controllers\n  require regular plugin updates, semi-monthly core upgrades, and regular\n  backups of configurations and build histories. Security settings and roles\n  will hav"
  },
  "266": {
    "source_file": "architecting-for-scale.txt",
    "text": "egular plugin updates, semi-monthly core upgrades, and regular\n  backups of configurations and build histories. Security settings and roles\n  will have to be manually configured for each controller. Downed controllers will\n  require manual restart of the Jenkins controller and any jobs that were killed by\n  the outage.\n* **How mission critical are each team's projects?** Consider segregating the\n "
  },
  "267": {
    "source_file": "architecting-for-scale.txt",
    "text": " the Jenkins controller and any jobs that were killed by\n  the outage.\n* **How mission critical are each team's projects?** Consider segregating the\n  most vital projects to separate controllers to minimize the impact of a single\n  downed controller. Also consider converting any mission-critical project\n  pipelines to Pipeline jobs, which continue executing even when the\n  agent connection to the "
  },
  "268": {
    "source_file": "architecting-for-scale.txt",
    "text": " Also consider converting any mission-critical project\n  pipelines to Pipeline jobs, which continue executing even when the\n  agent connection to the controller is lost.\n* **How important is a fast start-up time for your Jenkins controller?** The more\n  jobs a controller has configured, the longer it takes to load Jenkins after an\n  upgrade or a crash. The use of folders and views to organize jobs"
  },
  "269": {
    "source_file": "architecting-for-scale.txt",
    "text": "e\n  jobs a controller has configured, the longer it takes to load Jenkins after an\n  upgrade or a crash. The use of folders and views to organize jobs can limit\n  the number of that need to be rendered on start up.\n\nA Jenkins controller can operate by itself both managing the build environment and\nexecuting the builds with its own executors and resources. If you stick with\nthis \"standalone\" config"
  },
  "270": {
    "source_file": "architecting-for-scale.txt",
    "text": "y itself both managing the build environment and\nexecuting the builds with its own executors and resources. If you stick with\nthis \"standalone\" configuration you will most likely run out of resources when\nthe number or the load of your projects increase.\n\nTo come back up and running with your Jenkins infrastructure you will need to\nenhance the controller (increasing memory, number of CPUs, etc). T"
  },
  "271": {
    "source_file": "architecting-for-scale.txt",
    "text": "ase.\n\nTo come back up and running with your Jenkins infrastructure you will need to\nenhance the controller (increasing memory, number of CPUs, etc). The time it takes\nto maintain and upgrade the machine, the controller together with all the build\nenvironment will be down, the jobs will be stopped and the whole Jenkins\ninfrastructure will be unusable.\n\nScaling Jenkins in such a scenario would be ex"
  },
  "272": {
    "source_file": "architecting-for-scale.txt",
    "text": "ironment will be down, the jobs will be stopped and the whole Jenkins\ninfrastructure will be unusable.\n\nScaling Jenkins in such a scenario would be extremely painful and would\nintroduce many \"idle\" periods where all the resources assigned to your build\nenvironment are useless.\n\nMoreover, executing jobs on the controller introduces a \"security\"\nissue: the \"jenkins\" user that Jenkins uses to run the"
  },
  "273": {
    "source_file": "architecting-for-scale.txt",
    "text": "ld\nenvironment are useless.\n\nMoreover, executing jobs on the controller introduces a \"security\"\nissue: the \"jenkins\" user that Jenkins uses to run the jobs would have full\npermissions on all Jenkins resources on the controller. This means that, with a\nsimple script, a malicious user can have direct access to private information\nwhose integrity and privacy could not be, thus,  guaranteed.\nSee\n\nin t"
  },
  "274": {
    "source_file": "architecting-for-scale.txt",
    "text": "a\nsimple script, a malicious user can have direct access to private information\nwhose integrity and privacy could not be, thus,  guaranteed.\nSee\n\nin the\n\nchapter for more information.\n\nFor all these reasons Jenkins supports agents, where the\nworkload of building projects are delegated to multiple agents.\n\nAn agent is a machine set up to offload projects from the controller. The method\nwith which b"
  },
  "275": {
    "source_file": "architecting-for-scale.txt",
    "text": " of building projects are delegated to multiple agents.\n\nAn agent is a machine set up to offload projects from the controller. The method\nwith which builds are scheduled depends on the configuration given to each\nproject. For example, some projects may be configured to \"restrict where this\nproject is run\" which ties the project to a specific agent or set of labeled\nagents. Other projects which omi"
  },
  "276": {
    "source_file": "architecting-for-scale.txt",
    "text": "ay be configured to \"restrict where this\nproject is run\" which ties the project to a specific agent or set of labeled\nagents. Other projects which omit this configuration will select an agent from\nthe available pool in Jenkins.\nLearn more about Agents in\n\nIn a distributed builds environment, the Jenkins controller will use its resources\nto only handle HTTP requests and manage the build environment"
  },
  "277": {
    "source_file": "architecting-for-scale.txt",
    "text": "s in\n\nIn a distributed builds environment, the Jenkins controller will use its resources\nto only handle HTTP requests and manage the build environment. Actual execution\nof builds will be delegated to the agents. With this configuration it is\npossible to horizontally scale an architecture, which allows a single Jenkins\ninstallation to host a large number of projects and build environments.\n\nIn orde"
  },
  "278": {
    "source_file": "architecting-for-scale.txt",
    "text": " to horizontally scale an architecture, which allows a single Jenkins\ninstallation to host a large number of projects and build environments.\n\nIn order for a machine to be recognized as an agent, it needs to run a specific\nagent program to establish bi-directional communication with the controller.\n\nThere are different ways to establish a connection between controller and agent:\n\n* *The SSH connec"
  },
  "279": {
    "source_file": "architecting-for-scale.txt",
    "text": "bi-directional communication with the controller.\n\nThere are different ways to establish a connection between controller and agent:\n\n* *The SSH connector*: Configuring an agent to use the SSH connector is the\n preferred and the most stable way to establish controller-agent communication.\n Jenkins has a built-in SSH client implementation. This means that the\n Jenkins controller can easily communica"
  },
  "280": {
    "source_file": "architecting-for-scale.txt",
    "text": "ablish controller-agent communication.\n Jenkins has a built-in SSH client implementation. This means that the\n Jenkins controller can easily communicate with any machine with an SSH server\n installed. The only requirement is that the public key of the controller is\n part of the set of the authorized keys on the agent. Once the host and SSH key\n is defined for a new agent, Jenkins will establish a "
  },
  "281": {
    "source_file": "architecting-for-scale.txt",
    "text": "e controller is\n part of the set of the authorized keys on the agent. Once the host and SSH key\n is defined for a new agent, Jenkins will establish a connection to\n the machine and bootstrap the agent process.\n\n* *The inbound connector*: In this case the communication is established\n  starting the agent through a connection initiated by an agent program. With this connector\n  the agent is launched"
  },
  "282": {
    "source_file": "architecting-for-scale.txt",
    "text": " the communication is established\n  starting the agent through a connection initiated by an agent program. With this connector\n  the agent is launched in the machine in 2 different ways:\n\n . Manually: by navigating to the Jenkins controller URL in a browser on the agent.\n   Once the Java Web Start icon is clicked, the agent will be launched on the\n   machine. The downside of this approach is that "
  },
  "283": {
    "source_file": "architecting-for-scale.txt",
    "text": "browser on the agent.\n   Once the Java Web Start icon is clicked, the agent will be launched on the\n   machine. The downside of this approach is that the agents cannot be centrally\n   managed by the Jenkins controller and each/stop/start/update of the agent needs to\n   be executed manually on the agent's machine in versions of Jenkins older than\n   1.611. This approach is convenient when the contr"
  },
  "284": {
    "source_file": "architecting-for-scale.txt",
    "text": "e agent needs to\n   be executed manually on the agent's machine in versions of Jenkins older than\n   1.611. This approach is convenient when the controller cannot instantiate the\n   connection with the client, for example: with agents running inside a\n   firewalled network connecting to a controller located outside the firewall.\n\n . As a service: First you'll need to manually launch the agent usin"
  },
  "285": {
    "source_file": "architecting-for-scale.txt",
    "text": "a\n   firewalled network connecting to a controller located outside the firewall.\n\n . As a service: First you'll need to manually launch the agent using the above\n   method. After manually launching it, _jenkins-slave.exe_ and\n   _jenkins-slave.xml_ will be created in the agent's work directory. Now go to\n   the command line to execute the following command:\n\nsc.exe create \"<serviceKey>\" start= aut"
  },
  "286": {
    "source_file": "architecting-for-scale.txt",
    "text": "ill be created in the agent's work directory. Now go to\n   the command line to execute the following command:\n\nsc.exe create \"<serviceKey>\" start= auto binPath= \"<path to jenkins-slave.exe>\" DisplayName= \"<service display name>\"\n\n_<serviceKey>_ is the name of the registry key to define this agent service and\n<service display name> is the label that will identify the service in the\nService Manager "
  },
  "287": {
    "source_file": "architecting-for-scale.txt",
    "text": "e name of the registry key to define this agent service and\n<service display name> is the label that will identify the service in the\nService Manager interface.\n\nTo ensure that restarts are automated, you will need to download a recent agent jar and copy it to a permanent location on the machine.\nThe_.jar_ file can be found at:\n\nhttp://<your-jenkins-host>/jnlpJars/agent.jar\n\nIf running a version o"
  },
  "288": {
    "source_file": "architecting-for-scale.txt",
    "text": "copy it to a permanent location on the machine.\nThe_.jar_ file can be found at:\n\nhttp://<your-jenkins-host>/jnlpJars/agent.jar\n\nIf running a version of Jenkins newer than 1.559, the _.jar_ will be kept\nup to date each time it connects to the controller.\n\n * *The Inbound-HTTP connector*: This approach is quite similar to the Inbound-TCP\n   Java Web Start approach, with the difference in this case b"
  },
  "289": {
    "source_file": "architecting-for-scale.txt",
    "text": "er.\n\n * *The Inbound-HTTP connector*: This approach is quite similar to the Inbound-TCP\n   Java Web Start approach, with the difference in this case being that the\n   agent is executed as headless and the connection can be tunneled via HTTP(s).\n   The exact command can be found on your Inbound agent's configuration page:\n\n[[inbound_agent]]\n.Inbound agent launch command\n\nThis approach is convenient"
  },
  "290": {
    "source_file": "architecting-for-scale.txt",
    "text": "e exact command can be found on your Inbound agent's configuration page:\n\n[[inbound_agent]]\n.Inbound agent launch command\n\nThis approach is convenient for an execution as a daemon on Unix.\n\n* *Custom-script*: It is also possible to create a custom script to initialize\n  the communication between controller and agent if the other solutions do not\n  provide enough flexibility for a specific use-case"
  },
  "291": {
    "source_file": "architecting-for-scale.txt",
    "text": "ript to initialize\n  the communication between controller and agent if the other solutions do not\n  provide enough flexibility for a specific use-case. The only requirement is\n  that the script runs the java program as a _java -jar agent.jar_ on the\n  agent.\n\nWindows agent set-up can follow the standard SSH and inbound agent approaches.\nWindows agents have the following options:\n\n* *SSH-connector "
  },
  "292": {
    "source_file": "architecting-for-scale.txt",
    "text": "  agent.\n\nWindows agent set-up can follow the standard SSH and inbound agent approaches.\nWindows agents have the following options:\n\n* *SSH-connector approach with Putty*\n* *SSH-connector approach with Cygwin and OpenSSH*:\n  https://wiki.jenkins.io/display/JENKINS/SSH+slaves+and+Cygwin[This] is the\n  easiest to setup and recommended approach.\n* *SSH-connector approach with Microsoft OpenSSH*:\n  Th"
  },
  "293": {
    "source_file": "architecting-for-scale.txt",
    "text": "isplay/JENKINS/SSH+slaves+and+Cygwin[This] is the\n  easiest to setup and recommended approach.\n* *SSH-connector approach with Microsoft OpenSSH*:\n  The  works well for Microsoft operating systems that support the server.\n  Refer to installation instructions in the .\n* *Inbound agent approach*: With\n  https://wiki.jenkins.io/display/JENKINS/Installing+Jenkins+as+a+Windows+service[this approach]\n   "
  },
  "294": {
    "source_file": "architecting-for-scale.txt",
    "text": "uctions in the .\n* *Inbound agent approach*: With\n  https://wiki.jenkins.io/display/JENKINS/Installing+Jenkins+as+a+Windows+service[this approach]\n   it is possible to manually register the agent as Windows service,\n  but it will not be possible to centrally manage it from the controller. Each\n  stop/start/update of the agent needs to be executed manually on the\n  agent machine, unless running Jen"
  },
  "295": {
    "source_file": "architecting-for-scale.txt",
    "text": "entrally manage it from the controller. Each\n  stop/start/update of the agent needs to be executed manually on the\n  agent machine, unless running Jenkins 1.611 or newer.\n\nThe Jenkins Global configuration page lets you specify the tools needed during\nthe builds (i.e. Ant, Maven, Java, etc).\n\nWhen defining a tool, it is possible to create a pointer to an existing\ninstallation by giving the director"
  },
  "296": {
    "source_file": "architecting-for-scale.txt",
    "text": "\nthe builds (i.e. Ant, Maven, Java, etc).\n\nWhen defining a tool, it is possible to create a pointer to an existing\ninstallation by giving the directory where the program is expected to be on the\nagent. Another option is to let Jenkins take care of the installation of a\nspecific version in the given location. It is also possible to specify more\nthan one installation for the same tool since differen"
  },
  "297": {
    "source_file": "architecting-for-scale.txt",
    "text": "e installation of a\nspecific version in the given location. It is also possible to specify more\nthan one installation for the same tool since different jobs may need different\nversions of the same tool.\n\nThe pre-compiled \"Default\" option calls whatever is already installed on the\nagent and exists in the machine PATH, but this returns a failure if the tool is not\ninstalled and its location was not "
  },
  "298": {
    "source_file": "architecting-for-scale.txt",
    "text": "er is already installed on the\nagent and exists in the machine PATH, but this returns a failure if the tool is not\ninstalled and its location was not added to the PATH system variable.\n\nOne best practice to avoid this failure is to configure a job with the\nassumption that the target agent does not have the necessary tools installed,\nand to include the tools' installation as part of the build proce"
  },
  "299": {
    "source_file": "architecting-for-scale.txt",
    "text": "th the\nassumption that the target agent does not have the necessary tools installed,\nand to include the tools' installation as part of the build process.\n\nAs mentioned previously, agents should be interchangeable and standardized in\norder to make them sharable and to optimize resource usage.  Agents should not\nbe customized for a particular set of jobs, nor for a particular team.\n\nLately Jenkins h"
  },
  "300": {
    "source_file": "architecting-for-scale.txt",
    "text": "m sharable and to optimize resource usage.  Agents should not\nbe customized for a particular set of jobs, nor for a particular team.\n\nLately Jenkins has become more and more popular not only in CI but also in CD,\nwhich means that it must orchestrate jobs and pipelines which involve different\nteams and technical profiles: developers, QA people and Dev-Ops people.\n\nIn such a scenario, it might make "
  },
  "301": {
    "source_file": "architecting-for-scale.txt",
    "text": "jobs and pipelines which involve different\nteams and technical profiles: developers, QA people and Dev-Ops people.\n\nIn such a scenario, it might make sense to create customized and dedicated\nagents: different tools are usually required by different teams (i.e.\nPuppet/Chef for the Ops team) and teams' credentials are usually stored on the\nagent in order to ensure their protection and privacy.\n\nIn o"
  },
  "302": {
    "source_file": "architecting-for-scale.txt",
    "text": "eams (i.e.\nPuppet/Chef for the Ops team) and teams' credentials are usually stored on the\nagent in order to ensure their protection and privacy.\n\nIn order to ensure the execution of a job on a single/group of agents only\n(i.e. iOS builds on OSX agents only), it is possible to tie the job to the\nagent by specifying the agent's label in the job configuration page. Note that\nthe restriction has to be"
  },
  "303": {
    "source_file": "architecting-for-scale.txt",
    "text": "s only), it is possible to tie the job to the\nagent by specifying the agent's label in the job configuration page. Note that\nthe restriction has to be replicated in every single job to be tied and that\nthe agent won't be protected from being used by other teams.\n\nCloud build resources can be a solution for a case when it is necessary to\nmaintain a reasonably small cluster of agents on-premises whi"
  },
  "304": {
    "source_file": "architecting-for-scale.txt",
    "text": "other teams.\n\nCloud build resources can be a solution for a case when it is necessary to\nmaintain a reasonably small cluster of agents on-premises while still providing\nnew build resources when needed.\n\nIn particular it is possible to offload the execution of the jobs to agents in\nthe cloud thanks to ad-hoc plugins which will handle the creation of the cloud\nresources together with their destructi"
  },
  "305": {
    "source_file": "architecting-for-scale.txt",
    "text": "cution of the jobs to agents in\nthe cloud thanks to ad-hoc plugins which will handle the creation of the cloud\nresources together with their destruction when they are not needed anymore:\n\n* The plugin:ec2[EC2 Plugin]\n  lets Jenkins use AWS EC2 instances as cloud build resources when it runs out of on-premises agents.\n  The EC2 agents will be dynamically created inside an AWS network and de-provisi"
  },
  "306": {
    "source_file": "architecting-for-scale.txt",
    "text": "ces as cloud build resources when it runs out of on-premises agents.\n  The EC2 agents will be dynamically created inside an AWS network and de-provisioned when they are not needed.\n* The plugin:azure-vm-agents[Azure VM Agents Plugin]\n  dynamically spins up Jenkins agents as Azure VMs per user provided\n  configuration via templates, including support for virtual network integration\n  and subnet pla"
  },
  "307": {
    "source_file": "architecting-for-scale.txt",
    "text": "ins up Jenkins agents as Azure VMs per user provided\n  configuration via templates, including support for virtual network integration\n  and subnet placement. Idle agents can be configured for automatic shutdown\n  to reduce costs.\n* The plugin:jclouds-jenkins[JCloud plugin]\n  creates the possibility of executing the jobs on any cloud provider supported\n  by JCloud libraries\n\n[[right-sizing-jenkins-"
  },
  "308": {
    "source_file": "architecting-for-scale.txt",
    "text": "-jenkins[JCloud plugin]\n  creates the possibility of executing the jobs on any cloud provider supported\n  by JCloud libraries\n\n[[right-sizing-jenkins-masters]]\n\nComprehensive hardware recommendations:\n\n* Hardware: see the  page\n\n[[master-division-strategies]]\n\nDesigning the best Jenkins architecture for your organization is dependent on\nhow you stratify the development of your projects and can be "
  },
  "309": {
    "source_file": "architecting-for-scale.txt",
    "text": "ategies]]\n\nDesigning the best Jenkins architecture for your organization is dependent on\nhow you stratify the development of your projects and can be constrained by\nlimitations of the existing Jenkins plugins.\n\nThe 3 most common forms of stratifying development by controllers is:\n\n1. **By environment (QA, DEV, etc)** - With this strategy, Jenkins controllers are populated by jobs based on what env"
  },
  "310": {
    "source_file": "architecting-for-scale.txt",
    "text": "development by controllers is:\n\n1. **By environment (QA, DEV, etc)** - With this strategy, Jenkins controllers are populated by jobs based on what environment they are deploying to.\n\n* **Pros**\n** Can tailor plugins on controllers to be specific to that environment's needs\n** Can easily restrict access to an environment to only users who will be using that environment\n\n* **Cons**\n** Reduces abilit"
  },
  "311": {
    "source_file": "architecting-for-scale.txt",
    "text": "hat environment's needs\n** Can easily restrict access to an environment to only users who will be using that environment\n\n* **Cons**\n** Reduces ability to create pipelines\n** No way to visualize the complete flow across controllers\n** Outage of a controller will block flow of all products\n\n2. **By org chart** - This strategy is when controllers are assigned to divisions within an organization.\n\n* "
  },
  "312": {
    "source_file": "architecting-for-scale.txt",
    "text": "troller will block flow of all products\n\n2. **By org chart** - This strategy is when controllers are assigned to divisions within an organization.\n\n* **Pros**\n** Can tailor plugins on controllers to be specific to that team's needs\n** Can easily restrict access to a division's projects to only users who are within that division\n\n* **Cons**\n** Reduces ability to create cross-division pipelines\n** N"
  },
  "313": {
    "source_file": "architecting-for-scale.txt",
    "text": "rict access to a division's projects to only users who are within that division\n\n* **Cons**\n** Reduces ability to create cross-division pipelines\n** No way to visualize the complete flow across controllers\n** Outage of a controller will block flow of all products\n\n3. **Group controllers by product lines** - When a group of products, with on only critical product in each group, gets its own Jenkins"
  },
  "314": {
    "source_file": "architecting-for-scale.txt",
    "text": " all products\n\n3. **Group controllers by product lines** - When a group of products, with on only critical product in each group, gets its own Jenkins controllers.\n\n* **Pros**\n** Entire flows can be visualized because all steps are on one controller\n** Reduces the impact of one controller's downtime on only affects a small subset of products\n\n* **Cons**\n** A strategy for restricting permissions mu"
  },
  "315": {
    "source_file": "architecting-for-scale.txt",
    "text": "** Reduces the impact of one controller's downtime on only affects a small subset of products\n\n* **Cons**\n** A strategy for restricting permissions must be devised to keep all users from having access to all items on a controller.\n\nWhen evaluating these strategies, it is important to weigh them against the\nvertical and horizontal scaling pitfalls discussed in the introduction.\n\nAnother note is tha"
  },
  "316": {
    "source_file": "architecting-for-scale.txt",
    "text": "ese strategies, it is important to weigh them against the\nvertical and horizontal scaling pitfalls discussed in the introduction.\n\nAnother note is that a smaller number of jobs translates to faster recovery\nfrom failures and more importantly a higher mean time between failures.\n\n[[Calculating-how-many-jobs,-masters,-and-executors-are-needed]]\n\nHaving the best possible estimate of necessary configu"
  },
  "317": {
    "source_file": "architecting-for-scale.txt",
    "text": " mean time between failures.\n\n[[Calculating-how-many-jobs,-masters,-and-executors-are-needed]]\n\nHaving the best possible estimate of necessary configurations for a Jenkins\ninstallation allows an organization to get started on the right foot with\nJenkins and reduces the number of configuration iterations needed to achieve an\noptimal installation. The challenge for Jenkins architects is that true li"
  },
  "318": {
    "source_file": "architecting-for-scale.txt",
    "text": "ins and reduces the number of configuration iterations needed to achieve an\noptimal installation. The challenge for Jenkins architects is that true limit\nof vertical scaling on a Jenkins controller is constrained by whatever hardware is\nin place for the controller, as well as harder to quantify pieces like the types of\nbuilds and tests that will be run on the build nodes.\n\nThere is a way to estima"
  },
  "319": {
    "source_file": "architecting-for-scale.txt",
    "text": "the controller, as well as harder to quantify pieces like the types of\nbuilds and tests that will be run on the build nodes.\n\nThere is a way to estimate roughly how many controllers, jobs and executors will be\nneeded based on build needs and number of developers served. These equations\nassume that the Jenkins controller will have 5 cores with one core per 100 jobs\n(500 total jobs/controller) and t"
  },
  "320": {
    "source_file": "architecting-for-scale.txt",
    "text": "f developers served. These equations\nassume that the Jenkins controller will have 5 cores with one core per 100 jobs\n(500 total jobs/controller) and that teams will be divided into groups of 40.\n\nIf you have information on the actual number of available cores on your planned\ncontroller, you can make adjustments to the\n\"number of controllers\" equations accordingly.\n\nThe equation for *estimating the"
  },
  "321": {
    "source_file": "architecting-for-scale.txt",
    "text": "ble cores on your planned\ncontroller, you can make adjustments to the\n\"number of controllers\" equations accordingly.\n\nThe equation for *estimating the number of controllers and executors needed* when\nthe number of configured jobs is known is as follows:\n\ncontrollers = number of jobs/500\nexecutors = number of jobs * 0.03\n\nThe equation for *estimating the maximum number of jobs, controllers, and exe"
  },
  "322": {
    "source_file": "architecting-for-scale.txt",
    "text": "ws:\n\ncontrollers = number of jobs/500\nexecutors = number of jobs * 0.03\n\nThe equation for *estimating the maximum number of jobs, controllers, and executors\nneeded* for an organization based on the number of developers is as follows:\n\nnumber of jobs = number of developers * 3.333\nnumber of controllers = number of jobs/500\nnumber of executors = number of jobs * 0.03\n\nThese numbers will provide a go"
  },
  "323": {
    "source_file": "architecting-for-scale.txt",
    "text": "= number of developers * 3.333\nnumber of controllers = number of jobs/500\nnumber of executors = number of jobs * 0.03\n\nThese numbers will provide a good starting point for a Jenkins installation,\nbut adjustments to actual installation size may be needed based on the types of\nbuilds and tests that an installation runs.\n\n[[scalable-storage-for-master]]\n\nIt is also recommended to choose a controller "
  },
  "324": {
    "source_file": "architecting-for-scale.txt",
    "text": "ded based on the types of\nbuilds and tests that an installation runs.\n\n[[scalable-storage-for-master]]\n\nIt is also recommended to choose a controller with consideration for future growth\nin the number of plugins or jobs stored in your controller's _$JENKINS_HOME_.\nStorage is cheap and Jenkins does not require fast disk access to run well, so\nit is more advantageous to invest in a larger machine fo"
  },
  "325": {
    "source_file": "architecting-for-scale.txt",
    "text": "JENKINS_HOME_.\nStorage is cheap and Jenkins does not require fast disk access to run well, so\nit is more advantageous to invest in a larger machine for your controller over a\nfaster one.\n\nDifferent operating systems for the Jenkins controller will also allow for\ndifferent approaches to expandable storage:\n\n* *Spanned Volumes on Windows* - On NTFS devices like Windows, you can create a\n  spanned vo"
  },
  "326": {
    "source_file": "architecting-for-scale.txt",
    "text": "so allow for\ndifferent approaches to expandable storage:\n\n* *Spanned Volumes on Windows* - On NTFS devices like Windows, you can create a\n  spanned volume that allows you to add new volumes to an existing one, but\n  have them behave as a single volume. To do this, you will have to ensure that\n  Jenkins is installed on a separate partition so that it can be converted to a\n  spanned volume later.\n* "
  },
  "327": {
    "source_file": "architecting-for-scale.txt",
    "text": "e. To do this, you will have to ensure that\n  Jenkins is installed on a separate partition so that it can be converted to a\n  spanned volume later.\n* *Logical Volume Manager for Linux* - LVM manages disk drives and allows\n  logical volumes to be resized on the fly. Many distributions of Linux use LVM\n  when they are installed, but Jenkins should have its own LVM setup.\n* *ZFS for Solaris* - ZFS is"
  },
  "328": {
    "source_file": "architecting-for-scale.txt",
    "text": "zed on the fly. Many distributions of Linux use LVM\n  when they are installed, but Jenkins should have its own LVM setup.\n* *ZFS for Solaris* - ZFS is even more flexible than LVM and spanned volumes\n  and just requires that the _$JENKINS_HOME_ be on its own filesystem. This\n  makes it easier to create snapshots, backups, etc.\n- For systems with an existing Jenkins installation, there are at least "
  },
  "329": {
    "source_file": "architecting-for-scale.txt",
    "text": "its own filesystem. This\n  makes it easier to create snapshots, backups, etc.\n- For systems with an existing Jenkins installation, there are at least two options:\n** The System Property\n** *Symbolic Links* (symlinks) may be used instead to store job\n  folders on separate volumes with symlinks to those directories.\n\nAdditionally, to easily prevent a _$JENKINS_HOME_ folder from becoming bloated,\nmak"
  },
  "330": {
    "source_file": "architecting-for-scale.txt",
    "text": "  folders on separate volumes with symlinks to those directories.\n\nAdditionally, to easily prevent a _$JENKINS_HOME_ folder from becoming bloated,\nmake it mandatory for jobs to discard build records after a specific time\nperiod has passed and/or after a specific number of builds have been run.\nThis policy can be set on a job's configuration page.\n\nIt is a best practice to take regular backups of y"
  },
  "331": {
    "source_file": "architecting-for-scale.txt",
    "text": "r a specific number of builds have been run.\nThis policy can be set on a job's configuration page.\n\nIt is a best practice to take regular backups of your $JENKINS_HOME.\nA backup ensures that your Jenkins controller can be restored despite a misconfiguration,\naccidental job deletion, or data corruption.\nSee the  for more details.\n\n**Windows**\n\nIf you install Jenkins with the Windows installer, Jenk"
  },
  "332": {
    "source_file": "architecting-for-scale.txt",
    "text": "uration,\naccidental job deletion, or data corruption.\nSee the  for more details.\n\n**Windows**\n\nIf you install Jenkins with the Windows installer, Jenkins is installed as\na service and the default _$JENKINS_HOME_ will be \"C:\\Program Files (x86)\\jenkins\".\nYou can edit the location of your _$JENKINS_HOME_ by opening the jenkins.xml\nfile and editing the _$JENKINS_HOME_ variable, or going to the \"Manag"
  },
  "333": {
    "source_file": "architecting-for-scale.txt",
    "text": "s\".\nYou can edit the location of your _$JENKINS_HOME_ by opening the jenkins.xml\nfile and editing the _$JENKINS_HOME_ variable, or going to the \"Manage Jenkins\"\nscreen, clicking on the \"Install as Windows Service\" option in the menu, and\nthen editing the \"Installation Directory\" field to point to another existing\ndirectory.\n\n**Mac OSX**\n\nBy default, the _$JENKINS_HOME_ will be set to \"~/.jenkins\"."
  },
  "334": {
    "source_file": "architecting-for-scale.txt",
    "text": " the \"Installation Directory\" field to point to another existing\ndirectory.\n\n**Mac OSX**\n\nBy default, the _$JENKINS_HOME_ will be set to \"~/.jenkins\".\n\n**Linux**\n\nBy default, `$JENKINS_HOME` is set to `/var/lib/jenkins`\nand `$JENKINS_WAR` is set to `/usr/share/java/jenkins.war`.\n\nYou can edit the location of `$JENKINS_HOME`\nby running `systemctl edit jenkins` and adding the following:\n\n[Service]\nE"
  },
  "335": {
    "source_file": "architecting-for-scale.txt",
    "text": "/usr/share/java/jenkins.war`.\n\nYou can edit the location of `$JENKINS_HOME`\nby running `systemctl edit jenkins` and adding the following:\n\n[Service]\nEnvironment=\"HOME=/var/lib/jenkins\"\nEnvironment=\"JENKINS_HOME=/var/lib/jenkins\"\nWorkingDirectory=/var/lib/jenkins\n\nYou can edit the location of `$JENKINS_WAR`\nby running `systemctl edit jenkins` and adding the following:\n\n[Service]\nEnvironment=\"JENKIN"
  },
  "336": {
    "source_file": "architecting-for-scale.txt",
    "text": "/lib/jenkins\n\nYou can edit the location of `$JENKINS_WAR`\nby running `systemctl edit jenkins` and adding the following:\n\n[Service]\nEnvironment=\"JENKINS_WAR=/usr/share/java/jenkins.war\"\n\n**FreeBSD**\n\nIf installing Jenkins using a port, the _$JENKINS_HOME_ will be located in\nwhichever directory you run the \"make\" command in. It is recommended to create\na \"/usr/ports/devel/jenkins\" folder and compile"
  },
  "337": {
    "source_file": "architecting-for-scale.txt",
    "text": "OME_ will be located in\nwhichever directory you run the \"make\" command in. It is recommended to create\na \"/usr/ports/devel/jenkins\" folder and compile Jenkins in that directory.\n\nYou will be able to edit the _$JENKINS_HOME_ by editing the\n\"/usr/local/etc/jenkins\".\n\n**OpenBSD**\n\nIf installing Jenkins using a package,the _$JENKINS_HOME_ is set by default to\n\"/var/jenkins\".\n\nIf installing Jenkins usi"
  },
  "338": {
    "source_file": "architecting-for-scale.txt",
    "text": "/etc/jenkins\".\n\n**OpenBSD**\n\nIf installing Jenkins using a package,the _$JENKINS_HOME_ is set by default to\n\"/var/jenkins\".\n\nIf installing Jenkins using a port, the _$JENKINS_HOME_ will be located in\nwhichever directory you run the \"make\" command in. It is recommended to create\na \"/usr/ports/devel/jenkins\" folder and compile Jenkins in that directory.\n\nYou will be able to edit the _$JENKINS_HOME_ "
  },
  "339": {
    "source_file": "architecting-for-scale.txt",
    "text": " It is recommended to create\na \"/usr/ports/devel/jenkins\" folder and compile Jenkins in that directory.\n\nYou will be able to edit the _$JENKINS_HOME_ by editing the\n\"/usr/local/etc/jenkins\" file.\n\nThe folder structure for a _$JENKINS_HOME_ directory is as follows:\n\nJENKINS_HOME\n +- config.xml     (Jenkins root configuration file)\n +- *.xml          (other site-wide configuration files)\n +- identit"
  },
  "340": {
    "source_file": "architecting-for-scale.txt",
    "text": "is as follows:\n\nJENKINS_HOME\n +- config.xml     (Jenkins root configuration file)\n +- *.xml          (other site-wide configuration files)\n +- identity.key.enc   (RSA key pair that identifies an instance)\n +- secret.key     (deprecated key used for some plugins' secure operations)\n +- secret.key.not-so-secret  (used for validating _$JENKINS_HOME_ creation date)\n +- userContent    (files served und"
  },
  "341": {
    "source_file": "architecting-for-scale.txt",
    "text": "ome plugins' secure operations)\n +- secret.key.not-so-secret  (used for validating _$JENKINS_HOME_ creation date)\n +- userContent    (files served under your https://server/userContent/)\n +- secrets        (root directory for the secret+key for credential decryption)\n     +- hudson.util.Secret   (used for encrypting some Jenkins data)\n     +- master.key           (used for encrypting the hudson.ut"
  },
  "342": {
    "source_file": "architecting-for-scale.txt",
    "text": "ntial decryption)\n     +- hudson.util.Secret   (used for encrypting some Jenkins data)\n     +- master.key           (used for encrypting the hudson.util.Secret key)\n     +- InstanceIdentity.KEY (used to identity this instance)\n     +- jenkins.model.Jenkins.crumbSalt   (used for encrypting some Jenkins data)\n     +- initialAdminPassword (used for initial login)\n +- fingerprints   (stores fingerprin"
  },
  "343": {
    "source_file": "architecting-for-scale.txt",
    "text": "enkins.crumbSalt   (used for encrypting some Jenkins data)\n     +- initialAdminPassword (used for initial login)\n +- fingerprints   (stores fingerprint records, if any)\n +- plugins        (root directory for all Jenkins plugins)\n     +- [PLUGINNAME]   (sub directory for each plugin)\n         +- META-INF       (subdirectory for plugin manifest + pom.xml)\n         +- WEB-INF        (subdirectory for"
  },
  "344": {
    "source_file": "architecting-for-scale.txt",
    "text": "  (sub directory for each plugin)\n         +- META-INF       (subdirectory for plugin manifest + pom.xml)\n         +- WEB-INF        (subdirectory for plugin jar(s) and licenses.xml)\n     +- [PLUGINNAME].jpi   (.jpi or .hpi file for the plugin)\n +- jobs           (root directory for all Jenkins jobs)\n     +- [JOBNAME]      (sub directory for each job)\n         +- config.xml     (job configuration "
  },
  "345": {
    "source_file": "architecting-for-scale.txt",
    "text": "obs           (root directory for all Jenkins jobs)\n     +- [JOBNAME]      (sub directory for each job)\n         +- config.xml     (job configuration file)\n         +- workspace      (working directory for the version control system)\n         +- latest         (symbolic link to the last successful build)\n         +- builds         (stores past build records)\n             +- [BUILD_ID]     (subdire"
  },
  "346": {
    "source_file": "architecting-for-scale.txt",
    "text": "st         (symbolic link to the last successful build)\n         +- builds         (stores past build records)\n             +- [BUILD_ID]     (subdirectory for each build)\n                 +- build.xml      (build result summary)\n                 +- log            (log file)\n                 +- changelog.xml  (change log)\n     +- [FOLDERNAME]   (sub directory for each folder)\n         +- config.xm"
  },
  "347": {
    "source_file": "architecting-for-scale.txt",
    "text": "log            (log file)\n                 +- changelog.xml  (change log)\n     +- [FOLDERNAME]   (sub directory for each folder)\n         +- config.xml     (folder configuration file)\n         +- jobs           (sub directory for all nested jobs)\n\n[[segrate-data]]\n\nCAUTION: No data migration is handled by Jenkins when using those settings.\nSo you either want to use them from the beginning, or make"
  },
  "348": {
    "source_file": "architecting-for-scale.txt",
    "text": "segrate-data]]\n\nCAUTION: No data migration is handled by Jenkins when using those settings.\nSo you either want to use them from the beginning, or make sure you take into consideration which data you would like to be moved to the right place before using the following switches.\n\nIt is possible to separate customize some of the layout to better separate pure job configurations from less durable data"
  },
  "349": {
    "source_file": "architecting-for-scale.txt",
    "text": "ing the following switches.\n\nIt is possible to separate customize some of the layout to better separate pure job configurations from less durable data, like build data or logs.\nfootnote:[These switches are used to configure out of the box  instances.]\n\nHistorically, the configuration of a given job is located under `$JENKINS_HOME/jobs/[JOB_NAME]/config.xml` and its builds are under `$JENKINS_HOME/"
  },
  "350": {
    "source_file": "architecting-for-scale.txt",
    "text": "]\n\nHistorically, the configuration of a given job is located under `$JENKINS_HOME/jobs/[JOB_NAME]/config.xml` and its builds are under `$JENKINS_HOME/jobs/[JOB_NAME]/builds`.\n\nThis typically makes it more impractical to set up a different backup policy, or set up a quicker disk for making builds potentially faster.\n\nFor instance, if you would like to move builds under a different root, you can use"
  },
  "351": {
    "source_file": "architecting-for-scale.txt",
    "text": "cy, or set up a quicker disk for making builds potentially faster.\n\nFor instance, if you would like to move builds under a different root, you can use the following value: `+$JENKINS_VAR/${ITEM_FULL_NAME}/builds+`.\n\nNote that starting with Jenkins 2.119, the User Interface for this was replaced by the `jenkins.model.Jenkins.buildsDir` system property. See the  for more details.\n\nAll of your Jenkin"
  },
  "352": {
    "source_file": "architecting-for-scale.txt",
    "text": "119, the User Interface for this was replaced by the `jenkins.model.Jenkins.buildsDir` system property. See the  for more details.\n\nAll of your Jenkins-specific configurations that need to be backed up will live\nin the _$JENKINS_HOME_, but it is a best practice to back up only a subset of\nthose files and folders.\n\nBelow are a few guidelines to consider when planning your backup strategy.\n\n.Exclusi"
  },
  "353": {
    "source_file": "architecting-for-scale.txt",
    "text": "st practice to back up only a subset of\nthose files and folders.\n\nBelow are a few guidelines to consider when planning your backup strategy.\n\n.Exclusions\n\nWhen it comes to creating a backup, it is recommended to exclude archiving the\nfollowing folders to reduce the size of your backup:\n\n[literal]\n/war      (the exploded Jenkins war directory)\n/cache    (downloaded tools)\n/tools    (extracted tools"
  },
  "354": {
    "source_file": "architecting-for-scale.txt",
    "text": "s to reduce the size of your backup:\n\n[literal]\n/war      (the exploded Jenkins war directory)\n/cache    (downloaded tools)\n/tools    (extracted tools)\n\nThese folders will automatically be recreated the next time a build runs or\nJenkins is launched.\n\n.Jobs and Folders\n\nYour job or folder configurations, build histories, archived artifacts, and\nworkspace will exist entirely within the _jobs_ folder"
  },
  "355": {
    "source_file": "architecting-for-scale.txt",
    "text": "\n.Jobs and Folders\n\nYour job or folder configurations, build histories, archived artifacts, and\nworkspace will exist entirely within the _jobs_ folder.\n\nThe _jobs_ directory, whether nested within a folder or at the root level is as\nfollows:\n\n +- jobs           (root directory for all Jenkins jobs)\n     +- [JOBNAME]      (sub directory for each job)\n         +- config.xml     (job configuration fi"
  },
  "356": {
    "source_file": "architecting-for-scale.txt",
    "text": "s           (root directory for all Jenkins jobs)\n     +- [JOBNAME]      (sub directory for each job)\n         +- config.xml     (job configuration file)\n         +- workspace      (working directory for the version control system)\n         +- latest         (symbolic link to the last successful build)\n         +- builds         (stores past build records)\n             +- [BUILD_ID]     (subdirect"
  },
  "357": {
    "source_file": "architecting-for-scale.txt",
    "text": "         (symbolic link to the last successful build)\n         +- builds         (stores past build records)\n             +- [BUILD_ID]     (subdirectory for each build)\n                 +- build.xml      (build result summary)\n                 +- log            (log file)\n                 +- changelog.xml  (change log)\n\nIf you only need to backup your job configurations, you can opt to only backu"
  },
  "358": {
    "source_file": "architecting-for-scale.txt",
    "text": "g            (log file)\n                 +- changelog.xml  (change log)\n\nIf you only need to backup your job configurations, you can opt to only backup\nthe _config.xml_ for each job. Generally build records and workspaces do not\nneed to be backed up, as workspaces will be re-created when a job is run and\nbuild records are only as important as your organizations deems them.\n\n.System configurations\n"
  },
  "359": {
    "source_file": "architecting-for-scale.txt",
    "text": " as workspaces will be re-created when a job is run and\nbuild records are only as important as your organizations deems them.\n\n.System configurations\n\nYour controller's system configurations exist in the root level of the\n_$JENKINS_HOME_ folder:\n\n[literal]\n +- config.xml     (Jenkins root configuration file)\n +- *.xml          (other site-wide configuration files)\n\nThe _config.xml_ is the root con"
  },
  "360": {
    "source_file": "architecting-for-scale.txt",
    "text": "teral]\n +- config.xml     (Jenkins root configuration file)\n +- *.xml          (other site-wide configuration files)\n\nThe _config.xml_ is the root configuration file for your Jenkins. It includes\nconfigurations for the paths of installed tools, workspace directory, and\nagent port.\n\nAny .xml other than that _config.xml_ in the root Jenkins folder is a global\nconfiguration file for an installed tool"
  },
  "361": {
    "source_file": "architecting-for-scale.txt",
    "text": "pace directory, and\nagent port.\n\nAny .xml other than that _config.xml_ in the root Jenkins folder is a global\nconfiguration file for an installed tool or plugin (i.e. Maven, Git, Ant, etc).\nThis includes the _credentials.xml_ if the Credentials plugin is installed.\n\nIf you only want to backup your core Jenkins configuration, you only need to\nback up the _config.xml_.\n\n.Plugins\n\nYour deployment's p"
  },
  "362": {
    "source_file": "architecting-for-scale.txt",
    "text": "n is installed.\n\nIf you only want to backup your core Jenkins configuration, you only need to\nback up the _config.xml_.\n\n.Plugins\n\nYour deployment's plugin files (.hpi and .jpi) and any of their dependent\nresources (help files, _pom.xml_ files, etc) will exist in the _plugins_ folder\nin $JENKINS_HOME.\n\n[literal]\n +- plugins        (root directory for all Jenkins plugins)\n     +- [PLUGINNAME]     ("
  },
  "363": {
    "source_file": "architecting-for-scale.txt",
    "text": "will exist in the _plugins_ folder\nin $JENKINS_HOME.\n\n[literal]\n +- plugins        (root directory for all Jenkins plugins)\n     +- [PLUGINNAME]     (sub directory for each plugin)\n         +- META-INF       (subdirectory for plugin manifest + pom.xml)\n         +- WEB-INF        (subdirectory for plugin jar(s) and licenses.xml)\n     +- [PLUGINNAME].jpi (.jpi or .hpi file for the plugin)\n\nIt is rec"
  },
  "364": {
    "source_file": "architecting-for-scale.txt",
    "text": "l)\n         +- WEB-INF        (subdirectory for plugin jar(s) and licenses.xml)\n     +- [PLUGINNAME].jpi (.jpi or .hpi file for the plugin)\n\nIt is recommended to back up the entirety of the plugins folder (.hpi/.jpis + folders).\n\n.Other data\n\nOther data that you are recommended to back up include the contents of your\n_secrets_ folder, your _identity.key_, your _secret.key_, and your\n_secret.key.no"
  },
  "365": {
    "source_file": "architecting-for-scale.txt",
    "text": "ata that you are recommended to back up include the contents of your\n_secrets_ folder, your _identity.key_, your _secret.key_, and your\n_secret.key.not-so-secret_ file.\n\n[literal]\n +- secret.key     (used for various secure Jenkins operations)\n +- secret.key.not-so-secret  (used for validating _$JENKINS_HOME_ creation date)\n +- userContent    (files served in https://server/userContent/)\n +- secre"
  },
  "366": {
    "source_file": "architecting-for-scale.txt",
    "text": "cret.key.not-so-secret  (used for validating _$JENKINS_HOME_ creation date)\n +- userContent    (files served in https://server/userContent/)\n +- secrets        (directory for the secret+key decryption)\n     +- hudson.util.Secret   (used for encrypting some Jenkins data)\n     +- master.key           (used for encrypting the hudson.util.Secret key)\n     +- InstanceIdentity.KEY (used to identity this"
  },
  "367": {
    "source_file": "architecting-for-scale.txt",
    "text": "g some Jenkins data)\n     +- master.key           (used for encrypting the hudson.util.Secret key)\n     +- InstanceIdentity.KEY (used to identity this instance)\n     +- jenkins.model.Jenkins.crumbSalt   (used for encrypting some Jenkins data)\n     +- initialAdminPassword (used for initial login)\n\nThe _identity.key_ is an RSA key pair that identifies and authenticates the\ncurrent Jenkins controller"
  },
  "368": {
    "source_file": "architecting-for-scale.txt",
    "text": " initialAdminPassword (used for initial login)\n\nThe _identity.key_ is an RSA key pair that identifies and authenticates the\ncurrent Jenkins controller.\n\nThe _secret.key_ is used to encrypt plugin and other Jenkins data, and to\nestablish a secure connection between a controller and agent.\n\nThe _secret.key.not-so-secret_ file is used to validate when the\n_$JENKINS_HOME_ was created. It is also meant"
  },
  "369": {
    "source_file": "architecting-for-scale.txt",
    "text": "ection between a controller and agent.\n\nThe _secret.key.not-so-secret_ file is used to validate when the\n_$JENKINS_HOME_ was created. It is also meant to be a flag that the secret.key\nfile is a deprecated way of encrypting information.\n\nThe files in the secrets folder are used by Jenkins to encrypt and decrypt your\ncontroller's stored credentials, if any exist. Loss of these files will prevent\nrec"
  },
  "370": {
    "source_file": "architecting-for-scale.txt",
    "text": "the secrets folder are used by Jenkins to encrypt and decrypt your\ncontroller's stored credentials, if any exist. Loss of these files will prevent\nrecovery of any stored credentials. _hudson.util.Secret_ is used for encrypting\nsome Jenkins data like the credentials.xml, while the _master.key_ is used for\nencrypting the hudson.util.Secret key. Finally, the _InstanceIdentity.KEY_ is\nused to identity"
  },
  "371": {
    "source_file": "architecting-for-scale.txt",
    "text": "the credentials.xml, while the _master.key_ is used for\nencrypting the hudson.util.Secret key. Finally, the _InstanceIdentity.KEY_ is\nused to identity this controller and for producing digital signatures.\n\nIn the case of a total machine failure, it is important to ensure that there is\na plan in place to get Jenkins both back online and in its last good state.\n\nIf a high availability set up has not"
  },
  "372": {
    "source_file": "architecting-for-scale.txt",
    "text": "s important to ensure that there is\na plan in place to get Jenkins both back online and in its last good state.\n\nIf a high availability set up has not been enabled and no back up of that\ncontroller's filesystem has been taken, then an corruption of a machine running\nJenkins means that all historical build data and artifacts, job and system\nconfigurations, etc. will be lost and the lost configurati"
  },
  "373": {
    "source_file": "architecting-for-scale.txt",
    "text": " machine running\nJenkins means that all historical build data and artifacts, job and system\nconfigurations, etc. will be lost and the lost configurations will need to be\nrecreated on a new controller.\n\n1. Backup policy - In addition to creating backups using the previous section's\n   backup guide, it is important to establish a policy for selecting which backup\n   should be used when restoring a d"
  },
  "374": {
    "source_file": "architecting-for-scale.txt",
    "text": "ps using the previous section's\n   backup guide, it is important to establish a policy for selecting which backup\n   should be used when restoring a downed controller.\n2. Restoring from a backup - A plan must be put in place on whether the backup\n   should be restored manually or with scripts when the primary goes down.\n\nAdministrators are constantly adding more and more teams to the software\nfact"
  },
  "375": {
    "source_file": "architecting-for-scale.txt",
    "text": "should be restored manually or with scripts when the primary goes down.\n\nAdministrators are constantly adding more and more teams to the software\nfactory, making administrators in the business of making their controllers\nresilient to failures and scaling them in order to onboard more teams.\n\nAdding build nodes to a Jenkins controller while beefing up the machine that runs\nthe Jenkins controller is"
  },
  "376": {
    "source_file": "architecting-for-scale.txt",
    "text": "ling them in order to onboard more teams.\n\nAdding build nodes to a Jenkins controller while beefing up the machine that runs\nthe Jenkins controller is the typical way to scale Jenkins. Said differently,\nadministrators scale their Jenkins controller vertically. However, there is a limit\nto how much a controller can be scaled. These limitations are covered in the\nintroduction to this chapter.\n\nIdeal"
  },
  "377": {
    "source_file": "architecting-for-scale.txt",
    "text": "ertically. However, there is a limit\nto how much a controller can be scaled. These limitations are covered in the\nintroduction to this chapter.\n\nIdeally, controllers will be set up to automatically recover from failures without\nhuman intervention. There are proxy servers monitoring active controllers and\nre-routing requests to backup controllers if the active controller goes down. There are\nadditi"
  },
  "378": {
    "source_file": "architecting-for-scale.txt",
    "text": "ere are proxy servers monitoring active controllers and\nre-routing requests to backup controllers if the active controller goes down. There are\nadditional factors that should be reviewed on the path to continuous delivery.\nThese factors include componetizing the application under development,\nautomating the entire pipeline (within reasonable limits) and freeing up\ncontentious resources.\n\n.Step 1: "
  },
  "379": {
    "source_file": "architecting-for-scale.txt",
    "text": "netizing the application under development,\nautomating the entire pipeline (within reasonable limits) and freeing up\ncontentious resources.\n\n.Step 1: Make each controller highly available\n\nEach Jenkins controller needs to be set up such that it is part of a Jenkins cluster.\n\nA proxy (typically HAProxy or F5) then fronts the primary controller. The proxy's\njob is to continuously monitor the primary"
  },
  "380": {
    "source_file": "architecting-for-scale.txt",
    "text": "rt of a Jenkins cluster.\n\nA proxy (typically HAProxy or F5) then fronts the primary controller. The proxy's\njob is to continuously monitor the primary controller and route requests to the\nbackup if the primary goes down. To make the infrastructure more resilient, you\ncan have multiple backup controllers configured.\n\n.Step 2: Enable security\n\nSet up an authentication realm that Jenkins will use for"
  },
  "381": {
    "source_file": "architecting-for-scale.txt",
    "text": "re resilient, you\ncan have multiple backup controllers configured.\n\n.Step 2: Enable security\n\nSet up an authentication realm that Jenkins will use for its user database.\n\nTIP: If you are trying to set up a proof-of-concept, it is recommended to use\nthe plugin:mock-security-realm[Mock Security Realm plugin] for authentication.\n\n.Step 3: Add build nodes (agents) to controller\n\nAdd build servers to y"
  },
  "382": {
    "source_file": "architecting-for-scale.txt",
    "text": "he plugin:mock-security-realm[Mock Security Realm plugin] for authentication.\n\n.Step 3: Add build nodes (agents) to controller\n\nAdd build servers to your controller to ensure you are conducting actual build\nexecution off of the controller, which is meant to be an orchestration hub, and\nonto a \"dumb\" machine with sufficient memory and I/O for a given job or test.\n\n.Step 4: Setup a test controller\n\n"
  },
  "383": {
    "source_file": "architecting-for-scale.txt",
    "text": "eant to be an orchestration hub, and\nonto a \"dumb\" machine with sufficient memory and I/O for a given job or test.\n\n.Step 4: Setup a test controller\n\nA test controller is typically used to test new plugin updates. When a plugin is\nready to be used, it should be installed into the main production update\ncenter."
  },
  "384": {
    "source_file": "architecting-for-scale.txt",
    "text": "t should be installed into the main production update\ncenter."
  },
  "385": {
    "source_file": "artifact-repository.txt",
    "text": "title: Artifact Repository\nlayout: developersection\n\n\nThe Jenkins project uses its own Artifactory binary repository, to distribute core, library, and plugin releases.\nOnly artifacts uploaded there can be considered released.\nPlugins and libraries are not uploaded or mirrored to Maven Central.\nThe Jenkins Artifactory is hosted at https://repo.jenkins-ci.org.\n\n* Anyone has permission to view and do"
  },
  "386": {
    "source_file": "artifact-repository.txt",
    "text": "e not uploaded or mirrored to Maven Central.\nThe Jenkins Artifactory is hosted at https://repo.jenkins-ci.org.\n\n* Anyone has permission to view and download all (public) artifacts.\n* Permission to upload/deploy artifacts is controlled via .\n** See  for information about requesting permissions\n\nPermission to delete artifacts is not granted to anyone but administrators.\nDo not expect them to delete "
  },
  "387": {
    "source_file": "artifact-repository.txt",
    "text": "or information about requesting permissions\n\nPermission to delete artifacts is not granted to anyone but administrators.\nDo not expect them to delete even broken or accidental releases on request unless leaving it up puts Jenkins users or project infrastructure at risk.\nPlease report such an exceptional situation as .\n\nIf a specific plugin or specific releases of a plugin should not be published o"
  },
  "388": {
    "source_file": "artifact-repository.txt",
    "text": "rastructure at risk.\nPlease report such an exceptional situation as .\n\nIf a specific plugin or specific releases of a plugin should not be published on update sites, see  for instructions how to do that.\nNote that this will not prevent anyone from directly downloading the artifacts from Artifactory."
  },
  "389": {
    "source_file": "artifact-repository.txt",
    "text": "rectly downloading the artifacts from Artifactory."
  },
  "390": {
    "source_file": "authenticating-scripted-clients.txt",
    "text": "layout: section\n\n\nifndef::env-github[:imagesdir: ../../resources]\n\nTo make scripted clients (such as wget) invoke operations that require\nauthorization (such as scheduling a build), use HTTP BASIC\nauthentication to specify the user name and the API token.\n\nEarlier versions of Jenkins require you to specify your real password,\nand it is only available when your security realm is password-based (for"
  },
  "391": {
    "source_file": "authenticating-scripted-clients.txt",
    "text": "oken.\n\nEarlier versions of Jenkins require you to specify your real password,\nand it is only available when your security realm is password-based (for\nexample, OpenID, Crowd and CAS plugins authenticate you without a\npassword, so you simply don't have any password!) Specifying the real\npassword is still supported, but it is not recommended\nbecause the risk of revealing password, and the human tend"
  },
  "392": {
    "source_file": "authenticating-scripted-clients.txt",
    "text": "e any password!) Specifying the real\npassword is still supported, but it is not recommended\nbecause the risk of revealing password, and the human tendency to reuse\nthe same password in different places.\n\nThe API token is available in your personal configuration page.\nClick your name on the top right corner on every page,\nthen click \"Configure\" to see your API token.\n(The URL `+$root/me/configure+`"
  },
  "393": {
    "source_file": "authenticating-scripted-clients.txt",
    "text": "nfiguration page.\nClick your name on the top right corner on every page,\nthen click \"Configure\" to see your API token.\n(The URL `+$root/me/configure+` is a good shortcut.)\nYou can also change your API token from here.\n\nNote that Jenkins does not do any authorization negotiation.\ni.e. it immediately returns a 403 (Forbidden) response instead\nof a 401 (Unauthorized) response, so make sure to send th"
  },
  "394": {
    "source_file": "authenticating-scripted-clients.txt",
    "text": "ny authorization negotiation.\ni.e. it immediately returns a 403 (Forbidden) response instead\nof a 401 (Unauthorized) response, so make sure to send the authentication\ninformation from the first request (aka \"preemptive authentication\").\n\nThe `curl` command is available for most operating systems including Linux, macOS, Windows, FreeBSD, and more.\n\ncurl -X POST -L --user your-user-name:apiToken \\\n "
  },
  "395": {
    "source_file": "authenticating-scripted-clients.txt",
    "text": "ommand is available for most operating systems including Linux, macOS, Windows, FreeBSD, and more.\n\ncurl -X POST -L --user your-user-name:apiToken \\\n    https://jenkins.example.com/job/your_job/build\n\nNOTE: The `wget` command needs the `--auth-no-challenge` option\nto authenticate to Jenkins:\n\nwget --auth-no-challenge \\\n    --user=user --password=apiToken \\\n    http://jenkins.example.com/job/your_j"
  },
  "396": {
    "source_file": "authenticating-scripted-clients.txt",
    "text": "llenge` option\nto authenticate to Jenkins:\n\nwget --auth-no-challenge \\\n    --user=user --password=apiToken \\\n    http://jenkins.example.com/job/your_job/build\n\nThe https://github.com/cdancy/jenkins-rest[cdancy/jenkins-rest client]\ngreatly simplifies REST API access.\nThe following Groovy code shows how to authenticate to Jenkins and get some system info:\n\n@Grab(group='com.cdancy', module='jenkins-r"
  },
  "397": {
    "source_file": "authenticating-scripted-clients.txt",
    "text": "REST API access.\nThe following Groovy code shows how to authenticate to Jenkins and get some system info:\n\n@Grab(group='com.cdancy', module='jenkins-rest', version='0.0.18')\n\nimport com.cdancy.jenkins.rest.JenkinsClient\n\nJenkinsClient client = JenkinsClient.builder()\n    .endPoint(\"http://127.0.0.1:8080\") // Optional. Defaults to http://127.0.0.1:8080\n    .credentials(\"user:apiToken\") // Optional."
  },
  "398": {
    "source_file": "authenticating-scripted-clients.txt",
    "text": "sClient.builder()\n    .endPoint(\"http://127.0.0.1:8080\") // Optional. Defaults to http://127.0.0.1:8080\n    .credentials(\"user:apiToken\") // Optional.\n    .build()\n\nprintln(client.api().systemApi().systemInfo())\n\nFor additional information, see the\nhttps://github.com/cdancy/jenkins-rest/wiki[cdancy/jenkins-rest wiki].\n\nThe following code shows how to create a job\n\nconst credentials = `myusername:m"
  },
  "399": {
    "source_file": "authenticating-scripted-clients.txt",
    "text": "ttps://github.com/cdancy/jenkins-rest/wiki[cdancy/jenkins-rest wiki].\n\nThe following code shows how to create a job\n\nconst credentials = `myusername:myapitoken`;\nconst baseJenkinsUrl = \"http://myjenkins:8080\";\nasync function getCrumb() {\n    return axios({\n      method: \"get\",\n      url: baseJenkinsUrl + \"/crumbIssuer/api/json\",\n      withCredentials: false,\n    });\n  }\ngetCrumb().then((response: "
  },
  "400": {
    "source_file": "authenticating-scripted-clients.txt",
    "text": "xios({\n      method: \"get\",\n      url: baseJenkinsUrl + \"/crumbIssuer/api/json\",\n      withCredentials: false,\n    });\n  }\ngetCrumb().then((response: any) => {\n      let crumb = response.data;\n     const base64Credentials = btoa(credentials);\n    const authHeader = `Basic ${base64Credentials}`;\n    // Create new job\n    const requestConfig: AxiosRequestConfig = {\n      method: \"post\",\n      url: `"
  },
  "401": {
    "source_file": "authenticating-scripted-clients.txt",
    "text": "st authHeader = `Basic ${base64Credentials}`;\n    // Create new job\n    const requestConfig: AxiosRequestConfig = {\n      method: \"post\",\n      url: `${baseJenkinsUrl}/createItem?name=${jobName}`,\n      headers: {\n        Authorization: authHeader,\n        [crumb.crumbRequestField]: crumb.crumb,\n        \"Content-Type\": \"application/xml\",\n      },\n      data: xmlconfig,\n    };\n    axios(requestConf"
  },
  "402": {
    "source_file": "authenticating-scripted-clients.txt",
    "text": "       [crumb.crumbRequestField]: crumb.crumb,\n        \"Content-Type\": \"application/xml\",\n      },\n      data: xmlconfig,\n    };\n    axios(requestConfig);\n});\n\n[[Authenticatingscriptedclients-PerlLWPexampleforascriptedclient]]\n\nThe following Perl example uses the LWP module to start a Job via a\n\"Trigger builds remotely\" token:\n\n#\n# Use LWP to run a Jenkins job\n# set authorization_basic on the requ"
  },
  "403": {
    "source_file": "authenticating-scripted-clients.txt",
    "text": "mple uses the LWP module to start a Job via a\n\"Trigger builds remotely\" token:\n\n#\n# Use LWP to run a Jenkins job\n# set authorization_basic on the request object\n# to make use of BASIC HTTP authorization, apparently\n# already handling the preemptive part correctly this\n# way.\n#\nuse strict;\nuse warnings;\n\nuse LWP;\n\nmy $server = 'srvname';\nmy $srvurl = \"http://$server/jenkins\";\nmy $uagent = LWP::User"
  },
  "404": {
    "source_file": "authenticating-scripted-clients.txt",
    "text": "art correctly this\n# way.\n#\nuse strict;\nuse warnings;\n\nuse LWP;\n\nmy $server = 'srvname';\nmy $srvurl = \"http://$server/jenkins\";\nmy $uagent = LWP::UserAgent->new;\nmy $req = HTTP::Request->new(\n  GET => \"$srvurl/job/test/build?token=theTokenConfiguredForThisJob&cause=LWP+Test\"\n);\n$req->authorization_basic('username@mydomain.com', 'apiToken');\nmy $res = $uagent->request($req);\n\n# Check the outcome of"
  },
  "405": {
    "source_file": "authenticating-scripted-clients.txt",
    "text": "orThisJob&cause=LWP+Test\"\n);\n$req->authorization_basic('username@mydomain.com', 'apiToken');\nmy $res = $uagent->request($req);\n\n# Check the outcome of the response\nprint \"Result: \" . $res->status_line . \"\\n\";\nprint $res->headers->as_string;\nprint \"\\n\";\nif (!$res->is_success) {\n  print \"Failed\\n\";\n}\nelse {\n  print \"Success!\\n\";\n  # print $res->content, \"\\n\";\n}\n\n[[Authenticatingscriptedclients-Javae"
  },
  "406": {
    "source_file": "authenticating-scripted-clients.txt",
    "text": "\";\nif (!$res->is_success) {\n  print \"Failed\\n\";\n}\nelse {\n  print \"Success!\\n\";\n  # print $res->content, \"\\n\";\n}\n\n[[Authenticatingscriptedclients-Javaexamplewithhttpclient4.3.x]]\n\nThis will cause httpclient 4.3 to issue authentication preemptively:\n\nimport java.io.IOException;\nimport java.net.URI;\n\nimport org.apache.http.HttpHost;\nimport org.apache.http.HttpResponse;\nimport org.apache.http.auth.Aut"
  },
  "407": {
    "source_file": "authenticating-scripted-clients.txt",
    "text": "mport java.io.IOException;\nimport java.net.URI;\n\nimport org.apache.http.HttpHost;\nimport org.apache.http.HttpResponse;\nimport org.apache.http.auth.AuthScope;\nimport org.apache.http.auth.UsernamePasswordCredentials;\nimport org.apache.http.client.AuthCache;\nimport org.apache.http.client.ClientProtocolException;\nimport org.apache.http.client.CredentialsProvider;\nimport org.apache.http.client.methods."
  },
  "408": {
    "source_file": "authenticating-scripted-clients.txt",
    "text": "ache;\nimport org.apache.http.client.ClientProtocolException;\nimport org.apache.http.client.CredentialsProvider;\nimport org.apache.http.client.methods.HttpGet;\nimport org.apache.http.client.protocol.HttpClientContext;\nimport org.apache.http.impl.auth.BasicScheme;\nimport org.apache.http.impl.client.BasicAuthCache;\nimport org.apache.http.impl.client.BasicCredentialsProvider;\nimport org.apache.http.im"
  },
  "409": {
    "source_file": "authenticating-scripted-clients.txt",
    "text": "BasicScheme;\nimport org.apache.http.impl.client.BasicAuthCache;\nimport org.apache.http.impl.client.BasicCredentialsProvider;\nimport org.apache.http.impl.client.CloseableHttpClient;\nimport org.apache.http.impl.client.HttpClients;\nimport org.apache.http.util.EntityUtils;\n\npublic class JenkinsScraper {\n\n    public String scrape(String urlString, String username, String password)\n        throws Client"
  },
  "410": {
    "source_file": "authenticating-scripted-clients.txt",
    "text": "p.util.EntityUtils;\n\npublic class JenkinsScraper {\n\n    public String scrape(String urlString, String username, String password)\n        throws ClientProtocolException, IOException {\n        URI uri = URI.create(urlString);\n        HttpHost host = new HttpHost(uri.getHost(), uri.getPort(), uri.getScheme());\n        CredentialsProvider credsProvider = new BasicCredentialsProvider();\n        credsPr"
  },
  "411": {
    "source_file": "authenticating-scripted-clients.txt",
    "text": "w HttpHost(uri.getHost(), uri.getPort(), uri.getScheme());\n        CredentialsProvider credsProvider = new BasicCredentialsProvider();\n        credsProvider.setCredentials(new AuthScope(uri.getHost(), uri.getPort()),\n            new UsernamePasswordCredentials(username, password));\n        // Create AuthCache instance\n        AuthCache authCache = new BasicAuthCache();\n        // Generate BASIC sc"
  },
  "412": {
    "source_file": "authenticating-scripted-clients.txt",
    "text": "redentials(username, password));\n        // Create AuthCache instance\n        AuthCache authCache = new BasicAuthCache();\n        // Generate BASIC scheme object and add it to the local auth cache\n        BasicScheme basicAuth = new BasicScheme();\n        authCache.put(host, basicAuth);\n        CloseableHttpClient httpClient =\n            HttpClients.custom().setDefaultCredentialsProvider(credsPro"
  },
  "413": {
    "source_file": "authenticating-scripted-clients.txt",
    "text": "      authCache.put(host, basicAuth);\n        CloseableHttpClient httpClient =\n            HttpClients.custom().setDefaultCredentialsProvider(credsProvider).build();\n        HttpGet httpGet = new HttpGet(uri);\n        // Add AuthCache to the execution context\n        HttpClientContext localContext = HttpClientContext.create();\n        localContext.setAuthCache(authCache);\n\n        HttpResponse res"
  },
  "414": {
    "source_file": "authenticating-scripted-clients.txt",
    "text": "n context\n        HttpClientContext localContext = HttpClientContext.create();\n        localContext.setAuthCache(authCache);\n\n        HttpResponse response = httpClient.execute(host, httpGet, localContext);\n\n        return EntityUtils.toString(response.getEntity());\n    }\n\n}"
  },
  "415": {
    "source_file": "authenticating-scripted-clients.txt",
    "text": "se.getEntity());\n    }\n\n}"
  },
  "416": {
    "source_file": "automate-dependency-update-checks.txt",
    "text": "layout: developersection\ntitle: Check dependencies\n\n\n.Automate dependency checks with dependabot\nvideo::2c8wK2jkcIA[youtube,width=800,height=420,start=980]\n\nJenkins plugins frequently depend on external libraries and other plugins.\nAutomatic dependency checks help assure that new releases of dependencies are reviewed by plugin maintainers.\n\nThe GitHub `dependabot` tool can be configured to periodi"
  },
  "417": {
    "source_file": "automate-dependency-update-checks.txt",
    "text": "cy checks help assure that new releases of dependencies are reviewed by plugin maintainers.\n\nThe GitHub `dependabot` tool can be configured to periodically check for new releases of dependencies.\nWhen a new release is detected, dependabot submits a pull request to include that update in the plugin pom file.\n\nSee the  for more details on dependabot with Jenkins.\n\n// Create the branch\n\nAutomated dep"
  },
  "418": {
    "source_file": "automate-dependency-update-checks.txt",
    "text": "ull request to include that update in the plugin pom file.\n\nSee the  for more details on dependabot with Jenkins.\n\n// Create the branch\n\nAutomated dependency checks by dependabot are defined in a .github/dependabot.yml file.\n\nmkdir .github\ncat > .github/dependabot.yml <<END-OF-HERE-DOC\n# https://docs.github.com/code-security/dependabot/dependabot-version-updates/configuring-dependabot-version-upda"
  },
  "419": {
    "source_file": "automate-dependency-update-checks.txt",
    "text": "hub/dependabot.yml <<END-OF-HERE-DOC\n# https://docs.github.com/code-security/dependabot/dependabot-version-updates/configuring-dependabot-version-updates\n\nversion: 2\nupdates:\n- package-ecosystem: maven\n  directory: /\n  schedule:\n    interval: monthly\n- package-ecosystem: github-actions\n  directory: /\n  schedule:\n    interval: monthly\nEND-OF-HERE-DOC\n\nCommit the file and push it to GitHub with the "
  },
  "420": {
    "source_file": "automate-dependency-update-checks.txt",
    "text": "\n- package-ecosystem: github-actions\n  directory: /\n  schedule:\n    interval: monthly\nEND-OF-HERE-DOC\n\nCommit the file and push it to GitHub with the commands:\n\n// Create a pull request"
  },
  "421": {
    "source_file": "backing-up.txt",
    "text": "layout: section\n\n\nHaving good backups of your Jenkins controller is critically important.\nBackups are used for:\n\n* Disaster recovery.\n* Recovering an older configuration (an accidental configuration change may not be discovered for some time).\n* Recovering a file that is corrupted or was deleted accidentally.\n\nThis page discusses the following:\n\n* How to create a backup\n* Files that should be back"
  },
  "422": {
    "source_file": "backing-up.txt",
    "text": "vering a file that is corrupted or was deleted accidentally.\n\nThis page discusses the following:\n\n* How to create a backup\n* Files that should be backed up\n* How to validate a backup to ensure that it is usable\n\nVarious schemes can be used to create backups.\nThese are discussed in this section:\n\n* Filesystem snapshots\n* Plugins for backup\n* Write a shell script that backs up the Jenkins controller"
  },
  "423": {
    "source_file": "backing-up.txt",
    "text": "backups.\nThese are discussed in this section:\n\n* Filesystem snapshots\n* Plugins for backup\n* Write a shell script that backs up the Jenkins controller\n\nFilesystem snapshots provide maximum consistency for backups.\nThey also run faster than live backups,\nreducing the possibility of copying different data at different time points.\nThey are supported by:\n\n* The Linux Logical Volume Manager (LVM)\n* Li"
  },
  "424": {
    "source_file": "backing-up.txt",
    "text": "ps,\nreducing the possibility of copying different data at different time points.\nThey are supported by:\n\n* The Linux Logical Volume Manager (LVM)\n* Linux btrfs\n* Solaris ZFS (which also supports incremental backups)\n* FreeBSD ZFS\n* OpenZFS on Linux\n* Some other file system architectures\n* Many cloud providers\n* Some separate storage devices also let you create snapshots at the storage level.\n\nSeve"
  },
  "425": {
    "source_file": "backing-up.txt",
    "text": " Some other file system architectures\n* Many cloud providers\n* Some separate storage devices also let you create snapshots at the storage level.\n\nSeveral plugins are available for backup.\nFrom the main menu select _Manage Jenkins_, then go to _Plugins>Available_ and search for **backup**.\nNote that only the  of the open source plugins is currently being maintained.\nYou can try the other plugins bu"
  },
  "426": {
    "source_file": "backing-up.txt",
    "text": "s>Available_ and search for **backup**.\nNote that only the  of the open source plugins is currently being maintained.\nYou can try the other plugins but you may have problems with them.\n\nYou can write your own shell script that copies the appropriate files and directories to a backup location.\nUse\nto schedule when the backup script runs.\n\nThe shell script should create a directory such as `/mnt/bac"
  },
  "427": {
    "source_file": "backing-up.txt",
    "text": "files and directories to a backup location.\nUse\nto schedule when the backup script runs.\n\nThe shell script should create a directory such as `/mnt/backup`\nto which the backup will be written;\nbe sure that you have write permissions to that directory.\nConsider creating `/mnt/backup` as a separate filesystem with its own mount point.\nAn alternative method is to create a subdirectory in `/var`.\nNote "
  },
  "428": {
    "source_file": "backing-up.txt",
    "text": "\nConsider creating `/mnt/backup` as a separate filesystem with its own mount point.\nAn alternative method is to create a subdirectory in `/var`.\nNote that if you use this method,\nyou might need to use the **sudo** command to execute the restore operation.\nBacking up to `/tmp` is not advised because `/tmp` may be cleaned on reboot.\n\nCreate a unique identifier for each backup (use a timestamp, for e"
  },
  "429": {
    "source_file": "backing-up.txt",
    "text": "tion.\nBacking up to `/tmp` is not advised because `/tmp` may be cleaned on reboot.\n\nCreate a unique identifier for each backup (use a timestamp, for example)\nto ensure that today's backup does not overwrite yesterday's backup.\n\nWriting files to a local file system is the fastest way to take the backup.\nConsider copying the completed backup to a remote backup server or device for long term storage."
  },
  "430": {
    "source_file": "backing-up.txt",
    "text": "al file system is the fastest way to take the backup.\nConsider copying the completed backup to a remote backup server or device for long term storage.\n\n*Never include the controller key in your Jenkins backup!*\n\nThe controller key is used to encrypt data in the _secrets_ directory that secures credentials.\nIt is stored in the _$JENKINS_HOME/secrets/hudson.util.Secret_ file\nin the _$JENKINS_HOME/se"
  },
  "431": {
    "source_file": "backing-up.txt",
    "text": "data in the _secrets_ directory that secures credentials.\nIt is stored in the _$JENKINS_HOME/secrets/hudson.util.Secret_ file\nin the _$JENKINS_HOME/secrets/_ directory and encrypted with `master.key`.\nIf you need to restore a system from a backup, you will need this file.\nAnd, if someone else accesses your backups and has this key, they have full access to all your information.\n\nYou should treat y"
  },
  "432": {
    "source_file": "backing-up.txt",
    "text": "u will need this file.\nAnd, if someone else accesses your backups and has this key, they have full access to all your information.\n\nYou should treat your controller key like you treat your SSH private key and NEVER include it in a regular backup.\nInstead, back up the `master.key` file separately and store it in a very secure location away from your other backups.\nIt is a very small file that is se"
  },
  "433": {
    "source_file": "backing-up.txt",
    "text": "tead, back up the `master.key` file separately and store it in a very secure location away from your other backups.\nIt is a very small file that is seldom changed.\nIf you need to do a full system restore, you will need to restore the rest of the system and then apply the backup of the `master.key` file separately.\n\nThe number of files you back up can affect both the time required to run the backup"
  },
  "434": {
    "source_file": "backing-up.txt",
    "text": "em and then apply the backup of the `master.key` file separately.\n\nThe number of files you back up can affect both the time required to run the backup and the size of the resulting backup.\nIt also impacts the complexity of restoring the system from the backup.\nHere we discuss why various files should be backed up\nand list some files that could safely be excluded from at least some backups.\n\nBackin"
  },
  "435": {
    "source_file": "backing-up.txt",
    "text": "he backup.\nHere we discuss why various files should be backed up\nand list some files that could safely be excluded from at least some backups.\n\nBacking up the entire `$JENKINS_HOME` directory\npreserves the entire Jenkins controller.\nTo restore the system, just copy the entire backup to the new system.\n\nNote, however, that `JENKINS_HOME` includes a number of files that do not really need to be back"
  },
  "436": {
    "source_file": "backing-up.txt",
    "text": "stem, just copy the entire backup to the new system.\n\nNote, however, that `JENKINS_HOME` includes a number of files that do not really need to be backed up.\nSelecting specific directories and files to back up yields smaller backups\nbut may require a greater effort to restore a system.\nOne approach is to back up different directories on different schedules.\n\nConfiguration files are stored directly "
  },
  "437": {
    "source_file": "backing-up.txt",
    "text": "greater effort to restore a system.\nOne approach is to back up different directories on different schedules.\n\nConfiguration files are stored directly in the `$JENKINS_HOME` directory.\n`./config.xml` is the main Jenkins configuration file.\nOther configuration files also have the `.xml` suffix.\nSpecify `$JENKINS_HOME/*.xml` to back up all configuration files.\n\nConfiguration files can also be stored "
  },
  "438": {
    "source_file": "backing-up.txt",
    "text": "guration files also have the `.xml` suffix.\nSpecify `$JENKINS_HOME/*.xml` to back up all configuration files.\n\nConfiguration files can also be stored in an SCM repository.\nThis keeps copies of all previous versions of each file\nthat can be retrieved using standard SCM facilities.\n\nThe `$JENKINS_HOME/jobs` directory contains information related\nto all the jobs you create in Jenkins.\n\n* **./builds**"
  },
  "439": {
    "source_file": "backing-up.txt",
    "text": "using standard SCM facilities.\n\nThe `$JENKINS_HOME/jobs` directory contains information related\nto all the jobs you create in Jenkins.\n\n* **./builds** -- Contains build records\n\n* **./builds/archive** -- Contains archived artifacts\n** Back this up if it is important to retain these artifacts long-term\n** These can be very large and may make your backups very large\n\n* **./workspace** -- Contains fi"
  },
  "440": {
    "source_file": "backing-up.txt",
    "text": " it is important to retain these artifacts long-term\n** These can be very large and may make your backups very large\n\n* **./workspace** -- Contains files checked out from the SCM\n** It is usually not necessary to back up these files. You can perform a clean checkout after restoring the system.\n\n* **./plugins/*.hpi** -- Plugin packages with specific versions used on your system\n\n* **./plugins/*.jpi"
  },
  "441": {
    "source_file": "backing-up.txt",
    "text": "a clean checkout after restoring the system.\n\n* **./plugins/*.hpi** -- Plugin packages with specific versions used on your system\n\n* **./plugins/*.jpi** -- Plugin packages with specific versions used on your system\n\nThe following files and directories\ndo not usually need to be included in every routine backup\nbecause you can download the latest version when you are restoring a system.\nHowever, som"
  },
  "442": {
    "source_file": "backing-up.txt",
    "text": "s\ndo not usually need to be included in every routine backup\nbecause you can download the latest version when you are restoring a system.\nHowever, some disaster recovery experts recommend against doing any upgrades\nwhile restoring the system,\nto avoid delays caused by compatibility issues that might arise.\nIf your disaster recovery plan specifies that you restore the system\nusing the same software"
  },
  "443": {
    "source_file": "backing-up.txt",
    "text": "d delays caused by compatibility issues that might arise.\nIf your disaster recovery plan specifies that you restore the system\nusing the same software versions that were previously running,\nyou can make an infrequent backup of the system and all downloaded tools\nand use that to restore the system..\n\n* **./war** -- Exploded `war` file\n** To restore a system, download the latest `war` file.\n\n* **./c"
  },
  "444": {
    "source_file": "backing-up.txt",
    "text": "loaded tools\nand use that to restore the system..\n\n* **./war** -- Exploded `war` file\n** To restore a system, download the latest `war` file.\n\n* **./cache** -- Downloaded tools\n** To restore a system, download the current version of the tools.\n\n* **./tools** -- Extracted tools\n** To restore a system, extract the tools again.\n\n* **./plugins/xxx** -- Subdirectories of installed plugins\n** These will"
  },
  "445": {
    "source_file": "backing-up.txt",
    "text": "/tools** -- Extracted tools\n** To restore a system, extract the tools again.\n\n* **./plugins/xxx** -- Subdirectories of installed plugins\n** These will be automatically populated on the next restart.\n\nYour backup strategy should include validation of each backup.\nYou do not want to learn that your backup is no good when you need it!\n\nA simple way to validate a full backup is to restore it to a temp"
  },
  "446": {
    "source_file": "backing-up.txt",
    "text": "each backup.\nYou do not want to learn that your backup is no good when you need it!\n\nA simple way to validate a full backup is to restore it to a temporary location.\nCreate a directory for the test validation (such as **/mnt/backup-test**)\nand restore the backup to that directory.\n\nSet $JENKINS_HOME to point to this directory,\nspecifying a random HTTP port so you do not collide with the real Jenki"
  },
  "447": {
    "source_file": "backing-up.txt",
    "text": "e the backup to that directory.\n\nSet $JENKINS_HOME to point to this directory,\nspecifying a random HTTP port so you do not collide with the real Jenkins controller:\n\nexport JENKINS_HOME=/mnt/backup-test\n\nNow execute the restored Jenkins controller:\n\njava -jar jenkins.war --httpPort=9999\n\n* Making backups is a Jenkins best practice.\n* Backups are critical for disaster recovery.\n* Always set up a ba"
  },
  "448": {
    "source_file": "backing-up.txt",
    "text": "java -jar jenkins.war --httpPort=9999\n\n* Making backups is a Jenkins best practice.\n* Backups are critical for disaster recovery.\n* Always set up a backup policy that defines:\n** The configurations and records that need to be saved from the controller\n** How often backups should be taken\n** Where backups should be stored\n* Validate your backups.\n** You should periodically check whether your backup"
  },
  "449": {
    "source_file": "backing-up.txt",
    "text": "r\n** How often backups should be taken\n** Where backups should be stored\n* Validate your backups.\n** You should periodically check whether your backups are intact\nand can be used to meet your recovery objectives.\n\nSome recommended readings on this subject:\n\n*\n*\n*"
  },
  "450": {
    "source_file": "backing-up.txt",
    "text": "bject:\n\n*\n*\n*"
  },
  "451": {
    "source_file": "backward-compatibility.txt",
    "text": "title: Backward Compatibility with XStream\nsummary: How to make object model changes with XStream while preserving backward compatibility.\nlayout: developersection\n\n\nPersistence is XML-based,\nand when the data is read back from disk and the XML does not contain data for a particular field,\nthe existing field value is left as-is.\n\"As-is\" normally means the JVM default value (0, `false`, `null`, etc"
  },
  "452": {
    "source_file": "backward-compatibility.txt",
    "text": "not contain data for a particular field,\nthe existing field value is left as-is.\n\"As-is\" normally means the JVM default value (0, `false`, `null`, etc.),\nbecause the persistence logic does not invoke your constructor to create your object as Java serialization would.\n\nThere are a few exceptions to this, where objects first create themselves and then load XML onto themselves.\nThese include https://"
  },
  "453": {
    "source_file": "backward-compatibility.txt",
    "text": "ialization would.\n\nThere are a few exceptions to this, where objects first create themselves and then load XML onto themselves.\nThese include https://javadoc.jenkins.io/jenkins/model/Jenkins.html[`Jenkins`] and https://javadoc.jenkins.io/hudson/model/Item.html[`Item`],\nbut these exceptions are limited to the root object of persistence.\nIn these exceptional cases, the values set in the constructor "
  },
  "454": {
    "source_file": "backward-compatibility.txt",
    "text": "/Item.html[`Item`],\nbut these exceptions are limited to the root object of persistence.\nIn these exceptional cases, the values set in the constructor will survive.\n\nIf you want to fill in your field with a non-trivial default value,\nyou can write a `readResolve` method, which gets invoked right after your object is resurrected from persistence.\n`readResolve` is called by XStream, but it is not par"
  },
  "455": {
    "source_file": "backward-compatibility.txt",
    "text": "readResolve` method, which gets invoked right after your object is resurrected from persistence.\n`readResolve` is called by XStream, but it is not part of the Jenkins class hierarchy, so there is no `@Override` annotation.\nJust put it right in your class alongside your fields. For example:\n\nprotected Object readResolve() {\n  if (gridBuilder == null) {\n    if (selectedJob != null) {\n      gridBuild"
  },
  "456": {
    "source_file": "backward-compatibility.txt",
    "text": "lass alongside your fields. For example:\n\nprotected Object readResolve() {\n  if (gridBuilder == null) {\n    if (selectedJob != null) {\n      gridBuilder = new DownstreamProjectGridBuilder(selectedJob);\n    }\n  }\n  return this;\n}\n\nIf you need to force the _Manage Old Data_ screen to list jobs, builds, etc. using your data in the old format so that it can be saved in the new format in bulk,\nyou cann"
  },
  "457": {
    "source_file": "backward-compatibility.txt",
    "text": " the _Manage Old Data_ screen to list jobs, builds, etc. using your data in the old format so that it can be saved in the new format in bulk,\nyou cannot use `readResolve`, since it will not notify this system of the problem.\nInstead you must create a static nested class called `ConverterImpl` extending `XStream2.PassthruConverter`,\nwhich should clean up the storage of your instance and finally cal"
  },
  "458": {
    "source_file": "backward-compatibility.txt",
    "text": " static nested class called `ConverterImpl` extending `XStream2.PassthruConverter`,\nwhich should clean up the storage of your instance and finally call `OldDataMonitor#report` to record the conversion.\n\nRemoving a field requires that you leave the field with the `transient` keyword.\nWhen Jenkins reads the old XML, XStream will set the value for this field,\nbut it will no longer be written back to "
  },
  "459": {
    "source_file": "backward-compatibility.txt",
    "text": "eld with the `transient` keyword.\nWhen Jenkins reads the old XML, XStream will set the value for this field,\nbut it will no longer be written back to XML when data is saved.\n\nRenaming a field is a combination of the above:\nmark your old field as `transient`, declare your new field, and then migrate the data from the old format to the new in your `readResolve` method:\n\nprotected transient Long myOb"
  },
  "460": {
    "source_file": "backward-compatibility.txt",
    "text": "nsient`, declare your new field, and then migrate the data from the old format to the new in your `readResolve` method:\n\nprotected transient Long myObjectId;\nprotected List<Long> myObjectIds;\n\nprotected Object readResolve() {\n  if (myObjectId != null) {\n   myObjectIds = Arrays.asList(myObjectId)\n  }\n  return this;\n}\n\n* You decide to extend a class and create new choosable classes; for example, add"
  },
  "461": {
    "source_file": "backward-compatibility.txt",
    "text": ") {\n   myObjectIds = Arrays.asList(myObjectId)\n  }\n  return this;\n}\n\n* You decide to extend a class and create new choosable classes; for example, adding additional browsers to an SCM plugin.\n* The old data structure looked like this when you had only one class `SCMBrowser`:\n<browser>\n  <url>http://example.com/</url>\n</browser>\n\n* Now you decide to add a new `NewSCMBrowser`. All your `SCMBrowsers`"
  },
  "462": {
    "source_file": "backward-compatibility.txt",
    "text": "y one class `SCMBrowser`:\n<browser>\n  <url>http://example.com/</url>\n</browser>\n\n* Now you decide to add a new `NewSCMBrowser`. All your `SCMBrowsers` extend `SCMBrowserBase` and your XML suddenly looks like this:\n<browser class=\"org.jenkinsci.plugins.foo.NewSCMBrowser\">\n  <url>http://example.com/</url>\n</browser>\n\nor\n<browser class=\"org.jenkinsci.plugins.foo.SCMBrowser\">\n  <url>http://example.com"
  },
  "463": {
    "source_file": "backward-compatibility.txt",
    "text": "s.foo.NewSCMBrowser\">\n  <url>http://example.com/</url>\n</browser>\n\nor\n<browser class=\"org.jenkinsci.plugins.foo.SCMBrowser\">\n  <url>http://example.com/</url>\n</browser>\n\n* With new jobs, no problem. Old jobs however will probably break.\n* In your `SCMBrowserBase` class add a `readResolve` method (see the ):\n// compatibility with earlier plugins\npublic Object readResolve() {\n  if (this.getClass() !"
  },
  "464": {
    "source_file": "backward-compatibility.txt",
    "text": "MBrowserBase` class add a `readResolve` method (see the ):\n// compatibility with earlier plugins\npublic Object readResolve() {\n  if (this.getClass() != SCMBrowserBase.class) {\n    return this;\n  }\n  // make sure to return the default SCMBrowser only if we no class is given in config.\n  try {\n    return new SCMBrowser(url.toExternalForm());\n  } catch (MalformedURLException e) {\n    throw new Runtim"
  },
  "465": {
    "source_file": "backward-compatibility.txt",
    "text": "if we no class is given in config.\n  try {\n    return new SCMBrowser(url.toExternalForm());\n  } catch (MalformedURLException e) {\n    throw new RuntimeException(e);\n  }\n}\n\nSometimes, you need to rename packages or class names.\nIf your serialization data includes a fully qualified class name (which happens, for example, if you have a collection of them),\nthen measures must be taken to maintain back"
  },
  "466": {
    "source_file": "backward-compatibility.txt",
    "text": "ata includes a fully qualified class name (which happens, for example, if you have a collection of them),\nthen measures must be taken to maintain backward compatibility.\n\nTo do this, use `XSTREAM2#addCompatibilityAlias(String, Class)` to register aliases.\nYou need to do this against the right XStream instance,\nas a few different instances are used to persist different parts of data.\n\n`Items#XSTREA"
  },
  "467": {
    "source_file": "backward-compatibility.txt",
    "text": "ases.\nYou need to do this against the right XStream instance,\nas a few different instances are used to persist different parts of data.\n\n`Items#XSTREAM2` is used for serializing project configuration,\nand `Run#XSTREAM2` is used for serializing builds and their associated s.\n\nFor example, to alias `Foo` in the \"old\" package to the \"updated\" one,\nyou can use this method call:\n\nItems.XSTREAM2.addComp"
  },
  "468": {
    "source_file": "backward-compatibility.txt",
    "text": " and their associated s.\n\nFor example, to alias `Foo` in the \"old\" package to the \"updated\" one,\nyou can use this method call:\n\nItems.XSTREAM2.addCompatibilityAlias(\"org.acme.old.Foo\", org.acme.updated.Foo.class);\n\nTo ensure your alias is registered early in the Jenkins boot sequence,\nyou can use the  annotation on a static method, e.g. in your `DescriptorImpl`:\n\n@Initializer(before = InitMileston"
  },
  "469": {
    "source_file": "backward-compatibility.txt",
    "text": "early in the Jenkins boot sequence,\nyou can use the  annotation on a static method, e.g. in your `DescriptorImpl`:\n\n@Initializer(before = InitMilestone.PLUGINS_STARTED)\npublic static void addAliases() {\n  Items.XSTREAM2.addCompatibilityAlias(\"org.acme.old.Foo\", Foo.class);\n}\n\nSince 1.507 https://javadoc.jenkins.io/hudson/model/Descriptor.html#getConfigFile--[`Descriptor#getConfigFile`] is overrida"
  },
  "470": {
    "source_file": "backward-compatibility.txt",
    "text": "e.old.Foo\", Foo.class);\n}\n\nSince 1.507 https://javadoc.jenkins.io/hudson/model/Descriptor.html#getConfigFile--[`Descriptor#getConfigFile`] is overridable and https://javadoc.jenkins.io/hudson/XmlFile.html[`XmlFile`] can be instantiated with any XStream instance."
  },
  "471": {
    "source_file": "backward-compatibility.txt",
    "text": "am instance."
  },
  "472": {
    "source_file": "best-practices.txt",
    "text": "layout: section\ntitle: Best Practices\n\n\nifdef::env-github[:imagesdir: ../resources]\nifndef::env-github[:imagesdir: ../../resources]\n\nContinuous Integration (CI) with automated test execution and trend analysis has revolutionized the way companies approach build management, release management, deployment automation, and test orchestration.\nIn this section, we will explore best practices that aim to"
  },
  "473": {
    "source_file": "best-practices.txt",
    "text": "roach build management, release management, deployment automation, and test orchestration.\nIn this section, we will explore best practices that aim to enlighten executives, business managers, software developers, and architects about the invaluable contributions Jenkins can make throughout the project lifecycle.\n\nJenkins has the ability to automatically create, update, and delete jobs based on the"
  },
  "474": {
    "source_file": "best-practices.txt",
    "text": "ontributions Jenkins can make throughout the project lifecycle.\n\nJenkins has the ability to automatically create, update, and delete jobs based on the repositories it identifies in your software configuration management system.\nLeverage this feature and optimize your job management by structuring your job definitions in a way that maximizes the benefits offered by Jenkins' automatic job management"
  },
  "475": {
    "source_file": "best-practices.txt",
    "text": "and optimize your job management by structuring your job definitions in a way that maximizes the benefits offered by Jenkins' automatic job management capabilities.\n\nThere are multiple alternatives for automatic job management, including:\n\n* <<Use organization folders>> - create, update, and delete multibranch Pipeline folders and Pipeline jobs automatically (preferred)\n* <<Use multibranch Pipelin"
  },
  "476": {
    "source_file": "best-practices.txt",
    "text": "ganization folders>> - create, update, and delete multibranch Pipeline folders and Pipeline jobs automatically (preferred)\n* <<Use multibranch Pipelines>> - create, update and delete Pipeline jobs automatically\n* <<Use Pipeline>> - Manually defined Pipeline jobs for more control over the job management process.\n\nOrganization Folders provide a convenient way to automate the creation and deletion of"
  },
  "477": {
    "source_file": "best-practices.txt",
    "text": "ipeline jobs for more control over the job management process.\n\nOrganization Folders provide a convenient way to automate the creation and deletion of jobs in Jenkins as repositories and branches are added or removed.\nIf you are using GitHub organizations, Bitbucket teams, GitLab groups, or Gitea organizations, Jenkins can automatically detect the creation of a new repository and generate a Multib"
  },
  "478": {
    "source_file": "best-practices.txt",
    "text": "tions, Bitbucket teams, GitLab groups, or Gitea organizations, Jenkins can automatically detect the creation of a new repository and generate a Multibranch Pipeline project for it.\n\nRefer to the  documentation for more details.\n\n.GitHub organization folders\nvideo::LbXKUKQ24T8[youtube,width=800,height=420]\n\n.GitLab group folders\nvideo::it6TOeQ6EHg[youtube,width=800,height=420]\n\n.Bitbucket project f"
  },
  "479": {
    "source_file": "best-practices.txt",
    "text": "folders\nvideo::LbXKUKQ24T8[youtube,width=800,height=420]\n\n.GitLab group folders\nvideo::it6TOeQ6EHg[youtube,width=800,height=420]\n\n.Bitbucket project folders\nvideo::85b6fiVolfk[youtube,width=800,height=420]\n\n.Gitea organization folders\nvideo::NO3sZWRxgQM[youtube,width=800,height=420]\n\nIf you are unable to use organization folders, you can opt for multibranch Pipelines as an alternative.\nHowever, it"
  },
  "480": {
    "source_file": "best-practices.txt",
    "text": "gQM[youtube,width=800,height=420]\n\nIf you are unable to use organization folders, you can opt for multibranch Pipelines as an alternative.\nHowever, it's important to note that organization folders are preferred over multibranch Pipelines because they provide the automation of creating and deleting multibranch projects when repositories are added or removed.\n\n.GitHub multibranch Pipelines\nvideo::aD"
  },
  "481": {
    "source_file": "best-practices.txt",
    "text": " provide the automation of creating and deleting multibranch projects when repositories are added or removed.\n\n.GitHub multibranch Pipelines\nvideo::aDmeeVDrp0o[youtube,width=800,height=420]\n\n.GitLab group folders\nvideo::y4XGFluzPHY[youtube,width=800,height=420]\n\n.Bitbucket project folders\nvideo::LNfthmZuRDI[youtube,width=800,height=420]\n\nRefer to the  documentation for more details.\n\nIf organizati"
  },
  "482": {
    "source_file": "best-practices.txt",
    "text": "height=420]\n\n.Bitbucket project folders\nvideo::LNfthmZuRDI[youtube,width=800,height=420]\n\nRefer to the  documentation for more details.\n\nIf organization folders are not an option for you, consider using multibranch Pipelines as an alternative.\nHowever, it's important to highlight that organization folders are preferred, due to their ability to automatically create and delete multibranch projects w"
  },
  "483": {
    "source_file": "best-practices.txt",
    "text": "r, it's important to highlight that organization folders are preferred, due to their ability to automatically create and delete multibranch projects when repositories are added or removed.\n\nRefer to the  documentation for more details.\n\n.Differences between Freestyle and Pipeline in Jenkins\nvideo::IOUm1lw7F58[youtube,width=800,height=420]\n\nJenkins job definitions can be managed and optimized to en"
  },
  "484": {
    "source_file": "best-practices.txt",
    "text": "between Freestyle and Pipeline in Jenkins\nvideo::IOUm1lw7F58[youtube,width=800,height=420]\n\nJenkins job definitions can be managed and optimized to enhance user interactions and productivity.\n\nCharts and graphs provide valuable insights into project status and progress, showcasing trends and patterns.\nAutomated test results including unit tests, integration tests, and end-to-end tests can reveal b"
  },
  "485": {
    "source_file": "best-practices.txt",
    "text": "status and progress, showcasing trends and patterns.\nAutomated test results including unit tests, integration tests, and end-to-end tests can reveal brittleness or instability.\nCoverage reports help identify areas where automated tests are not being executed.\nCompiler warning messages often serve as the first indication of a problem.\nStatic analysis tools are effective in reporting risky code or c"
  },
  "486": {
    "source_file": "best-practices.txt",
    "text": "executed.\nCompiler warning messages often serve as the first indication of a problem.\nStatic analysis tools are effective in reporting risky code or code with potential security risks.\nPerformance test results help identify delays or areas of concern.\n\nThe plugin:warnings-ng[Warnings Next Generation] plugin provides convenient access to many reports including:\n\n* Compiler warnings and errors (like"
  },
  "487": {
    "source_file": "best-practices.txt",
    "text": ".\n\nThe plugin:warnings-ng[Warnings Next Generation] plugin provides convenient access to many reports including:\n\n* Compiler warnings and errors (like gcc, clang, javac, or  golang)\n* Static analysis warnings and errors (spotbugs, checkstyle, pmd, lint, cpd, or Simian)\n* Code coverage reports\n\n.How to use the Warnings Next Generation plugin\nvideo::tj3xYFA6Q2o[youtube,width=800,height=420]\n\nUse age"
  },
  "488": {
    "source_file": "best-practices.txt",
    "text": "nt, cpd, or Simian)\n* Code coverage reports\n\n.How to use the Warnings Next Generation plugin\nvideo::tj3xYFA6Q2o[youtube,width=800,height=420]\n\nUse agents to perform builds instead of running builds on the controller.\nUtilizing agents offers enhanced safety and scalability.\n\nRefer to the  documentation for more details.\n\nConfigure notifications for failing and unstable jobs, to ensure that the righ"
  },
  "489": {
    "source_file": "best-practices.txt",
    "text": "safety and scalability.\n\nRefer to the  documentation for more details.\n\nConfigure notifications for failing and unstable jobs, to ensure that the right people receive them without causing unnecessary distractions for others.\nMany Jenkins users prefer to be notified only when a failure is likely their responsibility.\nThis approach acknowledges that if they are not responsible for the failure, they "
  },
  "490": {
    "source_file": "best-practices.txt",
    "text": " to be notified only when a failure is likely their responsibility.\nThis approach acknowledges that if they are not responsible for the failure, they may not be the most suitable person to investigate it.\n\nRefine your notification system to prioritize notifying the most recent committers when new test failures occur, as they are likely to be the cause of the issue.\n\n.Sending Slack notifications\nvi"
  },
  "491": {
    "source_file": "best-practices.txt",
    "text": "e notifying the most recent committers when new test failures occur, as they are likely to be the cause of the issue.\n\n.Sending Slack notifications\nvideo::EDVZli8GdUM[youtube,width=800,height=420]\n\nJenkins utilizes project names for organizing related folders.\nHowever, it's important to note that certain tools may encounter issues with spaces, dollar signs, or similar characters in file paths.\nTo "
  },
  "492": {
    "source_file": "best-practices.txt",
    "text": "d folders.\nHowever, it's important to note that certain tools may encounter issues with spaces, dollar signs, or similar characters in file paths.\nTo ensure compatibility, it's recommended to limit project names to alphanumeric characters (`a-z,A-Z,0-9,_,-,+`).\nTo enhance the appearance of project names, you can utilize the *Display Name* feature.\nThis allows you to customize the presentation, whi"
  },
  "493": {
    "source_file": "best-practices.txt",
    "text": "-9,_,-,+`).\nTo enhance the appearance of project names, you can utilize the *Display Name* feature.\nThis allows you to customize the presentation, while maintaining the restricted characters in the underlying project name.\nTo enforce consistent naming conventions across all projects, enable the \"Restrict project naming\" setting in the system configuration.\nThis ensures that naming restrictions are"
  },
  "494": {
    "source_file": "best-practices.txt",
    "text": "g conventions across all projects, enable the \"Restrict project naming\" setting in the system configuration.\nThis ensures that naming restrictions are enforced uniformly.\n\nWhen dealing with interdependent projects, it can be challenging to keep track of which version of one project is used by another.\nHowever, Jenkins offers a solution called \"file fingerprinting\" to simplify this process.\n\nRefer "
  },
  "495": {
    "source_file": "best-practices.txt",
    "text": " of which version of one project is used by another.\nHowever, Jenkins offers a solution called \"file fingerprinting\" to simplify this process.\n\nRefer to the  for more information.\n\nJenkins has been providing the plugin:maven-plugin[Maven integration plugin] for many years, allowing users to create Maven projects using the \"Maven project\" selection from the Jenkins \"New item\" menu.\nWhile the Maven "
  },
  "496": {
    "source_file": "best-practices.txt",
    "text": "plugin] for many years, allowing users to create Maven projects using the \"Maven project\" selection from the Jenkins \"New item\" menu.\nWhile the Maven job type offers a higher level of integration with Maven builds, it can sometimes introduce unnecessary complexities due to this deep integration.\n\nConsider using organization folders, multibranch Pipelines, or Pipeline jobs instead of the Maven job "
  },
  "497": {
    "source_file": "best-practices.txt",
    "text": "ary complexities due to this deep integration.\n\nConsider using organization folders, multibranch Pipelines, or Pipeline jobs instead of the Maven job type.\nThese alternatives provide more flexibility and simplicity in managing your Jenkins jobs and workflows.\n\nThe Jenkins project uses organization folders to build  and  on ci.jenkins.io.\nA Jenkins Pipeline builds Maven projects easily and provides"
  },
  "498": {
    "source_file": "best-practices.txt",
    "text": "orkflows.\n\nThe Jenkins project uses organization folders to build  and  on ci.jenkins.io.\nA Jenkins Pipeline builds Maven projects easily and provides much better control for Maven users.\n\nRefer to the  for more details.\n\nThe Jenkins controller plays a crucial role as a central resource, requiring effective management for optimal performance.\nBy following these practices, you can ensure that your "
  },
  "499": {
    "source_file": "best-practices.txt",
    "text": " a crucial role as a central resource, requiring effective management for optimal performance.\nBy following these practices, you can ensure that your controller provides the best possible experience for users.\n\nJenkins installations come with security enabled by default, which is a crucial aspect of protecting your system.\nWhile it is technically possible to disable security, it is strongly advise"
  },
  "500": {
    "source_file": "best-practices.txt",
    "text": "y enabled by default, which is a crucial aspect of protecting your system.\nWhile it is technically possible to disable security, it is strongly advised **not** to do so.\nDisabling security can leave your Jenkins controller vulnerable to unauthorized access and potential security breaches.\nIt is important to maintain a secure environment by keeping security enabled at all times.\n\nRefer to the  chap"
  },
  "501": {
    "source_file": "best-practices.txt",
    "text": "access and potential security breaches.\nIt is important to maintain a secure environment by keeping security enabled at all times.\n\nRefer to the  chapter of the User Handbook for more details.\n\nEven the most reliable systems can experience failures.\nThat's why it's crucial to be prepared and regularly check the health of your backups.\nBackups are a critical component of ensuring the integrity and "
  },
  "502": {
    "source_file": "best-practices.txt",
    "text": "That's why it's crucial to be prepared and regularly check the health of your backups.\nBackups are a critical component of ensuring the integrity and availability of your data.\nRegularly testing your backups and verifying their completeness and restorability will help you mitigate the impact of any potential failures and ensure that your data can be recovered effectively when needed.\nPrioritizing "
  },
  "503": {
    "source_file": "best-practices.txt",
    "text": "rability will help you mitigate the impact of any potential failures and ensure that your data can be recovered effectively when needed.\nPrioritizing backup health and conducting routine checks is essential for maintaining a robust and resilient system.\n\nMore details can be found in the .\n\nSchedule your jobs strategically to balance the number of jobs running concurrently.\nIf you're using timer tr"
  },
  "504": {
    "source_file": "best-practices.txt",
    "text": "em.\n\nMore details can be found in the .\n\nSchedule your jobs strategically to balance the number of jobs running concurrently.\nIf you're using timer triggers or periodic polling, consider using the `H` syntax in the cron expression to introduce scheduling jitter.\nThis helps to distribute the start times of jobs more evenly and prevent them from all starting simultaneously.\nAdditionally, take advant"
  },
  "505": {
    "source_file": "best-practices.txt",
    "text": "ling jitter.\nThis helps to distribute the start times of jobs more evenly and prevent them from all starting simultaneously.\nAdditionally, take advantage of predefined tokens like `@hourly` to further distribute the starting times of your jobs.\nThese tokens can help create a more balanced schedule and reduce the likelihood of resource contention.\n\nBy implementing these scheduling techniques, you c"
  },
  "506": {
    "source_file": "best-practices.txt",
    "text": " tokens can help create a more balanced schedule and reduce the likelihood of resource contention.\n\nBy implementing these scheduling techniques, you can optimize the utilization of your resources and ensure a smoother execution of your jobs.\n\nWhen multiple jobs run simultaneously, there is a possibility of collisions occurring, especially if they require exclusive access to certain resources or se"
  },
  "507": {
    "source_file": "best-practices.txt",
    "text": "ltiple jobs run simultaneously, there is a possibility of collisions occurring, especially if they require exclusive access to certain resources or set-up services.\nTo prevent interference and ensure smooth execution, it is important to manage resource access effectively.\nFor builds involving databases or networked services, it is crucial to implement measures that prevent conflicts.\nThe plugin:lo"
  },
  "508": {
    "source_file": "best-practices.txt",
    "text": "ce access effectively.\nFor builds involving databases or networked services, it is crucial to implement measures that prevent conflicts.\nThe plugin:lockable-resources[Lockable Resources plugin] offers fine-grained resource-locking capabilities for Jenkins jobs.\nBy using this plugin, you can ensure that only one job has access to a specific resource at a time, avoiding conflicts and ensuring proper"
  },
  "509": {
    "source_file": "best-practices.txt",
    "text": "nkins jobs.\nBy using this plugin, you can ensure that only one job has access to a specific resource at a time, avoiding conflicts and ensuring proper synchronization.\nIn cases where resource locking with the lockable resources plugin is not sufficient, you can further control concurrent builds using the plugin:throttle-concurrents[Throttle Concurrent Builds plugin].\nThis plugin allows you to limi"
  },
  "510": {
    "source_file": "best-practices.txt",
    "text": "nt, you can further control concurrent builds using the plugin:throttle-concurrents[Throttle Concurrent Builds plugin].\nThis plugin allows you to limit the number of builds that can run simultaneously, providing additional control and preventing overload on shared resources.\n\nBy leveraging these plugins, you can manage resource conflicts and concurrency effectively, ensuring smooth and reliable ex"
  },
  "511": {
    "source_file": "best-practices.txt",
    "text": "load on shared resources.\n\nBy leveraging these plugins, you can manage resource conflicts and concurrency effectively, ensuring smooth and reliable execution of your Jenkins jobs.\n\n.How to use lockable resources\nvideo::y_z8mqV8G68[youtube,width=800,height=420]"
  },
  "512": {
    "source_file": "best-practices.txt",
    "text": "eight=420]"
  },
  "513": {
    "source_file": "build-a-cpp-app-with-jenkins.txt",
    "text": "layout: documentation\ntitle: Build a C++ app with Jenkins\nsection: doc\n\n\nThis tutorial shows you how to use Jenkins to build a simple C++ application, specifically a **Casino Number Guessing Game**. The application generates a random number based on the selected difficulty level, and the player wins a prize if they guess the correct number.\n\nIf you are a C++ developer who is new to CI/CD concepts,"
  },
  "514": {
    "source_file": "build-a-cpp-app-with-jenkins.txt",
    "text": "the selected difficulty level, and the player wins a prize if they guess the correct number.\n\nIf you are a C++ developer who is new to CI/CD concepts, or you might be familiar with these concepts but don't know how to implement building your application using Jenkins, then this tutorial is for you.\n\n*Duration:* This tutorial takes 20-40 minutes to complete (assuming you've already met the <<prereq"
  },
  "515": {
    "source_file": "build-a-cpp-app-with-jenkins.txt",
    "text": "ion using Jenkins, then this tutorial is for you.\n\n*Duration:* This tutorial takes 20-40 minutes to complete (assuming you've already met the <<prerequisites,prerequisites>> below). The exact duration will depend on the speed of your machine and whether you've already installed `docker` and `docker compose`.\n\nYou can stop this tutorial at any point in time and continue from where you left off.\n\n**"
  },
  "516": {
    "source_file": "build-a-cpp-app-with-jenkins.txt",
    "text": "her you've already installed `docker` and `docker compose`.\n\nYou can stop this tutorial at any point in time and continue from where you left off.\n\n** , and optionally .\n\n[[fork-sample-repository]]\n\nGet the **Casino Number Guessing Game** C++ application from GitHub by forking the sample repository of the application's source code into your own GitHub account and then cloning this fork locally.\n\nE"
  },
  "517": {
    "source_file": "build-a-cpp-app-with-jenkins.txt",
    "text": "tion from GitHub by forking the sample repository of the application's source code into your own GitHub account and then cloning this fork locally.\n\nEnsure you are signed in to your GitHub account. If you don't yet have a GitHub account, sign up for free on the https://github.com/[GitHub website].\nFork the https://github.com/biru-codeastromer/casino-number-guessing-game[`casino-number-guessing-gam"
  },
  "518": {
    "source_file": "build-a-cpp-app-with-jenkins.txt",
    "text": "free on the https://github.com/[GitHub website].\nFork the https://github.com/biru-codeastromer/casino-number-guessing-game[`casino-number-guessing-game`] repository on GitHub into your local GitHub account. If you need help with this process, refer to the https://help.github.com/articles/fork-a-repo/[repository forking instructions] on the GitHub website for more information.\nClone your forked `ca"
  },
  "519": {
    "source_file": "build-a-cpp-app-with-jenkins.txt",
    "text": "o the https://help.github.com/articles/fork-a-repo/[repository forking instructions] on the GitHub website for more information.\nClone your forked `casino-number-guessing-game` repository from GitHub to your local machine. To begin this process, do either of the following (where `<your-username>` is the name of your user account on your operating system):\n** If you have the  app installed on your "
  },
  "520": {
    "source_file": "build-a-cpp-app-with-jenkins.txt",
    "text": "ither of the following (where `<your-username>` is the name of your user account on your operating system):\n** If you have the  app installed on your machine:\n.. In GitHub, select the green *Clone or download* button on your forked repository, then select *Open in Desktop*.\n.. In GitHub Desktop, before selecting *Clone* on the *Clone a Repository* dialog box, confirm the *Local Path* for your oper"
  },
  "521": {
    "source_file": "build-a-cpp-app-with-jenkins.txt",
    "text": "elect *Open in Desktop*.\n.. In GitHub Desktop, before selecting *Clone* on the *Clone a Repository* dialog box, confirm the *Local Path* for your operating system:\n*** macOS is `/Users/<your-username>/Documents/GitHub/casino-number-guessing-game`\n*** Linux is `/home/<your-username>/GitHub/casino-number-guessing-game`\n*** Windows is `C:\\Users\\<your-username>\\Documents\\GitHub\\casino-number-guessing-"
  },
  "522": {
    "source_file": "build-a-cpp-app-with-jenkins.txt",
    "text": " Linux is `/home/<your-username>/GitHub/casino-number-guessing-game`\n*** Windows is `C:\\Users\\<your-username>\\Documents\\GitHub\\casino-number-guessing-game`\n** Otherwise:\n.. Open up a terminal/command line prompt and `cd` to the appropriate directory on:\n*** macOS - `/Users/<your-username>/Documents/GitHub/`\n*** Linux - `/home/<your-username>/GitHub/`\n*** Windows - `C:\\Users\\<your-username>\\Documen"
  },
  "523": {
    "source_file": "build-a-cpp-app-with-jenkins.txt",
    "text": "on:\n*** macOS - `/Users/<your-username>/Documents/GitHub/`\n*** Linux - `/home/<your-username>/GitHub/`\n*** Windows - `C:\\Users\\<your-username>\\Documents\\GitHub\\` (Use a Git bash command line window as opposed to the usual Microsoft command prompt)\n.. Run the following command to clone your forked repo, replacing `YOUR-GITHUB-ACCOUNT-NAME` with the name of your GitHub account:\ngit clone https://git"
  },
  "524": {
    "source_file": "build-a-cpp-app-with-jenkins.txt",
    "text": " Run the following command to clone your forked repo, replacing `YOUR-GITHUB-ACCOUNT-NAME` with the name of your GitHub account:\ngit clone https://github.com/YOUR-GITHUB-ACCOUNT-NAME/casino-number-guessing-game\n\n1. Obtain the latest Jenkins deployment, customized for this tutorial, by cloning the .\n2. After cloning, navigate to the `quickstart-tutorials` directory and execute the command\ndocker co"
  },
  "525": {
    "source_file": "build-a-cpp-app-with-jenkins.txt",
    "text": "t, customized for this tutorial, by cloning the .\n2. After cloning, navigate to the `quickstart-tutorials` directory and execute the command\ndocker compose --profile cpp up -d\n\nto run the example.\n3. Once the containers are running successfully (you can verify this with `docker compose ps`), the controller can be accessed at http://localhost:8080.\n\nIf you are unable to install `docker compose` on "
  },
  "526": {
    "source_file": "build-a-cpp-app-with-jenkins.txt",
    "text": "can verify this with `docker compose ps`), the controller can be accessed at http://localhost:8080.\n\nIf you are unable to install `docker compose` on your machine for any reason, you can still run the example in the cloud for free using either:\n\n* *GitHub Codespaces* (Recommended): Click the *Code* button in the , select *Codespaces*, then *Create codespace on master*.\nGitHub Codespaces provides ."
  },
  "527": {
    "source_file": "build-a-cpp-app-with-jenkins.txt",
    "text": "itHub Codespaces* (Recommended): Click the *Code* button in the , select *Codespaces*, then *Create codespace on master*.\nGitHub Codespaces provides .\nOnce the Codespace starts, the setup will run automatically, and you'll see a welcome message with instructions.\n\n* *GitPod*: Click on  to open a GitPod workspace.\nGitPod .\nYou need to link it to your GitHub account.\n\nNow, log in using the `admin` u"
  },
  "528": {
    "source_file": "build-a-cpp-app-with-jenkins.txt",
    "text": "instructions.\n\n* *GitPod*: Click on  to open a GitPod workspace.\nGitPod .\nYou need to link it to your GitHub account.\n\nNow, log in using the `admin` username and `admin` password.\n\nIn Jenkins, select *New Item* under *Dashboard >* at the top left.\nEnter your new Pipeline project name, such as `casino-number-guessing-game`, in *Enter an item name*.\nScroll down if necessary and select *Pipeline*, th"
  },
  "529": {
    "source_file": "build-a-cpp-app-with-jenkins.txt",
    "text": "ter your new Pipeline project name, such as `casino-number-guessing-game`, in *Enter an item name*.\nScroll down if necessary and select *Pipeline*, then select *OK* at the end of the page.\n(Optional) Enter a Pipeline *Description*.\nSelect *Pipeline* on the left pane.\nSelect *Definition* and then choose the *Pipeline script from SCM* option. This option instructs Jenkins to obtain your Pipeline fro"
  },
  "530": {
    "source_file": "build-a-cpp-app-with-jenkins.txt",
    "text": "on the left pane.\nSelect *Definition* and then choose the *Pipeline script from SCM* option. This option instructs Jenkins to obtain your Pipeline from the source control management (SCM), which is your forked Git repository.\nChoose *Git* from the options in *SCM*.\nEnter the URL of your repository in *Repositories/Repository URL*. This URL can be found when selecting the green *Code* button in the"
  },
  "531": {
    "source_file": "build-a-cpp-app-with-jenkins.txt",
    "text": "tions in *SCM*.\nEnter the URL of your repository in *Repositories/Repository URL*. This URL can be found when selecting the green *Code* button in the main page of your GitHub repo.\nIn _Branches to build_, enter `*/main`\nIn _Script Path_, set the script path to `Jenkinsfile`.\nSelect *Save* at the end of the page. You're now ready to create a `Jenkinsfile` to check into your locally cloned Git repo"
  },
  "532": {
    "source_file": "build-a-cpp-app-with-jenkins.txt",
    "text": "ipt path to `Jenkinsfile`.\nSelect *Save* at the end of the page. You're now ready to create a `Jenkinsfile` to check into your locally cloned Git repository.\n\nYou're now ready to create your Pipeline that will automate building your C++ application in Jenkins. Your Pipeline is created as a `Jenkinsfile`, which is committed to your locally cloned Git repository (`casino-number-guessing-game`).\n\nThi"
  },
  "533": {
    "source_file": "build-a-cpp-app-with-jenkins.txt",
    "text": "n Jenkins. Your Pipeline is created as a `Jenkinsfile`, which is committed to your locally cloned Git repository (`casino-number-guessing-game`).\n\nThis is the foundation of \"Pipeline-as-Code\", which treats the continuous delivery pipeline as a part of the application to be versioned and reviewed like any other code. Read more about Pipeline and what a Jenkinsfile is in the  and  sections of the Us"
  },
  "534": {
    "source_file": "build-a-cpp-app-with-jenkins.txt",
    "text": "f the application to be versioned and reviewed like any other code. Read more about Pipeline and what a Jenkinsfile is in the  and  sections of the User Handbook.\n\nFirst, create an initial Pipeline to build your C++ application. Add a \"Build\" stage to the Pipeline that begins orchestrating this whole process.\n\nAs you forked our sample repo, you already have an empty `Jenkinsfile`.\nCopy the followi"
  },
  "535": {
    "source_file": "build-a-cpp-app-with-jenkins.txt",
    "text": "o the Pipeline that begins orchestrating this whole process.\n\nAs you forked our sample repo, you already have an empty `Jenkinsfile`.\nCopy the following Declarative Pipeline code and paste it into your empty `Jenkinsfile`:\npipeline {\n    agent any\n    stages {\n        stage('Build') { // <1> steps {\n                sh 'rm -rf build'\n                sh 'cmake -B build -S .' // <2> sh 'cmake --build"
  },
  "536": {
    "source_file": "build-a-cpp-app-with-jenkins.txt",
    "text": "  stages {\n        stage('Build') { // <1> steps {\n                sh 'rm -rf build'\n                sh 'cmake -B build -S .' // <2> sh 'cmake --build build'\n            }\n        }\n    }\n}\n\n<1> Defines a  (directive) called `Build` that appears on the Jenkins UI.\n<2> The second  step executes the `cmake` command to build your C++ application.\n\nSave your edited `Jenkinsfile` and commit it to your "
  },
  "537": {
    "source_file": "build-a-cpp-app-with-jenkins.txt",
    "text": "he Jenkins UI.\n<2> The second  step executes the `cmake` command to build your C++ application.\n\nSave your edited `Jenkinsfile` and commit it to your local `casino-number-guessing-game` Git repository. Within the `casino-number-guessing-game` directory, run the commands: +\n  `git add Jenkinsfile` +\n  then +\n  `git commit -m \"Add initial Jenkinsfile\"` +\n  and finally +\n  `git push` to push your cha"
  },
  "538": {
    "source_file": "build-a-cpp-app-with-jenkins.txt",
    "text": "ry, run the commands: +\n  `git add Jenkinsfile` +\n  then +\n  `git commit -m \"Add initial Jenkinsfile\"` +\n  and finally +\n  `git push` to push your changes to your forked repository on GitHub, so it can be picked up by Jenkins.\n\nNow select *Build Now* on the left pane of your Pipeline project in Jenkins. After making a clone of your local `casino-number-guessing-game` Git repository itself, Jenkins"
  },
  "539": {
    "source_file": "build-a-cpp-app-with-jenkins.txt",
    "text": " on the left pane of your Pipeline project in Jenkins. After making a clone of your local `casino-number-guessing-game` Git repository itself, Jenkins:\n\n  . Initially queues the project to be run on the agent.\n  . Runs the `Build` stage defined in the `Jenkinsfile` on the agent.\n\nDuring this time, CMake configures the necessary build files for your C++ application, builds, and links your applicati"
  },
  "540": {
    "source_file": "build-a-cpp-app-with-jenkins.txt",
    "text": "e `Jenkinsfile` on the agent.\n\nDuring this time, CMake configures the necessary build files for your C++ application, builds, and links your application.\nYou can now select *#1* to see the details of the build. On the job status page, you can see how much time the build spent waiting in the queue and how much time it took to run.\n\n[.boxshadow]\n\nIn the left navigation pane, you can select *Pipeline"
  },
  "541": {
    "source_file": "build-a-cpp-app-with-jenkins.txt",
    "text": " much time the build spent waiting in the queue and how much time it took to run.\n\n[.boxshadow]\n\nIn the left navigation pane, you can select *Pipeline Overview* to see the stages of the Pipeline.\n\n[.boxshadow]\n\nSelecting the *Build* stage will provide more information about the stage, including the output of the `cmake` command if you select the green `cmake` section.\n\n[.boxshadow]\n\nYou can now se"
  },
  "542": {
    "source_file": "build-a-cpp-app-with-jenkins.txt",
    "text": "e more information about the stage, including the output of the `cmake` command if you select the green `cmake` section.\n\n[.boxshadow]\n\nYou can now select *casino-number-guessing-game* (if that's the name you chose for your pipeline) on the top left to return to your pipeline main page.\n\nGo back to your text editor/IDE and ensure your `Jenkinsfile` is open.\nCopy and paste the following Declarative"
  },
  "543": {
    "source_file": "build-a-cpp-app-with-jenkins.txt",
    "text": "to return to your pipeline main page.\n\nGo back to your text editor/IDE and ensure your `Jenkinsfile` is open.\nCopy and paste the following Declarative Pipeline syntax immediately under the `Build` stage:\nstage('Test') {\n            steps {\n                sh './build/casino_game'\n                sh './build/test_game'\n            }\n        }\n\nso that you end up with:\npipeline {\n    agent any\n    s"
  },
  "544": {
    "source_file": "build-a-cpp-app-with-jenkins.txt",
    "text": "      sh './build/casino_game'\n                sh './build/test_game'\n            }\n        }\n\nso that you end up with:\npipeline {\n    agent any\n    stages {\n        stage('Build') {\n            steps {\n                sh 'rm -rf build'\n                sh 'cmake -B build -S .'\n                sh 'cmake --build build'\n            }\n        }\n        stage('Test') { // <1> steps {\n                sh"
  },
  "545": {
    "source_file": "build-a-cpp-app-with-jenkins.txt",
    "text": "   sh 'cmake -B build -S .'\n                sh 'cmake --build build'\n            }\n        }\n        stage('Test') { // <1> steps {\n                sh './build/casino_game' // <2> sh './build/test_game'\n            }\n        }\n    }\n}\n\n<1> Defines a  (directive) called `Test` that appears on the Jenkins UI.\n<2> This  step runs the game and unit tests to ensure the application works as expected.\n\nS"
  },
  "546": {
    "source_file": "build-a-cpp-app-with-jenkins.txt",
    "text": " (directive) called `Test` that appears on the Jenkins UI.\n<2> This  step runs the game and unit tests to ensure the application works as expected.\n\nSave your edited `Jenkinsfile` and commit it to your local `casino-number-guessing-game` Git repository. Within the `casino-number-guessing-game` directory, run the commands: +\n  `git add Jenkinsfile` +\n  then +\n  `git commit -m \"Add 'Test' stage\"` +\n"
  },
  "547": {
    "source_file": "build-a-cpp-app-with-jenkins.txt",
    "text": "ry. Within the `casino-number-guessing-game` directory, run the commands: +\n  `git add Jenkinsfile` +\n  then +\n  `git commit -m \"Add 'Test' stage\"` +\n  and finally +\n  `git push` to push your changes to your forked repository on GitHub, so it can be picked up by Jenkins.\n\nIn Jenkins, go back to your *Dashboard* if necessary, then select *casino-number-guessing-game* and launch another build thanks"
  },
  "548": {
    "source_file": "build-a-cpp-app-with-jenkins.txt",
    "text": "picked up by Jenkins.\n\nIn Jenkins, go back to your *Dashboard* if necessary, then select *casino-number-guessing-game* and launch another build thanks to *Build Now*.\nAfter a while, a new column titled *Test* will appear in the *Stage View*.\n\n[.boxshadow]\n\nYou can select *#2*, or on the number representing your last build on the left, under *Build History* to see the details of the build.\n\n[.boxsh"
  },
  "549": {
    "source_file": "build-a-cpp-app-with-jenkins.txt",
    "text": "adow]\n\nYou can select *#2*, or on the number representing your last build on the left, under *Build History* to see the details of the build.\n\n[.boxshadow]\n\nYou can now select *Pipeline Overview* to see the stages of the Pipeline.\n\n[.boxshadow]\n\nThe newly added \"Test\" stage is visible here. Selecting the \"Test\" stage checkmark displays the stage output.\n\n[.boxshadow]\n\nDuring the **Test** stage, th"
  },
  "550": {
    "source_file": "build-a-cpp-app-with-jenkins.txt",
    "text": "newly added \"Test\" stage is visible here. Selecting the \"Test\" stage checkmark displays the stage output.\n\n[.boxshadow]\n\nDuring the **Test** stage, the `casino_game` executable runs and displays output similar to the following in the Jenkins console:\n\nWelcome to the Casino Number Guessing Game!\nRunning in non-interactive mode. Using default values.\nGenerated random number: 8 // <1> Generated rando"
  },
  "551": {
    "source_file": "build-a-cpp-app-with-jenkins.txt",
    "text": "\n\nWelcome to the Casino Number Guessing Game!\nRunning in non-interactive mode. Using default values.\nGenerated random number: 8 // <1> Generated random number: 4\nGenerated number: 4 // <2> Wrong guess! Try again. // <3> Wrong guess! Try again.\nWrong guess! Try again.\nWrong guess! Try again.\nWrong guess! Try again.\nWrong guess! Try again.\nWrong guess! Try again.\nWrong guess! Try again.\nWrong guess!"
  },
  "552": {
    "source_file": "build-a-cpp-app-with-jenkins.txt",
    "text": "guess! Try again.\nWrong guess! Try again.\nWrong guess! Try again.\nWrong guess! Try again.\nWrong guess! Try again.\nWrong guess! Try again.\nWrong guess! Try again.\nWrong guess! Try again.\nWrong guess! Try again.\nWrong guess! Try again.\nWrong guess! Try again.\nWrong guess! Try again.\nWrong guess! Try again.\nWrong guess! Try again.\nWrong guess! Try again.\nCongratulations! You guessed the number! // <4"
  },
  "553": {
    "source_file": "build-a-cpp-app-with-jenkins.txt",
    "text": " again.\nWrong guess! Try again.\nWrong guess! Try again.\nWrong guess! Try again.\nWrong guess! Try again.\nCongratulations! You guessed the number! // <4> You won $5! // <5> Total winnings: $5 // <6> This output confirms that the application is working as expected. Here\u2019s what each part of the output means:\n<1> **`Generated random number`**: This line shows the random number generated by the game. In"
  },
  "554": {
    "source_file": "build-a-cpp-app-with-jenkins.txt",
    "text": "as expected. Here\u2019s what each part of the output means:\n<1> **`Generated random number`**: This line shows the random number generated by the game. In non-interactive mode, the game generates multiple random numbers to simulate guesses until it finds the correct one.\n<2> **`Generated number`**: This is the secret number the game is trying to guess.\n<3> **`Wrong guess! Try again.`**: This indicates"
  },
  "555": {
    "source_file": "build-a-cpp-app-with-jenkins.txt",
    "text": " the correct one.\n<2> **`Generated number`**: This is the secret number the game is trying to guess.\n<3> **`Wrong guess! Try again.`**: This indicates that the game made an incorrect guess. In non-interactive mode, the game continues guessing until it finds the correct number.\n<4> **`Congratulations! You guessed the number!`**: This indicates that the game successfully guessed the correct number.\n"
  },
  "556": {
    "source_file": "build-a-cpp-app-with-jenkins.txt",
    "text": "t finds the correct number.\n<4> **`Congratulations! You guessed the number!`**: This indicates that the game successfully guessed the correct number.\n<5> **`You won $5!`**: This shows the prize awarded based on the number of attempts and the difficulty level.\n<6> **`Total winnings: $5`**: This displays the total winnings accumulated during the game.\n\nThe `test_game` executable also runs during the"
  },
  "557": {
    "source_file": "build-a-cpp-app-with-jenkins.txt",
    "text": "ty level.\n<6> **`Total winnings: $5`**: This displays the total winnings accumulated during the game.\n\nThe `test_game` executable also runs during the **Test** stage and display output similar to the following:\n\nGenerated random number: 8\nGenerated random number: 4\nGenerated random number: 3\nAll tests passed!\n\nThis output confirms that the unit tests for the game logic have passed successfully.\n\nF"
  },
  "558": {
    "source_file": "build-a-cpp-app-with-jenkins.txt",
    "text": "andom number: 4\nGenerated random number: 3\nAll tests passed!\n\nThis output confirms that the unit tests for the game logic have passed successfully.\n\nFor reference, this is an example of how the output renders:\n\n[.boxshadow]\n\nGo back to your text editor/IDE and ensure your `Jenkinsfile` is open.\nCopy and paste the following Declarative Pipeline syntax immediately under the `Test` stage of your `Jen"
  },
  "559": {
    "source_file": "build-a-cpp-app-with-jenkins.txt",
    "text": "or/IDE and ensure your `Jenkinsfile` is open.\nCopy and paste the following Declarative Pipeline syntax immediately under the `Test` stage of your `Jenkinsfile`:\nstage('Deliver') {\n            steps {\n                sh 'tar -czf casino_game.tar.gz build/casino_game'\n                archiveArtifacts artifacts: 'casino_game.tar.gz', fingerprint: true\n            }\n        }\n\nso that you will end up "
  },
  "560": {
    "source_file": "build-a-cpp-app-with-jenkins.txt",
    "text": "ild/casino_game'\n                archiveArtifacts artifacts: 'casino_game.tar.gz', fingerprint: true\n            }\n        }\n\nso that you will end up with:\npipeline {\n    agent any\n    stages {\n        stage('Build') {\n            steps {\n                sh 'rm -rf build'\n                sh 'cmake -B build -S .'\n                sh 'cmake --build build'\n            }\n        }\n        stage('Test')"
  },
  "561": {
    "source_file": "build-a-cpp-app-with-jenkins.txt",
    "text": "     sh 'rm -rf build'\n                sh 'cmake -B build -S .'\n                sh 'cmake --build build'\n            }\n        }\n        stage('Test') {\n            steps {\n                sh './build/casino_game'\n                sh './build/test_game'\n            }\n        }\n        stage('Deliver') { // <1> steps {\n                sh 'tar -czf casino_game.tar.gz build/casino_game' // <2> archive"
  },
  "562": {
    "source_file": "build-a-cpp-app-with-jenkins.txt",
    "text": "e'\n            }\n        }\n        stage('Deliver') { // <1> steps {\n                sh 'tar -czf casino_game.tar.gz build/casino_game' // <2> archiveArtifacts artifacts: 'casino_game.tar.gz', fingerprint: true // <3> }\n        }\n    }\n}\n\n<1> Defines a new stage called `Deliver` that appears on the Jenkins UI.\n<2> This  step packages the executable into a `.tar.gz` file.\n<3> This  step archives th"
  },
  "563": {
    "source_file": "build-a-cpp-app-with-jenkins.txt",
    "text": " a new stage called `Deliver` that appears on the Jenkins UI.\n<2> This  step packages the executable into a `.tar.gz` file.\n<3> This  step archives the `.tar.gz` file as a build artifact.\n\nSave your edited `Jenkinsfile` and commit it to your local `casino-number-guessing-game` Git repository. Within the `casino-number-guessing-game` directory, run the commands: +\n  `git add Jenkinsfile` +\n  then +"
  },
  "564": {
    "source_file": "build-a-cpp-app-with-jenkins.txt",
    "text": "asino-number-guessing-game` Git repository. Within the `casino-number-guessing-game` directory, run the commands: +\n  `git add Jenkinsfile` +\n  then +\n  `git commit -m \"Add 'Deliver' stage\"` +\n  and finally +\n  `git push` to push your changes to your forked repository on GitHub, so it can be picked up by Jenkins.\n\nIn Jenkins, sign in if necessary, go back to the *Dashboard*, and then navigate to *"
  },
  "565": {
    "source_file": "build-a-cpp-app-with-jenkins.txt",
    "text": " forked repository on GitHub, so it can be picked up by Jenkins.\n\nIn Jenkins, sign in if necessary, go back to the *Dashboard*, and then navigate to *casino-number-guessing-game*. Alternatively, you can go directly to *casino-number-guessing-game* depending on where you're starting from.\nSelect *Build Now* on the left. After a while, a new column titled *Deliver* will appear in the *Stage View*.\n["
  },
  "566": {
    "source_file": "build-a-cpp-app-with-jenkins.txt",
    "text": "pending on where you're starting from.\nSelect *Build Now* on the left. After a while, a new column titled *Deliver* will appear in the *Stage View*.\n[.boxshadow]\n\nSelect *#3*, or on the number representing your last build on the left, under *Build History*.\n[.boxshadow]\n\nSelect *Pipeline Overview* to see the stages of the Pipeline.\n[.boxshadow]\n\nSelect the *Deliver* stage. You will then see a gree"
  },
  "567": {
    "source_file": "build-a-cpp-app-with-jenkins.txt",
    "text": "story*.\n[.boxshadow]\n\nSelect *Pipeline Overview* to see the stages of the Pipeline.\n[.boxshadow]\n\nSelect the *Deliver* stage. You will then see a green part displaying *tar -czf casino_game.tar.gz build/casino_game*, which represents the successful execution of the `tar` command.\n[.boxshadow]\n\nYou can see the full stage view by clicking on the \"Full Stage View\" in the left menu.\n[.boxshadow]\n\nWell"
  },
  "568": {
    "source_file": "build-a-cpp-app-with-jenkins.txt",
    "text": "xecution of the `tar` command.\n[.boxshadow]\n\nYou can see the full stage view by clicking on the \"Full Stage View\" in the left menu.\n[.boxshadow]\n\nWell done! You've just used Jenkins to build a C++ application!\n\nThe \"Build\", \"Test\", and \"Deliver\" stages you created above are the basis for building more complex C++ applications in Jenkins, as well as C++ applications that integrate with other techno"
  },
  "569": {
    "source_file": "build-a-cpp-app-with-jenkins.txt",
    "text": "es you created above are the basis for building more complex C++ applications in Jenkins, as well as C++ applications that integrate with other technology stacks.\n\nBecause Jenkins is extremely extensible, it can be modified and configured to handle practically any aspect of build orchestration and automation.\n\nTo learn more about what Jenkins can do, check out:\n\n* The  page for other introductory "
  },
  "570": {
    "source_file": "build-a-cpp-app-with-jenkins.txt",
    "text": "ractically any aspect of build orchestration and automation.\n\nTo learn more about what Jenkins can do, check out:\n\n* The  page for other introductory tutorials.\n* The  for more detailed information about using Jenkins, such as  (in particular ) and the  interface.\n* The  for the latest events, other tutorials and updates.\n\nAfter completing the tutorial, it's important to clean up your environment "
  },
  "571": {
    "source_file": "build-a-cpp-app-with-jenkins.txt",
    "text": "he  interface.\n* The  for the latest events, other tutorials and updates.\n\nAfter completing the tutorial, it's important to clean up your environment to prevent interference with other tutorials you might try later.\n\nTo stop the containers and remove associated volumes:\n\ndocker compose --profile cpp down -v --remove-orphans\n\nThis command ensures a clean slate for your next project.\n\nThe `--remove-"
  },
  "572": {
    "source_file": "build-a-cpp-app-with-jenkins.txt",
    "text": " associated volumes:\n\ndocker compose --profile cpp down -v --remove-orphans\n\nThis command ensures a clean slate for your next project.\n\nThe `--remove-orphans` option instructs Docker Compose to remove any containers that are not defined in the `docker-compose.yml` file but are labeled as belonging to the project. This helps in cleaning up any services that might have been started independently but"
  },
  "573": {
    "source_file": "build-a-cpp-app-with-jenkins.txt",
    "text": "r-compose.yml` file but are labeled as belonging to the project. This helps in cleaning up any services that might have been started independently but are considered part of the project.\n\n'''\n+++\n\n+++"
  },
  "574": {
    "source_file": "build-a-dotnet-web-app-with-jenkins.txt",
    "text": "layout: documentation\ntitle: Build a .NET Web App with Jenkins\nsection: doc\n\n\nThis tutorial shows you how to build a CI/CD pipeline in Jenkins to build, test, and deliver a simple .\n\nIf you are unfamiliar with publishing a .NET web app or you are not sure how to prepare a web app using Jenkins, this tutorial is for you.\n\nThis tutorial provides a ready-to-use web app, simple .NET API, and an integr"
  },
  "575": {
    "source_file": "build-a-dotnet-web-app-with-jenkins.txt",
    "text": " sure how to prepare a web app using Jenkins, this tutorial is for you.\n\nThis tutorial provides a ready-to-use web app, simple .NET API, and an integration test to ensure functionality.\nThe test results are generated in a Cobertura XML report.\n\n*Duration:* This tutorial takes 30 - 40 minutes to complete, assuming you meet the below <<prerequisites,prerequisites>>.\nThe exact duration will depend on"
  },
  "576": {
    "source_file": "build-a-dotnet-web-app-with-jenkins.txt",
    "text": "tion:* This tutorial takes 30 - 40 minutes to complete, assuming you meet the below <<prerequisites,prerequisites>>.\nThe exact duration will depend on the speed of your machine and whether you've already installed `docker` and `docker compose`.\n\nYou can stop this tutorial at any time and continue from where you left off.\n\n** , and optionally .\n\n[[fork-sample-repository]]\n[[fork-and-clone-the-sampl"
  },
  "577": {
    "source_file": "build-a-dotnet-web-app-with-jenkins.txt",
    "text": "can stop this tutorial at any time and continue from where you left off.\n\n** , and optionally .\n\n[[fork-sample-repository]]\n[[fork-and-clone-the-sample-repository-on-github]]\n\nGet the \"Weather Forecast\" .NET Web API from GitHub, by forking the sample repository of the application's source code into your own GitHub account, and then cloning this fork locally.\n\nMake sure you are signed in to your Gi"
  },
  "578": {
    "source_file": "build-a-dotnet-web-app-with-jenkins.txt",
    "text": " repository of the application's source code into your own GitHub account, and then cloning this fork locally.\n\nMake sure you are signed in to your GitHub account.\nIf you don't yet have a GitHub account, sign up for free at .\nFork the  on GitHub into your local GitHub account.\nIf you need help, refer to the  for more information.\nClone the forked `simple-dotnet-web-app` repository from GitHub to y"
  },
  "579": {
    "source_file": "build-a-dotnet-web-app-with-jenkins.txt",
    "text": " your local GitHub account.\nIf you need help, refer to the  for more information.\nClone the forked `simple-dotnet-web-app` repository from GitHub to your machine.\nTo begin this process, do either of the following, where `<your-username>` is the name of your user account on your operating system:\n** If you have the  app installed on your machine:\n.. In GitHub, select *Code* in your forked repositor"
  },
  "580": {
    "source_file": "build-a-dotnet-web-app-with-jenkins.txt",
    "text": "of your user account on your operating system:\n** If you have the  app installed on your machine:\n.. In GitHub, select *Code* in your forked repository, then select *Open with GitHub Desktop*.\n.. In GitHub Desktop, before selecting *Clone* in *Clone a Repository*, ensure *Local Path* for your operating system, as follows:\n*** macOS is `/Users/<your-username>/Documents/GitHub/simple-dotnet-web-app`"
  },
  "581": {
    "source_file": "build-a-dotnet-web-app-with-jenkins.txt",
    "text": "a Repository*, ensure *Local Path* for your operating system, as follows:\n*** macOS is `/Users/<your-username>/Documents/GitHub/simple-dotnet-web-app`\n*** Linux is `/home/<your-username>/GitHub/simple-dotnet-web-app`\n*** Windows is `C:\\Users\\<your-username>\\Documents\\GitHub\\simple-dotnet-web-app`\n** Alternatively:\n.. Open a terminal/command line prompt and `cd` to the appropriate directory, accord"
  },
  "582": {
    "source_file": "build-a-dotnet-web-app-with-jenkins.txt",
    "text": "ername>\\Documents\\GitHub\\simple-dotnet-web-app`\n** Alternatively:\n.. Open a terminal/command line prompt and `cd` to the appropriate directory, according to your operating system:\n*** macOS - `/Users/<your-username>/Documents/GitHub/`\n*** Linux - `/home/<your-username>/GitHub/`\n*** Windows - `C:\\Users\\<your-username>\\Documents\\GitHub\\` (Use a Git bash command line window, not the usual Microsoft c"
  },
  "583": {
    "source_file": "build-a-dotnet-web-app-with-jenkins.txt",
    "text": "ome/<your-username>/GitHub/`\n*** Windows - `C:\\Users\\<your-username>\\Documents\\GitHub\\` (Use a Git bash command line window, not the usual Microsoft command prompt)\n.. Run the following command to clone your forked repo, replacing `YOUR-GITHUB-ACCOUNT-NAME` with the name of your GitHub account:\ngit clone https://github.com/YOUR-GITHUB-ACCOUNT-NAME/simple-dotnet-web-app\n\n1. Obtain the latest Jenkin"
  },
  "584": {
    "source_file": "build-a-dotnet-web-app-with-jenkins.txt",
    "text": "T-NAME` with the name of your GitHub account:\ngit clone https://github.com/YOUR-GITHUB-ACCOUNT-NAME/simple-dotnet-web-app\n\n1. Obtain the latest Jenkins deployment, customized for this tutorial, by cloning the .\n2. After cloning, navigate to the `quickstart-tutorials` directory, and execute the command\ndocker compose --profile dotnet up -d\n\nto run the example.\n3. Once the containers are running suc"
  },
  "585": {
    "source_file": "build-a-dotnet-web-app-with-jenkins.txt",
    "text": "kstart-tutorials` directory, and execute the command\ndocker compose --profile dotnet up -d\n\nto run the example.\n3. Once the containers are running successfully (you can verify this with `docker compose ps`), the controller can be accessed at http://localhost:8080.\n\nIf you are unable to install `docker compose` on your machine for any reason, you can still run the example in the cloud for free usin"
  },
  "586": {
    "source_file": "build-a-dotnet-web-app-with-jenkins.txt",
    "text": "ocalhost:8080.\n\nIf you are unable to install `docker compose` on your machine for any reason, you can still run the example in the cloud for free using either:\n\n* *GitHub Codespaces* (Recommended): Click the *Code* button in the , select *Codespaces*, then *Create codespace on master*.\nGitHub Codespaces provides .\nOnce the Codespace starts, the setup will run automatically, and you'll see a welcom"
  },
  "587": {
    "source_file": "build-a-dotnet-web-app-with-jenkins.txt",
    "text": ", then *Create codespace on master*.\nGitHub Codespaces provides .\nOnce the Codespace starts, the setup will run automatically, and you'll see a welcome message with instructions.\n\n* *GitPod*: Click on  to open a GitPod workspace.\nGitPod .\nYou need to link it to your GitHub account.\n\nNow, log in using the `admin` username and `admin` password.\n\nIn Jenkins, select *New Item* under *Dashboard >* at t"
  },
  "588": {
    "source_file": "build-a-dotnet-web-app-with-jenkins.txt",
    "text": " link it to your GitHub account.\n\nNow, log in using the `admin` username and `admin` password.\n\nIn Jenkins, select *New Item* under *Dashboard >* at the top left.\nEnter your new Pipeline project name, such as `dotnet-tutorial`, in *Enter an item name*.\nScroll down if necessary and select *Pipeline*, then select *OK* at the end of the page.\n(Optional) Enter a Pipeline *Description*.\nSelect *Pipelin"
  },
  "589": {
    "source_file": "build-a-dotnet-web-app-with-jenkins.txt",
    "text": "*.\nScroll down if necessary and select *Pipeline*, then select *OK* at the end of the page.\n(Optional) Enter a Pipeline *Description*.\nSelect *Pipeline* on the left pane.\nSelect *Definition*, and then choose the *Pipeline script from SCM* option.\nThis option instructs Jenkins to obtain your Pipeline from the source control management (SCM), which is your forked Git repository.\nChoose *Git* from th"
  },
  "590": {
    "source_file": "build-a-dotnet-web-app-with-jenkins.txt",
    "text": "s option instructs Jenkins to obtain your Pipeline from the source control management (SCM), which is your forked Git repository.\nChoose *Git* from the options in *SCM*.\nEnter the URL of your repository in *Repositories/Repository URL*. This URL can be found when selecting the green *Code* button in the main page of your GitHub repo.\nUnder *Branches to build*, enter `*/main` in the *Branch Specifi"
  },
  "591": {
    "source_file": "build-a-dotnet-web-app-with-jenkins.txt",
    "text": "be found when selecting the green *Code* button in the main page of your GitHub repo.\nUnder *Branches to build*, enter `*/main` in the *Branch Specifier* field.\nSelect *Save* at the end of the page.\nYou're now ready to create a `Jenkinsfile` to check into your locally cloned Git repository.\n\nYou are now ready to create a Pipeline to automate the building of your .NET web app.\n\nYour Pipeline is cre"
  },
  "592": {
    "source_file": "build-a-dotnet-web-app-with-jenkins.txt",
    "text": " into your locally cloned Git repository.\n\nYou are now ready to create a Pipeline to automate the building of your .NET web app.\n\nYour Pipeline is created as a `Jenkinsfile`, which is committed to your locally cloned Git repository (`simple-dotnet-web-app`).\n\nThis is the foundation of \"Pipeline-as-Code\", which treats the continuous delivery pipeline as a part of the application, to be versioned an"
  },
  "593": {
    "source_file": "build-a-dotnet-web-app-with-jenkins.txt",
    "text": "b-app`).\n\nThis is the foundation of \"Pipeline-as-Code\", which treats the continuous delivery pipeline as a part of the application, to be versioned and reviewed like any other code.\nRead more about Pipeline and what a Jenkinsfile is in the  and  sections of the User Handbook.\n\nFirst, create an initial Pipeline to build your .NET web app.\nThe pipeline utilizes a customized agent that is shipped wit"
  },
  "594": {
    "source_file": "build-a-dotnet-web-app-with-jenkins.txt",
    "text": "ions of the User Handbook.\n\nFirst, create an initial Pipeline to build your .NET web app.\nThe pipeline utilizes a customized agent that is shipped with .NET SDK.\nEnsure you add a \"Build\" stage to the Pipeline that begins orchestrating this whole process.\n\nUsing your preferred text editor or IDE, create and save a new text file named `Jenkinsfile` at the root of your local `simple-dotnet-web-app` G"
  },
  "595": {
    "source_file": "build-a-dotnet-web-app-with-jenkins.txt",
    "text": "ess.\n\nUsing your preferred text editor or IDE, create and save a new text file named `Jenkinsfile` at the root of your local `simple-dotnet-web-app` Git repository.\nCopy the following Declarative Pipeline code and paste it into your newly created `Jenkinsfile`:\npipeline {\n    agent any\n    stages {\n        stage('Build') { // <1> steps {\n                sh 'dotnet restore' // <2> sh 'dotnet build "
  },
  "596": {
    "source_file": "build-a-dotnet-web-app-with-jenkins.txt",
    "text": "nkinsfile`:\npipeline {\n    agent any\n    stages {\n        stage('Build') { // <1> steps {\n                sh 'dotnet restore' // <2> sh 'dotnet build --no-restore' // <3> }\n        }\n    }\n}\n\n<1> Defines a  (directive) called `Build` that appears on the Jenkins UI.\n<2> This  step runs the `dotnet restore` command to download/restore the required dependencies of the .NET web app.\n<3> This  step run"
  },
  "597": {
    "source_file": "build-a-dotnet-web-app-with-jenkins.txt",
    "text": "the Jenkins UI.\n<2> This  step runs the `dotnet restore` command to download/restore the required dependencies of the .NET web app.\n<3> This  step runs the `dotnet build` command to build the .NET web app.\nSave your edited `Jenkinsfile` and commit it to your local `simple-dotnet-web-app` Git repository.\nWithin the `simple-dotnet-web-app` directory, run the commands:\n.. `git add .`\n.. `git commit -"
  },
  "598": {
    "source_file": "build-a-dotnet-web-app-with-jenkins.txt",
    "text": " to your local `simple-dotnet-web-app` Git repository.\nWithin the `simple-dotnet-web-app` directory, run the commands:\n.. `git add .`\n.. `git commit -m \"Add initial Jenkinsfile\"`\n.. `git push` to push your changes to your forked repository on GitHub, so it can be picked up by Jenkins.\n\nNow select *Build Now* on the left pane of your Pipeline project in Jenkins.\nAfter making a clone of your local `"
  },
  "599": {
    "source_file": "build-a-dotnet-web-app-with-jenkins.txt",
    "text": " so it can be picked up by Jenkins.\n\nNow select *Build Now* on the left pane of your Pipeline project in Jenkins.\nAfter making a clone of your local `simple-dotnet-web-app` Git repository itself, Jenkins:\n\nInitially queues the project to be run on the agent.\nRuns the `Build` stage defined in the `Jenkinsfile` on the agent.\n\nWhen it's a success, the green check will be shown and now you are ready t"
  },
  "600": {
    "source_file": "build-a-dotnet-web-app-with-jenkins.txt",
    "text": "e agent.\nRuns the `Build` stage defined in the `Jenkinsfile` on the agent.\n\nWhen it's a success, the green check will be shown and now you are ready to explore your initial pipeline.\n[.boxshadow]\n\nYou can now select *#1* in the *Stage View* or *Builds* widget to see the details of the build.\nThe status page displays how much time the build took waiting in the queue and how much time it took to run"
  },
  "601": {
    "source_file": "build-a-dotnet-web-app-with-jenkins.txt",
    "text": "s* widget to see the details of the build.\nThe status page displays how much time the build took waiting in the queue and how much time it took to run.\n\n[.boxshadow]\n\nIn the left navigation pane, you can select *Pipeline Overview* to see the stages of the Pipeline.\n[.boxshadow]\n\nIf you select the *Build* stage, you will see more information about the stage, including the output of the `dotnet buil"
  },
  "602": {
    "source_file": "build-a-dotnet-web-app-with-jenkins.txt",
    "text": "f the Pipeline.\n[.boxshadow]\n\nIf you select the *Build* stage, you will see more information about the stage, including the output of the `dotnet build` command if you select the green `dotnet build` section.\n[.boxshadow]\n\nYou can now select *dotnet-tutorial* (if that's the name you chose for your pipeline) from the breadcrumb navigation in the top-left to return to your pipeline main page.\n\nGo ba"
  },
  "603": {
    "source_file": "build-a-dotnet-web-app-with-jenkins.txt",
    "text": "tutorial* (if that's the name you chose for your pipeline) from the breadcrumb navigation in the top-left to return to your pipeline main page.\n\nGo back to your text editor/IDE and ensure your `Jenkinsfile` is open.\nCopy and paste the following Declarative Pipeline syntax immediately under the `Build` stage of your `Jenkinsfile`:\nstage('Test') {\n            steps {\n                sh 'dotnet test "
  },
  "604": {
    "source_file": "build-a-dotnet-web-app-with-jenkins.txt",
    "text": "rative Pipeline syntax immediately under the `Build` stage of your `Jenkinsfile`:\nstage('Test') {\n            steps {\n                sh 'dotnet test --no-build --no-restore --collect \"XPlat Code Coverage\"'\n            }\n            post {\n                always {\n                    recordCoverage(tools: [[parser: 'COBERTURA', pattern: '**/*.xml']], sourceDirectories: [[path: 'SimpleWebApi.Test/T"
  },
  "605": {
    "source_file": "build-a-dotnet-web-app-with-jenkins.txt",
    "text": "      always {\n                    recordCoverage(tools: [[parser: 'COBERTURA', pattern: '**/*.xml']], sourceDirectories: [[path: 'SimpleWebApi.Test/TestResults']])\n                }\n            }\n        }\n\nso that you end up with:\npipeline {\n    agent any\n    stages {\n        stage('Build') {\n            steps {\n                sh 'dotnet restore'\n                sh 'dotnet build --no-restore'\n "
  },
  "606": {
    "source_file": "build-a-dotnet-web-app-with-jenkins.txt",
    "text": "ent any\n    stages {\n        stage('Build') {\n            steps {\n                sh 'dotnet restore'\n                sh 'dotnet build --no-restore'\n            }\n        }\n        stage('Test') { // <1> steps {\n                sh 'dotnet test --no-build --no-restore --collect \"XPlat Code Coverage\"' // <2> }\n            post {\n                always {\n                    recordCoverage(tools: [[pa"
  },
  "607": {
    "source_file": "build-a-dotnet-web-app-with-jenkins.txt",
    "text": "uild --no-restore --collect \"XPlat Code Coverage\"' // <2> }\n            post {\n                always {\n                    recordCoverage(tools: [[parser: 'COBERTURA', pattern: '**/*.xml']], sourceDirectories: [[path: 'SimpleWebApi.Test/TestResults']])  // <3> }\n            }\n        }\n    }\n}\n\n<1> Defines a  (directive) called `Test` that appears on the Jenkins UI.\n<2> This  step executes the `d"
  },
  "608": {
    "source_file": "build-a-dotnet-web-app-with-jenkins.txt",
    "text": "]])  // <3> }\n            }\n        }\n    }\n}\n\n<1> Defines a  (directive) called `Test` that appears on the Jenkins UI.\n<2> This  step executes the `dotnet test` command to run the unit/integration test on your .NET web app.\nThis command also generates a Cobertura XML report, which is saved to the `SimpleWebApi.Test/TestResults` directory within the `/home/jenkins/agent/workspace/dotnet-tutorial` "
  },
  "609": {
    "source_file": "build-a-dotnet-web-app-with-jenkins.txt",
    "text": "es a Cobertura XML report, which is saved to the `SimpleWebApi.Test/TestResults` directory within the `/home/jenkins/agent/workspace/dotnet-tutorial` directory in the Jenkins agent container.\n<3> This  step (provided by the ), archives the Cobertura XML report generated by the `dotnet test` command above, and displays the results through the Jenkins interface.\nThe  section's `always` condition tha"
  },
  "610": {
    "source_file": "build-a-dotnet-web-app-with-jenkins.txt",
    "text": "XML report generated by the `dotnet test` command above, and displays the results through the Jenkins interface.\nThe  section's `always` condition that contains this `recordCoverage` step ensures that the step is _always_ executed _at the completion_ of the `Test` stage, regardless of the stage's outcome.\nSave your edited `Jenkinsfile` and commit it to your local `simple-dotnet-web-app` Git reposi"
  },
  "611": {
    "source_file": "build-a-dotnet-web-app-with-jenkins.txt",
    "text": " of the `Test` stage, regardless of the stage's outcome.\nSave your edited `Jenkinsfile` and commit it to your local `simple-dotnet-web-app` Git repository.\nWithin the `simple-dotnet-web-app` directory, run the commands:\n.. `git stage .`\n.. `git commit -m \"Add 'Test' stage\"`\n.. `git push` to push your changes to your forked repository on GitHub, so it can be picked up by Jenkins.\n\nIn Jenkins, go ba"
  },
  "612": {
    "source_file": "build-a-dotnet-web-app-with-jenkins.txt",
    "text": "t -m \"Add 'Test' stage\"`\n.. `git push` to push your changes to your forked repository on GitHub, so it can be picked up by Jenkins.\n\nIn Jenkins, go back to *Dashboard* if necessary, then *dotnet-tutorial* and launch another build using *Build Now*.\nAfter a while, a new column titled *Test* appears in the *Stage View*.\n\n[.boxshadow]\n\nYou can select *#2* (or the number representing your last build) "
  },
  "613": {
    "source_file": "build-a-dotnet-web-app-with-jenkins.txt",
    "text": "fter a while, a new column titled *Test* appears in the *Stage View*.\n\n[.boxshadow]\n\nYou can select *#2* (or the number representing your last build) in the *Stage View* or *Builds* widget to see the details of the build.\n\n[.boxshadow]\n\nYou can now select *Pipeline Overview* to see the stages of the Pipeline.\n[.boxshadow]\n\nThe newly added \"Test\" stage is visible here.\nSelecting the \"Test\" stage ch"
  },
  "614": {
    "source_file": "build-a-dotnet-web-app-with-jenkins.txt",
    "text": "elect *Pipeline Overview* to see the stages of the Pipeline.\n[.boxshadow]\n\nThe newly added \"Test\" stage is visible here.\nSelecting the \"Test\" stage checkmark displays the stage output.\n[.boxshadow]\n\nAdditionally, you can check the coverage result by navigating back to the job status page and selecting *Coverage Report*.\n\n[.boxshadow]\n\nGo back to your text editor/IDE and ensure your `Jenkinsfile` i"
  },
  "615": {
    "source_file": "build-a-dotnet-web-app-with-jenkins.txt",
    "text": "navigating back to the job status page and selecting *Coverage Report*.\n\n[.boxshadow]\n\nGo back to your text editor/IDE and ensure your `Jenkinsfile` is open.\nCopy and paste the following Declarative Pipeline syntax immediately under the `Test` stage of your `Jenkinsfile`:\nstage('Deliver') {\n            steps {\n                sh 'dotnet publish SimpleWebApi --no-restore -o published'\n            }"
  },
  "616": {
    "source_file": "build-a-dotnet-web-app-with-jenkins.txt",
    "text": "of your `Jenkinsfile`:\nstage('Deliver') {\n            steps {\n                sh 'dotnet publish SimpleWebApi --no-restore -o published'\n            }\n            post {\n                success {\n                    archiveArtifacts 'published/*.*'\n                }\n            }\n        }\n\nAdd a `skipStagesAfterUnstable` option, resulting in:\npipeline {\n    agent any\n    options {\n        skipSta"
  },
  "617": {
    "source_file": "build-a-dotnet-web-app-with-jenkins.txt",
    "text": "               }\n            }\n        }\n\nAdd a `skipStagesAfterUnstable` option, resulting in:\npipeline {\n    agent any\n    options {\n        skipStagesAfterUnstable()\n    }\n    stages {\n        stage('Build') {\n            steps {\n                sh 'dotnet restore'\n                sh 'dotnet build --no-restore'\n            }\n        }\n        stage('Test') {\n            steps {\n                "
  },
  "618": {
    "source_file": "build-a-dotnet-web-app-with-jenkins.txt",
    "text": "h 'dotnet restore'\n                sh 'dotnet build --no-restore'\n            }\n        }\n        stage('Test') {\n            steps {\n                sh 'dotnet test --no-build --no-restore --collect \"XPlat Code Coverage\"'\n            }\n            post {\n                always {\n                    recordCoverage(tools: [[parser: 'COBERTURA', pattern: '**/*.xml']], sourceDirectories: [[path: 'Sim"
  },
  "619": {
    "source_file": "build-a-dotnet-web-app-with-jenkins.txt",
    "text": "ost {\n                always {\n                    recordCoverage(tools: [[parser: 'COBERTURA', pattern: '**/*.xml']], sourceDirectories: [[path: 'SimpleWebApi.Test/TestResults']])\n                }\n            }\n        }\n        stage('Deliver') { // <1> steps {\n                sh 'dotnet publish SimpleWebApi --no-restore -o published'  // <2> }\n            post {\n                success {\n     "
  },
  "620": {
    "source_file": "build-a-dotnet-web-app-with-jenkins.txt",
    "text": "// <1> steps {\n                sh 'dotnet publish SimpleWebApi --no-restore -o published'  // <2> }\n            post {\n                success {\n                    archiveArtifacts 'published/*.*' // <3> }\n            }\n        }\n    }\n}\n\n<1> Defines a new stage called `Deliver` that appears on the Jenkins UI.\n<2> This  step executes the `dotnet publish` command to publish your .NET web app into "
  },
  "621": {
    "source_file": "build-a-dotnet-web-app-with-jenkins.txt",
    "text": "s a new stage called `Deliver` that appears on the Jenkins UI.\n<2> This  step executes the `dotnet publish` command to publish your .NET web app into executable and store it into the `published` directory.\n<3> This  step archives the `published` directory as a build artifact.\n\nSave your updated `Jenkinsfile` and commit it to your local `simple-dotnet-web-app` Git repository.\n.. `git stage .`\n.. `g"
  },
  "622": {
    "source_file": "build-a-dotnet-web-app-with-jenkins.txt",
    "text": "ctory as a build artifact.\n\nSave your updated `Jenkinsfile` and commit it to your local `simple-dotnet-web-app` Git repository.\n.. `git stage .`\n.. `git commit -m \"Add 'Deliver' stage\"`\n.. `git push` to push your changes to your forked repository on GitHub, so it can be picked up by Jenkins.\n\nReturn to the *Dashboard* and select *dotnet-tutorial*.\nSelect *Build Now* on the left. After a while, a n"
  },
  "623": {
    "source_file": "build-a-dotnet-web-app-with-jenkins.txt",
    "text": "GitHub, so it can be picked up by Jenkins.\n\nReturn to the *Dashboard* and select *dotnet-tutorial*.\nSelect *Build Now* on the left. After a while, a new column titled *Deliver* will appear in the Stage View.\n[.boxshadow]\n\nYou can select *#3* (or the number representing your last build) in the *Stage View* or *Builds* widget to see the details of the build.\n\nYou can now select *Pipeline Overview* t"
  },
  "624": {
    "source_file": "build-a-dotnet-web-app-with-jenkins.txt",
    "text": "number representing your last build) in the *Stage View* or *Builds* widget to see the details of the build.\n\nYou can now select *Pipeline Overview* to see the stages of the Pipeline.\nOnce you are on the *Pipeline Overview* page, you can select the green checkmark under *Deliver* green checkmark to see the stage output.\nSelecting the `dotnet publish` section expands to display the execution result"
  },
  "625": {
    "source_file": "build-a-dotnet-web-app-with-jenkins.txt",
    "text": "reen checkmark under *Deliver* green checkmark to see the stage output.\nSelecting the `dotnet publish` section expands to display the execution results of your .NET web app at the end of the build.\n[.boxshadow]\n\nYou can now select *dotnet-tutorial* (if that's the name you chose for your pipeline) from the breadcrumb navigation in the top-left to return to your pipeline main page.\nOnce you are on t"
  },
  "626": {
    "source_file": "build-a-dotnet-web-app-with-jenkins.txt",
    "text": "if that's the name you chose for your pipeline) from the breadcrumb navigation in the top-left to return to your pipeline main page.\nOnce you are on the *Status* page, you can select *Stages* from the left navigation pane to list your previous Pipeline runs in reverse chronological order.\n[.boxshadow]\n\nAfter your job finishes, you can review the delivered artifacts by navigating to the *Status* pa"
  },
  "627": {
    "source_file": "build-a-dotnet-web-app-with-jenkins.txt",
    "text": "ne runs in reverse chronological order.\n[.boxshadow]\n\nAfter your job finishes, you can review the delivered artifacts by navigating to the *Status* page.\nAfter selecting *dotnet-tutorial* from the breadcrumb navigation, the status page displays artifacts under *Last Successful Artifacts*.\n[.boxshadow]\n\nWell done!\nYou've just used Jenkins to build a simple .NET web app!\n\nThe \"Build\", \"Test\" and \"De"
  },
  "628": {
    "source_file": "build-a-dotnet-web-app-with-jenkins.txt",
    "text": "acts under *Last Successful Artifacts*.\n[.boxshadow]\n\nWell done!\nYou've just used Jenkins to build a simple .NET web app!\n\nThe \"Build\", \"Test\" and \"Deliver\" stages you created above are the basis for building more complex .NET web apps in Jenkins, as well as .NET applications that integrate with other technology stacks.\n\nBecause Jenkins is extremely extensible, it can be modified and configured to"
  },
  "629": {
    "source_file": "build-a-dotnet-web-app-with-jenkins.txt",
    "text": " well as .NET applications that integrate with other technology stacks.\n\nBecause Jenkins is extremely extensible, it can be modified and configured to handle practically any aspect of build orchestration and automation.\n\nTo learn more about what Jenkins can do, check out:\n\n* The  page for other introductory tutorials.\n* The  for more detailed information about using Jenkins, such as  (in particula"
  },
  "630": {
    "source_file": "build-a-dotnet-web-app-with-jenkins.txt",
    "text": "ins can do, check out:\n\n* The  page for other introductory tutorials.\n* The  for more detailed information about using Jenkins, such as  (in particular ) and the  interface.\n* The  for the latest events, other tutorials and updates.\n\nAfter completing the tutorial, it's important to clean up your environment to prevent interference with other tutorials you might try later.\n\nTo stop the containers a"
  },
  "631": {
    "source_file": "build-a-dotnet-web-app-with-jenkins.txt",
    "text": " the tutorial, it's important to clean up your environment to prevent interference with other tutorials you might try later.\n\nTo stop the containers and remove associated volumes:\n\ndocker compose --profile dotnet down -v --remove-orphans\n\nThis command ensures a clean slate for your next project.\n\nThe `--remove-orphans` option instructs Docker Compose to remove any containers that are not defined i"
  },
  "632": {
    "source_file": "build-a-dotnet-web-app-with-jenkins.txt",
    "text": "d ensures a clean slate for your next project.\n\nThe `--remove-orphans` option instructs Docker Compose to remove any containers that are not defined in the `docker-compose.yml` file but are labeled as belonging to the project.\nThis helps in cleaning up any services that might have been started independently but are considered part of the project.\n\n[[appendix]]\n\n'''\n+++\n\n+++"
  },
  "633": {
    "source_file": "build-a-dotnet-web-app-with-jenkins.txt",
    "text": "up any services that might have been started independently but are considered part of the project.\n\n[[appendix]]\n\n'''\n+++\n\n+++"
  },
  "634": {
    "source_file": "build-a-java-app-with-maven.txt",
    "text": "layout: documentation\ntitle: Build a Java app with Maven\nsection: doc\n\n\nThis tutorial shows you how to use Jenkins to build a simple Java application with https://maven.apache.org/[Maven].\n\nIf you are a Java developer using Maven, but new to CI/CD concepts, or if you are familiar with these concepts, but don't know how to implement building your application using Jenkins, then this tutorial is for"
  },
  "635": {
    "source_file": "build-a-java-app-with-maven.txt",
    "text": "ncepts, or if you are familiar with these concepts, but don't know how to implement building your application using Jenkins, then this tutorial is for you.\n\nThis example Java application from a GitHub repository outputs the string \"Hello world!\", and is accompanied by some unit tests, to check that the main application works as expected.\nThe test results are saved to a JUnit XML report.\n\n*Duration"
  },
  "636": {
    "source_file": "build-a-java-app-with-maven.txt",
    "text": " is accompanied by some unit tests, to check that the main application works as expected.\nThe test results are saved to a JUnit XML report.\n\n*Duration:* This tutorial takes 20-40 minutes to complete, assuming you meet the below <<prerequisites,prerequisites>>.\nThe exact duration will depend on the speed of your machine and whether you've already installed `docker` and `docker compose`.\n\nYou can st"
  },
  "637": {
    "source_file": "build-a-java-app-with-maven.txt",
    "text": "uisites>>.\nThe exact duration will depend on the speed of your machine and whether you've already installed `docker` and `docker compose`.\n\nYou can stop this tutorial at any time and continue from where you left off.\n\nMake sure you have  installed locally.\n\n** , and optionally .\n\n[[fork-sample-repository]]\n[[fork-and-clone-the-sample-repository-on-github]]\n\nGet the \"Hello world!\" Java application "
  },
  "638": {
    "source_file": "build-a-java-app-with-maven.txt",
    "text": "cally.\n\n** , and optionally .\n\n[[fork-sample-repository]]\n[[fork-and-clone-the-sample-repository-on-github]]\n\nGet the \"Hello world!\" Java application from GitHub, by forking the sample repository of the application's source code into your own GitHub account, and then cloning this fork locally.\n\nMake sure you are signed in to your GitHub account.\nIf you don't yet have a GitHub account, sign up for "
  },
  "639": {
    "source_file": "build-a-java-app-with-maven.txt",
    "text": "account, and then cloning this fork locally.\n\nMake sure you are signed in to your GitHub account.\nIf you don't yet have a GitHub account, sign up for free at .\nFork the  on GitHub into your local GitHub account.\nIf you need help, refer to the  for more information.\nClone the forked `simple-java-maven-app` repository from GitHub to your machine.\nTo begin this process, do either of the following, wh"
  },
  "640": {
    "source_file": "build-a-java-app-with-maven.txt",
    "text": "re information.\nClone the forked `simple-java-maven-app` repository from GitHub to your machine.\nTo begin this process, do either of the following, where `<your-username>` is the name of your user account on your operating system:\n** If you have the  app installed on your machine:\n.. In GitHub, select *Code* in your forked repository, then select *Open with GitHub Desktop*.\n.. In GitHub Desktop, b"
  },
  "641": {
    "source_file": "build-a-java-app-with-maven.txt",
    "text": " app installed on your machine:\n.. In GitHub, select *Code* in your forked repository, then select *Open with GitHub Desktop*.\n.. In GitHub Desktop, before selecting *Clone* in *Clone a Repository*, ensure *Local Path* for your operating system, as follows:\n*** macOS is `/Users/<your-username>/Documents/GitHub/simple-java-maven-app`\n*** Linux is `/home/<your-username>/GitHub/simple-java-maven-app`"
  },
  "642": {
    "source_file": "build-a-java-app-with-maven.txt",
    "text": "ollows:\n*** macOS is `/Users/<your-username>/Documents/GitHub/simple-java-maven-app`\n*** Linux is `/home/<your-username>/GitHub/simple-java-maven-app`\n*** Windows is `C:\\Users\\<your-username>\\Documents\\GitHub\\simple-java-maven-app`\n** Alternatively:\n.. Open a terminal/command line prompt and `cd` to the appropriate directory, according to your operating system:\n*** macOS - `/Users/<your-username>/"
  },
  "643": {
    "source_file": "build-a-java-app-with-maven.txt",
    "text": ".. Open a terminal/command line prompt and `cd` to the appropriate directory, according to your operating system:\n*** macOS - `/Users/<your-username>/Documents/GitHub/`\n*** Linux - `/home/<your-username>/GitHub/`\n*** Windows - `C:\\Users\\<your-username>\\Documents\\GitHub\\` (Use a Git bash command line window, not the usual Microsoft command prompt)\n.. Run the following command to clone your forked r"
  },
  "644": {
    "source_file": "build-a-java-app-with-maven.txt",
    "text": "e>\\Documents\\GitHub\\` (Use a Git bash command line window, not the usual Microsoft command prompt)\n.. Run the following command to clone your forked repo, replacing `YOUR-GITHUB-ACCOUNT-NAME` with the name of your GitHub account:\ngit clone https://github.com/YOUR-GITHUB-ACCOUNT-NAME/simple-java-maven-app\n\n1. Obtain the latest Jenkins deployment, customized for this tutorial, by cloning the .\n2. Af"
  },
  "645": {
    "source_file": "build-a-java-app-with-maven.txt",
    "text": "thub.com/YOUR-GITHUB-ACCOUNT-NAME/simple-java-maven-app\n\n1. Obtain the latest Jenkins deployment, customized for this tutorial, by cloning the .\n2. After cloning, navigate to the `quickstart-tutorials` directory, and execute the command\ndocker compose --profile maven up -d\n\nto run the example.\n3. Once the containers are running successfully (you can verify this with `docker compose ps`), the contr"
  },
  "646": {
    "source_file": "build-a-java-app-with-maven.txt",
    "text": "e --profile maven up -d\n\nto run the example.\n3. Once the containers are running successfully (you can verify this with `docker compose ps`), the controller can be accessed at http://localhost:8080.\n\nIf you are unable to install `docker compose` on your machine for any reason, you can still run the example in the cloud for free using either:\n\n* *GitHub Codespaces* (Recommended): Click the *Code* bu"
  },
  "647": {
    "source_file": "build-a-java-app-with-maven.txt",
    "text": "ur machine for any reason, you can still run the example in the cloud for free using either:\n\n* *GitHub Codespaces* (Recommended): Click the *Code* button in the , select *Codespaces*, then *Create codespace on master*.\nGitHub Codespaces provides .\nOnce the Codespace starts, the setup will run automatically, and you'll see a welcome message with instructions.\n\n* *GitPod*: Click on  to open a GitPo"
  },
  "648": {
    "source_file": "build-a-java-app-with-maven.txt",
    "text": "nce the Codespace starts, the setup will run automatically, and you'll see a welcome message with instructions.\n\n* *GitPod*: Click on  to open a GitPod workspace.\nGitPod .\nYou need to link it to your GitHub account.\n\nNow, log in using the `admin` username and `admin` password.\n\nIn Jenkins, select *New Item* under *Dashboard >* at the top left.\nEnter your new Pipeline project name in *Enter an item"
  },
  "649": {
    "source_file": "build-a-java-app-with-maven.txt",
    "text": "rname and `admin` password.\n\nIn Jenkins, select *New Item* under *Dashboard >* at the top left.\nEnter your new Pipeline project name in *Enter an item name*.\nScroll down if necessary and select *Pipeline*, then select *OK* at the end of the page.\n(Optional) Enter a Pipeline *Description*.\nSelect *Pipeline* on the left pane.\nSelect *Definition*, and then choose the *Pipeline script from SCM* option"
  },
  "650": {
    "source_file": "build-a-java-app-with-maven.txt",
    "text": "tional) Enter a Pipeline *Description*.\nSelect *Pipeline* on the left pane.\nSelect *Definition*, and then choose the *Pipeline script from SCM* option.\nThis option instructs Jenkins to obtain your Pipeline from the source control management (SCM), which is your forked Git repository.\nChoose *Git* from the options in *SCM*.\nEnter the URL of your repository in *Repositories/Repository URL*. This URL"
  },
  "651": {
    "source_file": "build-a-java-app-with-maven.txt",
    "text": "ich is your forked Git repository.\nChoose *Git* from the options in *SCM*.\nEnter the URL of your repository in *Repositories/Repository URL*. This URL can be found when clicking on the green *Code* button in the main page of your GitHub repo.\nSelect *Save* at the end of the page.\nYou're now ready to create a `Jenkinsfile` to check into your locally cloned Git repository.\n\nYou can now create a Pipe"
  },
  "652": {
    "source_file": "build-a-java-app-with-maven.txt",
    "text": "*Save* at the end of the page.\nYou're now ready to create a `Jenkinsfile` to check into your locally cloned Git repository.\n\nYou can now create a Pipeline that automates the building of your Java application with Maven in Jenkins.\n\nYour Pipeline is created as a `Jenkinsfile`, which is committed to your locally cloned Git repository (`simple-java-maven-app`).\n\nThis is the foundation of \"Pipeline-as"
  },
  "653": {
    "source_file": "build-a-java-app-with-maven.txt",
    "text": "reated as a `Jenkinsfile`, which is committed to your locally cloned Git repository (`simple-java-maven-app`).\n\nThis is the foundation of \"Pipeline-as-Code\", which treats the continuous delivery pipeline as a part of the application, to be versioned and reviewed like any other code.\nRead more about Pipeline and what a Jenkinsfile is in the  and  sections of the User Handbook.\n\nFirst, create an ini"
  },
  "654": {
    "source_file": "build-a-java-app-with-maven.txt",
    "text": "and reviewed like any other code.\nRead more about Pipeline and what a Jenkinsfile is in the  and  sections of the User Handbook.\n\nFirst, create an initial Pipeline to download a Maven Docker image and run it as a Docker container, which will build your Java application.\nEnsure you add a \"Build\" stage to the Pipeline that begins orchestrating this whole process.\n\nUsing your preferred text editor or"
  },
  "655": {
    "source_file": "build-a-java-app-with-maven.txt",
    "text": "ur Java application.\nEnsure you add a \"Build\" stage to the Pipeline that begins orchestrating this whole process.\n\nUsing your preferred text editor or IDE, create and save a new text file named `Jenkinsfile` at the root of your local `simple-java-maven-app` Git repository.\nCopy the following Declarative Pipeline code and paste it into your newly created `Jenkinsfile`:\npipeline {\n    agent any\n    "
  },
  "656": {
    "source_file": "build-a-java-app-with-maven.txt",
    "text": "en-app` Git repository.\nCopy the following Declarative Pipeline code and paste it into your newly created `Jenkinsfile`:\npipeline {\n    agent any\n    stages {\n        stage('Build') { // <1> steps {\n                sh 'mvn -B -DskipTests clean package' // <2> }\n        }\n    }\n}\n\n<1> Defines a  (directive) called `Build` that appears on the Jenkins UI.\n<2> This  step runs the Maven command to clea"
  },
  "657": {
    "source_file": "build-a-java-app-with-maven.txt",
    "text": "e' // <2> }\n        }\n    }\n}\n\n<1> Defines a  (directive) called `Build` that appears on the Jenkins UI.\n<2> This  step runs the Maven command to cleanly build your Java application without running any tests.\nSave your edited `Jenkinsfile` and commit it to your local `simple-java-maven-app` Git repository.\nWithin the `simple-java-maven-app` directory, run the commands:\n.. `git add .`\n.. `git commi"
  },
  "658": {
    "source_file": "build-a-java-app-with-maven.txt",
    "text": " it to your local `simple-java-maven-app` Git repository.\nWithin the `simple-java-maven-app` directory, run the commands:\n.. `git add .`\n.. `git commit -m \"Add initial Jenkinsfile\"`\n.. `git push` to push your changes to your forked repository on GitHub, so it can be picked up by Jenkins.\n\nNow select *Build Now* on the left pane of your Pipeline project in Jenkins.\nAfter making a clone of your loca"
  },
  "659": {
    "source_file": "build-a-java-app-with-maven.txt",
    "text": "ub, so it can be picked up by Jenkins.\n\nNow select *Build Now* on the left pane of your Pipeline project in Jenkins.\nAfter making a clone of your local `simple-java-maven-app` Git repository itself, Jenkins:\n\nInitially queues the project to be run on the agent.\nRuns the `Build` stage defined in the `Jenkinsfile` on the agent.\n\nDuring this time, Maven downloads many artifacts necessary to build you"
  },
  "660": {
    "source_file": "build-a-java-app-with-maven.txt",
    "text": " the agent.\nRuns the `Build` stage defined in the `Jenkinsfile` on the agent.\n\nDuring this time, Maven downloads many artifacts necessary to build your Java application, which are ultimately stored in Jenkins' local Maven repository.\n[.boxshadow]\n\nYou can now click on *#1* to see the details of the build.\nYou will then see how much time the build took waiting in the queue, and how much time it too"
  },
  "661": {
    "source_file": "build-a-java-app-with-maven.txt",
    "text": "u can now click on *#1* to see the details of the build.\nYou will then see how much time the build took waiting in the queue, and how much time it took to run.\n\n[.boxshadow]\n\nOn the left, you can click on *Pipeline Overview* to see the stages of the Pipeline.\n[.boxshadow]\n\nIf you select the *Build* stage, you will see more information about the stage, including the output of the `mvn` command if y"
  },
  "662": {
    "source_file": "build-a-java-app-with-maven.txt",
    "text": "Pipeline.\n[.boxshadow]\n\nIf you select the *Build* stage, you will see more information about the stage, including the output of the `mvn` command if you click on the green `maven` section.\n[.boxshadow]\n\nYou can now click on *Maven tutorial* (if that's the name you chose for your pipeline) on the top left to return to your pipeline main page.\n\nGo back to your text editor/IDE and ensure your `Jenkin"
  },
  "663": {
    "source_file": "build-a-java-app-with-maven.txt",
    "text": "s the name you chose for your pipeline) on the top left to return to your pipeline main page.\n\nGo back to your text editor/IDE and ensure your `Jenkinsfile` is open.\nCopy and paste the following Declarative Pipeline syntax immediately under the `Build` stage of your `Jenkinsfile`:\nstage('Test') {\n            steps {\n                sh 'mvn test'\n            }\n            post {\n                alw"
  },
  "664": {
    "source_file": "build-a-java-app-with-maven.txt",
    "text": "d` stage of your `Jenkinsfile`:\nstage('Test') {\n            steps {\n                sh 'mvn test'\n            }\n            post {\n                always {\n                    junit 'target/surefire-reports/*.xml'\n                }\n            }\n        }\n\nso that you end up with:\npipeline {\n    agent any\n    stages {\n        stage('Build') {\n            steps {\n                sh 'mvn -B -DskipTe"
  },
  "665": {
    "source_file": "build-a-java-app-with-maven.txt",
    "text": "    }\n\nso that you end up with:\npipeline {\n    agent any\n    stages {\n        stage('Build') {\n            steps {\n                sh 'mvn -B -DskipTests clean package'\n            }\n        }\n        stage('Test') { // <1> steps {\n                sh 'mvn test' // <2> }\n            post {\n                always {\n                    junit 'target/surefire-reports/*.xml' // <3> }\n            }\n    "
  },
  "666": {
    "source_file": "build-a-java-app-with-maven.txt",
    "text": " 'mvn test' // <2> }\n            post {\n                always {\n                    junit 'target/surefire-reports/*.xml' // <3> }\n            }\n        }\n    }\n}\n\n<1> Defines a  (directive) called `Test` that appears on the Jenkins UI.\n<2> This  step executes the Maven command to run the unit test on your Java application.\nThis command also generates a JUnit XML report, which is saved to the `ta"
  },
  "667": {
    "source_file": "build-a-java-app-with-maven.txt",
    "text": "ep executes the Maven command to run the unit test on your Java application.\nThis command also generates a JUnit XML report, which is saved to the `target/surefire-reports` directory within the `/var/jenkins_home/workspace/simple-java-maven-app` directory in the Jenkins container.\n<3> This  step (provided by the ), archives the JUnit XML report generated by the `mvn test` command above, and displa"
  },
  "668": {
    "source_file": "build-a-java-app-with-maven.txt",
    "text": "ctory in the Jenkins container.\n<3> This  step (provided by the ), archives the JUnit XML report generated by the `mvn test` command above, and displays the results through the Jenkins interface.\nThe  section's `always` condition that contains this `junit` step ensures that the step is _always_ executed _at the completion_ of the `Test` stage, regardless of the stage's outcome.\nSave your edited `J"
  },
  "669": {
    "source_file": "build-a-java-app-with-maven.txt",
    "text": "junit` step ensures that the step is _always_ executed _at the completion_ of the `Test` stage, regardless of the stage's outcome.\nSave your edited `Jenkinsfile` and commit it to your local `simple-java-maven-app` Git repository.\nWithin the `simple-java-maven-app` directory, run the commands:\n.. `git stage .`\n.. `git commit -m \"Add 'Test' stage\"`\n.. `git push` to push your changes to your forked r"
  },
  "670": {
    "source_file": "build-a-java-app-with-maven.txt",
    "text": "ava-maven-app` directory, run the commands:\n.. `git stage .`\n.. `git commit -m \"Add 'Test' stage\"`\n.. `git push` to push your changes to your forked repository on GitHub, so it can be picked up by Jenkins.\n\nIn Jenkins, go back to *Dashboard* if necessary, then *Maven Tutorial* and launch another build thanks to *Build Now*.\nAfter a while, a new column *Test* appear in the *Stage View*.\n\n[.boxshado"
  },
  "671": {
    "source_file": "build-a-java-app-with-maven.txt",
    "text": "sary, then *Maven Tutorial* and launch another build thanks to *Build Now*.\nAfter a while, a new column *Test* appear in the *Stage View*.\n\n[.boxshadow]\n\nYou can click on *#2* or on the number representing your last build on the left, under *Build History*. You will then see the details of the build.\nIf Docker has not restarted since you last ran the Pipeline <<create-your-initial-pipeline-as-a-je"
  },
  "672": {
    "source_file": "build-a-java-app-with-maven.txt",
    "text": "story*. You will then see the details of the build.\nIf Docker has not restarted since you last ran the Pipeline <<create-your-initial-pipeline-as-a-jenkinsfile,above>>, then no Maven artifacts are downloaded during the \"Build\" stage.\nTherefore, running your Pipeline this subsequent time should be much faster.\n\nYou can now click on *Pipeline Overview* to see the stages of the Pipeline.\n[.boxshadow]"
  },
  "673": {
    "source_file": "build-a-java-app-with-maven.txt",
    "text": "ng your Pipeline this subsequent time should be much faster.\n\nYou can now click on *Pipeline Overview* to see the stages of the Pipeline.\n[.boxshadow]\n\nNotice the additional \"Test\" stage.\nYou can select the \"Test\" stage checkmark to access the output from that stage.\n[.boxshadow]\n\nGo back to your text editor/IDE and ensure your `Jenkinsfile` is open.\nCopy and paste the following Declarative Pipeli"
  },
  "674": {
    "source_file": "build-a-java-app-with-maven.txt",
    "text": " from that stage.\n[.boxshadow]\n\nGo back to your text editor/IDE and ensure your `Jenkinsfile` is open.\nCopy and paste the following Declarative Pipeline syntax immediately under the `Test` stage of your `Jenkinsfile`:\nstage('Deliver') {\n            steps {\n                sh './jenkins/scripts/deliver.sh'\n            }\n        }\n\nAdd a `skipStagesAfterUnstable` option, resulting in:\npipeline {\n   "
  },
  "675": {
    "source_file": "build-a-java-app-with-maven.txt",
    "text": "teps {\n                sh './jenkins/scripts/deliver.sh'\n            }\n        }\n\nAdd a `skipStagesAfterUnstable` option, resulting in:\npipeline {\n    agent any\n    options {\n        skipStagesAfterUnstable()\n    }\n    stages {\n        stage('Build') {\n            steps {\n                sh 'mvn -B -DskipTests clean package'\n            }\n        }\n        stage('Test') {\n            steps {\n     "
  },
  "676": {
    "source_file": "build-a-java-app-with-maven.txt",
    "text": " {\n            steps {\n                sh 'mvn -B -DskipTests clean package'\n            }\n        }\n        stage('Test') {\n            steps {\n                sh 'mvn test'\n            }\n            post {\n                always {\n                    junit 'target/surefire-reports/*.xml'\n                }\n            }\n        }\n        stage('Deliver') { // <1> steps {\n                sh './jen"
  },
  "677": {
    "source_file": "build-a-java-app-with-maven.txt",
    "text": "   junit 'target/surefire-reports/*.xml'\n                }\n            }\n        }\n        stage('Deliver') { // <1> steps {\n                sh './jenkins/scripts/deliver.sh' // <2> }\n        }\n    }\n}\n\n<1> Defines a new stage called `Deliver` that appears on the Jenkins UI.\n<2> This  step runs the shell script `deliver.sh` located in the `jenkins/scripts` directory from the root of the `simple-ja"
  },
  "678": {
    "source_file": "build-a-java-app-with-maven.txt",
    "text": "ppears on the Jenkins UI.\n<2> This  step runs the shell script `deliver.sh` located in the `jenkins/scripts` directory from the root of the `simple-java-maven-app` repository.\nRefer to the `deliver.sh` script file to learn more.\nIt is generally good practice to keep your Pipeline code, such as your `Jenkinsfile`, streamlined, and place more complex build steps, particularly stages consisting of 2 "
  },
  "679": {
    "source_file": "build-a-java-app-with-maven.txt",
    "text": "practice to keep your Pipeline code, such as your `Jenkinsfile`, streamlined, and place more complex build steps, particularly stages consisting of 2 or more steps, into separate shell script files (like the `deliver.sh` file).\nMaintaining your Pipeline code is easier this way.\nSave your updated `Jenkinsfile` and commit it to your local `simple-java-maven-app` Git repository.\n.. `git stage .`\n.. `"
  },
  "680": {
    "source_file": "build-a-java-app-with-maven.txt",
    "text": "ine code is easier this way.\nSave your updated `Jenkinsfile` and commit it to your local `simple-java-maven-app` Git repository.\n.. `git stage .`\n.. `git commit -m \"Add 'Deliver' stage\"`\n.. `git push` to push your changes to your forked repository on GitHub, so it can be picked up by Jenkins.\n\nIn Jenkins, sign in if necessary, and go back to the *Dashboard* and then *Maven tutorial* or go directly"
  },
  "681": {
    "source_file": "build-a-java-app-with-maven.txt",
    "text": " GitHub, so it can be picked up by Jenkins.\n\nIn Jenkins, sign in if necessary, and go back to the *Dashboard* and then *Maven tutorial* or go directly to *Maven tutorial* depending on where you're starting from.\nSelect *Build Now* on the left. You should see after a while a new column *Deliver* appear in the *Stage View*.\n[.boxshadow]\n\nYou can click on *#3* or on the number representing your last "
  },
  "682": {
    "source_file": "build-a-java-app-with-maven.txt",
    "text": "ould see after a while a new column *Deliver* appear in the *Stage View*.\n[.boxshadow]\n\nYou can click on *#3* or on the number representing your last build on the left, under *Build History*. You will then see the details of the build.\n\nYou can now click on *Pipeline Overview* to see the stages of the Pipeline.\nOnce you click on the *Deliver* green checkmark, and then on the first green section, t"
  },
  "683": {
    "source_file": "build-a-java-app-with-maven.txt",
    "text": "lick on *Pipeline Overview* to see the stages of the Pipeline.\nOnce you click on the *Deliver* green checkmark, and then on the first green section, the output should be something like below, showing you the execution results of your Java application at the end.\n[.boxshadow]\n\nYou can now click on *Maven tutorial* on the top left, and then on *Stages* at the left. It will list your previous Pipelin"
  },
  "684": {
    "source_file": "build-a-java-app-with-maven.txt",
    "text": " at the end.\n[.boxshadow]\n\nYou can now click on *Maven tutorial* on the top left, and then on *Stages* at the left. It will list your previous Pipeline runs in reverse chronological order.\n[.boxshadow]\n\nWell done!\nYou've just used Jenkins to build a simple Java application with Maven!\n\nThe \"Build\", \"Test\" and \"Deliver\" stages you created above are the basis for building more complex Java applicati"
  },
  "685": {
    "source_file": "build-a-java-app-with-maven.txt",
    "text": "simple Java application with Maven!\n\nThe \"Build\", \"Test\" and \"Deliver\" stages you created above are the basis for building more complex Java applications with Maven in Jenkins, as well as Java and Maven applications that integrate with other technology stacks.\n\nBecause Jenkins is extremely extensible, it can be modified and configured to handle practically any aspect of build orchestration and aut"
  },
  "686": {
    "source_file": "build-a-java-app-with-maven.txt",
    "text": "gy stacks.\n\nBecause Jenkins is extremely extensible, it can be modified and configured to handle practically any aspect of build orchestration and automation.\n\nTo learn more about what Jenkins can do, check out:\n\n* The  page for other introductory tutorials.\n* The  for more detailed information about using Jenkins, such as  (in particular ) and the  interface.\n* The  for the latest events, other t"
  },
  "687": {
    "source_file": "build-a-java-app-with-maven.txt",
    "text": "torials.\n* The  for more detailed information about using Jenkins, such as  (in particular ) and the  interface.\n* The  for the latest events, other tutorials and updates.\n\nAfter completing the tutorial, it's important to clean up your environment to prevent interference with other tutorials you might try later.\n\nTo stop the containers and remove associated volumes:\n\ndocker compose --profile maven"
  },
  "688": {
    "source_file": "build-a-java-app-with-maven.txt",
    "text": " prevent interference with other tutorials you might try later.\n\nTo stop the containers and remove associated volumes:\n\ndocker compose --profile maven down -v --remove-orphans\n\nThis command ensures a clean slate for your next project.\n\nThe `--remove-orphans` option instructs Docker Compose to remove any containers that are not defined in the `docker-compose.yml` file but are labeled as belonging t"
  },
  "689": {
    "source_file": "build-a-java-app-with-maven.txt",
    "text": "orphans` option instructs Docker Compose to remove any containers that are not defined in the `docker-compose.yml` file but are labeled as belonging to the project.\nThis helps in cleaning up any services that might have been started independently but are considered part of the project.\n\n[[appendix]]\n\n'''\n+++\n\n+++"
  },
  "690": {
    "source_file": "build-a-java-app-with-maven.txt",
    "text": " are considered part of the project.\n\n[[appendix]]\n\n'''\n+++\n\n+++"
  },
  "691": {
    "source_file": "build-a-labview-app.txt",
    "text": "layout: documentation\ntitle: Build a LabVIEW app\nsection: doc\n\n\nThis tutorial shows you how to use LabVIEW to orchestrate building a simple https://www.ni.com/en-us/shop/labview.html[LabVIEW] application.\n\nIf you are a LabVIEW developer who is new to CI/CD concepts, or you might be familiar with these concepts but don't know how to implement building your application using Jenkins, then this tutor"
  },
  "692": {
    "source_file": "build-a-labview-app.txt",
    "text": " CI/CD concepts, or you might be familiar with these concepts but don't know how to implement building your application using Jenkins, then this tutorial is for you.\n\nWe\u2019ll walk through setting up Jenkins as our CI server and using it to automate graphical diffing and testing of our project (which you'll obtain from http://www.ni.com/example/lv-ci[this example page] on ni.com). Jenkins will monito"
  },
  "693": {
    "source_file": "build-a-labview-app.txt",
    "text": "phical diffing and testing of our project (which you'll obtain from http://www.ni.com/example/lv-ci[this example page] on ni.com). Jenkins will monitor GitHub Pull Requests for changes and will comment and check if the LabVIEW project can build successfully. Unit test results will be saved to a JUnit XML report.\n\n*Duration:* This tutorial takes 20-40 minutes to complete (assuming you've\nalready me"
  },
  "694": {
    "source_file": "build-a-labview-app.txt",
    "text": "ssfully. Unit test results will be saved to a JUnit XML report.\n\n*Duration:* This tutorial takes 20-40 minutes to complete (assuming you've\nalready met the <<prerequisites,prerequisites>> below). The exact duration will\ndepend on the speed of your machine and whether or not you've already  from .\n\nYou can stop this tutorial at any point in time and continue from where you left off.\n\nFor this tutor"
  },
  "695": {
    "source_file": "build-a-labview-app.txt",
    "text": "chine and whether or not you've already  from .\n\nYou can stop this tutorial at any point in time and continue from where you left off.\n\nFor this tutorial, you will require:\n\n* A macOS, Linux or Windows machine with:\n** 256 MB of RAM, although more than 2 GB is recommended.\n** 10 GB of drive space for Jenkins and your Docker images and containers.\n* The following software installed:\n**\n**\n**\n** . F"
  },
  "696": {
    "source_file": "build-a-labview-app.txt",
    "text": "an 2 GB is recommended.\n** 10 GB of drive space for Jenkins and your Docker images and containers.\n* The following software installed:\n**\n**\n**\n** . For these examples to work, make sure Python is added to your System Path.\n**  and optionally .\n\n*Note*: This tutorial uses Jenkins on a Windows machine. This means that file paths may be Windows-specific. Please modify any file paths and/or commands "
  },
  "697": {
    "source_file": "build-a-labview-app.txt",
    "text": "e*: This tutorial uses Jenkins on a Windows machine. This means that file paths may be Windows-specific. Please modify any file paths and/or commands to your specific Operating System.\n\n[[labview-cli-setup]]\n\nThe  is installed alongside LabVIEW 2018+ and is used to run LabVIEW commands, such as unit testing, through the Command Line. To use the LabVIEWCLI, you must enable VI Server: *Tools >> Opti"
  },
  "698": {
    "source_file": "build-a-labview-app.txt",
    "text": " and is used to run LabVIEW commands, such as unit testing, through the Command Line. To use the LabVIEWCLI, you must enable VI Server: *Tools >> Options >> VI Server*. Make sure the TCP/IP checkbox is enabled and leave the Port as 3363.\n\n[.boxshadow]\n\nThe Python  library must be installed in order for Jenkins to post results to GitHub. One way to do this is by opening a command prompt and running"
  },
  "699": {
    "source_file": "build-a-labview-app.txt",
    "text": "]\n\nThe Python  library must be installed in order for Jenkins to post results to GitHub. One way to do this is by opening a command prompt and running the following command:\n\n    pip install requests\n\nWe\u2019ll create three GitHub repositories. Each of these repositories will be used for one of the following:\n\n* Host the script files, library files, and  infrastructure items needed for the build serve"
  },
  "700": {
    "source_file": "build-a-labview-app.txt",
    "text": "hese repositories will be used for one of the following:\n\n* Host the script files, library files, and  infrastructure items needed for the build server.\n* Host the actual example application.\n* Host images used during the VI diffing step.\n\nTo create these repositories:\n\nCreate or log in to your https://github.com/[GitHub] account. Make sure your email is verified.\nClick on the *New* button next to"
  },
  "701": {
    "source_file": "build-a-labview-app.txt",
    "text": "these repositories:\n\nCreate or log in to your https://github.com/[GitHub] account. Make sure your email is verified.\nClick on the *New* button next to Repositories:\n[.boxshadow]\n\nOn the *Create a new repository* screen, fill out the Repository name and Description:\n[.boxshadow]\n\nClick Create repository to create the repository.\nRepeat steps 2-4 using the below information. This will be the reposit"
  },
  "702": {
    "source_file": "build-a-labview-app.txt",
    "text": "nd Description:\n[.boxshadow]\n\nClick Create repository to create the repository.\nRepeat steps 2-4 using the below information. This will be the repository for the actual example application.\n[.boxshadow]\n\nRepeat steps 2-4 with the following information. This will be used to host images for diffing.\n[.boxshadow]\n\nOpen a terminal with Git. If you installed Git Bash on Windows, open Git Bash:\n[.boxsha"
  },
  "703": {
    "source_file": "build-a-labview-app.txt",
    "text": "n. This will be used to host images for diffing.\n[.boxshadow]\n\nOpen a terminal with Git. If you installed Git Bash on Windows, open Git Bash:\n[.boxshadow]\n\nCreate a local directory to maintain your Jenkins files. For this example, we\u2019ll be using the `C:/Users/<User>/Documents/GitHub` directory. To create and navigate to this directory, run the following commands:\n\n    cd \u201cC:/Users/<User>/Documents"
  },
  "704": {
    "source_file": "build-a-labview-app.txt",
    "text": "`C:/Users/<User>/Documents/GitHub` directory. To create and navigate to this directory, run the following commands:\n\n    cd \u201cC:/Users/<User>/Documents\u201d\n\n    mkdir GitHub\n\n    cd GitHub\n\nRun the following command (using the URL copied from Step 5) to copy the Git repository and its contents onto your machine (You can also obtain the HTTPS URL of the repository by clicking on the Copy button on the "
  },
  "705": {
    "source_file": "build-a-labview-app.txt",
    "text": "copy the Git repository and its contents onto your machine (You can also obtain the HTTPS URL of the repository by clicking on the Copy button on the GitHub repository page):\n\n    git clone https://github.com/<Organization Name>/<Repository Name>.git\n\nRepeat Step 9 for the myApplication repository.\n\nIn Windows Explorer, place the contents of `../myBuildsystem` from the example files located http:/"
  },
  "706": {
    "source_file": "build-a-labview-app.txt",
    "text": "\n\nRepeat Step 9 for the myApplication repository.\n\nIn Windows Explorer, place the contents of `../myBuildsystem` from the example files located http://www.ni.com/example/lv-ci[here] in the `../myBuildSystem` directory located on your machine:\n[.boxshadow]\n\nNavigate to the directory in the Git terminal, and run the following command to add all files within the directory to the Git repository:\n\n    "
  },
  "707": {
    "source_file": "build-a-labview-app.txt",
    "text": "adow]\n\nNavigate to the directory in the Git terminal, and run the following command to add all files within the directory to the Git repository:\n\n    cd \u201cC:/Users/<User>/Documents/GitHub/<Repository Name>\u201d\n    git add .\n\nRun the _git commit_ command to commit all changes and add a comment. If you can\u2019t run the command because you\u2019re missing credentials, you can set them:\n\n    git config --global u"
  },
  "708": {
    "source_file": "build-a-labview-app.txt",
    "text": "to commit all changes and add a comment. If you can\u2019t run the command because you\u2019re missing credentials, you can set them:\n\n    git config --global user.email <<Your GitHub Email>>\n    git config --global user.name <<Your GitHub Username>>\n    git commit -m \u201cAdded files\u201d\n\nRun the _git push_ command to push all committed changes to the remote repository (i.e. GitHub). After this step, the reposito"
  },
  "709": {
    "source_file": "build-a-labview-app.txt",
    "text": "ommit -m \u201cAdded files\u201d\n\nRun the _git push_ command to push all committed changes to the remote repository (i.e. GitHub). After this step, the repository will contain all necessary components we will need for this example.\n\n    git push origin master\n\nNext, we\u2019ll perform similar steps to set up the example application repository. In Windows Explorer, place the contents of `../myApplication` from th"
  },
  "710": {
    "source_file": "build-a-labview-app.txt",
    "text": "\nNext, we\u2019ll perform similar steps to set up the example application repository. In Windows Explorer, place the contents of `../myApplication` from the example files located http://www.ni.com/example/lv-ci[here] in the `../myApplication` directory located on your machine:\n[.boxshadow]\n\nOpen up `Jenkinsfile` in the `../myApplication` directory. Change the lvVersion and lvBitness variables according"
  },
  "711": {
    "source_file": "build-a-labview-app.txt",
    "text": "cated on your machine:\n[.boxshadow]\n\nOpen up `Jenkinsfile` in the `../myApplication` directory. Change the lvVersion and lvBitness variables according to which version of LabVIEW you are using. For instance, with LabVIEW 2018 32-bit, your Jenkinsfile will look like this:\n[.boxshadow]\n\nRun the commands from steps 12-14, this time for the myApplication repository:\n\n    cd <<myApplication directory>>"
  },
  "712": {
    "source_file": "build-a-labview-app.txt",
    "text": " will look like this:\n[.boxshadow]\n\nRun the commands from steps 12-14, this time for the myApplication repository:\n\n    cd <<myApplication directory>>\n    git add .\n    git commit -m \"Added files\"\n    git push origin master\n\nNow, your files are set up and in place for Jenkins to use.\n\nFor Jenkins to access your GitHub information, it will need a Personal Access Token. We will generate Personal Acc"
  },
  "713": {
    "source_file": "build-a-labview-app.txt",
    "text": "p and in place for Jenkins to use.\n\nFor Jenkins to access your GitHub information, it will need a Personal Access Token. We will generate Personal Access token through GitHub:\n\nOn the GitHub website, click on your *Avatar >> Settings*\n\nOn the left-hand side of the Settings page, click on *Developer Settings*\n\nClick on *Personal access tokens >> Generate new token*.\n\nEnter a descriptive name for th"
  },
  "714": {
    "source_file": "build-a-labview-app.txt",
    "text": "nd side of the Settings page, click on *Developer Settings*\n\nClick on *Personal access tokens >> Generate new token*.\n\nEnter a descriptive name for the token, such as \u2018Jenkins LabVIEW Token\u2019, and select the _repo_ scope.\n[.boxshadow]\n\nAt the bottom of the page, click *Generate token*.\n\nCopy down your Personal access token. This is your only chance to copy the token. Keep your access token safe, so"
  },
  "715": {
    "source_file": "build-a-labview-app.txt",
    "text": "f the page, click *Generate token*.\n\nCopy down your Personal access token. This is your only chance to copy the token. Keep your access token safe, so others can\u2019t access your GitHub.\n[.boxshadow]\n\nCongrats! You\u2019ve set up the GitHub repositories you\u2019ll need for this example, and you have the personal access token so Jenkins can access your GitHub information. Next, we\u2019ll configure Jenkins to use t"
  },
  "716": {
    "source_file": "build-a-labview-app.txt",
    "text": "ll need for this example, and you have the personal access token so Jenkins can access your GitHub information. Next, we\u2019ll configure Jenkins to use these items.\n\n*Note*: This tutorial uses the classic Jenkins view, with minimal plugins to get the example running. You can use additional plugins such as  for an enhanced UI experience.\n\nInstall Jenkins based on your Operating System using the , and "
  },
  "717": {
    "source_file": "build-a-labview-app.txt",
    "text": "ample running. You can use additional plugins such as  for an enhanced UI experience.\n\nInstall Jenkins based on your Operating System using the , and navigate to the address of your Jenkins server in your browser. A few additional notes (all of which are already mentioned in the aforementioned Jenkins help):\n** The default Jenkins address is http://localhost:8080\n** The first time you launch Jenki"
  },
  "718": {
    "source_file": "build-a-labview-app.txt",
    "text": " are already mentioned in the aforementioned Jenkins help):\n** The default Jenkins address is http://localhost:8080\n** The first time you launch Jenkins, you will need to unlock it with the admin password from the Console log output\n[.boxshadow]\n\nWhen prompted to Customize Jenkins, select the *Select plugins to install* option. Here, make sure the following Plugins are selected:\n** GitHub Branch S"
  },
  "719": {
    "source_file": "build-a-labview-app.txt",
    "text": "n prompted to Customize Jenkins, select the *Select plugins to install* option. Here, make sure the following Plugins are selected:\n** GitHub Branch Source\n** Folders Plugin\n** Pipeline: GitHub Groovy Libraries\n\nClick *Install* at the bottom of the page to install the plugins.\n\nOnce plugins are complete, you\u2019ll be prompted to create a user. Enter your credentials and click Save and Continue.\n[.box"
  },
  "720": {
    "source_file": "build-a-labview-app.txt",
    "text": "age to install the plugins.\n\nOnce plugins are complete, you\u2019ll be prompted to create a user. Enter your credentials and click Save and Continue.\n[.boxshadow]\n\nOn the following Instance Configuration page, leave the Jenkins URL as-is.\nClick *Start using Jenkins* to begin your Jenkins configuration.\n\nEnvironment variables can be accessed across Jenkins jobs. We will want certain values accessible wh"
  },
  "721": {
    "source_file": "build-a-labview-app.txt",
    "text": "ng Jenkins* to begin your Jenkins configuration.\n\nEnvironment variables can be accessed across Jenkins jobs. We will want certain values accessible when Jenkins tries to build, test and diff your application. Since the GitHub organization name, access token, and picture repository will likely be the same across Jenkins jobs, we will set them in our Jenkins configuration.\n\nFrom the Jenkins dashboar"
  },
  "722": {
    "source_file": "build-a-labview-app.txt",
    "text": "s token, and picture repository will likely be the same across Jenkins jobs, we will set them in our Jenkins configuration.\n\nFrom the Jenkins dashboard, navigate to the system configuration page: *Manage Jenkins >> System*\nNavigate to the _Global properties_ section.\nCheck the *Environment* variables box to display the List of variables.\nClick *Add* to add a new environment variable. Fill out the "
  },
  "723": {
    "source_file": "build-a-labview-app.txt",
    "text": "perties_ section.\nCheck the *Environment* variables box to display the List of variables.\nClick *Add* to add a new environment variable. Fill out the Name as shown below (BUILD_SYSTEM_REPO), and enter myBuildSystem in the Value field:\n[.boxshadow]\n\nClick *Add* another time and add the LV_BUILD_OUTPUT_DIR environment variable. This should be an _empty local directory_ anywhere on your computer, tha"
  },
  "724": {
    "source_file": "build-a-labview-app.txt",
    "text": "lick *Add* another time and add the LV_BUILD_OUTPUT_DIR environment variable. This should be an _empty local directory_ anywhere on your computer, that LabVIEW will build and output files to. For instance, you may use something like `C:\\Windows\\Temp\\jenkins`.\nClick *Add* two more times to add the ORG_NAME variable and the PIC_REPO variable. The value fields for these variables should be your organ"
  },
  "725": {
    "source_file": "build-a-labview-app.txt",
    "text": "jenkins`.\nClick *Add* two more times to add the ORG_NAME variable and the PIC_REPO variable. The value fields for these variables should be your organization\u2019s name (instead of \u2018branchNI\u2019) and myPicRepo, respectively. These are the two repositories we created in the *GitHub Setup* section. Your Environment variables section should look like this:\n[.boxshadow]\n\nClick *Save* at the bottom of the scr"
  },
  "726": {
    "source_file": "build-a-labview-app.txt",
    "text": "e created in the *GitHub Setup* section. Your Environment variables section should look like this:\n[.boxshadow]\n\nClick *Save* at the bottom of the screen to save your changes.\nNow, navigate to the *Credentials* page: *Jenkins Dashboard >> Credentials >> System >> Global credentials >> Add credentials*\nUse the following settings, entering your GitHub access token as the \u2018Secret\u2019 field.\n[.boxshadow]"
  },
  "727": {
    "source_file": "build-a-labview-app.txt",
    "text": " >> System >> Global credentials >> Add credentials*\nUse the following settings, entering your GitHub access token as the \u2018Secret\u2019 field.\n[.boxshadow]\n\nThe Global Library contains the script files and other components that will be used each time Jenkins tries to build. In this example, we are hosting them in the myBuildSystem repository. We will link Jenkins to that repository so it can use those "
  },
  "728": {
    "source_file": "build-a-labview-app.txt",
    "text": "ins tries to build. In this example, we are hosting them in the myBuildSystem repository. We will link Jenkins to that repository so it can use those files for each job.\n\nOn the main Jenkins dashboard: *Manage Jenkins >> System*\n\nUnder the _Global Pipeline Libraries section_, click *Add* and fill out the credentials for the myBuildSystem repository. Make sure to check the *Load implicitly* checkbo"
  },
  "729": {
    "source_file": "build-a-labview-app.txt",
    "text": "peline Libraries section_, click *Add* and fill out the credentials for the myBuildSystem repository. Make sure to check the *Load implicitly* checkbox. Your options should look like this:\n[.boxshadow]\n\n** Here, \u2018master\u2019 refers to the master branch of the repository. The steps we performed in the GitHub Setup section pushed all files to the \u2018master\u2019 branch. More info on GitHub flows https://guides"
  },
  "730": {
    "source_file": "build-a-labview-app.txt",
    "text": "f the repository. The steps we performed in the GitHub Setup section pushed all files to the \u2018master\u2019 branch. More info on GitHub flows https://guides.github.com/introduction/flow/[here].\n\nNow, we\u2019ll want to select the Retrieval method. For this example, we\u2019ll use Modern SCM. Select the *Modern SCM* radio button, followed by the *GitHub* radio button under _Source Code Management_:\n[.boxshadow]\n\nS"
  },
  "731": {
    "source_file": "build-a-labview-app.txt",
    "text": "ple, we\u2019ll use Modern SCM. Select the *Modern SCM* radio button, followed by the *GitHub* radio button under _Source Code Management_:\n[.boxshadow]\n\nStart by adding Credentials. Click the *Add* dropdown next to the credentials field >> *Jenkins*.\n[.boxshadow]\n\nOn the Jenkins Credentials Provider screen, leave the default options, and enter your GitHub Username. The Password will be your GitHub Acc"
  },
  "732": {
    "source_file": "build-a-labview-app.txt",
    "text": "oxshadow]\n\nOn the Jenkins Credentials Provider screen, leave the default options, and enter your GitHub Username. The Password will be your GitHub Access Token. Click *Add* once the credentials are filled out.\n[.boxshadow]\n\nOnce the credentials are created, select them from the Credentials dropdown.\n[.boxshadow]\n\nFill out the _Owner_ field and select _myBuildSystem_ from the _Repository_ dropdown."
  },
  "733": {
    "source_file": "build-a-labview-app.txt",
    "text": "reated, select them from the Credentials dropdown.\n[.boxshadow]\n\nFill out the _Owner_ field and select _myBuildSystem_ from the _Repository_ dropdown. Leave the other options as-is. Your fields should look like this:\n[.boxshadow]\n\nClick *Save* at the bottom of the screen to save your changes.\n\nWe\u2019ve successfully linked Jenkins to the global library \u2013 this means that the files hosted on the myBuild"
  },
  "734": {
    "source_file": "build-a-labview-app.txt",
    "text": " bottom of the screen to save your changes.\n\nWe\u2019ve successfully linked Jenkins to the global library \u2013 this means that the files hosted on the myBuildSystem repository can be accessed and used by Jenkins!\n\nFinally, we\u2019ll set up Jenkins to scan and automate testing and diffing of your myApplication repository.\n\nFrom the Jenkins dashboard, select *New Item*. Enter a name for the item and select *Git"
  },
  "735": {
    "source_file": "build-a-labview-app.txt",
    "text": "tomate testing and diffing of your myApplication repository.\n\nFrom the Jenkins dashboard, select *New Item*. Enter a name for the item and select *GitHub Organization*.\n[.boxshadow]\n\nClick *OK* to create the item. You will be redirected to the configuration page.\n\nUnder the _Projects_ section:\n.. Select your _Credentials_ from the dropdown menu and change the value of the _Owner_ field to your Git"
  },
  "736": {
    "source_file": "build-a-labview-app.txt",
    "text": "uration page.\n\nUnder the _Projects_ section:\n.. Select your _Credentials_ from the dropdown menu and change the value of the _Owner_ field to your GitHub organization name.\n.. In _Behaviors_, change the Discover branches option to Only branches that are also filed as PRs.\n\nMake sure the _Script Path_ value is Jenkinsfile. Your _Projects_ section should look like this:\n[.boxshadow]\n\nUnder the _Scan"
  },
  "737": {
    "source_file": "build-a-labview-app.txt",
    "text": "are also filed as PRs.\n\nMake sure the _Script Path_ value is Jenkinsfile. Your _Projects_ section should look like this:\n[.boxshadow]\n\nUnder the _Scan Organization Triggers_ section, select the Interval that you want Jenkins to scan your repository for changes. If Jenkins detects a change, it will initiate the testing and diffing process. For this example, we will use 10 minutes.\n[.boxshadow]\n\n** "
  },
  "738": {
    "source_file": "build-a-labview-app.txt",
    "text": "or changes. If Jenkins detects a change, it will initiate the testing and diffing process. For this example, we will use 10 minutes.\n[.boxshadow]\n\n** *Note*: While the method used in this tutorial sets up Jenkins to scan GitHub for changes, there are methods for GitHub to trigger Jenkins builds whenever a change happens. This involves exposing your Jenkins server so that GitHub can communicate wit"
  },
  "739": {
    "source_file": "build-a-labview-app.txt",
    "text": " methods for GitHub to trigger Jenkins builds whenever a change happens. This involves exposing your Jenkins server so that GitHub can communicate with it through .\n\nClick *Save* to save your changes. Through this pipeline, Jenkins will now scan your repository based on the interval you just configured.\n\nLet\u2019s confirm that everything works. We\u2019ll do this by configuring our LabVIEW project, making "
  },
  "740": {
    "source_file": "build-a-labview-app.txt",
    "text": " repository based on the interval you just configured.\n\nLet\u2019s confirm that everything works. We\u2019ll do this by configuring our LabVIEW project, making changes to the VIs in our myApplication directory, and creating a Pull Request on GitHub.\n\nWe will create a https://help.github.com/en/articles/about-branches[branch] to the _myApplication_ GitHub repository. Start by opening a Git terminal and navig"
  },
  "741": {
    "source_file": "build-a-labview-app.txt",
    "text": "reate a https://help.github.com/en/articles/about-branches[branch] to the _myApplication_ GitHub repository. Start by opening a Git terminal and navigating to the local `../myApplication` directory.\n\nTo create and checkout or use a branch, enter the following commands:\n\n    git branch myBranch\n    git checkout myBranch\n\nNavigate to the `../myApplication/source` directory.\n\nOpen the `Jenkins.lvproj"
  },
  "742": {
    "source_file": "build-a-labview-app.txt",
    "text": "following commands:\n\n    git branch myBranch\n    git checkout myBranch\n\nNavigate to the `../myApplication/source` directory.\n\nOpen the `Jenkins.lvproj` file.\n\nExpand the Build Specifications, and double click _myBuildSpec_ to open its properties:\n[.boxshadow]\n\nModify the _Destination directory_ to be the specific directory you set for the LV_BUILD_OUTPUT_DIR environment variable value, in the *Jen"
  },
  "743": {
    "source_file": "build-a-labview-app.txt",
    "text": "oxshadow]\n\nModify the _Destination directory_ to be the specific directory you set for the LV_BUILD_OUTPUT_DIR environment variable value, in the *Jenkins Setup* section. This will be the output directory of the build specification.\n\nNext, we will modify the VIs. First, open `Add.vi`. This is a simple VI that adds two numbers together and returns a result.\n[.boxshadow]\n\nMake some cosmetic changes "
  },
  "744": {
    "source_file": "build-a-labview-app.txt",
    "text": "dify the VIs. First, open `Add.vi`. This is a simple VI that adds two numbers together and returns a result.\n[.boxshadow]\n\nMake some cosmetic changes to `Add.vi` (don\u2019t change anything that would alter the functionality of the VI), like so:\n[.boxshadow]\n\nClick *File >> Save* to save the VI changes, and close `Add.vi`.\n\nNow, open `Subtract.vi`. This is a simple VI that subtracts two numbers and ret"
  },
  "745": {
    "source_file": "build-a-labview-app.txt",
    "text": "ow]\n\nClick *File >> Save* to save the VI changes, and close `Add.vi`.\n\nNow, open `Subtract.vi`. This is a simple VI that subtracts two numbers and returns a result.\n[.boxshadow]\n\nMake cosmetic changes to `Subtract.vi`; for example:\n[.boxshadow]\n\nClick *File >> Save* to save changes, and close `Subtract.vi`.\n\nClose `Jenkins.lvproj`. Save files if prompted.\n\nWith the Git terminal open, make sure we "
  },
  "746": {
    "source_file": "build-a-labview-app.txt",
    "text": "k *File >> Save* to save changes, and close `Subtract.vi`.\n\nClose `Jenkins.lvproj`. Save files if prompted.\n\nWith the Git terminal open, make sure we are still in the `../myApplication` directory. Run the following commands to push our changes to the _myBranch_ branch on the _myApplication_ repository:\n\n    git add .\n    git commit -m \u201cCosmetic VI changes\u201d\n    git push origin myBranch\n\nWith our ch"
  },
  "747": {
    "source_file": "build-a-labview-app.txt",
    "text": " _myBranch_ branch on the _myApplication_ repository:\n\n    git add .\n    git commit -m \u201cCosmetic VI changes\u201d\n    git push origin myBranch\n\nWith our changes pushed to the Branch, we\u2019ll go on GitHub to create a Pull Request. First, navigate to the _myApplication_ repository on https://www.github.com[GitHub].\n\nNavigate to the \u2018myBranch\u2019 Branch using the dropdown:\n[.boxshadow]\n\nOn the _myBranch_ page,"
  },
  "748": {
    "source_file": "build-a-labview-app.txt",
    "text": "pplication_ repository on https://www.github.com[GitHub].\n\nNavigate to the \u2018myBranch\u2019 Branch using the dropdown:\n[.boxshadow]\n\nOn the _myBranch_ page, click on *New pull request*.\n\nFill out the pull request details as shown. Click *Create pull request* to create the request.\n[.boxshadow]\n\nWait for Jenkins to perform its check based on the interval you set, or navigate to your *Jenkins dashboard >>"
  },
  "749": {
    "source_file": "build-a-labview-app.txt",
    "text": "t* to create the request.\n[.boxshadow]\n\nWait for Jenkins to perform its check based on the interval you set, or navigate to your *Jenkins dashboard >> GitHub Builder (or whatever you named your Jenkins pipeline) >> Scan Organization Now*. Then, navigate to *myApplication >> Scan Repository Now*.\n\nTo view the progress of your job, you can navigate to the *Pull Requests* tab.\n[.boxshadow]\n\nClick on "
  },
  "750": {
    "source_file": "build-a-labview-app.txt",
    "text": "ate to *myApplication >> Scan Repository Now*.\n\nTo view the progress of your job, you can navigate to the *Pull Requests* tab.\n[.boxshadow]\n\nClick on the pull request name (_PR-1_ in this case). The progress of each step is displayed on the main page. The _Build History_ section on the bottom left displays the jobs run.\n[.boxshadow]\n\nIf the job was successful, each stage should be Green, and the l"
  },
  "751": {
    "source_file": "build-a-labview-app.txt",
    "text": ". The _Build History_ section on the bottom left displays the jobs run.\n[.boxshadow]\n\nIf the job was successful, each stage should be Green, and the latest Build in the _Build History_ section should have a blue dot next to it. Additionally, you\u2019ll see the latest artifacts (files you can upload to Jenkins), and the unit test results:\n[.boxshadow]\n\nIf you navigate to your Pull Request on GitHub (*R"
  },
  "752": {
    "source_file": "build-a-labview-app.txt",
    "text": "ee the latest artifacts (files you can upload to Jenkins), and the unit test results:\n[.boxshadow]\n\nIf you navigate to your Pull Request on GitHub (*Repository Page >> Pull requests tab >> Click on the Pull Request*), you should also see the comment that Jenkins posted.\n[.boxshadow]\n\nIf you\u2019re satisfied with the results, you can scroll to the bottom of the Pull Request and click *Merge pull reques"
  },
  "753": {
    "source_file": "build-a-labview-app.txt",
    "text": "that Jenkins posted.\n[.boxshadow]\n\nIf you\u2019re satisfied with the results, you can scroll to the bottom of the Pull Request and click *Merge pull request* to merge the changes with the master branch.\n[.boxshadow]\n\nIf the job was not successful, on the Pull Request page in Jenkins, click on the build number that failed, and click on Console Output on the left sidebar to view error information.\n[.boxs"
  },
  "754": {
    "source_file": "build-a-labview-app.txt",
    "text": "Pull Request page in Jenkins, click on the build number that failed, and click on Console Output on the left sidebar to view error information.\n[.boxshadow]\n\n[.boxshadow]\n\nCongrats! You\u2019ve just set up Jenkins to automate LabVIEW builds. The \"Build\", \"Test\" and \"Deliver\" stages you created above are the basis for\nbuilding more complex LabVIEW in Jenkins, as well as LabVIEW applications that integra"
  },
  "755": {
    "source_file": "build-a-labview-app.txt",
    "text": "\"Test\" and \"Deliver\" stages you created above are the basis for\nbuilding more complex LabVIEW in Jenkins, as well as LabVIEW applications that integrate with other technology stacks. When doing so, there are some https://knowledge.ni.com/KnowledgeArticleDetails?id=kA00Z000001De1JSAS&l=en-US[Best Practices] you should follow. In case you would like additional command line functionality, we have exa"
  },
  "756": {
    "source_file": "build-a-labview-app.txt",
    "text": "icleDetails?id=kA00Z000001De1JSAS&l=en-US[Best Practices] you should follow. In case you would like additional command line functionality, we have examples on how to extend the LabVIEWCLI https://github.com/ni/niveristand-custom-device-build-tools/[here].\n\nBecause Jenkins is extremely extensible, it can be modified and configured to handle practically any aspect of build orchestration and automati"
  },
  "757": {
    "source_file": "build-a-labview-app.txt",
    "text": "ere].\n\nBecause Jenkins is extremely extensible, it can be modified and configured to handle practically any aspect of build orchestration and automation.\n\nTo learn more about what Jenkins can do, check out:\n\n* The  page for other introductory\n  tutorials.\n* The  for more detailed information about using\n  Jenkins, such as  (in particular\n  ) and the\n   interface.\n* The  for the latest events, othe"
  },
  "758": {
    "source_file": "build-a-labview-app.txt",
    "text": "ials.\n* The  for more detailed information about using\n  Jenkins, such as  (in particular\n  ) and the\n   interface.\n* The  for the latest events, other tutorials and\n  updates.\n\n'''\n+++\n\n+++"
  },
  "759": {
    "source_file": "build-a-multibranch-pipeline-project.txt",
    "text": "layout: documentation\ntitle: End-to-End Multibranch Pipeline Project Creation\nsection: doc\n\n\nThis tutorial shows you how to use Jenkins to orchestrate building and testing\na simple https://nodejs.org/en/[Node.js] and https://reactjs.org/[React]\napplication with the https://www.npmjs.com/[Node Package Manager (npm)], _as\nwell as_ deliver different outcomes for development and production purposes.\n\n"
  },
  "760": {
    "source_file": "build-a-multibranch-pipeline-project.txt",
    "text": "cation with the https://www.npmjs.com/[Node Package Manager (npm)], _as\nwell as_ deliver different outcomes for development and production purposes.\n\nBefore starting this tutorial, it is recommended that you run through at least\none of the initial set of  from the  page first to familiarize\nyourself with CI/CD concepts (relevant to a technology stack you're most\nfamiliar with), how these concepts "
  },
  "761": {
    "source_file": "build-a-multibranch-pipeline-project.txt",
    "text": "t of  from the  page first to familiarize\nyourself with CI/CD concepts (relevant to a technology stack you're most\nfamiliar with), how these concepts are implemented in Jenkins and the\nfundamentals of Jenkins Pipelines.\n\nIn this tutorial, you'll use the same application that the\n tutorial is based on. Therefore, you'll be building and testing the\nsame application but this time, its delivery will b"
  },
  "762": {
    "source_file": "build-a-multibranch-pipeline-project.txt",
    "text": "the same application that the\n tutorial is based on. Therefore, you'll be building and testing the\nsame application but this time, its delivery will be different depending on the\nGit branch that Jenkins builds from. That is, the branch being built determines\nwhich delivery stage of your Pipeline is executed.\n\n*Duration:* This tutorial takes 30-50 minutes to complete (assuming you've\nalready met th"
  },
  "763": {
    "source_file": "build-a-multibranch-pipeline-project.txt",
    "text": "termines\nwhich delivery stage of your Pipeline is executed.\n\n*Duration:* This tutorial takes 30-50 minutes to complete (assuming you've\nalready met the <<prerequisites,Prerequisites>> below).\nThe exact duration will depend on the speed of your machine and whether you've already installed `docker` and `docker compose`.\n\nYou can stop this tutorial at any point in time and continue from where you lef"
  },
  "764": {
    "source_file": "build-a-multibranch-pipeline-project.txt",
    "text": "e and whether you've already installed `docker` and `docker compose`.\n\nYou can stop this tutorial at any point in time and continue from where you left\noff.\n\n** , and optionally .\n\n[[fork-sample-repository]]\n[[fork-and-clone-the-sample-repository-on-github]]\n\nObtain the simple \"\" Node.js and React application from GitHub,\nby forking the sample repository of the application's source code into your "
  },
  "765": {
    "source_file": "build-a-multibranch-pipeline-project.txt",
    "text": "github]]\n\nObtain the simple \"\" Node.js and React application from GitHub,\nby forking the sample repository of the application's source code into your own\nGitHub account and then cloning this fork locally.\n\nEnsure you are signed in to your GitHub account. If you don't yet have a\nGitHub account, sign up for a free one on the .\nFork the\n\non GitHub into your local GitHub account. If you need help with"
  },
  "766": {
    "source_file": "build-a-multibranch-pipeline-project.txt",
    "text": "unt. If you don't yet have a\nGitHub account, sign up for a free one on the .\nFork the\n\non GitHub into your local GitHub account. If you need help with this process,\nrefer to the\ndocumentation on the GitHub website for more information.\nClone your forked `building-a-multibranch-pipeline-project` repository (on\nGitHub) locally to your machine. To begin this process, do either of the\nfollowing (where"
  },
  "767": {
    "source_file": "build-a-multibranch-pipeline-project.txt",
    "text": "ked `building-a-multibranch-pipeline-project` repository (on\nGitHub) locally to your machine. To begin this process, do either of the\nfollowing (where `<your-username>` is the name of your user account on your\noperating system):\n** If you have the GitHub Desktop app installed on your machine:\n.. In GitHub, click the green *Clone or download* button on your forked\nrepository, then *Open in Desktop*"
  },
  "768": {
    "source_file": "build-a-multibranch-pipeline-project.txt",
    "text": "tHub Desktop app installed on your machine:\n.. In GitHub, click the green *Clone or download* button on your forked\nrepository, then *Open in Desktop*.\n.. In GitHub Desktop, before clicking *Clone* on the *Clone a Repository* dialog\nbox, ensure *Local Path* for:\n*** macOS is `/Users/<your-username>/Documents/GitHub/building-a-multibranch-pipeline-project`\n*** Linux is `/home/<your-username>/GitHub"
  },
  "769": {
    "source_file": "build-a-multibranch-pipeline-project.txt",
    "text": "l Path* for:\n*** macOS is `/Users/<your-username>/Documents/GitHub/building-a-multibranch-pipeline-project`\n*** Linux is `/home/<your-username>/GitHub/building-a-multibranch-pipeline-project`\n*** Windows is `C:\\Users\\<your-username>\\Documents\\GitHub\\building-a-multibranch-pipeline-project`\n** Otherwise:\n.. Open up a terminal/command line prompt and `cd` to the appropriate directory\non:\n*** macOS -"
  },
  "770": {
    "source_file": "build-a-multibranch-pipeline-project.txt",
    "text": "building-a-multibranch-pipeline-project`\n** Otherwise:\n.. Open up a terminal/command line prompt and `cd` to the appropriate directory\non:\n*** macOS - `/Users/<your-username>/Documents/GitHub/`\n*** Linux - `/home/<your-username>/GitHub/`\n*** Windows - `C:\\Users\\<your-username>\\Documents\\GitHub\\` (although use a Git\nbash command line window as opposed to the usual Microsoft command prompt)\n.. Run t"
  },
  "771": {
    "source_file": "build-a-multibranch-pipeline-project.txt",
    "text": "- `C:\\Users\\<your-username>\\Documents\\GitHub\\` (although use a Git\nbash command line window as opposed to the usual Microsoft command prompt)\n.. Run the following command to continue/complete cloning your forked repo: +\n`git clone https://github.com/YOUR-GITHUB-ACCOUNT-NAME/building-a-multibranch-pipeline-project` +\nwhere `YOUR-GITHUB-ACCOUNT-NAME` is the name of your GitHub account.\n\nBefore creat"
  },
  "772": {
    "source_file": "build-a-multibranch-pipeline-project.txt",
    "text": "YOUR-GITHUB-ACCOUNT-NAME/building-a-multibranch-pipeline-project` +\nwhere `YOUR-GITHUB-ACCOUNT-NAME` is the name of your GitHub account.\n\nBefore creating your Pipeline project in Jenkins, create \"development\" and\n\"production\" branches of your locally cloned Git repository. You'll be creating\na single Jenkinsfile (initially in the `master` branch, which you'll pull into\nthe other branches) whose st"
  },
  "773": {
    "source_file": "build-a-multibranch-pipeline-project.txt",
    "text": " cloned Git repository. You'll be creating\na single Jenkinsfile (initially in the `master` branch, which you'll pull into\nthe other branches) whose stages will be selectively executed based on the\nbranch that Jenkins is building from.\n\nWithin the `building-a-multibranch-pipeline-project` directory (i.e. your local clone of the sample repository):\n\nRun the following command to create the `developme"
  },
  "774": {
    "source_file": "build-a-multibranch-pipeline-project.txt",
    "text": "ilding-a-multibranch-pipeline-project` directory (i.e. your local clone of the sample repository):\n\nRun the following command to create the `development` branch (from the contents of the `master` branch):\ngit checkout development\n\nPush the `development` branch and set it to track the remote branch:\ngit push -u origin development\n\nRun the following command to create the `production` branch (from th"
  },
  "775": {
    "source_file": "build-a-multibranch-pipeline-project.txt",
    "text": "nt` branch and set it to track the remote branch:\ngit push -u origin development\n\nRun the following command to create the `production` branch (from the contents of the `master` branch):\ngit checkout production\n\nPush the `production` branch and set it to track the remote branch:\ngit push -u origin production\n\nGet back to the `master` branch:\ngit checkout master\n\nCheck that these branches now exist "
  },
  "776": {
    "source_file": "build-a-multibranch-pipeline-project.txt",
    "text": " to track the remote branch:\ngit push -u origin production\n\nGet back to the `master` branch:\ngit checkout master\n\nCheck that these branches now exist by running the command `git branch`, which should give you:\ndevelopment\n* master\n  production\n\n1. Obtain the latest Jenkins deployment, customized for this tutorial, by cloning the .\n2. After cloning, navigate to the `quickstart-tutorials` directory,"
  },
  "777": {
    "source_file": "build-a-multibranch-pipeline-project.txt",
    "text": "tain the latest Jenkins deployment, customized for this tutorial, by cloning the .\n2. After cloning, navigate to the `quickstart-tutorials` directory, and execute the command\ndocker compose --profile multi up -d\n\nto run the example.\n3. Once the containers are running successfully (you can verify this with `docker compose ps`), the controller can be accessed at http://localhost:8080.\n\nIf you are un"
  },
  "778": {
    "source_file": "build-a-multibranch-pipeline-project.txt",
    "text": "iners are running successfully (you can verify this with `docker compose ps`), the controller can be accessed at http://localhost:8080.\n\nIf you are unable to install `docker compose` on your machine for any reason, you can still run the example in the cloud for free using either:\n\n* *GitHub Codespaces* (Recommended): Click the *Code* button in the , select *Codespaces*, then *Create codespace on m"
  },
  "779": {
    "source_file": "build-a-multibranch-pipeline-project.txt",
    "text": "e cloud for free using either:\n\n* *GitHub Codespaces* (Recommended): Click the *Code* button in the , select *Codespaces*, then *Create codespace on master*.\nGitHub Codespaces provides .\nOnce the Codespace starts, the setup will run automatically, and you'll see a welcome message with instructions.\n\n* *GitPod*: Click on  to open a GitPod workspace.\nGitPod .\nYou need to link it to your GitHub accou"
  },
  "780": {
    "source_file": "build-a-multibranch-pipeline-project.txt",
    "text": "d you'll see a welcome message with instructions.\n\n* *GitPod*: Click on  to open a GitPod workspace.\nGitPod .\nYou need to link it to your GitHub account.\n\nNow, log in using the `admin` username and `admin` password.\n\nGo back to Jenkins and ensure you are logged in  and have clicked *New Item* on the left.\nIn the *Enter an item name* box, type `building-a-multibranch-pipeline-project`, select *Mult"
  },
  "781": {
    "source_file": "build-a-multibranch-pipeline-project.txt",
    "text": " are logged in  and have clicked *New Item* on the left.\nIn the *Enter an item name* box, type `building-a-multibranch-pipeline-project`, select *Multibranch Pipeline* and click *OK*.\n[.boxshadow]\n\nIn the *Display Name* field, type `Building a Multibranch Pipeline Project`.\nIn the *Branch Sources* section, click *Add source* and select *GitHub*.\nIn the *GitHub* section, there is a field labeled *R"
  },
  "782": {
    "source_file": "build-a-multibranch-pipeline-project.txt",
    "text": "ranch Pipeline Project`.\nIn the *Branch Sources* section, click *Add source* and select *GitHub*.\nIn the *GitHub* section, there is a field labeled *Repository HTTPS URL*. Enter `https://github.com/YOUR-GITHUB-ACCOUNT-NAME/building-a-multibranch-pipeline-project.git`, and click *Validate*.\n[.boxshadow]\n\nYou can now click on *Save* to save your new Pipeline project. +\nJenkins will now scan your rem"
  },
  "783": {
    "source_file": "build-a-multibranch-pipeline-project.txt",
    "text": "line-project.git`, and click *Validate*.\n[.boxshadow]\n\nYou can now click on *Save* to save your new Pipeline project. +\nJenkins will now scan your remote repository for branches and create a Pipeline for each branch that contains a `Jenkinsfile`.\n[.boxshadow]\n\nJenkins has found your three branches, and no pull requests for the time being. +\nYou can now scroll up and click on *Building a Multibranc"
  },
  "784": {
    "source_file": "build-a-multibranch-pipeline-project.txt",
    "text": "oxshadow]\n\nJenkins has found your three branches, and no pull requests for the time being. +\nYou can now scroll up and click on *Building a Multibranch Pipeline Project* to access the main page of your new Multibranch Pipeline project.\n[.boxshadow]\n\nJenkins found a `Jenkinsfile` in each branch, and it has already built each branch.\n\nThe Pipeline stub consists of the basic requirements for a valid "
  },
  "785": {
    "source_file": "build-a-multibranch-pipeline-project.txt",
    "text": "Jenkins found a `Jenkinsfile` in each branch, and it has already built each branch.\n\nThe Pipeline stub consists of the basic requirements for a valid Pipeline - i.e.\nan  and a\n section, as well as a\n directive.\n\nThe reason why the `building-a-multibranch-pipeline-project` repository includes a `Jenkinsfile` Pipeline stub is that its presence in a branch makes Jenkins detect that there's something "
  },
  "786": {
    "source_file": "build-a-multibranch-pipeline-project.txt",
    "text": "anch-pipeline-project` repository includes a `Jenkinsfile` Pipeline stub is that its presence in a branch makes Jenkins detect that there's something to build (i.e. the `Jenkinsfile`) immediately after creating the Multibranch Pipeline project, which in turn makes these branches accessible through the Jenkins interface.\n\nIf you created a Pipeline project, but created more branches later on, either"
  },
  "787": {
    "source_file": "build-a-multibranch-pipeline-project.txt",
    "text": " in turn makes these branches accessible through the Jenkins interface.\n\nIf you created a Pipeline project, but created more branches later on, either:\n\n* Use the *Scan Repository Now* feature in the Multibranch Pipeline project or\n* Implement webhooks into your Git repository.\n\nYou're now ready to create the Pipeline that will automate building your Node.js and React application in Jenkins.\nYour "
  },
  "788": {
    "source_file": "build-a-multibranch-pipeline-project.txt",
    "text": "ks into your Git repository.\n\nYou're now ready to create the Pipeline that will automate building your Node.js and React application in Jenkins.\nYour Pipeline will be created as a `Jenkinsfile`, which will be committed to the `master` branch of your forked and locally cloned Git repository (`building-a-multibranch-pipeline-project`).\n\nFirst, create an initial Pipeline to build your simple Node.js "
  },
  "789": {
    "source_file": "build-a-multibranch-pipeline-project.txt",
    "text": "forked and locally cloned Git repository (`building-a-multibranch-pipeline-project`).\n\nFirst, create an initial Pipeline to build your simple Node.js and React application.\nAlso add a \"Build\" stage to the Pipeline to begin orchestrating this whole process and a \"Test\" stage to check that the application renders satisfactorily.\n\nUsing your favorite text editor or IDE, open the existing `Jenkinsfile"
  },
  "790": {
    "source_file": "build-a-multibranch-pipeline-project.txt",
    "text": "ocess and a \"Test\" stage to check that the application renders satisfactorily.\n\nUsing your favorite text editor or IDE, open the existing `Jenkinsfile` at the root of your local `building-a-multibranch-pipeline-project` Git repository and _clear_ its contents. +\n*Note:* Be sure you are performing this step on the `master` branch of your\nrepository.\nCopy the following Declarative Pipeline code and "
  },
  "791": {
    "source_file": "build-a-multibranch-pipeline-project.txt",
    "text": " contents. +\n*Note:* Be sure you are performing this step on the `master` branch of your\nrepository.\nCopy the following Declarative Pipeline code and paste it into your empty\n`Jenkinsfile`:\npipeline {\n    agent any\n    environment {\n        CI = 'true'\n    }\n    stages {\n        stage('Build') {\n            steps {\n                sh 'npm install'\n            }\n        }\n        stage('Test') {\n  "
  },
  "792": {
    "source_file": "build-a-multibranch-pipeline-project.txt",
    "text": "e'\n    }\n    stages {\n        stage('Build') {\n            steps {\n                sh 'npm install'\n            }\n        }\n        stage('Test') {\n            steps {\n                sh './jenkins/scripts/test.sh'\n            }\n        }\n    }\n}\n\n*Note:* For an explanation of the other components of this `Jenkinsfile`, refer to the annotations of the Declarative Pipeline in the  and  sections of "
  },
  "793": {
    "source_file": "build-a-multibranch-pipeline-project.txt",
    "text": "ote:* For an explanation of the other components of this `Jenkinsfile`, refer to the annotations of the Declarative Pipeline in the  and  sections of the  tutorial.\nSave your edited `Jenkinsfile` and commit it to your local `building-a-multibranch-pipeline-project` Git repository.\nE.g. Within the `building-a-multibranch-pipeline-project` directory, run the commands: +\n`git add Jenkinsfile` +\nthen "
  },
  "794": {
    "source_file": "build-a-multibranch-pipeline-project.txt",
    "text": "peline-project` Git repository.\nE.g. Within the `building-a-multibranch-pipeline-project` directory, run the commands: +\n`git add Jenkinsfile` +\nthen +\n`git commit -m \"Add initial Jenkinsfile with 'Test' stage\"` +\nand finally +\n`git push` to push your changes to your forked repository on GitHub, so it can be picked up by Jenkins.\nGo back to Jenkins again, log in again if necessary, click on the *B"
  },
  "795": {
    "source_file": "build-a-multibranch-pipeline-project.txt",
    "text": "r changes to your forked repository on GitHub, so it can be picked up by Jenkins.\nGo back to Jenkins again, log in again if necessary, click on the *Building a Multibranch Pipeline Project* link if it is visible, or on *Dashboard* and then on the *Building a Multibranch Pipeline Project* link.\nYou should see the list of branches detected on the previous steps. Look at the row containing `master`. "
  },
  "796": {
    "source_file": "build-a-multibranch-pipeline-project.txt",
    "text": "ilding a Multibranch Pipeline Project* link.\nYou should see the list of branches detected on the previous steps. Look at the row containing `master`. There is a green triangle on the right side of this row (the run icon).\nClick on it.\n[.boxshadow]\n\nClick on `master` to see a new Pipeline being built. +\n[.boxshadow]\n\nClick on `#2` or on the latest build number to see the details of the build. +\n[.b"
  },
  "797": {
    "source_file": "build-a-multibranch-pipeline-project.txt",
    "text": "lick on `master` to see a new Pipeline being built. +\n[.boxshadow]\n\nClick on `#2` or on the latest build number to see the details of the build. +\n[.boxshadow]\n\nClick on *Pipeline Overview* on the left to see the stages of the Pipeline. +\n[.boxshadow]\n\nClick on *Test* and then on the green part to see the details of the test stage. +\n[.boxshadow]\n\nNext, add \"`Deliver for development`\" and \"`Deploy"
  },
  "798": {
    "source_file": "build-a-multibranch-pipeline-project.txt",
    "text": "]\n\nClick on *Test* and then on the green part to see the details of the test stage. +\n[.boxshadow]\n\nNext, add \"`Deliver for development`\" and \"`Deploy for production`\" stages to your\nPipeline, which Jenkins will selectively execute based on the branch that Jenkins is building from.\n\nThis takes the \"Pipeline-as-Code\" concept to a new level, in which a single `Jenkinsfile` describes your project's e"
  },
  "799": {
    "source_file": "build-a-multibranch-pipeline-project.txt",
    "text": "h that Jenkins is building from.\n\nThis takes the \"Pipeline-as-Code\" concept to a new level, in which a single `Jenkinsfile` describes your project's entire build, test, delivery and deployment processes in Jenkins for each branch of your repository.\nRead more about Pipeline and what a Jenkinsfile is in the  and  sections of the User Handbook.\n\nGo back to your text editor/IDE and ensure your `Jenki"
  },
  "800": {
    "source_file": "build-a-multibranch-pipeline-project.txt",
    "text": "Read more about Pipeline and what a Jenkinsfile is in the  and  sections of the User Handbook.\n\nGo back to your text editor/IDE and ensure your `Jenkinsfile` is open.\nCopy and paste the following Declarative Pipeline syntax immediately under the\n`Test` stage of your `Jenkinsfile`:\nstage('Deliver for development') {\n            when {\n                branch 'development'\n            }\n            s"
  },
  "801": {
    "source_file": "build-a-multibranch-pipeline-project.txt",
    "text": "t` stage of your `Jenkinsfile`:\nstage('Deliver for development') {\n            when {\n                branch 'development'\n            }\n            steps {\n                sh './jenkins/scripts/deliver-for-development.sh'\n                input message: 'Finished using the web site? (Click \"Proceed\" to continue)'\n                sh './jenkins/scripts/kill.sh'\n            }\n        }\n        stage("
  },
  "802": {
    "source_file": "build-a-multibranch-pipeline-project.txt",
    "text": "ge: 'Finished using the web site? (Click \"Proceed\" to continue)'\n                sh './jenkins/scripts/kill.sh'\n            }\n        }\n        stage('Deploy for production') {\n            when {\n                branch 'production'\n            }\n            steps {\n                sh './jenkins/scripts/deploy-for-production.sh'\n                input message: 'Finished using the web site? (Click \"P"
  },
  "803": {
    "source_file": "build-a-multibranch-pipeline-project.txt",
    "text": "        steps {\n                sh './jenkins/scripts/deploy-for-production.sh'\n                input message: 'Finished using the web site? (Click \"Proceed\" to continue)'\n                sh './jenkins/scripts/kill.sh'\n            }\n        }\n\nso that you end up with:\npipeline {\n    agent any\n    environment {\n        CI = 'true'\n    }\n    stages {\n        stage('Build') {\n            steps {\n    "
  },
  "804": {
    "source_file": "build-a-multibranch-pipeline-project.txt",
    "text": "t you end up with:\npipeline {\n    agent any\n    environment {\n        CI = 'true'\n    }\n    stages {\n        stage('Build') {\n            steps {\n                sh 'npm install'\n            }\n        }\n        stage('Test') {\n            steps {\n                sh './jenkins/scripts/test.sh'\n            }\n        }\n        stage('Deliver for development') {\n            when {\n                bran"
  },
  "805": {
    "source_file": "build-a-multibranch-pipeline-project.txt",
    "text": "             sh './jenkins/scripts/test.sh'\n            }\n        }\n        stage('Deliver for development') {\n            when {\n                branch 'development' // <1> }\n            steps {\n                sh './jenkins/scripts/deliver-for-development.sh'\n                input message: 'Finished using the web site? (Click \"Proceed\" to continue)'\n                sh './jenkins/scripts/kill.sh'"
  },
  "806": {
    "source_file": "build-a-multibranch-pipeline-project.txt",
    "text": "lopment.sh'\n                input message: 'Finished using the web site? (Click \"Proceed\" to continue)'\n                sh './jenkins/scripts/kill.sh'\n            }\n        }\n        stage('Deploy for production') {\n            when {\n                branch 'production'  // <1> }\n            steps {\n                sh './jenkins/scripts/deploy-for-production.sh'\n                input message: 'Fin"
  },
  "807": {
    "source_file": "build-a-multibranch-pipeline-project.txt",
    "text": " branch 'production'  // <1> }\n            steps {\n                sh './jenkins/scripts/deploy-for-production.sh'\n                input message: 'Finished using the web site? (Click \"Proceed\" to continue)'\n                sh './jenkins/scripts/kill.sh'\n            }\n        }\n    }\n}\n\n<1> These  directives (along with their `branch` conditions) determine whether or not the\n (containing these `whe"
  },
  "808": {
    "source_file": "build-a-multibranch-pipeline-project.txt",
    "text": "sh'\n            }\n        }\n    }\n}\n\n<1> These  directives (along with their `branch` conditions) determine whether or not the\n (containing these `when` directives) should be executed.\nIf a `branch` condition's value (i.e. pattern) matches the name of the branch that Jenkins is running the build from, then the\n`stage` that contains this `when` and `branch` construct will be executed.\n*Notes:*\n* Fo"
  },
  "809": {
    "source_file": "build-a-multibranch-pipeline-project.txt",
    "text": "f the branch that Jenkins is running the build from, then the\n`stage` that contains this `when` and `branch` construct will be executed.\n*Notes:*\n* For an explanation of the `input message` steps, refer to annotation *4* of the Declarative Pipeline at the  tutorial.\n* For an explanation of the `deliver-for-development.sh`, `deploy-for-production.sh` and `kill.sh` script steps, refer to the content"
  },
  "810": {
    "source_file": "build-a-multibranch-pipeline-project.txt",
    "text": "t the  tutorial.\n* For an explanation of the `deliver-for-development.sh`, `deploy-for-production.sh` and `kill.sh` script steps, refer to the contents\nof these files located in the `jenkins/scripts` directory from the root of the `building-a-multibranch-pipeline-project` repository.\nSave your edited `Jenkinsfile` and commit it to your local `building-a-multibranch-pipeline-project` Git repository"
  },
  "811": {
    "source_file": "build-a-multibranch-pipeline-project.txt",
    "text": "anch-pipeline-project` repository.\nSave your edited `Jenkinsfile` and commit it to your local `building-a-multibranch-pipeline-project` Git repository.\nE.g. Within the `building-a-multibranch-pipeline-project` directory, run the commands: +\n`git add .` +\nthen +\n`git commit -m \"Add 'Deliver...' and 'Deploy...' stages\"` +\nand finally +\n`git push` to push your changes to your forked repository on Git"
  },
  "812": {
    "source_file": "build-a-multibranch-pipeline-project.txt",
    "text": ".` +\nthen +\n`git commit -m \"Add 'Deliver...' and 'Deploy...' stages\"` +\nand finally +\n`git push` to push your changes to your forked repository on GitHub, so it can be picked up by Jenkins.\nGo back to Jenkins again, log in again if necessary and go to the Dashboard.\nClick *Building a Multibranch Pipeline Project* to access the main page of your Multibranch Pipeline project.\nClick the run icon  of "
  },
  "813": {
    "source_file": "build-a-multibranch-pipeline-project.txt",
    "text": "o the Dashboard.\nClick *Building a Multibranch Pipeline Project* to access the main page of your Multibranch Pipeline project.\nClick the run icon  of the `master` branch of your Pipeline project.\nClick on *master* to see a new Pipeline being built.\nClick on `#3` or on the latest build number to see the details of the build.\nClick on *Pipeline Overview* on the left to see the stages of the Pipeline"
  },
  "814": {
    "source_file": "build-a-multibranch-pipeline-project.txt",
    "text": "lick on `#3` or on the latest build number to see the details of the build.\nClick on *Pipeline Overview* on the left to see the stages of the Pipeline. +\n[.boxshadow]\n\nNotice how Jenkins skips the last two stages you added, since the branch you are running the build from (`master`) does not meet the `when` directives' `branch` conditions in these stages.\n\nNow that you have a completed `Jenkinsfile"
  },
  "815": {
    "source_file": "build-a-multibranch-pipeline-project.txt",
    "text": "unning the build from (`master`) does not meet the `when` directives' `branch` conditions in these stages.\n\nNow that you have a completed `Jenkinsfile` to build your application in\nJenkins, you can pull this file from the `master` branch of your local\nrepository into its `development` and `production` branches.\n\nWithin your local repository's `building-a-multibranch-pipeline-project`\ndirectory:\n\nR"
  },
  "816": {
    "source_file": "build-a-multibranch-pipeline-project.txt",
    "text": "l\nrepository into its `development` and `production` branches.\n\nWithin your local repository's `building-a-multibranch-pipeline-project`\ndirectory:\n\nRun the following commands to pull changes from `master` to\n`development`:\n* `git checkout development` +\nand\n* `git pull . master`\nand then\n* `git push` to push your changes to your forked repository on GitHub, so it can be picked up by Jenkins.\nAlso"
  },
  "817": {
    "source_file": "build-a-multibranch-pipeline-project.txt",
    "text": "t` +\nand\n* `git pull . master`\nand then\n* `git push` to push your changes to your forked repository on GitHub, so it can be picked up by Jenkins.\nAlso run the following commands to pull changes from `master` to `production`:\n* `git checkout production` +\nand\n* `git pull . master`\nand then\n* `git push` to push your changes to your forked repository on GitHub, so it can be picked up by Jenkins.\n\nYou"
  },
  "818": {
    "source_file": "build-a-multibranch-pipeline-project.txt",
    "text": "n` +\nand\n* `git pull . master`\nand then\n* `git push` to push your changes to your forked repository on GitHub, so it can be picked up by Jenkins.\n\nYour `development` and `production` branches should now have all your\n`Jenkinsfile` updates you made on the `master` branch.\n\nGo back to Jenkins again, log in again if necessary, navigate to the dashboard, and select *Building a Multibranch Pipeline Pro"
  },
  "819": {
    "source_file": "build-a-multibranch-pipeline-project.txt",
    "text": " the `master` branch.\n\nGo back to Jenkins again, log in again if necessary, navigate to the dashboard, and select *Building a Multibranch Pipeline Project*.\nClick the Run icon  of the `development` branch of your Pipeline project on the far right to see Jenkins building the `development` branch with the amended `Jenkinsfile`. +\nSelect *development* to see a new Pipeline being built. +\n[.boxshadow]"
  },
  "820": {
    "source_file": "build-a-multibranch-pipeline-project.txt",
    "text": "see Jenkins building the `development` branch with the amended `Jenkinsfile`. +\nSelect *development* to see a new Pipeline being built. +\n[.boxshadow]\n\nSelect *#2* (or the latest build number) on the left, and then *Pipeline Overview* on the left. +\n[.boxshadow]\n\nSelect the *Deliver for development* stage and then the top green *Shell Script* step to expand its contents and scroll down until you s"
  },
  "821": {
    "source_file": "build-a-multibranch-pipeline-project.txt",
    "text": "[.boxshadow]\n\nSelect the *Deliver for development* stage and then the top green *Shell Script* step to expand its contents and scroll down until you see the `http://localhost:3000` link. +\n[.boxshadow]\n\n*Note:* Since you are building the application on a different branch, the `npm install` step might require a few minutes for `npm` to download the many dependencies required to run your Node.js and"
  },
  "822": {
    "source_file": "build-a-multibranch-pipeline-project.txt",
    "text": "on a different branch, the `npm install` step might require a few minutes for `npm` to download the many dependencies required to run your Node.js and React application (stored in a local `node_modules` directory within the Jenkins home directory).\nThese dependencies are downloaded again because this Jenkins build would be the first time you are running your Pipeline project on the `development` b"
  },
  "823": {
    "source_file": "build-a-multibranch-pipeline-project.txt",
    "text": "hese dependencies are downloaded again because this Jenkins build would be the first time you are running your Pipeline project on the `development` branch and each branch has its own workspace directory (containing its own `node_modules` directory) within the Jenkins home directory.\n+++<kbd>+++Ctrl+++</kbd>+++-Click or +++<kbd>+++Cmd+++</kbd>+++-Click the `http://localhost:3000` link to view your"
  },
  "824": {
    "source_file": "build-a-multibranch-pipeline-project.txt",
    "text": "within the Jenkins home directory.\n+++<kbd>+++Ctrl+++</kbd>+++-Click or +++<kbd>+++Cmd+++</kbd>+++-Click the `http://localhost:3000` link to view your Node.js and React application running in development mode (with the `npm start` command) in a new web browser tab.\nYou should see a page/site with the title *Welcome to React* on it.\nWhen you are finished viewing the page/site, go back to the Jenkin"
  },
  "825": {
    "source_file": "build-a-multibranch-pipeline-project.txt",
    "text": "eb browser tab.\nYou should see a page/site with the title *Welcome to React* on it.\nWhen you are finished viewing the page/site, go back to the Jenkins tab and select *#2* (or the last number of your build), and then *Paused for Input* on the left hand side. +\n[.boxshadow]\n\nSelect the *Proceed* button to complete the Pipeline's execution.\nOnce more, select the *#2* on top of the screen (or the las"
  },
  "826": {
    "source_file": "build-a-multibranch-pipeline-project.txt",
    "text": "nd side. +\n[.boxshadow]\n\nSelect the *Proceed* button to complete the Pipeline's execution.\nOnce more, select the *#2* on top of the screen (or the last number of your build) and then *Pipeline Overview* on the left hand side to see the stages of the Pipeline. +\n[.boxshadow]\n\nNotice how the *Deliver for development* stage was executed but the *Deploy for production* stage was not.\n\nGo back to Jenki"
  },
  "827": {
    "source_file": "build-a-multibranch-pipeline-project.txt",
    "text": "Pipeline. +\n[.boxshadow]\n\nNotice how the *Deliver for development* stage was executed but the *Deploy for production* stage was not.\n\nGo back to Jenkins again, log in again if necessary, navigate to the dashboard, and select *Building a Multibranch Pipeline Project*.\nClick the Run icon  of the `production` branch of your Pipeline project on the far right to see Jenkins building the `production` br"
  },
  "828": {
    "source_file": "build-a-multibranch-pipeline-project.txt",
    "text": "ipeline Project*.\nClick the Run icon  of the `production` branch of your Pipeline project on the far right to see Jenkins building the `production` branch with the amended `Jenkinsfile`. +\nSelect *production* to see a new Pipeline being built. +\n[.boxshadow]\n\nSelect *#2* (or the latest build number) on the left, and then *Pipeline Overview* on the left. +\n[.boxshadow]\n\nSelect the *Deploy for produ"
  },
  "829": {
    "source_file": "build-a-multibranch-pipeline-project.txt",
    "text": "xshadow]\n\nSelect *#2* (or the latest build number) on the left, and then *Pipeline Overview* on the left. +\n[.boxshadow]\n\nSelect the *Deploy for production* stage and then the top green *Shell Script* step to expand its contents and scroll down until you see the `http://localhost:5000` link. +\n[.boxshadow]\n\n+++<kbd>+++Ctrl+++</kbd>+++-Click or +++<kbd>+++Cmd+++</kbd>+++-Click the `http://localhost"
  },
  "830": {
    "source_file": "build-a-multibranch-pipeline-project.txt",
    "text": " you see the `http://localhost:5000` link. +\n[.boxshadow]\n\n+++<kbd>+++Ctrl+++</kbd>+++-Click or +++<kbd>+++Cmd+++</kbd>+++-Click the `http://localhost:5000` link to view your Node.js and React application in a new web browser tab.\nThis will be running in production mode from a production build of your source code (generated using the `npm run build` command).\nOnce again, you should see a page/site"
  },
  "831": {
    "source_file": "build-a-multibranch-pipeline-project.txt",
    "text": "g in production mode from a production build of your source code (generated using the `npm run build` command).\nOnce again, you should see a page/site with the title *Welcome to React* on it.\nHowever, this time, the application's contents are served by the  and are also\nlikely to continue running in the background in your browser.\nWhen you are finished viewing the page/site, go back to the Jenkins"
  },
  "832": {
    "source_file": "build-a-multibranch-pipeline-project.txt",
    "text": "by the  and are also\nlikely to continue running in the background in your browser.\nWhen you are finished viewing the page/site, go back to the Jenkins tab and select *#2* (or the last number of your build), and then *Paused for Input* on the left hand side. +\n[.boxshadow]\n\nSelect the *Proceed* button to complete the Pipeline's execution.\nOnce more, select the *#2* on top of the screen (or the last"
  },
  "833": {
    "source_file": "build-a-multibranch-pipeline-project.txt",
    "text": "d side. +\n[.boxshadow]\n\nSelect the *Proceed* button to complete the Pipeline's execution.\nOnce more, select the *#2* on top of the screen (or the last number of your build) and then *Pipeline Overview* on the left hand side to see the stages of the Pipeline. +\n[.boxshadow]\n\nThe *Deploy for production* stage turns green if Jenkins built your Node.js and React application successfully from your prod"
  },
  "834": {
    "source_file": "build-a-multibranch-pipeline-project.txt",
    "text": "ipeline. +\n[.boxshadow]\n\nThe *Deploy for production* stage turns green if Jenkins built your Node.js and React application successfully from your production branch.\nNotice how the *Deploy for production* stage was executed but the *Deliver for development* stage was skipped.\n*Note:* Since your browser is likely to continue running the application's\ncontent served by the npm `serve` module, your br"
  },
  "835": {
    "source_file": "build-a-multibranch-pipeline-project.txt",
    "text": "pment* stage was skipped.\n*Note:* Since your browser is likely to continue running the application's\ncontent served by the npm `serve` module, your browser will still show the\ncontent you viewed at `http://localhost:5000` long after Jenkins has killed\noff the `serve` process. Read more about how to clear the application and its\ncontent from your browser <<clearing-the-app-from-your-browser,below>>"
  },
  "836": {
    "source_file": "build-a-multibranch-pipeline-project.txt",
    "text": "d\noff the `serve` process. Read more about how to clear the application and its\ncontent from your browser <<clearing-the-app-from-your-browser,below>>.\n\nThis section takes you through a simulated development workflow using\nJenkins, whereby changes made to your application (i.e. the `App.js` source\nfile) can be examined from the `development` branch before they are deployed to\nproduction (from the "
  },
  "837": {
    "source_file": "build-a-multibranch-pipeline-project.txt",
    "text": "de to your application (i.e. the `App.js` source\nfile) can be examined from the `development` branch before they are deployed to\nproduction (from the `production` branch) via the `master` branch.\n\nWithin your local repository's `building-a-multibranch-pipeline-project`\ndirectory, run the command `git checkout development` to change to the\n`development` branch.\nGo back to your text editor/IDE and o"
  },
  "838": {
    "source_file": "build-a-multibranch-pipeline-project.txt",
    "text": "h-pipeline-project`\ndirectory, run the command `git checkout development` to change to the\n`development` branch.\nGo back to your text editor/IDE and open the `App.js` file in the `src`\ndirectory of your local `building-a-multibranch-pipeline-project` Git\nrepository.\nCopy and paste the following HTML syntax immediately under the `To get\nstarted...` line of your `App.js` file:\n<br/>\n          This i"
  },
  "839": {
    "source_file": "build-a-multibranch-pipeline-project.txt",
    "text": " Git\nrepository.\nCopy and paste the following HTML syntax immediately under the `To get\nstarted...` line of your `App.js` file:\n<br/>\n          This is a new line I added.\n\nso that you end up with:\nimport logo from './logo.svg';\nimport './App.css';\n\nfunction App() {\n  return (\n    <div className=\"App\">\n      <header className=\"App-header\">\n        <img src={logo} className=\"App-logo\" alt=\"logo\" />"
  },
  "840": {
    "source_file": "build-a-multibranch-pipeline-project.txt",
    "text": "function App() {\n  return (\n    <div className=\"App\">\n      <header className=\"App-header\">\n        <img src={logo} className=\"App-logo\" alt=\"logo\" />\n        <p>\n          Edit <code>src/App.js</code> and save to reload.\n        </p>\n        <a\n          className=\"App-link\"\n          href=\"https://reactjs.org\"\n          target=\"_blank\"\n          rel=\"noopener noreferrer\"\n        >\n          Lear"
  },
  "841": {
    "source_file": "build-a-multibranch-pipeline-project.txt",
    "text": "      className=\"App-link\"\n          href=\"https://reactjs.org\"\n          target=\"_blank\"\n          rel=\"noopener noreferrer\"\n        >\n          Learn React<br/>\n          This is a new line I added.\n        </a>\n      </header>\n    </div>\n  );\n}\n\nexport default App;\n\nSave the edited `App.js` file and commit it to your local\n`building-a-multibranch-pipeline-project` Git repository. E.g. Within th"
  },
  "842": {
    "source_file": "build-a-multibranch-pipeline-project.txt",
    "text": "xport default App;\n\nSave the edited `App.js` file and commit it to your local\n`building-a-multibranch-pipeline-project` Git repository. E.g. Within the\n`building-a-multibranch-pipeline-project` directory, run the commands: +\n`git add src/App.js` +\nthen +\n`git commit -m \"Update 'App.js'\"`\nand finally +\n`git push` to push your changes to your forked repository on GitHub, so it can be picked up by Je"
  },
  "843": {
    "source_file": "build-a-multibranch-pipeline-project.txt",
    "text": "en +\n`git commit -m \"Update 'App.js'\"`\nand finally +\n`git push` to push your changes to your forked repository on GitHub, so it can be picked up by Jenkins.\n\nBack in Jenkins, run your Pipeline on the `development` branch (as you did <<run-your-pipeline-on-the-development-branch,above>>) and check the results through `http://localhost:3000` to see your new line added.\nAssuming you're happy with the"
  },
  "844": {
    "source_file": "build-a-multibranch-pipeline-project.txt",
    "text": "ne-on-the-development-branch,above>>) and check the results through `http://localhost:3000` to see your new line added.\nAssuming you're happy with the change, then within your local repository's `building-a-multibranch-pipeline-project` directory, run the following set of commands to merge your change into the `production` branch (via the `master` branch):\n* `git checkout master` +\nand\n* `git pull"
  },
  "845": {
    "source_file": "build-a-multibranch-pipeline-project.txt",
    "text": "n the following set of commands to merge your change into the `production` branch (via the `master` branch):\n* `git checkout master` +\nand\n* `git pull . development` +\nand then\n* `git push` +\nOnce done with master, let's move to production:\n* `git checkout production` +\nand\n* `git pull . master` +\nand then\n* `git push` +\nBack in Jenkins, run your Pipeline on the `production` branch this time (as y"
  },
  "846": {
    "source_file": "build-a-multibranch-pipeline-project.txt",
    "text": "eckout production` +\nand\n* `git pull . master` +\nand then\n* `git push` +\nBack in Jenkins, run your Pipeline on the `production` branch this time (as you did <<run-your-pipeline-on-the-production-branch,above>>) and check the results through `http://localhost:5000` to see your new line added. +\n*Notes:*\n* Since your browser is likely to cache the contents of the npm `serve` module, you may need to "
  },
  "847": {
    "source_file": "build-a-multibranch-pipeline-project.txt",
    "text": "ocalhost:5000` to see your new line added. +\n*Notes:*\n* Since your browser is likely to cache the contents of the npm `serve` module, you may need to refresh your browser page to see your change.\n* In a real software development environment with small to large teams of people, pulling changes between branches is more likely to be conducted using pull requests on a cloud- or web-hosted Git service "
  },
  "848": {
    "source_file": "build-a-multibranch-pipeline-project.txt",
    "text": "l to large teams of people, pulling changes between branches is more likely to be conducted using pull requests on a cloud- or web-hosted Git service (such as GitHub or BitBucket).\n\nYour browser is likely to continue running your application's content served by the , which means that your browser will still show the content you viewed at `http://localhost:5000` long after Jenkins has killed off th"
  },
  "849": {
    "source_file": "build-a-multibranch-pipeline-project.txt",
    "text": "t served by the , which means that your browser will still show the content you viewed at `http://localhost:5000` long after Jenkins has killed off the `serve` process.\nTo clear the application and its content from your browser:\n\nEnter the following into your browser's URL field: +\n`chrome://serviceworker-internals/`\nLocate the \"ServiceWorker\" entry for `http://localhost:5000`\nClick its *Unregiste"
  },
  "850": {
    "source_file": "build-a-multibranch-pipeline-project.txt",
    "text": "into your browser's URL field: +\n`chrome://serviceworker-internals/`\nLocate the \"ServiceWorker\" entry for `http://localhost:5000`\nClick its *Unregister* button.\n\nEnter the following into your browser's URL field: +\n`about:serviceworkers`\nLocate the \"Registered Service Worker\" entry for `http://localhost:5000`\nClick its *Unregister* button.\n\nWell done! You've just used Jenkins to build a multibranc"
  },
  "851": {
    "source_file": "build-a-multibranch-pipeline-project.txt",
    "text": "Registered Service Worker\" entry for `http://localhost:5000`\nClick its *Unregister* button.\n\nWell done! You've just used Jenkins to build a multibranch Pipeline project with selectively run stages!\n\nThis tutorial demonstrated the power of using a single `Jenkinsfile` across multiple branches of your repository to orchestrate different build and delivery outcomes in Jenkins.\n\nBecause Jenkins is ext"
  },
  "852": {
    "source_file": "build-a-multibranch-pipeline-project.txt",
    "text": "gle `Jenkinsfile` across multiple branches of your repository to orchestrate different build and delivery outcomes in Jenkins.\n\nBecause Jenkins is extremely extensible, it can be modified and configured to handle practically any aspect of build orchestration and automation.\n\nTo learn more about what Jenkins can do, check out:\n\n* The  page for other introductory tutorials.\n* The  for more detailed "
  },
  "853": {
    "source_file": "build-a-multibranch-pipeline-project.txt",
    "text": "stration and automation.\n\nTo learn more about what Jenkins can do, check out:\n\n* The  page for other introductory tutorials.\n* The  for more detailed information about using Jenkins, such as  (in particular ) and the  interface.\n* The  for the latest events, other tutorials and updates.\n\nAfter completing the tutorial, it's important to clean up your environment to prevent interference with other t"
  },
  "854": {
    "source_file": "build-a-multibranch-pipeline-project.txt",
    "text": " events, other tutorials and updates.\n\nAfter completing the tutorial, it's important to clean up your environment to prevent interference with other tutorials you might try later.\n\nTo stop the containers and remove associated volumes:\n\ndocker compose --profile multi down -v --remove-orphans\n\nThis command ensures a clean slate for your next project.\n\nThe `--remove-orphans` option instructs Docker C"
  },
  "855": {
    "source_file": "build-a-multibranch-pipeline-project.txt",
    "text": " --profile multi down -v --remove-orphans\n\nThis command ensures a clean slate for your next project.\n\nThe `--remove-orphans` option instructs Docker Compose to remove any containers that are not defined in the `docker-compose.yml` file but are labeled as belonging to the project.\nThis helps in cleaning up any services that might have been started independently but are considered part of the projec"
  },
  "856": {
    "source_file": "build-a-multibranch-pipeline-project.txt",
    "text": "d as belonging to the project.\nThis helps in cleaning up any services that might have been started independently but are considered part of the project.\n\n'''\n+++\n\n+++"
  },
  "857": {
    "source_file": "build-a-node-js-and-react-app-with-npm.txt",
    "text": "layout: documentation\ntitle: Build a Node.js and React app with npm\nsection: doc\n\n\nThis tutorial shows you how to use Jenkins to orchestrate building a simple\nhttps://nodejs.org/en/[Node.js] and https://reactjs.org/[React] application\nwith the https://www.npmjs.com/[Node Package Manager (npm)].\n\nIf you are a Node.js and React developer who is new to CI/CD concepts, or you\nmight be familiar with th"
  },
  "858": {
    "source_file": "build-a-node-js-and-react-app-with-npm.txt",
    "text": "//www.npmjs.com/[Node Package Manager (npm)].\n\nIf you are a Node.js and React developer who is new to CI/CD concepts, or you\nmight be familiar with these concepts but don't know how to implement building\nyour application using Jenkins, then this tutorial is for you.\n\nThe simple Node.js and React application (which you'll obtain from a sample\nrepository on GitHub) generates a web page with the cont"
  },
  "859": {
    "source_file": "build-a-node-js-and-react-app-with-npm.txt",
    "text": "rial is for you.\n\nThe simple Node.js and React application (which you'll obtain from a sample\nrepository on GitHub) generates a web page with the content \"Welcome to React\"\nand is accompanied by a test to check that the application renders\nsatisfactorily.\n\n*Duration:* This tutorial takes 20-40 minutes to complete (assuming you've\nalready met the <<prerequisites,prerequisites>> below).\nThe exact du"
  },
  "860": {
    "source_file": "build-a-node-js-and-react-app-with-npm.txt",
    "text": "rily.\n\n*Duration:* This tutorial takes 20-40 minutes to complete (assuming you've\nalready met the <<prerequisites,prerequisites>> below).\nThe exact duration will depend on the speed of your machine and whether you've already installed `docker` and `docker compose`.\n\nYou can stop this tutorial at any point in time and continue from where you left\noff.\n\nMake sure you have  installed locally.\n\n** , a"
  },
  "861": {
    "source_file": "build-a-node-js-and-react-app-with-npm.txt",
    "text": "ocker compose`.\n\nYou can stop this tutorial at any point in time and continue from where you left\noff.\n\nMake sure you have  installed locally.\n\n** , and optionally .\n\n[[fork-sample-repository]]\n[[fork-and-clone-the-sample-repository-on-github]]\n\nObtain the simple \"Welcome to React\" Node.js and React application from GitHub,\nby forking the sample repository of the application's source code into you"
  },
  "862": {
    "source_file": "build-a-node-js-and-react-app-with-npm.txt",
    "text": "in the simple \"Welcome to React\" Node.js and React application from GitHub,\nby forking the sample repository of the application's source code into your own\nGitHub account and then cloning this fork locally.\n\nEnsure you are signed in to your GitHub account.\nIf you don't yet have a GitHub account, sign up for a free one on the https://github.com/[GitHub website].\nFork the https://github.com/jenkins-"
  },
  "863": {
    "source_file": "build-a-node-js-and-react-app-with-npm.txt",
    "text": "count.\nIf you don't yet have a GitHub account, sign up for a free one on the https://github.com/[GitHub website].\nFork the https://github.com/jenkins-docs/simple-node-js-react-npm-app[`simple-node-js-react-npm-app`] on GitHub into your local GitHub account.\nIf you need help with this process, refer to the https://help.github.com/articles/fork-a-repo/[Fork A Repo] documentation on the GitHub websit"
  },
  "864": {
    "source_file": "build-a-node-js-and-react-app-with-npm.txt",
    "text": "ccount.\nIf you need help with this process, refer to the https://help.github.com/articles/fork-a-repo/[Fork A Repo] documentation on the GitHub website for more information.\nClone your forked `simple-node-js-react-npm-app` repository (on GitHub)\n  locally to your machine. To begin this process, do either of the following\n  (where `<your-username>` is the name of your user account on your operating"
  },
  "865": {
    "source_file": "build-a-node-js-and-react-app-with-npm.txt",
    "text": "cally to your machine. To begin this process, do either of the following\n  (where `<your-username>` is the name of your user account on your operating\n  system):\n** If you have the GitHub Desktop app installed on your machine:\n.. In GitHub, click the green *Clone or download* button on your forked\n   repository, then *Open in Desktop*.\n.. In GitHub Desktop, before clicking *Clone* on the *Clone a "
  },
  "866": {
    "source_file": "build-a-node-js-and-react-app-with-npm.txt",
    "text": " green *Clone or download* button on your forked\n   repository, then *Open in Desktop*.\n.. In GitHub Desktop, before clicking *Clone* on the *Clone a Repository* dialog\n   box, ensure *Local Path* for:\n*** macOS is `/Users/<your-username>/Documents/GitHub/simple-node-js-react-npm-app`\n*** Linux is `/home/<your-username>/GitHub/simple-node-js-react-npm-app`\n*** Windows is `C:\\Users\\<your-username>\\"
  },
  "867": {
    "source_file": "build-a-node-js-and-react-app-with-npm.txt",
    "text": "itHub/simple-node-js-react-npm-app`\n*** Linux is `/home/<your-username>/GitHub/simple-node-js-react-npm-app`\n*** Windows is `C:\\Users\\<your-username>\\Documents\\GitHub\\simple-node-js-react-npm-app`\n** Otherwise:\n.. Open up a terminal/command line prompt and `cd` to the appropriate directory\n   on:\n*** macOS - `/Users/<your-username>/Documents/GitHub/`\n*** Linux - `/home/<your-username>/GitHub/`\n***"
  },
  "868": {
    "source_file": "build-a-node-js-and-react-app-with-npm.txt",
    "text": "pt and `cd` to the appropriate directory\n   on:\n*** macOS - `/Users/<your-username>/Documents/GitHub/`\n*** Linux - `/home/<your-username>/GitHub/`\n*** Windows - `C:\\Users\\<your-username>\\Documents\\GitHub\\` (although use a Git\n    bash command line window as opposed to the usual Microsoft command prompt)\n.. Run the following command to continue/complete cloning your forked repo: +\n   `git clone htt"
  },
  "869": {
    "source_file": "build-a-node-js-and-react-app-with-npm.txt",
    "text": "ndow as opposed to the usual Microsoft command prompt)\n.. Run the following command to continue/complete cloning your forked repo: +\n   `git clone https://github.com/YOUR-GITHUB-ACCOUNT-NAME/simple-node-js-react-npm-app` +\n   where `YOUR-GITHUB-ACCOUNT-NAME` is the name of your GitHub account.\n\n1. Obtain the latest Jenkins deployment, customized for this tutorial, by cloning the .\n2. After cloning"
  },
  "870": {
    "source_file": "build-a-node-js-and-react-app-with-npm.txt",
    "text": "NT-NAME` is the name of your GitHub account.\n\n1. Obtain the latest Jenkins deployment, customized for this tutorial, by cloning the .\n2. After cloning, navigate to the `quickstart-tutorials` directory and execute the command\ndocker compose --profile node up -d\n\nto run the example.\n3. Once the containers are running successfully (you can verify this with `docker compose ps`), the controller can be "
  },
  "871": {
    "source_file": "build-a-node-js-and-react-app-with-npm.txt",
    "text": "node up -d\n\nto run the example.\n3. Once the containers are running successfully (you can verify this with `docker compose ps`), the controller can be accessed at http://localhost:8080.\n\nIf you are unable to install `docker compose` on your machine for any reason, you can still run the example in the cloud for free using either:\n\n* *GitHub Codespaces* (Recommended): Click the *Code* button in the ,"
  },
  "872": {
    "source_file": "build-a-node-js-and-react-app-with-npm.txt",
    "text": "r any reason, you can still run the example in the cloud for free using either:\n\n* *GitHub Codespaces* (Recommended): Click the *Code* button in the , select *Codespaces*, then *Create codespace on master*.\nGitHub Codespaces provides .\nOnce the Codespace starts, the setup will run automatically, and you'll see a welcome message with instructions.\n\n* *GitPod*: Click on  to open a GitPod workspace.\n"
  },
  "873": {
    "source_file": "build-a-node-js-and-react-app-with-npm.txt",
    "text": "pace starts, the setup will run automatically, and you'll see a welcome message with instructions.\n\n* *GitPod*: Click on  to open a GitPod workspace.\nGitPod .\nYou need to link it to your GitHub account.\n\nNow, log in using the `admin` username and `admin` password.\n\nIn Jenkins, select *New Item* under *Dashboard >* at the top left.\nEnter your new Pipeline project name, such as `simple-node-js-react"
  },
  "874": {
    "source_file": "build-a-node-js-and-react-app-with-npm.txt",
    "text": "min` password.\n\nIn Jenkins, select *New Item* under *Dashboard >* at the top left.\nEnter your new Pipeline project name, such as `simple-node-js-react-npm-app`, in *Enter an item name*.\nScroll down if necessary and select *Pipeline*, then select *OK* at the end of the page.\n(Optional) Enter a Pipeline *Description*.\nSelect *Pipeline* on the left pane.\nSelect *Definition* and then choose the *Pipel"
  },
  "875": {
    "source_file": "build-a-node-js-and-react-app-with-npm.txt",
    "text": " at the end of the page.\n(Optional) Enter a Pipeline *Description*.\nSelect *Pipeline* on the left pane.\nSelect *Definition* and then choose the *Pipeline script from SCM* option.\nThis option instructs Jenkins to obtain your Pipeline from the source control management (SCM), which is your forked Git repository.\nChoose *Git* from the options in *SCM*.\nEnter the URL of your repository in *Repositorie"
  },
  "876": {
    "source_file": "build-a-node-js-and-react-app-with-npm.txt",
    "text": "ontrol management (SCM), which is your forked Git repository.\nChoose *Git* from the options in *SCM*.\nEnter the URL of your repository in *Repositories/Repository URL*.\nThis URL can be found when selecting the green *Code* button in the main page of your GitHub repo.\nSelect *Save* at the end of the page.\nYou're now ready to create a `Jenkinsfile` to check into your locally cloned Git repository.\n\n"
  },
  "877": {
    "source_file": "build-a-node-js-and-react-app-with-npm.txt",
    "text": "your GitHub repo.\nSelect *Save* at the end of the page.\nYou're now ready to create a `Jenkinsfile` to check into your locally cloned Git repository.\n\nYou're now ready to create your Pipeline that will automate building your Node.js and React application in Jenkins.\nYour Pipeline is created as a `Jenkinsfile`, which is committed to your locally cloned Git repository (`simple-node-js-react-npm-app`)"
  },
  "878": {
    "source_file": "build-a-node-js-and-react-app-with-npm.txt",
    "text": "ion in Jenkins.\nYour Pipeline is created as a `Jenkinsfile`, which is committed to your locally cloned Git repository (`simple-node-js-react-npm-app`) and then pushed to GitHub.\n\nThis is the foundation of \"Pipeline-as-Code\", which treats the continuous delivery pipeline as a part of the application to be versioned and reviewed like any other code.\nRead more about Pipeline and what a Jenkinsfile is"
  },
  "879": {
    "source_file": "build-a-node-js-and-react-app-with-npm.txt",
    "text": "us delivery pipeline as a part of the application to be versioned and reviewed like any other code.\nRead more about Pipeline and what a Jenkinsfile is in the  and  sections of the User Handbook.\n\nFirst, create an initial Pipeline to download a Node Docker image and run it as\na Docker container (which will build your simple Node.js and React application).\nAlso add a \"Build\" stage to the Pipeline th"
  },
  "880": {
    "source_file": "build-a-node-js-and-react-app-with-npm.txt",
    "text": "ocker image and run it as\na Docker container (which will build your simple Node.js and React application).\nAlso add a \"Build\" stage to the Pipeline that begins orchestrating this whole\nprocess.\n\nUsing your favorite text editor or IDE, create and save new text file with the\n  name `Jenkinsfile` at the root of your local `simple-node-js-react-npm-app`\n  Git repository.\nCopy the following Declarative"
  },
  "881": {
    "source_file": "build-a-node-js-and-react-app-with-npm.txt",
    "text": " new text file with the\n  name `Jenkinsfile` at the root of your local `simple-node-js-react-npm-app`\n  Git repository.\nCopy the following Declarative Pipeline code and paste it into your empty\n  `Jenkinsfile`:\npipeline {\n    agent any\n    stages {\n        stage('Build') { // <1> steps {\n                sh 'npm install' // <2> }\n        }\n    }\n}\n\n<1> Defines a  (directive) called `Build` that app"
  },
  "882": {
    "source_file": "build-a-node-js-and-react-app-with-npm.txt",
    "text": "       stage('Build') { // <1> steps {\n                sh 'npm install' // <2> }\n        }\n    }\n}\n\n<1> Defines a  (directive) called `Build` that appears on the Jenkins UI.\n<2> This  step (of the  section) executes the `npm` command to ensure that all dependencies required to run your application have been downloaded to the `node_modules` workspace directory.\n\nSave your edited `Jenkinsfile` and c"
  },
  "883": {
    "source_file": "build-a-node-js-and-react-app-with-npm.txt",
    "text": "ll dependencies required to run your application have been downloaded to the `node_modules` workspace directory.\n\nSave your edited `Jenkinsfile` and commit it to your local `simple-node-js-react-npm-app` Git repository.\nWithin the  `simple-node-js-react-npm-app` directory, run the commands: +\n  `git add .` +\n  then +\n  `git commit -m \"Add initial Jenkinsfile\"` +\n and finally +\n`git push` to push y"
  },
  "884": {
    "source_file": "build-a-node-js-and-react-app-with-npm.txt",
    "text": "act-npm-app` directory, run the commands: +\n  `git add .` +\n  then +\n  `git commit -m \"Add initial Jenkinsfile\"` +\n and finally +\n`git push` to push your changes to your forked repository on GitHub, so it can be picked up by Jenkins.\n\nNow select *Build Now* on the left pane of your Pipeline project in Jenkins.\nAfter making a clone of your local `simple-node-js-react-npm-app` Git repository itself,"
  },
  "885": {
    "source_file": "build-a-node-js-and-react-app-with-npm.txt",
    "text": "ld Now* on the left pane of your Pipeline project in Jenkins.\nAfter making a clone of your local `simple-node-js-react-npm-app` Git repository itself, Jenkins:\n\nInitially queues the project to be run on the agent.\nRuns the `Build` stage defined in the `Jenkinsfile` on the agent.\n\nDuring this time, npm downloads and installs many artifacts necessary to build your node/js application, which are ulti"
  },
  "886": {
    "source_file": "build-a-node-js-and-react-app-with-npm.txt",
    "text": "e `Jenkinsfile` on the agent.\n\nDuring this time, npm downloads and installs many artifacts necessary to build your node/js application, which are ultimately stored in Jenkins' local `npm` repository.\n[.boxshadow]\n\nYou can now select *#1* to see the details of the build.\nYou will then see how much time the build took waiting in the queue, and how much time it took to run.\n[.boxshadow]\n\nIn the left "
  },
  "887": {
    "source_file": "build-a-node-js-and-react-app-with-npm.txt",
    "text": "etails of the build.\nYou will then see how much time the build took waiting in the queue, and how much time it took to run.\n[.boxshadow]\n\nIn the left navigation pane, you can select *Pipeline Overview* to see the stages of the Pipeline.\n[.boxshadow]\n\nIf you select the *Build* stage, you will see more information about the stage, including the output of the `npm` command if you select the green `np"
  },
  "888": {
    "source_file": "build-a-node-js-and-react-app-with-npm.txt",
    "text": "\nIf you select the *Build* stage, you will see more information about the stage, including the output of the `npm` command if you select the green `npm install` section.\n[.boxshadow]\n\nYou can now select *simple-node-js-react-npm-app* (if that's the name you chose for your pipeline) on the top left to return to your pipeline main page.\n\nGo back to your text editor/IDE and ensure your `Jenkinsfile` "
  },
  "889": {
    "source_file": "build-a-node-js-and-react-app-with-npm.txt",
    "text": "ame you chose for your pipeline) on the top left to return to your pipeline main page.\n\nGo back to your text editor/IDE and ensure your `Jenkinsfile` is open.\nCopy and paste the following Declarative Pipeline syntax immediately under the `Build` stage:\nstage('Test') {\n            steps {\n                sh './jenkins/scripts/test.sh'\n            }\n        }\n\nso that you end up with:\npipeline {\n   "
  },
  "890": {
    "source_file": "build-a-node-js-and-react-app-with-npm.txt",
    "text": "e:\nstage('Test') {\n            steps {\n                sh './jenkins/scripts/test.sh'\n            }\n        }\n\nso that you end up with:\npipeline {\n    agent any\n    stages {\n        stage('Build') {\n            steps {\n                sh 'npm install'\n            }\n        }\n        stage('Test') { // <1> steps {\n                sh './jenkins/scripts/test.sh' // <2> }\n        }\n    }\n}\n\n<1> Define"
  },
  "891": {
    "source_file": "build-a-node-js-and-react-app-with-npm.txt",
    "text": "'\n            }\n        }\n        stage('Test') { // <1> steps {\n                sh './jenkins/scripts/test.sh' // <2> }\n        }\n    }\n}\n\n<1> Defines a  (directive) called\n`Test` that appears on the Jenkins UI.\n<2> This\n\nstep (of the  section) runs the\nshell script `test.sh` located in the `jenkins/scripts` directory from the root\nof the `simple-node-js-react-npm-app` repository. Explanations ab"
  },
  "892": {
    "source_file": "build-a-node-js-and-react-app-with-npm.txt",
    "text": " the\nshell script `test.sh` located in the `jenkins/scripts` directory from the root\nof the `simple-node-js-react-npm-app` repository. Explanations about what this\nscript does are covered in the `test.sh` file itself. As a general principle,\nit's a good idea to keep your Pipeline code (i.e. the `Jenkinsfile`) as tidy as\npossible and place more complex build scripting steps into separate shell scri"
  },
  "893": {
    "source_file": "build-a-node-js-and-react-app-with-npm.txt",
    "text": "ood idea to keep your Pipeline code (i.e. the `Jenkinsfile`) as tidy as\npossible and place more complex build scripting steps into separate shell script\nfiles like the `test.sh` file. This ultimately facilitates the maintenance of\nyour Pipeline, especially if it gains more complexity.\nSave your edited `Jenkinsfile` and commit it to your local\n  `simple-node-js-react-npm-app` Git repository. E.g. W"
  },
  "894": {
    "source_file": "build-a-node-js-and-react-app-with-npm.txt",
    "text": "cially if it gains more complexity.\nSave your edited `Jenkinsfile` and commit it to your local\n  `simple-node-js-react-npm-app` Git repository. E.g. Within the\n  `simple-node-js-react-npm-app` directory, run the commands: +\n  `git add .` +\n  then +\n  `git commit -m \"Add 'Test' stage\"` +\nand finally +\n`git push` to push your changes to your forked repository on GitHub, so it can be picked up by Jen"
  },
  "895": {
    "source_file": "build-a-node-js-and-react-app-with-npm.txt",
    "text": " `git commit -m \"Add 'Test' stage\"` +\nand finally +\n`git push` to push your changes to your forked repository on GitHub, so it can be picked up by Jenkins.\n\nIn Jenkins, go back to *Dashboard* if necessary, then *simple-node-js-react-npm-app* and launch another build thanks to *Build Now*.\nAfter a while, a new column *Test* appear in the *Stage View*.\n\n[.boxshadow]\n\nYou can select*#2* or on the num"
  },
  "896": {
    "source_file": "build-a-node-js-and-react-app-with-npm.txt",
    "text": "ch another build thanks to *Build Now*.\nAfter a while, a new column *Test* appear in the *Stage View*.\n\n[.boxshadow]\n\nYou can select*#2* or on the number representing your last build on the left, under *Build History*.\nYou will then see the details of the build.\nIf Docker has not restarted since you last ran the Pipeline <<create-your-initial-pipeline-as-a-jenkinsfile,above>>, then no `npm` artifa"
  },
  "897": {
    "source_file": "build-a-node-js-and-react-app-with-npm.txt",
    "text": "f the build.\nIf Docker has not restarted since you last ran the Pipeline <<create-your-initial-pipeline-as-a-jenkinsfile,above>>, then no `npm` artifacts are downloaded during the \"Build\" stage.\nTherefore, running your Pipeline this subsequent time should be much faster.\n\nYou can now select *Pipeline Overview* to see the stages of the Pipeline.\n[.boxshadow]\n\nNotice the additional \"Test\" stage.\nYou"
  },
  "898": {
    "source_file": "build-a-node-js-and-react-app-with-npm.txt",
    "text": "hould be much faster.\n\nYou can now select *Pipeline Overview* to see the stages of the Pipeline.\n[.boxshadow]\n\nNotice the additional \"Test\" stage.\nYou can select the \"Test\" stage checkmark to access the output from that stage.\n[.boxshadow]\n\nGo back to your text editor/IDE and ensure your `Jenkinsfile` is open.\nCopy and paste the following Declarative Pipeline syntax immediately under the\n  `Test` "
  },
  "899": {
    "source_file": "build-a-node-js-and-react-app-with-npm.txt",
    "text": "o your text editor/IDE and ensure your `Jenkinsfile` is open.\nCopy and paste the following Declarative Pipeline syntax immediately under the\n  `Test` stage of your `Jenkinsfile`:\nstage('Deliver') {\n            steps {\n                sh './jenkins/scripts/deliver.sh'\n                input message: 'Finished using the web site? (Click \"Proceed\" to continue)'\n                sh './jenkins/scripts/ki"
  },
  "900": {
    "source_file": "build-a-node-js-and-react-app-with-npm.txt",
    "text": "ripts/deliver.sh'\n                input message: 'Finished using the web site? (Click \"Proceed\" to continue)'\n                sh './jenkins/scripts/kill.sh'\n            }\n        }\n\nso that you end up with:\npipeline {\n    agent any\n    stages {\n        stage('Build') {\n            steps {\n                sh 'npm install'\n            }\n        }\n        stage('Test') {\n            steps {\n         "
  },
  "901": {
    "source_file": "build-a-node-js-and-react-app-with-npm.txt",
    "text": "   stage('Build') {\n            steps {\n                sh 'npm install'\n            }\n        }\n        stage('Test') {\n            steps {\n                sh './jenkins/scripts/test.sh'\n            }\n        }\n        stage('Deliver') { // <1> steps {\n                sh './jenkins/scripts/deliver.sh' // <2> input message: 'Finished using the web site? (Click \"Proceed\" to continue)' // <3> sh './"
  },
  "902": {
    "source_file": "build-a-node-js-and-react-app-with-npm.txt",
    "text": "s {\n                sh './jenkins/scripts/deliver.sh' // <2> input message: 'Finished using the web site? (Click \"Proceed\" to continue)' // <3> sh './jenkins/scripts/kill.sh' // <4> }\n        }\n    }\n}\n\n<1> Defines a new stage called `Deliver` that appears on the Jenkins UI.\n<2> This\n\nstep (of the  section) runs the\nshell script `deliver.sh` located in the `jenkins/scripts` directory from the\nroot"
  },
  "903": {
    "source_file": "build-a-node-js-and-react-app-with-npm.txt",
    "text": "ppears on the Jenkins UI.\n<2> This\n\nstep (of the  section) runs the\nshell script `deliver.sh` located in the `jenkins/scripts` directory from the\nroot of the `simple-node-js-react-npm-app` repository. Explanations about what\nthis script does are covered in the `deliver.sh` file itself.\n<3> This\n\nstep (provided by the  plugin) pauses the running build and prompts the user (with a custom\nmessage) to"
  },
  "904": {
    "source_file": "build-a-node-js-and-react-app-with-npm.txt",
    "text": "red in the `deliver.sh` file itself.\n<3> This\n\nstep (provided by the  plugin) pauses the running build and prompts the user (with a custom\nmessage) to proceed or abort.\n<4> This\n\nstep runs the shell script `kill.sh`, also located in the `jenkins/scripts`\ndirectory. Explanations about what this script does are covered in the `kill.sh`\nfile itself.\nSave your edited `Jenkinsfile` and commit it to you"
  },
  "905": {
    "source_file": "build-a-node-js-and-react-app-with-npm.txt",
    "text": "pts`\ndirectory. Explanations about what this script does are covered in the `kill.sh`\nfile itself.\nSave your edited `Jenkinsfile` and commit it to your local\n  `simple-node-js-react-npm-app` Git repository. E.g. Within the\n  `simple-node-js-react-npm-app` directory, run the commands: +\n  `git add .` +\n  then +\n  `git commit -m \"Add 'Deliver' stage\"` +\nand finally +\n`git push` to push your changes "
  },
  "906": {
    "source_file": "build-a-node-js-and-react-app-with-npm.txt",
    "text": "-app` directory, run the commands: +\n  `git add .` +\n  then +\n  `git commit -m \"Add 'Deliver' stage\"` +\nand finally +\n`git push` to push your changes to your forked repository on GitHub, so it can be picked up by Jenkins.\n\nIn Jenkins, sign in if necessary, go back to the *Dashboard* and then navigate to *`simple-node-js-react-npm-app`*.\nAlternatively, you can go directly to *`simple-node-js-react-"
  },
  "907": {
    "source_file": "build-a-node-js-and-react-app-with-npm.txt",
    "text": "ssary, go back to the *Dashboard* and then navigate to *`simple-node-js-react-npm-app`*.\nAlternatively, you can go directly to *`simple-node-js-react-npm-app`* depending on where you're starting from.\nSelect *Build Now* on the left.\nYou should see after a while a new column *Deliver* appear in the *Stage View*.\n[.boxshadow]\n\nSelect *#3* or on the number representing your last build on the left, un"
  },
  "908": {
    "source_file": "build-a-node-js-and-react-app-with-npm.txt",
    "text": "ter a while a new column *Deliver* appear in the *Stage View*.\n[.boxshadow]\n\nSelect *#3* or on the number representing your last build on the left, under *Build History*.\nSelect *Pipeline Overview* to see the stages of the Pipeline.\n[.boxshadow]\n\nSelect the *Deliver* stage.+\nYou will then see a green part displaying *./jenkins/scripts/deliver.sh*, which represents the successful execution of the `"
  },
  "909": {
    "source_file": "build-a-node-js-and-react-app-with-npm.txt",
    "text": "ect the *Deliver* stage.+\nYou will then see a green part displaying *./jenkins/scripts/deliver.sh*, which represents the successful execution of the `deliver.sh` script.\n[.boxshadow]\n\nEnsure you are viewing the \"Deliver\" stage (click it if necessary), then click\n  the green *`./jenkins/scripts/deliver.sh`* step to expand its content and\n  scroll down until you see the `http://localhost:3000` link."
  },
  "910": {
    "source_file": "build-a-node-js-and-react-app-with-npm.txt",
    "text": ", then click\n  the green *`./jenkins/scripts/deliver.sh`* step to expand its content and\n  scroll down until you see the `http://localhost:3000` link.\n[.boxshadow]\n\nClick the `http://localhost:3000` link to view your Node.js and React\n  application running (in development mode) in a new web browser tab. You should\n  see a page/site with the title *Welcome to React* on it. +\nWhen you are finished v"
  },
  "911": {
    "source_file": "build-a-node-js-and-react-app-with-npm.txt",
    "text": "unning (in development mode) in a new web browser tab. You should\n  see a page/site with the title *Welcome to React* on it. +\nWhen you are finished viewing the page/site, select the *#3* link at the top of the page, or the number that represents your last build.\nOn the left, look for *Paused for Input*.\nYou should see two buttons, *Proceed* and *Abort*.\nSelect the *Process* link to complete the P"
  },
  "912": {
    "source_file": "build-a-node-js-and-react-app-with-npm.txt",
    "text": "r last build.\nOn the left, look for *Paused for Input*.\nYou should see two buttons, *Proceed* and *Abort*.\nSelect the *Process* link to complete the Pipeline's execution.\n[.boxshadow]\n\nYou can now select *simple-node-js-react-npm-app* on the top left, and then on Stages at the left.\nIt will list your previous Pipeline runs in reverse chronological order.\n[.boxshadow]\n\nWell done!\nYou've just used J"
  },
  "913": {
    "source_file": "build-a-node-js-and-react-app-with-npm.txt",
    "text": ", and then on Stages at the left.\nIt will list your previous Pipeline runs in reverse chronological order.\n[.boxshadow]\n\nWell done!\nYou've just used Jenkins to build a simple Node.js and React application with npm!\n\nThe \"Build\", \"Test\" and \"Deliver\" stages you created above are the basis for building more complex Node.js and React applications in Jenkins, as well as Node.js and React applications "
  },
  "914": {
    "source_file": "build-a-node-js-and-react-app-with-npm.txt",
    "text": "stages you created above are the basis for building more complex Node.js and React applications in Jenkins, as well as Node.js and React applications that integrate with other technology stacks.\n\nBecause Jenkins is extremely extensible, it can be modified and configured to handle practically any aspect of build orchestration and automation.\n\nTo learn more about what Jenkins can do, check out:\n\n* T"
  },
  "915": {
    "source_file": "build-a-node-js-and-react-app-with-npm.txt",
    "text": "ified and configured to handle practically any aspect of build orchestration and automation.\n\nTo learn more about what Jenkins can do, check out:\n\n* The  page for other introductory\n  tutorials.\n* The  for more detailed information about using\n  Jenkins, such as  (in particular\n  ) and the\n   interface.\n* The  for the latest events, other tutorials and\n  updates.\n\nAfter completing the tutorial, it"
  },
  "916": {
    "source_file": "build-a-node-js-and-react-app-with-npm.txt",
    "text": "ins, such as  (in particular\n  ) and the\n   interface.\n* The  for the latest events, other tutorials and\n  updates.\n\nAfter completing the tutorial, it's important to clean up your environment to prevent interference with other tutorials you might try later.\n\nTo stop the containers and remove associated volumes:\n\ndocker compose --profile node down -v --remove-orphans\n\nThis command ensures a clean s"
  },
  "917": {
    "source_file": "build-a-node-js-and-react-app-with-npm.txt",
    "text": " later.\n\nTo stop the containers and remove associated volumes:\n\ndocker compose --profile node down -v --remove-orphans\n\nThis command ensures a clean slate for your next project.\n\nThe `--remove-orphans` option instructs Docker Compose to remove any containers that are not defined in the `docker-compose.yml` file but are labeled as belonging to the project.\nThis helps in cleaning up any services tha"
  },
  "918": {
    "source_file": "build-a-node-js-and-react-app-with-npm.txt",
    "text": "ntainers that are not defined in the `docker-compose.yml` file but are labeled as belonging to the project.\nThis helps in cleaning up any services that might have been started independently but are considered part of the project.\n\n'''\n+++\n\n+++"
  },
  "919": {
    "source_file": "build-a-python-app-with-pyinstaller.txt",
    "text": "layout: documentation\ntitle: Build a Python app with PyInstaller\nsection: doc\n\n\nThis tutorial shows you how to use Jenkins to orchestrate building a simple\nPython application with https://www.pyinstaller.org/[PyInstaller].\n\nIf you are a Python developer who is new to CI/CD concepts, or you might be\nfamiliar with these concepts but don't know how to implement building your\napplication using Jenkins"
  },
  "920": {
    "source_file": "build-a-python-app-with-pyinstaller.txt",
    "text": "per who is new to CI/CD concepts, or you might be\nfamiliar with these concepts but don't know how to implement building your\napplication using Jenkins, then this tutorial is for you.\n\nThe simple Python application (which you'll obtain from a sample repository on\nGitHub) is a command line tool \"add2vals\" that outputs the addition of two\nvalues.\nIf at least one of the values is a string, \"add2vals\" "
  },
  "921": {
    "source_file": "build-a-python-app-with-pyinstaller.txt",
    "text": "epository on\nGitHub) is a command line tool \"add2vals\" that outputs the addition of two\nvalues.\nIf at least one of the values is a string, \"add2vals\" instead treats both values\nas a string and concatenates the values.\nThe \"add2\" function in the \"calc\" library (which \"add2vals\" imports) is accompanied by a set of unit tests.\nThese are tested with pytest to check that this function works as expected"
  },
  "922": {
    "source_file": "build-a-python-app-with-pyinstaller.txt",
    "text": "\" library (which \"add2vals\" imports) is accompanied by a set of unit tests.\nThese are tested with pytest to check that this function works as expected and\nthe results are saved to a JUnit XML report.\n\nThe delivery of the \"add2vals\" tool through PyInstaller converts this tool into\na standalone executable file for Linux, which you can download through Jenkins\nand execute at the command line on Linux"
  },
  "923": {
    "source_file": "build-a-python-app-with-pyinstaller.txt",
    "text": "taller converts this tool into\na standalone executable file for Linux, which you can download through Jenkins\nand execute at the command line on Linux machines without Python.\n\n*Duration:* This tutorial takes 20-40 minutes to complete (assuming you've\nalready met the <<prerequisites,prerequisites>> below). The exact duration will\ndepend on the speed of your machine and network.\n\nYou can stop this "
  },
  "924": {
    "source_file": "build-a-python-app-with-pyinstaller.txt",
    "text": "e\nalready met the <<prerequisites,prerequisites>> below). The exact duration will\ndepend on the speed of your machine and network.\n\nYou can stop this tutorial at any point in time and continue from where you left\noff.\n\nIf you've already run though , you can skip the\n<<prerequisites,Prerequisites>> section below and proceed on to <<fork-sample-repository,forking the\nsample repository>>. (Just ensur"
  },
  "925": {
    "source_file": "build-a-python-app-with-pyinstaller.txt",
    "text": "you can skip the\n<<prerequisites,Prerequisites>> section below and proceed on to <<fork-sample-repository,forking the\nsample repository>>. (Just ensure you have\n installed locally.) If you need to\nrestart Jenkins, simply follow the restart instructions in\n<<stopping-and-restarting-jenkins,Stopping and restarting Jenkins>> and then\nproceed on.\n\n**  and optionally\n\n[[fork-sample-repository]]\n[[fork-"
  },
  "926": {
    "source_file": "build-a-python-app-with-pyinstaller.txt",
    "text": "ns in\n<<stopping-and-restarting-jenkins,Stopping and restarting Jenkins>> and then\nproceed on.\n\n**  and optionally\n\n[[fork-sample-repository]]\n[[fork-and-clone-the-sample-repository-on-github]]\n\nObtain the simple \"add\" Python application from GitHub, by forking the sample\nrepository of the application's source code into your own GitHub account and\nthen cloning this fork locally.\n\nEnsure you are si"
  },
  "927": {
    "source_file": "build-a-python-app-with-pyinstaller.txt",
    "text": " by forking the sample\nrepository of the application's source code into your own GitHub account and\nthen cloning this fork locally.\n\nEnsure you are signed in to your GitHub account.\nIf you don't yet have a GitHub account, sign up for a free one on the .\nFork the\n on GitHub into your local GitHub account.\nIf you need help with this process, refer to the  documentation on the GitHub website for more"
  },
  "928": {
    "source_file": "build-a-python-app-with-pyinstaller.txt",
    "text": "e .\nFork the\n on GitHub into your local GitHub account.\nIf you need help with this process, refer to the  documentation on the GitHub website for more information.\nClone your forked `simple-python-pyinstaller-app` repository (on GitHub)locally to your machine.\nTo begin this process, do either of the following (where `<your-username>` is the name of your user account on your operating system):\n** I"
  },
  "929": {
    "source_file": "build-a-python-app-with-pyinstaller.txt",
    "text": "r machine.\nTo begin this process, do either of the following (where `<your-username>` is the name of your user account on your operating system):\n** If you have the GitHub Desktop app installed on your machine:\n.. In GitHub, click the green *Code* button on your forked repository, then *Open in Desktop*.\n.. In GitHub Desktop, before clicking *Clone* on the *Clone a Repository* dialog box, ensure *"
  },
  "930": {
    "source_file": "build-a-python-app-with-pyinstaller.txt",
    "text": "tton on your forked repository, then *Open in Desktop*.\n.. In GitHub Desktop, before clicking *Clone* on the *Clone a Repository* dialog box, ensure *Local Path* for:\n*** macOS is `/Users/<your-username>/Documents/GitHub/simple-python-pyinstaller-app`\n*** Linux is `/home/<your-username>/GitHub/simple-python-pyinstaller-app`\n*** Windows is `C:\\Users\\<your-username>\\Documents\\GitHub\\simple-python-py"
  },
  "931": {
    "source_file": "build-a-python-app-with-pyinstaller.txt",
    "text": "`\n*** Linux is `/home/<your-username>/GitHub/simple-python-pyinstaller-app`\n*** Windows is `C:\\Users\\<your-username>\\Documents\\GitHub\\simple-python-pyinstaller-app`\n** Otherwise:\n.. Open up a terminal/command line prompt and `cd` to the appropriate directory on:\n*** macOS - `/Users/<your-username>/Documents/GitHub/`\n*** Linux - `/home/<your-username>/GitHub/`\n*** Windows - `C:\\Users\\<your-username"
  },
  "932": {
    "source_file": "build-a-python-app-with-pyinstaller.txt",
    "text": "irectory on:\n*** macOS - `/Users/<your-username>/Documents/GitHub/`\n*** Linux - `/home/<your-username>/GitHub/`\n*** Windows - `C:\\Users\\<your-username>\\Documents\\GitHub\\` (although use a Git bash command line window as opposed to the usual Microsoft command prompt)\n.. Run the following command to continue/complete cloning your forked repo: +\n   `git clone https://github.com/YOUR-GITHUB-ACCOUNT-NAM"
  },
  "933": {
    "source_file": "build-a-python-app-with-pyinstaller.txt",
    "text": "command prompt)\n.. Run the following command to continue/complete cloning your forked repo: +\n   `git clone https://github.com/YOUR-GITHUB-ACCOUNT-NAME/simple-python-pyinstaller-app` +\n   where `YOUR-GITHUB-ACCOUNT-NAME` is the name of your GitHub account.\n\n1. Obtain the latest Jenkins LTS deployment, customized for this tutorial, by cloning the .\n2. After cloning, navigate to the `quickstart-tuto"
  },
  "934": {
    "source_file": "build-a-python-app-with-pyinstaller.txt",
    "text": "count.\n\n1. Obtain the latest Jenkins LTS deployment, customized for this tutorial, by cloning the .\n2. After cloning, navigate to the `quickstart-tutorials` directory, and execute the command\ndocker compose --profile python up -d\n\nto run the example.\n3. Once the containers (one for the controller, one for the agent) are running successfully (you can verify this with `docker compose ps`), the contr"
  },
  "935": {
    "source_file": "build-a-python-app-with-pyinstaller.txt",
    "text": "\n3. Once the containers (one for the controller, one for the agent) are running successfully (you can verify this with `docker compose ps`), the controller can be accessed at http://localhost:8080.\n\nIf you are unable to install `docker compose` on your machine for any reason, you can still run the example in the cloud for free using either:\n\n* *GitHub Codespaces* (Recommended): Click the *Code* bu"
  },
  "936": {
    "source_file": "build-a-python-app-with-pyinstaller.txt",
    "text": "ur machine for any reason, you can still run the example in the cloud for free using either:\n\n* *GitHub Codespaces* (Recommended): Click the *Code* button in the , select *Codespaces*, then *Create codespace on master*.\nGitHub Codespaces provides .\nOnce the Codespace starts, the setup will run automatically, and you'll see a welcome message with instructions.\n\n* *GitPod*: Click on  to open a GitPo"
  },
  "937": {
    "source_file": "build-a-python-app-with-pyinstaller.txt",
    "text": "nce the Codespace starts, the setup will run automatically, and you'll see a welcome message with instructions.\n\n* *GitPod*: Click on  to open a GitPod workspace.\nGitPod .\nYou need to link it to your GitHub account.\n\nNow, log in using the `admin` username and `admin` password.\n\nIn Jenkins, select *New Item* under *Dashboard >* at the top left.\nEnter your new Pipeline project name in *Enter an item"
  },
  "938": {
    "source_file": "build-a-python-app-with-pyinstaller.txt",
    "text": "rname and `admin` password.\n\nIn Jenkins, select *New Item* under *Dashboard >* at the top left.\nEnter your new Pipeline project name in *Enter an item name* (e.g. `simple-python-pyinstaller-app`).\nScroll down if necessary and select *Pipeline*, then click *OK* at the end of the page.\n(Optional) Enter a Pipeline *Description*.\nSelect *Pipeline* on the left pane.\nSelect *Definition*, and then choose"
  },
  "939": {
    "source_file": "build-a-python-app-with-pyinstaller.txt",
    "text": "click *OK* at the end of the page.\n(Optional) Enter a Pipeline *Description*.\nSelect *Pipeline* on the left pane.\nSelect *Definition*, and then choose the *Pipeline script from SCM* option.\nThis option instructs Jenkins to obtain your Pipeline from the source control management (SCM), which is your forked Git repository.\nChoose *Git* from the options in *SCM*.\nEnter the URL of your repository in *"
  },
  "940": {
    "source_file": "build-a-python-app-with-pyinstaller.txt",
    "text": "he source control management (SCM), which is your forked Git repository.\nChoose *Git* from the options in *SCM*.\nEnter the URL of your repository in *Repositories/Repository URL*.\nThis URL can be found when clicking on the green button *Code* in the main page of your GitHub repo.\nHit the *Save* button at the end of the page.\nYou're now ready to create a `Jenkinsfile` to check into your locally clo"
  },
  "941": {
    "source_file": "build-a-python-app-with-pyinstaller.txt",
    "text": "main page of your GitHub repo.\nHit the *Save* button at the end of the page.\nYou're now ready to create a `Jenkinsfile` to check into your locally cloned Git repository.\n\nYou're now ready to create your Pipeline that will automate building your Python application with PyInstaller in Jenkins.\nYour Pipeline will be created as a `Jenkinsfile`, which will be committed to your locally cloned Git reposi"
  },
  "942": {
    "source_file": "build-a-python-app-with-pyinstaller.txt",
    "text": "n application with PyInstaller in Jenkins.\nYour Pipeline will be created as a `Jenkinsfile`, which will be committed to your locally cloned Git repository (`simple-python-pyinstaller-app`), and then pushed to GitHub, where Jenkins will be able to find it.\n\nThis is the foundation of \"Pipeline-as-Code\", which treats the continuous delivery pipeline as part of the application to be versioned and revi"
  },
  "943": {
    "source_file": "build-a-python-app-with-pyinstaller.txt",
    "text": "d it.\n\nThis is the foundation of \"Pipeline-as-Code\", which treats the continuous delivery pipeline as part of the application to be versioned and reviewed like any other code.\nRead more about Pipeline and what a Jenkinsfile is in the  and  sections of the User Handbook.\n\nFirst, create an initial Pipeline with a \"Build\" stage that executes the first part of the entire production process for your ap"
  },
  "944": {
    "source_file": "build-a-python-app-with-pyinstaller.txt",
    "text": "f the User Handbook.\n\nFirst, create an initial Pipeline with a \"Build\" stage that executes the first part of the entire production process for your application.\nThis \"Build\" stage compiles your simple Python application into byte code.\n\nUsing your favorite text editor or IDE, create and save a new text file with the name `Jenkinsfile` at the root of your local `simple-python-pyinstaller-app` Git r"
  },
  "945": {
    "source_file": "build-a-python-app-with-pyinstaller.txt",
    "text": "vorite text editor or IDE, create and save a new text file with the name `Jenkinsfile` at the root of your local `simple-python-pyinstaller-app` Git repository.\nCopy the following Declarative Pipeline code and paste it into your empty `Jenkinsfile`:\npipeline {\n    agent any // <1> stages {\n        stage('Build') { // <2> steps {\n                sh 'python -m py_compile sources/add2vals.py sources/"
  },
  "946": {
    "source_file": "build-a-python-app-with-pyinstaller.txt",
    "text": "pipeline {\n    agent any // <1> stages {\n        stage('Build') { // <2> steps {\n                sh 'python -m py_compile sources/add2vals.py sources/calc.py' // <3> stash(name: 'compiled-results', includes: 'sources/*.py*') // <4> }\n        }\n    }\n}\n\n<1> The  section with the `any`\nparameter specified at the top of this Pipeline code block means that any agent could be allocated for the entire P"
  },
  "947": {
    "source_file": "build-a-python-app-with-pyinstaller.txt",
    "text": "}\n\n<1> The  section with the `any`\nparameter specified at the top of this Pipeline code block means that any agent could be allocated for the entire Pipeline's execution and that each\n directive does not have to specify its own `agent` section.\n<2> Defines a  (directive) called\n`Build` that appears on the Jenkins UI.\n<3> This\n\nstep (of the  section) runs the\nPython command to compile your applicat"
  },
  "948": {
    "source_file": "build-a-python-app-with-pyinstaller.txt",
    "text": "efines a  (directive) called\n`Build` that appears on the Jenkins UI.\n<3> This\n\nstep (of the  section) runs the\nPython command to compile your application and its `calc` library into byte code\nfiles (each with `.pyc` extension), which are placed into the `sources`\nworkspace directory (within the\n`/var/jenkins_home/workspace/simple-python-pyinstaller-app` directory in the\nJenkins container).\n<4> Thi"
  },
  "949": {
    "source_file": "build-a-python-app-with-pyinstaller.txt",
    "text": "the `sources`\nworkspace directory (within the\n`/var/jenkins_home/workspace/simple-python-pyinstaller-app` directory in the\nJenkins container).\n<4> This\n\nstep (of the  section) saves\nthe Python source code and compiled byte code files (with `.pyc` extension) from the `sources`\nworkspace directory for use in later stages.\nSave your edited `Jenkinsfile` and commit it to your local\n  `simple-python-py"
  },
  "950": {
    "source_file": "build-a-python-app-with-pyinstaller.txt",
    "text": "ension) from the `sources`\nworkspace directory for use in later stages.\nSave your edited `Jenkinsfile` and commit it to your local\n  `simple-python-pyinstaller-app` Git repository. E.g. Within the\n  `simple-python-pyinstaller-app` directory, run the commands: +\n  `git add .` +\n  then +\n  `git commit -m \"Add initial Jenkinsfile\"` +\nand in the end +\n  `git push`\n\nIn Jenkins, select *Build Now* on th"
  },
  "951": {
    "source_file": "build-a-python-app-with-pyinstaller.txt",
    "text": "commands: +\n  `git add .` +\n  then +\n  `git commit -m \"Add initial Jenkinsfile\"` +\nand in the end +\n  `git push`\n\nIn Jenkins, select *Build Now* on the left pane.\nAfter making a clone of your local `simple-python-pyinstaller-app` Git repository itself, Jenkins:\n.. Initially queues the project to be run on the agent.\n.. Runs the `Build` stage defined in the `Jenkinsfile` on the agent.\nYou should no"
  },
  "952": {
    "source_file": "build-a-python-app-with-pyinstaller.txt",
    "text": "f, Jenkins:\n.. Initially queues the project to be run on the agent.\n.. Runs the `Build` stage defined in the `Jenkinsfile` on the agent.\nYou should now see on the left a green check mark and #1, indicating that your first Pipeline has run successfully.\nYou should also see in the main part of the page a *Stage View* of your Pipeline, which shows the `Build` stage run, indicating that your first Pip"
  },
  "953": {
    "source_file": "build-a-python-app-with-pyinstaller.txt",
    "text": "y.\nYou should also see in the main part of the page a *Stage View* of your Pipeline, which shows the `Build` stage run, indicating that your first Pipeline has run successfully.\n[.boxshadow]\n\nYou can now click on *#1* to see the details of the build.\nYou will then see how much time the build took waiting in the queue and how much time it took to run.\n\n[.boxshadow]\n\nOn the left, you can click on *P"
  },
  "954": {
    "source_file": "build-a-python-app-with-pyinstaller.txt",
    "text": "\nYou will then see how much time the build took waiting in the queue and how much time it took to run.\n\n[.boxshadow]\n\nOn the left, you can click on *Pipeline Overview* to see the stages of the Pipeline.\n[.boxshadow]\n\nIf you click on the *Build* stage, you will see more information about the stage, including the output of the `python` command if you click on the green `python` section.\n[.boxshadow]"
  },
  "955": {
    "source_file": "build-a-python-app-with-pyinstaller.txt",
    "text": ", you will see more information about the stage, including the output of the `python` command if you click on the green `python` section.\n[.boxshadow]\n\nYou can now click on *simple-python-pyinstaller-app* (if that's the name you chose for your pipeline) on the top left to return to your pipeline main page.\n\nGo back to your text editor/IDE and ensure your `Jenkinsfile` is open.\nCopy and paste the f"
  },
  "956": {
    "source_file": "build-a-python-app-with-pyinstaller.txt",
    "text": "ne) on the top left to return to your pipeline main page.\n\nGo back to your text editor/IDE and ensure your `Jenkinsfile` is open.\nCopy and paste the following Declarative Pipeline syntax immediately under the\n  `Build` stage of your `Jenkinsfile`:\nstage('Test') {\n            steps {\n                sh 'py.test --junit-xml test-reports/results.xml sources/test_calc.py'\n            }\n            pos"
  },
  "957": {
    "source_file": "build-a-python-app-with-pyinstaller.txt",
    "text": "age('Test') {\n            steps {\n                sh 'py.test --junit-xml test-reports/results.xml sources/test_calc.py'\n            }\n            post {\n                always {\n                    junit 'test-reports/results.xml'\n                }\n            }\n        }\n\nso that you end up with:\npipeline {\n    agent any\n    stages {\n        stage('Build') {\n            steps {\n                s"
  },
  "958": {
    "source_file": "build-a-python-app-with-pyinstaller.txt",
    "text": "            }\n        }\n\nso that you end up with:\npipeline {\n    agent any\n    stages {\n        stage('Build') {\n            steps {\n                sh 'python -m py_compile sources/add2vals.py sources/calc.py'\n                stash(name: 'compiled-results', includes: 'sources/*.py*')\n            }\n        }\n        stage('Test') { // <1> steps {\n                sh 'py.test --junit-xml test-report"
  },
  "959": {
    "source_file": "build-a-python-app-with-pyinstaller.txt",
    "text": "esults', includes: 'sources/*.py*')\n            }\n        }\n        stage('Test') { // <1> steps {\n                sh 'py.test --junit-xml test-reports/results.xml sources/test_calc.py' // <2> }\n            post {\n                always {\n                    junit 'test-reports/results.xml' // <3> }\n            }\n        }\n    }\n}\n\n<1> Defines a  (directive) called `Test` that appears on the Jenki"
  },
  "960": {
    "source_file": "build-a-python-app-with-pyinstaller.txt",
    "text": "         junit 'test-reports/results.xml' // <3> }\n            }\n        }\n    }\n}\n\n<1> Defines a  (directive) called `Test` that appears on the Jenkins UI.\n<2> This  step (of the  section) executes pytest's `py.test` command on `sources/test_calc.py`, which runs a set of unit tests (defined in `test_calc.py`) on the \"calc\" library's `add2` function (used by your simple Python application `add2val"
  },
  "961": {
    "source_file": "build-a-python-app-with-pyinstaller.txt",
    "text": "`, which runs a set of unit tests (defined in `test_calc.py`) on the \"calc\" library's `add2` function (used by your simple Python application `add2vals`).\nThe:\n* `--junit-xml test-reports/results.xml` option makes `py.test` generate a JUnit\n  XML report, which is saved to `test-reports/results.xml` (within the\n  `/var/jenkins_home/workspace/simple-python-pyinstaller-app` directory in Jenkins).\n<3>"
  },
  "962": {
    "source_file": "build-a-python-app-with-pyinstaller.txt",
    "text": "ort, which is saved to `test-reports/results.xml` (within the\n  `/var/jenkins_home/workspace/simple-python-pyinstaller-app` directory in Jenkins).\n<3> This\n\nstep (provided by the ) archives the\nJUnit XML report (generated by the `py.test` command above) and exposes the\nresults through the Jenkins interface. The\n section's `always` condition that\ncontains this `junit` step ensures that the step is "
  },
  "963": {
    "source_file": "build-a-python-app-with-pyinstaller.txt",
    "text": "ve) and exposes the\nresults through the Jenkins interface. The\n section's `always` condition that\ncontains this `junit` step ensures that the step is _always_ executed _at the\ncompletion_ of the `Test` stage, regardless of the stage's outcome.\nSave your edited `Jenkinsfile` and commit it to your local\n  `simple-python-pyinstaller-app` Git repository. E.g. Within the\n  `simple-python-pyinstaller-ap"
  },
  "964": {
    "source_file": "build-a-python-app-with-pyinstaller.txt",
    "text": "our edited `Jenkinsfile` and commit it to your local\n  `simple-python-pyinstaller-app` Git repository. E.g. Within the\n  `simple-python-pyinstaller-app` directory, run the commands: +\n  `git add .` +\n  then +\n  `git commit -m \"Add 'Test' stage\"`\nand in the end +\n`git push`\n\nIn Jenkins, navigate back to the *Dashboard* if necessary, then *simple-python-pyinstaller-app* and launch another build than"
  },
  "965": {
    "source_file": "build-a-python-app-with-pyinstaller.txt",
    "text": "in the end +\n`git push`\n\nIn Jenkins, navigate back to the *Dashboard* if necessary, then *simple-python-pyinstaller-app* and launch another build thanks to *Build Now*.\nAfter a while, you should see a new column labeled *Test* appear in the *Stage View*.\n\n[.boxshadow]\n\nYou can click on *#2* or on the number representing your last build on the left, under *Build History*. You will then see the deta"
  },
  "966": {
    "source_file": "build-a-python-app-with-pyinstaller.txt",
    "text": "ew*.\n\n[.boxshadow]\n\nYou can click on *#2* or on the number representing your last build on the left, under *Build History*. You will then see the details of the build.\nYou can now select *Pipeline Overview* to see the stages of the Pipeline.\n[.boxshadow]\n\nNotice the additional \"Test\" stage.\nYou can select the \"Test\" stage checkmark to access the output from that stage.\n[.boxshadow]\n\nGo back to you"
  },
  "967": {
    "source_file": "build-a-python-app-with-pyinstaller.txt",
    "text": "dow]\n\nNotice the additional \"Test\" stage.\nYou can select the \"Test\" stage checkmark to access the output from that stage.\n[.boxshadow]\n\nGo back to your text editor/IDE and ensure your `Jenkinsfile` is open.\nCopy and paste the following Declarative Pipeline syntax immediately under the\n  `Test` stage of your `Jenkinsfile`:\nstage('Deliver') {\n            steps {\n                sh \"pyinstaller --one"
  },
  "968": {
    "source_file": "build-a-python-app-with-pyinstaller.txt",
    "text": "peline syntax immediately under the\n  `Test` stage of your `Jenkinsfile`:\nstage('Deliver') {\n            steps {\n                sh \"pyinstaller --onefile sources/add2vals.py\"\n            }\n            post {\n                success {\n                    archiveArtifacts 'dist/add2vals'\n                }\n            }\n        }\n\nand add a `skipStagesAfterUnstable` option so that you end up with:\np"
  },
  "969": {
    "source_file": "build-a-python-app-with-pyinstaller.txt",
    "text": "     archiveArtifacts 'dist/add2vals'\n                }\n            }\n        }\n\nand add a `skipStagesAfterUnstable` option so that you end up with:\npipeline {\n    agent any\n    options {\n        skipStagesAfterUnstable()\n    }\n    stages {\n        stage('Build') {\n            steps {\n                sh 'python -m py_compile sources/add2vals.py sources/calc.py'\n                stash(name: 'compile"
  },
  "970": {
    "source_file": "build-a-python-app-with-pyinstaller.txt",
    "text": "tage('Build') {\n            steps {\n                sh 'python -m py_compile sources/add2vals.py sources/calc.py'\n                stash(name: 'compiled-results', includes: 'sources/*.py*')\n            }\n        }\n        stage('Test') {\n            steps {\n                sh 'py.test --junit-xml test-reports/results.xml sources/test_calc.py'\n            }\n            post {\n                always "
  },
  "971": {
    "source_file": "build-a-python-app-with-pyinstaller.txt",
    "text": "teps {\n                sh 'py.test --junit-xml test-reports/results.xml sources/test_calc.py'\n            }\n            post {\n                always {\n                    junit 'test-reports/results.xml'\n                }\n            }\n        }\n        stage('Deliver') { // <1> steps {\n                sh \"pyinstaller --onefile sources/add2vals.py\" // <2> }\n            post {\n                succ"
  },
  "972": {
    "source_file": "build-a-python-app-with-pyinstaller.txt",
    "text": "     stage('Deliver') { // <1> steps {\n                sh \"pyinstaller --onefile sources/add2vals.py\" // <2> }\n            post {\n                success {\n                    archiveArtifacts 'dist/add2vals' // <3> }\n            }\n        }\n    }\n}\n\n<1> Defines a  (directive) called `Deliver` that appears on the Jenkins UI.\n<2> This  step (of the  section) executes the `pyinstaller` command on yo"
  },
  "973": {
    "source_file": "build-a-python-app-with-pyinstaller.txt",
    "text": "\n<1> Defines a  (directive) called `Deliver` that appears on the Jenkins UI.\n<2> This  step (of the  section) executes the `pyinstaller` command on your simple Python application.\nThis bundles your `add2vals.py` Python application into a single standalone executable file (via the `--onefile` option) and outputs this file to the `dist` workspace directory (within the Jenkins home directory).\nAlthou"
  },
  "974": {
    "source_file": "build-a-python-app-with-pyinstaller.txt",
    "text": "alone executable file (via the `--onefile` option) and outputs this file to the `dist` workspace directory (within the Jenkins home directory).\nAlthough this step consists of a single command, as a general principle, it's a good idea to keep your Pipeline code (i.e. the `Jenkinsfile`) as tidy as possible and place more complex build steps (particularly for stages consisting of 2 or more steps) int"
  },
  "975": {
    "source_file": "build-a-python-app-with-pyinstaller.txt",
    "text": "eline code (i.e. the `Jenkinsfile`) as tidy as possible and place more complex build steps (particularly for stages consisting of 2 or more steps) into separate shell script files.\nThis ultimately makes maintaining your Pipeline code easier, especially if your Pipeline gains more complexity.\n<3> This  step (provided as part of Jenkins core) archives the standalone executable file (generated by the"
  },
  "976": {
    "source_file": "build-a-python-app-with-pyinstaller.txt",
    "text": "ly if your Pipeline gains more complexity.\n<3> This  step (provided as part of Jenkins core) archives the standalone executable file (generated by the `pyinstaller` command above at `dist/add2vals` within the Jenkins home's workspace directory) and exposes this file through the Jenkins interface.\nThe  section's `success` condition that contains this `archiveArtifacts` step ensures that the step is"
  },
  "977": {
    "source_file": "build-a-python-app-with-pyinstaller.txt",
    "text": "xposes this file through the Jenkins interface.\nThe  section's `success` condition that contains this `archiveArtifacts` step ensures that the step is executed _at the completion_ of the `Deliver` stage _only if_ this stage completed successfully.\nSave your edited `Jenkinsfile` and commit it to your local\n  `simple-python-pyinstaller-app` Git repository. E.g. Within the\n  `simple-python-pyinstalle"
  },
  "978": {
    "source_file": "build-a-python-app-with-pyinstaller.txt",
    "text": "ve your edited `Jenkinsfile` and commit it to your local\n  `simple-python-pyinstaller-app` Git repository. E.g. Within the\n  `simple-python-pyinstaller-app` directory, run the commands: +\n  `git add .` +\n  then +\n  `git commit -m \"Add 'Deliver' stage\"` +\nand in the end +\n`git push`\n\nIn Jenkins, sign in if necessary, and go back to the *Dashboard* and then *simple-python-pyinstaller-app* or go dire"
  },
  "979": {
    "source_file": "build-a-python-app-with-pyinstaller.txt",
    "text": "\"` +\nand in the end +\n`git push`\n\nIn Jenkins, sign in if necessary, and go back to the *Dashboard* and then *simple-python-pyinstaller-app* or go directly to *simple-python-pyinstaller-app* depending on where you're starting from.\nSelect *Build Now* on the left.\nAfter a while, you should see a new column labeled *Deliver* appear in the *Stage View*.\n[.boxshadow]\n\nYou can click on *#3* or on the nu"
  },
  "980": {
    "source_file": "build-a-python-app-with-pyinstaller.txt",
    "text": "on the left.\nAfter a while, you should see a new column labeled *Deliver* appear in the *Stage View*.\n[.boxshadow]\n\nYou can click on *#3* or on the number representing your last build, in the left pane under *Build History* to see the details of the build.\n\nYou can now click on *Pipeline Overview* to see the stages of the Pipeline.\nOnce you click on the *Deliver* green checkmark, and then on the f"
  },
  "981": {
    "source_file": "build-a-python-app-with-pyinstaller.txt",
    "text": "build.\n\nYou can now click on *Pipeline Overview* to see the stages of the Pipeline.\nOnce you click on the *Deliver* green checkmark, and then on the first green section, the output should be something like below, showing you the results of PyInstaller bundling your Python application into a single standalone executable file.\n[.boxshadow]\n\nYou can now click on *simple-python-pyinstaller-app* on the"
  },
  "982": {
    "source_file": "build-a-python-app-with-pyinstaller.txt",
    "text": "r bundling your Python application into a single standalone executable file.\n[.boxshadow]\n\nYou can now click on *simple-python-pyinstaller-app* on the top left, and then on *Stages* at the left. It will list your previous Pipeline runs in reverse chronological order.\n[.boxshadow]\n\nIf you use Linux, you can try running the standalone `add2vals` application you\ngenerated with PyInstaller locally on "
  },
  "983": {
    "source_file": "build-a-python-app-with-pyinstaller.txt",
    "text": "onological order.\n[.boxshadow]\n\nIf you use Linux, you can try running the standalone `add2vals` application you\ngenerated with PyInstaller locally on your machine. To do this:\n\nAccess the *Stage View* interface (found after clicking on *Dashboard* *>* *simple-python-pyinstaller-app* or directly on *simple-python-pyinstaller-app* if it's accessible).\nYou should see a *Last Successful Artifacts* sec"
  },
  "984": {
    "source_file": "build-a-python-app-with-pyinstaller.txt",
    "text": "* *simple-python-pyinstaller-app* or directly on *simple-python-pyinstaller-app* if it's accessible).\nYou should see a *Last Successful Artifacts* section on top of *Stage View*.\n[.boxshadow]\n\nYou should then see a *add2vals* link in the *Last Successful Artifacts* section.\nClick the link to download the standalone executable file to your browser's \"Downloads\" directory.\nBack in your operating sys"
  },
  "985": {
    "source_file": "build-a-python-app-with-pyinstaller.txt",
    "text": "sful Artifacts* section.\nClick the link to download the standalone executable file to your browser's \"Downloads\" directory.\nBack in your operating system's terminal prompt, `cd` to your browser's \"Downloads\" directory.\nMake the `add2vals` file executable - i.e. `chmod a+x add2vals`\nRun the command `./add2vals` and follow the instructions provided by your app.\n\nWell done! You've just used Jenkins t"
  },
  "986": {
    "source_file": "build-a-python-app-with-pyinstaller.txt",
    "text": "able - i.e. `chmod a+x add2vals`\nRun the command `./add2vals` and follow the instructions provided by your app.\n\nWell done! You've just used Jenkins to build a simple Python application!\n\nThe \"Build\", \"Test\" and \"Deliver\" stages you created above are the basis for building more complex Python applications in Jenkins, as well as Python applications that integrate with other technology stacks.\n\nBeca"
  },
  "987": {
    "source_file": "build-a-python-app-with-pyinstaller.txt",
    "text": " the basis for building more complex Python applications in Jenkins, as well as Python applications that integrate with other technology stacks.\n\nBecause Jenkins is extremely extensible, it can be modified and configured to handle practically any aspect of build orchestration and automation.\n\nTo learn more about what Jenkins can do, check out:\n\n* The  page for other introductory\n  tutorials.\n* The"
  },
  "988": {
    "source_file": "build-a-python-app-with-pyinstaller.txt",
    "text": "ect of build orchestration and automation.\n\nTo learn more about what Jenkins can do, check out:\n\n* The  page for other introductory\n  tutorials.\n* The  for more detailed information about using\n  Jenkins, such as  (in particular\n  ) and the\n   interface.\n* The  for the latest events, other tutorials and\n  updates.\n\nAfter completing the tutorial, it's important to clean up your environment to preve"
  },
  "989": {
    "source_file": "build-a-python-app-with-pyinstaller.txt",
    "text": "ace.\n* The  for the latest events, other tutorials and\n  updates.\n\nAfter completing the tutorial, it's important to clean up your environment to prevent interference with other tutorials you might try later.\n\nTo stop the containers and remove associated volumes:\n\ndocker compose --profile python down -v --remove-orphans\n\nThis command ensures a clean slate for your next project.\n\nThe `--remove-orpha"
  },
  "990": {
    "source_file": "build-a-python-app-with-pyinstaller.txt",
    "text": "ted volumes:\n\ndocker compose --profile python down -v --remove-orphans\n\nThis command ensures a clean slate for your next project.\n\nThe `--remove-orphans` option instructs Docker Compose to remove any containers that are not defined in the `docker-compose.yml` file but are labeled as belonging to the project.\nThis helps in cleaning up any services that might have been started independently but are "
  },
  "991": {
    "source_file": "build-a-python-app-with-pyinstaller.txt",
    "text": "pose.yml` file but are labeled as belonging to the project.\nThis helps in cleaning up any services that might have been started independently but are considered part of the project.\n\n'''\n+++\n\n+++"
  },
  "992": {
    "source_file": "build-authorization.txt",
    "text": "layout: redirect\nredirect_url: \"/doc/book/security/build-authorization/\""
  },
  "993": {
    "source_file": "build-process.txt",
    "text": "layout: developersection\ntitle: Plugin Build Process\nreferences:\n- url: ../updating-parent/\n  title: Guide to Updating Your Maven Parent POM\n- url: https://github.com/jenkinsci/plugin-pom/\n  title: Plugin parent POM 2.x and up\n- url: https://github.com/jenkinsci/maven-hpi-plugin/\n  title: Maven HPI Plugin\n\n\nMost Jenkins plugins are built with .\nThey typically use the  as their parent , which provi"
  },
  "994": {
    "source_file": "build-process.txt",
    "text": "om/jenkinsci/maven-hpi-plugin/\n  title: Maven HPI Plugin\n\n\nMost Jenkins plugins are built with .\nThey typically use the  as their parent , which provides a sensible default configuration for the plugin build.\nThe  is one of the plugins configured there.\nIt does the heavy lifting, such as bundling plugins in the HPI/JPI archive format used for Jenkins plugins, or allowing developers to run a debug "
  },
  "995": {
    "source_file": "build-process.txt",
    "text": "re.\nIt does the heavy lifting, such as bundling plugins in the HPI/JPI archive format used for Jenkins plugins, or allowing developers to run a debug Jenkins controller with the plugin.\n\nSince version 2.0 of the plugin POM, it's possible to specify the core version dependency of the parent POM independent of its version.footnote:[Up to Jenkins 1.645, the plugin POM was kept in sync with Jenkins re"
  },
  "996": {
    "source_file": "build-process.txt",
    "text": "he core version dependency of the parent POM independent of its version.footnote:[Up to Jenkins 1.645, the plugin POM was kept in sync with Jenkins releases, so that the minimum required Jenkins version for a plugin determined the versions of the tools used to build the plugin. These versions should no longer be used.]\nThis allows plugins compatible with older Jenkins releases to benefit from fixe"
  },
  "997": {
    "source_file": "build-process.txt",
    "text": "ls used to build the plugin. These versions should no longer be used.]\nThis allows plugins compatible with older Jenkins releases to benefit from fixes and improvements in the parent POM.\nThe  provides more details.\n\nIt is generally recommended to frequently update to a recent plugin parent POM for multiple reasons:\n\n* Plugin developers and users benefit from bug fixes and improvements to the pare"
  },
  "998": {
    "source_file": "build-process.txt",
    "text": "equently update to a recent plugin parent POM for multiple reasons:\n\n* Plugin developers and users benefit from bug fixes and improvements to the parent POM and the tools and libraries it specifies\n* Additions to the default build like static code analysis and general tests aim to improve the overall quality of plugins.\n// TODO Need a good reference for that before including it as example:\n// For "
  },
  "999": {
    "source_file": "build-process.txt",
    "text": "alysis and general tests aim to improve the overall quality of plugins.\n// TODO Need a good reference for that before including it as example:\n// For example, plugins depending on the plugins parent POM 1.637 (with maven-hpi-plugin 1.110) or newer will need to specify the <code>escape-by-default</code> in all Jelly files for the InjectedTest to pass. Plugins depending on older releases may have hi"
  },
  "1000": {
    "source_file": "build-process.txt",
    "text": "ll need to specify the <code>escape-by-default</code> in all Jelly files for the InjectedTest to pass. Plugins depending on older releases may have hidden XSS vulnerabilities.\n* Recent versions of the tools (inherited from the parent plugins POM) allow developers to use more advanced tools like the https://github.com/jenkinsci/plugin-compat-tester[plugin compatibility tester] to determine whether "
  },
  "1001": {
    "source_file": "build-process.txt",
    "text": "ow developers to use more advanced tools like the https://github.com/jenkinsci/plugin-compat-tester[plugin compatibility tester] to determine whether their plugin is compatible with newest Jenkins releases.\n\nThe  includes a step to , along with an associated ."
  },
  "1002": {
    "source_file": "build-process.txt",
    "text": "sociated ."
  },
  "1003": {
    "source_file": "building-a-java-app-with-maven.txt",
    "text": "layout: redirect\nredirect_url: ../build-a-java-app-with-maven"
  },
  "1004": {
    "source_file": "building-a-multibranch-pipeline-project.txt",
    "text": "layout: redirect\nredirect_url: ../build-a-multibranch-pipeline-project"
  },
  "1005": {
    "source_file": "building-a-node-js-and-react-app-with-npm.txt",
    "text": "layout: redirect\nredirect_url: ../build-a-node-js-and-react-app-with-npm"
  },
  "1006": {
    "source_file": "built-in-node-migration.txt",
    "text": "layout: documentation\ntitle: Built-In Node Name and Label Migration"
  },
  "1007": {
    "source_file": "casc.txt",
    "text": "title: Configuration as Code\nlayout: section\n\n\nThe Jenkins Configuration as Code (JCasC) feature defines Jenkins configuration parameters\nin a human-readable YAML file that can be stored as source code.\nThis essentially captures the configuration parameters and values that are used when configuring Jenkins from the web UI.\nThe configuration can then be modified by editing this file and then applyi"
  },
  "1008": {
    "source_file": "casc.txt",
    "text": "ameters and values that are used when configuring Jenkins from the web UI.\nThe configuration can then be modified by editing this file and then applying it.\n\nTraditionally, experienced Jenkins administrators\ncreated Apache Groovy `init` scripts\nto automate the configuration for their Jenkins controllers.\nThis works but requires in-depth understanding of Jenkins APIs\nand the ability to write Groovy"
  },
  "1009": {
    "source_file": "casc.txt",
    "text": "tomate the configuration for their Jenkins controllers.\nThis works but requires in-depth understanding of Jenkins APIs\nand the ability to write Groovy scripts.\nSuch scripts are powerful and can do almost anything,\nbut they also provide few protections against configuration errors.\n\nJCasC provides the convenience and flexibility\nof configuring controllers without using the UI.\nIt does not require m"
  },
  "1010": {
    "source_file": "casc.txt",
    "text": "s against configuration errors.\n\nJCasC provides the convenience and flexibility\nof configuring controllers without using the UI.\nIt does not require more understanding of the configuration parameters\nthan is required to configure Jenkins through the UI\nand it provides some checks on the values that are provided.\n\nThe JCasC configuration file can be checked into an SCM,\nwhich enables you to determi"
  },
  "1011": {
    "source_file": "casc.txt",
    "text": "UI\nand it provides some checks on the values that are provided.\n\nThe JCasC configuration file can be checked into an SCM,\nwhich enables you to determine who made what modifications to the configuration\nand to roll back to a previous configuration if necessary.\n\nThe\n plugin\nmust be installed on the Jenkins controller\nthat you will use to build out your JCasC configuration.\nIf you do not see the *Co"
  },
  "1012": {
    "source_file": "casc.txt",
    "text": "necessary.\n\nThe\n plugin\nmust be installed on the Jenkins controller\nthat you will use to build out your JCasC configuration.\nIf you do not see the *Configuration as Code* tile\nin the *System Configuration* section\nof the *Manage Jenkins* page on your dashboard,\nyou need to install the plugin.\n\nWhen the Configuration as Code plugin is installed,\nyou will see *Configuration as Code* in the *System C"
  },
  "1013": {
    "source_file": "casc.txt",
    "text": " dashboard,\nyou need to install the plugin.\n\nWhen the Configuration as Code plugin is installed,\nyou will see *Configuration as Code* in the *System Configuration* section\nof the *Manage Jenkins* page on your dashboard.\nClick on this link,\nthen click on *View Configuration*\nto view the YAML file.\n\nThis file is an export of the current configuration on this controller.\nIn most cases, it is ready to"
  },
  "1014": {
    "source_file": "casc.txt",
    "text": " on *View Configuration*\nto view the YAML file.\n\nThis file is an export of the current configuration on this controller.\nIn most cases, it is ready to use without modification\nalthough you usually want to customize it before deploying it.\nYou may want to push the unmodified version to SCM\nso you have it as part of your history.\n\nThe *Configuration as Code* UI page shows the full pathname of the YA"
  },
  "1015": {
    "source_file": "casc.txt",
    "text": "t to push the unmodified version to SCM\nso you have it as part of your history.\n\nThe *Configuration as Code* UI page shows the full pathname of the YAML file being used\nand gives a box where you can specify a different file to use.\nSee the information below about how to modify the location used for JCasC YAML files.\n\nThe default JCasC YAML file has four sections:\n\n* `jenkins` section defines the r"
  },
  "1016": {
    "source_file": "casc.txt",
    "text": "n below about how to modify the location used for JCasC YAML files.\n\nThe default JCasC YAML file has four sections:\n\n* `jenkins` section defines the root Jenkins object,\nwith configurations that can be set with the\n*Manage Jenkins >> System*\nand *Manage Jenkins >> Configure Nodes and Clouds* screens.\n\n* `tool` section defines build tools that can be set on the\n*Manage Jenkins >> Tools* screen.\n\n* "
  },
  "1017": {
    "source_file": "casc.txt",
    "text": "age Jenkins >> Configure Nodes and Clouds* screens.\n\n* `tool` section defines build tools that can be set on the\n*Manage Jenkins >> Tools* screen.\n\n* `unclassified` section defines all other configurations,\nincluding configuration for installed plugins.\n\n* `credentials` section defines credentials that can be set on the\n*Manage Jenkins >> Manage Credentials* screen.\nYou may want to delete this sec"
  },
  "1018": {
    "source_file": "casc.txt",
    "text": "ns.\n\n* `credentials` section defines credentials that can be set on the\n*Manage Jenkins >> Manage Credentials* screen.\nYou may want to delete this section from your YAML file;\nthis is discussed in\nJCasC defines the controller configuration in a YAML file.\nYAML is a popular serialization language for configuration information,\nwith a syntax that is straight-forward and easy to read but precise.\n\nSo"
  },
  "1019": {
    "source_file": "casc.txt",
    "text": "file.\nYAML is a popular serialization language for configuration information,\nwith a syntax that is straight-forward and easy to read but precise.\n\nSome key points about YAML syntax:\n\n* YAML files are case sensitive.\n* Indentation is very significant and specific.\n* Each item is a key/value pair.\n** The key is followed by a colon (`:`) and a space.\n** YAML converts certain strings into other types"
  },
  "1020": {
    "source_file": "casc.txt",
    "text": " and specific.\n* Each item is a key/value pair.\n** The key is followed by a colon (`:`) and a space.\n** YAML converts certain strings into other types unless they are in quotes.\n*** Values such as `true`, `false`, `Yes`, and `No` are converted to Boolean values.\n*** Values such as `2` and `3.0` are converted to floating point values.\n* A value can be a list:\n** Each list item is on a separate line"
  },
  "1021": {
    "source_file": "casc.txt",
    "text": "lean values.\n*** Values such as `2` and `3.0` are converted to floating point values.\n* A value can be a list:\n** Each list item is on a separate line starting with a dash (`-`).\n** Each list item in the file must start at the same indentation.\n*** Use spaces, never tabs, for indentation.\n** Never leave a blank line in a YAML file -- things will break!\n\nSee the\n\nfor more details about YAML file sy"
  },
  "1022": {
    "source_file": "casc.txt",
    "text": "se spaces, never tabs, for indentation.\n** Never leave a blank line in a YAML file -- things will break!\n\nSee the\n\nfor more details about YAML file syntax.\n\nTo get the maximum benefit of JCasC, the YAML files should be stored in SCM.\nThis gives you a history that you can use to trace changes that are made\nand allow you to easily roll back to an earlier version of the file if necessary.\n\nJCasC does"
  },
  "1023": {
    "source_file": "casc.txt",
    "text": " history that you can use to trace changes that are made\nand allow you to easily roll back to an earlier version of the file if necessary.\n\nJCasC does not require that the file be stored in SCM\nand so does not enforce any rules about how you do this.\nThe most common practice is to create one SCM repository\nin which you store all of your JCasC files.\n\nIf you are storing your JCasC YAML files in SCM"
  },
  "1024": {
    "source_file": "casc.txt",
    "text": "\nThe most common practice is to create one SCM repository\nin which you store all of your JCasC files.\n\nIf you are storing your JCasC YAML files in SCM,\nyou should commit the first default file that is generated,\nbefore you make any modifications to the file.\n\nTo modify the JCasC YAML file,\nuse the text editor of your choice to edit the file\nthat is listed on the *Manage Jenkins >> Configuration as"
  },
  "1025": {
    "source_file": "casc.txt",
    "text": "he file.\n\nTo modify the JCasC YAML file,\nuse the text editor of your choice to edit the file\nthat is listed on the *Manage Jenkins >> Configuration as Code* UI page.\nBy default, this is _$JENKINS_HOME/jenkins.yaml_.\n\nFor a simple exercise to work through the process,\nyou can modify the value of the \"System Message\"\nthat is displayed on the Jenkins dashboard.\n\nOpen the JCasC YAML file with the text"
  },
  "1026": {
    "source_file": "casc.txt",
    "text": "ough the process,\nyou can modify the value of the \"System Message\"\nthat is displayed on the Jenkins dashboard.\n\nOpen the JCasC YAML file with the text editor of your choice.\nFind the `systemMessage` line near the top of the file:\njenkins:\n  systemMessage: \"Jenkins configured automatically by Jenkins Configuration as Code plugin\\n\\n\"\n\nModify the text between the quotation marks to contain your new "
  },
  "1027": {
    "source_file": "casc.txt",
    "text": "sage: \"Jenkins configured automatically by Jenkins Configuration as Code plugin\\n\\n\"\n\nModify the text between the quotation marks to contain your new text\nWrite/save the file\nClick the *Reload existing configuration* button to apply the changes\nView the modified \"System Message\" on your dashboard\n\nIt is not necessary to restart Jenkins to apply the JCasC changes,\nalthough you should try to restart"
  },
  "1028": {
    "source_file": "casc.txt",
    "text": "the modified \"System Message\" on your dashboard\n\nIt is not necessary to restart Jenkins to apply the JCasC changes,\nalthough you should try to restart Jenkins with the modifications\nbefore you check the modified YAML file into SCM,\nespecially when making more substantive configuration changes.\n\nWhen you have made and tested your desired changes,\npush the modified JCasC YAML file to your SCM.\n\nTo c"
  },
  "1029": {
    "source_file": "casc.txt",
    "text": "king more substantive configuration changes.\n\nWhen you have made and tested your desired changes,\npush the modified JCasC YAML file to your SCM.\n\nTo configure a plugin with JCasC:\n\nUse the UI of the current system to install and configure the plugin\nClick *Apply >> Save* to save the configuration\nUse *Manage Jenkins >> Configuration as Code >> View Configuration*\nto view the JCasC file with the pl"
  },
  "1030": {
    "source_file": "casc.txt",
    "text": "Click *Apply >> Save* to save the configuration\nUse *Manage Jenkins >> Configuration as Code >> View Configuration*\nto view the JCasC file with the plugin configured\nClick on *Download Configuration*  to save the modified configuration file locally\nEdit the JCasC YAML file to modify the configuration, if necessary\nSave the file\nClick *Reload existing configuration* to load the local changes onto t"
  },
  "1031": {
    "source_file": "casc.txt",
    "text": "dit the JCasC YAML file to modify the configuration, if necessary\nSave the file\nClick *Reload existing configuration* to load the local changes onto the Jenkins server\nVerify the changes on the UI\nWhen you have thoroughly tested the plugin configuration,\npush the modified YAML file to your SCM\n\nSee the\n\nblog for detailed instructions\nand an embedded video demonstration of this process.\n\nBy default"
  },
  "1032": {
    "source_file": "casc.txt",
    "text": "ion,\npush the modified YAML file to your SCM\n\nSee the\n\nblog for detailed instructions\nand an embedded video demonstration of this process.\n\nBy default, the YAML file for the CasC configuration\nis located in `$JENKINS_HOME/jenkins.yaml`.\nThe location and name of the file being used is displayed\non the *Configuration as Code* UI page.\nYou can specify a different file to view by typing the full pathn"
  },
  "1033": {
    "source_file": "casc.txt",
    "text": "and name of the file being used is displayed\non the *Configuration as Code* UI page.\nYou can specify a different file to view by typing the full pathname\ninto the *Path or URL* field.\n\nYou can specify a different location or a different file name\nfor the creation of the JCasC YAML file by doing either of the following:\n\n* Populate the `CASC_JENKINS_CONFIG` environment variable to point to\na comma-"
  },
  "1034": {
    "source_file": "casc.txt",
    "text": " the creation of the JCasC YAML file by doing either of the following:\n\n* Populate the `CASC_JENKINS_CONFIG` environment variable to point to\na comma-separated list that defines where configuration files are located.\n\n* Use the `casc.jenkins.config` Java property to control the file name and location.\nThis is useful when installing Jenkins via a package management tool.\nMost package management sys"
  },
  "1035": {
    "source_file": "casc.txt",
    "text": "Java property to control the file name and location.\nThis is useful when installing Jenkins via a package management tool.\nMost package management systems support configuration files that are retained across upgrades.\nIt is best to not modify a file installed by a package manager\nbecause it could be overwritten by an update.\nOn Linux systems, you can run `systemctl edit jenkins` and add the follow"
  },
  "1036": {
    "source_file": "casc.txt",
    "text": "installed by a package manager\nbecause it could be overwritten by an update.\nOn Linux systems, you can run `systemctl edit jenkins` and add the following:\n[Service]\nEnvironment=\"JAVA_OPTS=-Dcasc.jenkins.config=/jenkins/casc_configs\"\n\nThe file location and name can be specified as any of the following:\n\n* Path to a folder containing a set of config files such as `/var/jenkins_home/casc_configs`.\n* "
  },
  "1037": {
    "source_file": "casc.txt",
    "text": "n and name can be specified as any of the following:\n\n* Path to a folder containing a set of config files such as `/var/jenkins_home/casc_configs`.\n* A full path to a single file such as `/var/jenkins_home/casc_configs/jenkins.yaml`.\n* A URL pointing to a file served on the web such as `https://acme.org/jenkins.yaml`.\n\nThe value of the `CASC_JENKINS_CONFIG` variable is unpacked\naccording to the fo"
  },
  "1038": {
    "source_file": "casc.txt",
    "text": " to a file served on the web such as `https://acme.org/jenkins.yaml`.\n\nThe value of the `CASC_JENKINS_CONFIG` variable is unpacked\naccording to the following rules:\n\n* If an element of `CASC_JENKINS_CONFIG` points to a folder,\nthe plugin recursively traverses the folder to find file(s)\nwith the .yml, .yaml, .YAML, or .YML suffix.\n\n* It excludes hidden files or files that contain a hidden folder\n(s"
  },
  "1039": {
    "source_file": "casc.txt",
    "text": "traverses the folder to find file(s)\nwith the .yml, .yaml, .YAML, or .YML suffix.\n\n* It excludes hidden files or files that contain a hidden folder\n(such as/ `jenkins/casc_configs/.dir1/config.yaml`)\nin **any part** of the full path.\n\n* It follows symbolic links for both files and directories.\n\n* The order of traversal does not matter to the final outcome\nbecause all configuration files that are d"
  },
  "1040": {
    "source_file": "casc.txt",
    "text": "mbolic links for both files and directories.\n\n* The order of traversal does not matter to the final outcome\nbecause all configuration files that are discovered MUST be supplementary.\nIf a file attempts to overwrite configuration values from another file,\nit creates a conflict and raises a `ConfiguratorException`.\n\nConfiguration for a Jenkins controller should be implemented\neither with CasC or wit"
  },
  "1041": {
    "source_file": "casc.txt",
    "text": "ile,\nit creates a conflict and raises a `ConfiguratorException`.\n\nConfiguration for a Jenkins controller should be implemented\neither with CasC or with the UI, but not by both.\nThe system allows administrators to modify configuration options on the UI\neven when they were configured by CasC,\nbut these modifications are overwritten the next time the controller restarts.\n\nYou can install the\n,\nwhich "
  },
  "1042": {
    "source_file": "casc.txt",
    "text": "I\neven when they were configured by CasC,\nbut these modifications are overwritten the next time the controller restarts.\n\nYou can install the\n,\nwhich allows you to grant read-only access to configuration parameters to users.\nSee\n\nfor more details.\n\nA small group of administrators may have write access to the UI configuration fields.\nThey should understand that JCasC will overwrite changes they mak"
  },
  "1043": {
    "source_file": "casc.txt",
    "text": " small group of administrators may have write access to the UI configuration fields.\nThey should understand that JCasC will overwrite changes they make on the UI.\n\n*\nis a video of the 2018 DevOps World presentation\nthat introduced the JCasC feature.\n\n*\nis a blog post with video that demonstrates how to configure a plugin with JCasC.\n\n*  is a video presentation with details about using JCasC.\n\nMuch"
  },
  "1044": {
    "source_file": "casc.txt",
    "text": "\n*\nis a blog post with video that demonstrates how to configure a plugin with JCasC.\n\n*  is a video presentation with details about using JCasC.\n\nMuch of the detailed JCasC documentation is provided in the\n**\n\n* The\n\ndirectory contains sample _*.yaml_ files for configuring specific Jenkins components and plugins,\nwith a _README_ file in each directory that describes the configurations for that com"
  },
  "1045": {
    "source_file": "casc.txt",
    "text": "_ files for configuring specific Jenkins components and plugins,\nwith a _README_ file in each directory that describes the configurations for that component.\n\n*\n\n*\n\n*\n\n*\n\n**  for JCasC\n\n**"
  },
  "1046": {
    "source_file": "Cause-getShortDescription.txt",
    "text": "title: Redefinition of Cause#getShortDescription\nlayout: developer\n\n\nThe `Cause#getShortDescription` method was defined to return a \"one line\" short snippet of HTML in Jenkins 2.314 and earlier, LTS 2.303.1 and earlier.\nTo prevent further security vulnerabilities like  from having an impact on Jenkins users, the method has been redefined to return plain text in Jenkins 2.315 and LTS 2.303.2, and i"
  },
  "1047": {
    "source_file": "Cause-getShortDescription.txt",
    "text": "lnerabilities like  from having an impact on Jenkins users, the method has been redefined to return plain text in Jenkins 2.315 and LTS 2.303.2, and its output is no longer rendered as HTML on the UI.\n\nIf an implementation of `#getShortDescription` returns a string that includes user-specified content, plugin maintainers are advised to consider both the behavior of older and newer Jenkins releases"
  },
  "1048": {
    "source_file": "Cause-getShortDescription.txt",
    "text": "eturns a string that includes user-specified content, plugin maintainers are advised to consider both the behavior of older and newer Jenkins releases if their plugin can be used on Jenkins 2.314 and earlier.\n\"User content\" in this case refers to any dynamic content that is specified locally or provided by another system that Jenkins integrates with and is not guaranteed to be safe to interpret as"
  },
  "1049": {
    "source_file": "Cause-getShortDescription.txt",
    "text": " dynamic content that is specified locally or provided by another system that Jenkins integrates with and is not guaranteed to be safe to interpret as HTML.\n\nNo HTML intended, does not contain user content::\nThis is safe to use and no adaptation to the new behavior of Jenkins is necessary.\n\nHTML intended, does not contain user content::\nThis is safe to use, but will need to be adapted to the new b"
  },
  "1050": {
    "source_file": "Cause-getShortDescription.txt",
    "text": "he new behavior of Jenkins is necessary.\n\nHTML intended, does not contain user content::\nThis is safe to use, but will need to be adapted to the new behavior of Jenkins, otherwise the UI will render escaped HTML tags.\nDefine a custom `description.jelly` file that renders HTML, and return plain text content from `#getShortDescription`.\n\nNo HTML intended, contains user content::\nThis is likely unsaf"
  },
  "1051": {
    "source_file": "Cause-getShortDescription.txt",
    "text": "ly` file that renders HTML, and return plain text content from `#getShortDescription`.\n\nNo HTML intended, contains user content::\nThis is likely unsafe in older Jenkins releases if users are able to inject HTML.\nPlease  to the Jenkins security team.\n\nHTML intended, contains user content::\nThis may or may not be safe in older Jenkins releases, depending on whether user content is specifically escap"
  },
  "1052": {
    "source_file": "Cause-getShortDescription.txt",
    "text": "\nHTML intended, contains user content::\nThis may or may not be safe in older Jenkins releases, depending on whether user content is specifically escaped.\nDefine a custom `description.jelly` file that renders HTML, and return plain text content from `#getShortDescription`.\nBe mindful of user content rendered as part of `#getShortDescription` intending to be plain text, but which would still be rend"
  },
  "1053": {
    "source_file": "Cause-getShortDescription.txt",
    "text": "#getShortDescription`.\nBe mindful of user content rendered as part of `#getShortDescription` intending to be plain text, but which would still be rendered as HTML in Jenkins 2.314 and earlier, 2.303.1 and earlier."
  },
  "1054": {
    "source_file": "change-system-timezone.txt",
    "text": "layout: section\ntitle: Change System Time Zone\n\n\nifdef::env-github[:imagesdir: ../resources]\nifndef::env-github[:imagesdir: ../../resources]\n\nThe system time zone configuration is the default time zone displayed by Jenkins.\nThe \"Manage Jenkins\" => \"System Information\" page shows the value of the system properties that define the time zone for the Jenkins controller.\n\nRefer to the following video f"
  },
  "1055": {
    "source_file": "change-system-timezone.txt",
    "text": "ystem Information\" page shows the value of the system properties that define the time zone for the Jenkins controller.\n\nRefer to the following video for tips on changing the time zone\n\n.Changing the time zone in Jenkins\nvideo::4UmY4dDAlo0[youtube,width=800,height=420]\n\nA user defined time zone for the account can be set from the *Account* option in the user settings.\n\n{empty}\n\nIt is automatically "
  },
  "1056": {
    "source_file": "change-system-timezone.txt",
    "text": "th=800,height=420]\n\nA user defined time zone for the account can be set from the *Account* option in the user settings.\n\n{empty}\n\nIt is automatically set to the system default, but can be changed to match any country or time zone as desired.\n\n{empty}\n\nIf you cannot change the time zone of your server, you can force jelly to use a given time zone for formatting time stamps.\n\nYou need to start your "
  },
  "1057": {
    "source_file": "change-system-timezone.txt",
    "text": "\n\nIf you cannot change the time zone of your server, you can force jelly to use a given time zone for formatting time stamps.\n\nYou need to start your Jenkins with the following java system property:\n\njava -Dorg.apache.commons.jelly.tags.fmt.timeZone=TZ ...\n\nwhere TZ is a java.util.TimeZone ID (\"Europe/Paris\" for example).\n\n_Note that `+user.timezone=Europe/Paris+` will work as well, but it can int"
  },
  "1058": {
    "source_file": "change-system-timezone.txt",
    "text": "TZ ...\n\nwhere TZ is a java.util.TimeZone ID (\"Europe/Paris\" for example).\n\n_Note that `+user.timezone=Europe/Paris+` will work as well, but it can interfere with other contexts._\n\nIf running Jenkins via a Linux package, this can be accomplished\nby running `systemctl edit jenkins` and adding the following:\n\n[Service]\nEnvironment=\"JAVA_OPTS=-Dorg.apache.commons.jelly.tags.fmt.timeZone=America/New_Yo"
  },
  "1059": {
    "source_file": "change-system-timezone.txt",
    "text": "nning `systemctl edit jenkins` and adding the following:\n\n[Service]\nEnvironment=\"JAVA_OPTS=-Dorg.apache.commons.jelly.tags.fmt.timeZone=America/New_York\"\n\nor, if that doesn't work:\n\n[Service]\nEnvironment=\"JAVA_OPTS=-Duser.timezone=America/New_York\"\n\nOn FreeBSD, the file to edit is /etc/rc.conf, and the option to use is:\n\njenkins_java_opts=\"-Dorg.apache.commons.jelly.tags.fmt.timeZone=America/Denve"
  },
  "1060": {
    "source_file": "change-system-timezone.txt",
    "text": "On FreeBSD, the file to edit is /etc/rc.conf, and the option to use is:\n\njenkins_java_opts=\"-Dorg.apache.commons.jelly.tags.fmt.timeZone=America/Denver\"\n\nOn windows, edit `%INSTALL_PATH%/jenkins/jenkins.xml`. Put `-Dargs` before `-jar`:\n\n<arguments>-Duser.timezone=\"Europe/Minsk\" -jar \"%BASE%\\jenkins.war\"</arguments>\n\nYou can also set it from the  on a live system without the need for a restart.\nTh"
  },
  "1061": {
    "source_file": "change-system-timezone.txt",
    "text": "Duser.timezone=\"Europe/Minsk\" -jar \"%BASE%\\jenkins.war\"</arguments>\n\nYou can also set it from the  on a live system without the need for a restart.\nThis can also be included in a  to make it permanent.\n\nSystem.setProperty('org.apache.commons.jelly.tags.fmt.timeZone', 'America/New_York')"
  },
  "1062": {
    "source_file": "change-system-timezone.txt",
    "text": "gs.fmt.timeZone', 'America/New_York')"
  },
  "1063": {
    "source_file": "change-time-zone.txt",
    "text": "layout: section\ntitle: Change time zone\n\n\nifdef::env-github[:imagesdir: ../resources]\nifndef::env-github[:imagesdir: ../../resources]\n\nIf your Jenkins controller is running in a different location than your own (for example: the server is in NY but you are in LA), then the NY time zone will most probably be used.\nThis may be quite annoying if you need to compare build dates.\n\nTo see the time zone "
  },
  "1064": {
    "source_file": "change-time-zone.txt",
    "text": "ou are in LA), then the NY time zone will most probably be used.\nThis may be quite annoying if you need to compare build dates.\n\nTo see the time zone currently set, go to `jenkins_server/systemInfo` and see the `+user.timezone+` system property.\n\n[.boxshadow]\n\nYou may want to change the time zone displayed to match your own time zone. By going to your user configuration page, you can set the `User"
  },
  "1065": {
    "source_file": "change-time-zone.txt",
    "text": "oxshadow]\n\nYou may want to change the time zone displayed to match your own time zone. By going to your user configuration page, you can set the `User Defined Time Zone` to match your own.\n\n[.boxshadow]"
  },
  "1066": {
    "source_file": "choosing-jenkins-baseline.txt",
    "text": "layout: developersection\ntitle: Choosing a Jenkins version to build against\n\n\nYour plugin's POM controls which version of Jenkins it is building/testing against.\n\n## Choosing a version\n\nYou need to balance compatibility and features:\n\n* *Keeping the Jenkins version your plugin builds against low* will allow more users to install and use your plugin.\nIn particular, the LTS Release Line is based on "
  },
  "1067": {
    "source_file": "choosing-jenkins-baseline.txt",
    "text": "Jenkins version your plugin builds against low* will allow more users to install and use your plugin.\nIn particular, the LTS Release Line is based on slightly older releases to provide a more stable experience for conservative users.\n* *Building against recent Jenkins versions* allows you to use recently added core features and API from your plugin.\nYou will also use that newer version for `mvn hp"
  },
  "1068": {
    "source_file": "choosing-jenkins-baseline.txt",
    "text": "nst recent Jenkins versions* allows you to use recently added core features and API from your plugin.\nYou will also use that newer version for `mvn hpi:run`, so it may be easier to test your plugin with newer Jenkins releases.\n* *Do not use versions no longer supported by the update center*, which is currently anything older than 2.481 for weekly releases, and 2.462.3 for LTS releases.\n  Note that"
  },
  "1069": {
    "source_file": "choosing-jenkins-baseline.txt",
    "text": "no longer supported by the update center*, which is currently anything older than 2.481 for weekly releases, and 2.462.3 for LTS releases.\n  Note that the lowest supported version changes about every week (weekly release) or every month (LTS release), so these specific versions will be a bad choice soon.\n* *Prefer an LTS version over weekly versions.*\n** If you are based on the _currently active_ "
  },
  "1070": {
    "source_file": "choosing-jenkins-baseline.txt",
    "text": ", so these specific versions will be a bad choice soon.\n* *Prefer an LTS version over weekly versions.*\n** If you are based on the _currently active_ LTS line,\n   try to stay on the first release in that line (2.xxx.1) unless you have a specific reason to depend on a subsequent micro release\n   (such as a need to test against a recently released security fix).\n** If you are based on a _historical_"
  },
  "1071": {
    "source_file": "choosing-jenkins-baseline.txt",
    "text": "on to depend on a subsequent micro release\n   (such as a need to test against a recently released security fix).\n** If you are based on a _historical_ LTS line (at least one release in a newer line has been published),\n   prefer to depend on the last release in that line (typically 2.xxx.3).\n* *Prefer releases that result in few or no implied plugin dependencies*.\n  Sometimes Jenkins core features"
  },
  "1072": {
    "source_file": "choosing-jenkins-baseline.txt",
    "text": " release in that line (typically 2.xxx.3).\n* *Prefer releases that result in few or no implied plugin dependencies*.\n  Sometimes Jenkins core features are moved into plugins, and any plugin with a dependency on an older core release will have an _implied_ dependency on the new plugin.\n  This makes plugin management more difficult for administrators, so core dependencies should ideally be chosen so"
  },
  "1073": {
    "source_file": "choosing-jenkins-baseline.txt",
    "text": "lied_ dependency on the new plugin.\n  This makes plugin management more difficult for administrators, so core dependencies should ideally be chosen so that there are no, or few, implied dependencies.\n  See https://github.com/jenkinsci/jenkins/blob/master/core/src/main/resources/jenkins/split-plugins.txt[split-plugins.txt] for details.\n  At this time, a dependency on Jenkins versions *newer than 2."
  },
  "1074": {
    "source_file": "choosing-jenkins-baseline.txt",
    "text": "ster/core/src/main/resources/jenkins/split-plugins.txt[split-plugins.txt] for details.\n  At this time, a dependency on Jenkins versions *newer than 2.356* will not result in such implied dependencies.\n\nThere are  that can help you decide.\nThese are updated monthly.\nWhen updating the core dependency, choose the  that doesn't exclude a majority of your existing users (by requiring a newer Jenkins th"
  },
  "1075": {
    "source_file": "choosing-jenkins-baseline.txt",
    "text": "pdated monthly.\nWhen updating the core dependency, choose the  that doesn't exclude a majority of your existing users (by requiring a newer Jenkins than they have).\n\nNOTE: If you are packaging a pure API library (one that does not depend on Jenkins APIs) then you should ignore newer Jenkins versions and pick an older LTS.\nSomething around 1 year old that does not have too many detached plugins mak"
  },
  "1076": {
    "source_file": "choosing-jenkins-baseline.txt",
    "text": "PIs) then you should ignore newer Jenkins versions and pick an older LTS.\nSomething around 1 year old that does not have too many detached plugins makes a good choice and 2.462.3 would be a reasonable candidate.\n\n## Currently recommended versions\n\nAt the moment, the Jenkins releases *2.504.3 and 2.516.3* make good core dependencies.\nYou could also consider *2.528.1* if there are specific reasons, "
  },
  "1077": {
    "source_file": "choosing-jenkins-baseline.txt",
    "text": " the moment, the Jenkins releases *2.504.3 and 2.516.3* make good core dependencies.\nYou could also consider *2.528.1* if there are specific reasons, like new features, to want something newer.\n\n## Changing the minimum required version\n\nSet the `jenkins.version` property in `pom.xml` to the version you need to depend on.\n\n<properties>\n  <jenkins.version>2.516.3</jenkins.version>\n</properties>"
  },
  "1078": {
    "source_file": "choosing-jenkins-baseline.txt",
    "text": "ins.version` property in `pom.xml` to the version you need to depend on.\n\n<properties>\n  <jenkins.version>2.516.3</jenkins.version>\n</properties>"
  },
  "1079": {
    "source_file": "cli.txt",
    "text": "layout: section\n\n\nifdef::env-github[:imagesdir: ../resources]\nifndef::env-github[:imagesdir: ../../resources]\n\nJenkins has a built-in command line interface that allows users and\nadministrators to access Jenkins from a script or shell environment. This can\nbe convenient for scripting of routine tasks, bulk updates, troubleshooting,\nand more.\n\nThe command line interface can be accessed over SSH or "
  },
  "1080": {
    "source_file": "cli.txt",
    "text": "is can\nbe convenient for scripting of routine tasks, bulk updates, troubleshooting,\nand more.\n\nThe command line interface can be accessed over SSH or with the Jenkins CLI\nclient, a `.jar` file distributed with Jenkins.\n\nThis document assumes Jenkins 2.54 or newer.\nOlder versions of the CLI client are considered insecure and should not be used.\n\nWebSocket support is available when using both server"
  },
  "1081": {
    "source_file": "cli.txt",
    "text": "2.54 or newer.\nOlder versions of the CLI client are considered insecure and should not be used.\n\nWebSocket support is available when using both server and client 2.217 or newer.\n\n[[ssh]]\n\nIn a new Jenkins installation, the SSH service is disabled by default.\nAdministrators may choose to set a specific port or ask Jenkins to pick a random port\nin the <<security#ssh-server, Security>> page.\nIn order"
  },
  "1082": {
    "source_file": "cli.txt",
    "text": "default.\nAdministrators may choose to set a specific port or ask Jenkins to pick a random port\nin the <<security#ssh-server, Security>> page.\nIn order to determine the randomly assigned SSH port,\ninspect the headers returned on a Jenkins URL, for example:\n\n% curl -Lv https://JENKINS_URL/login 2>&1 | grep -i 'x-ssh-endpoint'\n< X-SSH-Endpoint: localhost:53801\n%\n\nWith the random SSH port (`53801` in "
  },
  "1083": {
    "source_file": "cli.txt",
    "text": "mple:\n\n% curl -Lv https://JENKINS_URL/login 2>&1 | grep -i 'x-ssh-endpoint'\n< X-SSH-Endpoint: localhost:53801\n%\n\nWith the random SSH port (`53801` in this example), and <<Authentication>>\nconfigured, any modern SSH client may securely execute CLI commands.\n\nWhichever user is used for authentication with the Jenkins controller must have the\n`Overall/Read` permission in order to _access_ the CLI. Th"
  },
  "1084": {
    "source_file": "cli.txt",
    "text": "mands.\n\nWhichever user is used for authentication with the Jenkins controller must have the\n`Overall/Read` permission in order to _access_ the CLI. The user may require\nadditional permissions depending on the commands executed.\n\nAuthentication in SSH mode relies on\nSSH-based public/private key authentication.\nTo add an SSH public key for the appropriate user, navigate to *Users* under the *Securit"
  },
  "1085": {
    "source_file": "cli.txt",
    "text": " mode relies on\nSSH-based public/private key authentication.\nTo add an SSH public key for the appropriate user, navigate to *Users* under the *Security* section of *Manage Jenkins*, select the user you want to update, and select *icon:lock[] Security*.\n\n{empty}\n\nAlternatively, you can go to `<your_jenkins_url>/user/<jenkins_username>/security`.\nOnce you're on the security settings page, you can pa"
  },
  "1086": {
    "source_file": "cli.txt",
    "text": "*.\n\n{empty}\n\nAlternatively, you can go to `<your_jenkins_url>/user/<jenkins_username>/security`.\nOnce you're on the security settings page, you can paste an SSH public key into the appropriate text area.\n\n{empty}\n\nJenkins has a number of built-in CLI commands which can be found in every\nJenkins environment, such as `build` or `list-jobs`. Plugins may also provide\nCLI commands; in order to determin"
  },
  "1087": {
    "source_file": "cli.txt",
    "text": " commands which can be found in every\nJenkins environment, such as `build` or `list-jobs`. Plugins may also provide\nCLI commands; in order to determine the full list of commands available\nin a given Jenkins environment, execute the CLI `help` command:\n\n% ssh -l kohsuke -p 53801 localhost help\n\nThe following list of commands is not comprehensive, but it is a useful\nstarting point for Jenkins CLI us"
  },
  "1088": {
    "source_file": "cli.txt",
    "text": ":\n\n% ssh -l kohsuke -p 53801 localhost help\n\nThe following list of commands is not comprehensive, but it is a useful\nstarting point for Jenkins CLI usage.\n\nOne of the most common and useful CLI commands is `build`, which allows the\nuser to trigger any job or Pipeline for which they have permission.\n\nThe most basic invocation will simply trigger the job or Pipeline and exit, but\nwith the additional"
  },
  "1089": {
    "source_file": "cli.txt",
    "text": "y job or Pipeline for which they have permission.\n\nThe most basic invocation will simply trigger the job or Pipeline and exit, but\nwith the additional options a user may also pass parameters, poll SCM, or even\nfollow the console output of the triggered build or Pipeline run.\n\n% ssh -l kohsuke -p 53801 localhost help build\n\njava -jar jenkins-cli.jar build JOB [-c] [-f] [-p] [-r N] [-s] [-v] [-w]\nSt"
  },
  "1090": {
    "source_file": "cli.txt",
    "text": "ed build or Pipeline run.\n\n% ssh -l kohsuke -p 53801 localhost help build\n\njava -jar jenkins-cli.jar build JOB [-c] [-f] [-p] [-r N] [-s] [-v] [-w]\nStarts a build, and optionally waits for a completion.  Aside from general\nscripting use, this command can be used to invoke another job from within a\nbuild of one job.  With the -s option, this command changes the exit code based\non the outcome of the"
  },
  "1091": {
    "source_file": "cli.txt",
    "text": " can be used to invoke another job from within a\nbuild of one job.  With the -s option, this command changes the exit code based\non the outcome of the build (exit code 0 indicates a success) and interrupting\nthe command will interrupt the job.  With the -f option, this command changes\nthe exit code based on the outcome of the build (exit code 0 indicates a\nsuccess) however, unlike -s, interrupting"
  },
  "1092": {
    "source_file": "cli.txt",
    "text": "the -f option, this command changes\nthe exit code based on the outcome of the build (exit code 0 indicates a\nsuccess) however, unlike -s, interrupting the command will not interrupt the\njob (exit code 125 indicates the command was interrupted).  With the -c option,\na build will only run if there has been an SCM change.\n JOB : Name of the job to build\n -c  : Check for SCM changes before starting th"
  },
  "1093": {
    "source_file": "cli.txt",
    "text": " the -c option,\na build will only run if there has been an SCM change.\n JOB : Name of the job to build\n -c  : Check for SCM changes before starting the build, and if there's no\n       change, exit without doing a build\n -f  : Follow the build progress. Like -s only interrupts are not passed\n       through to the build.\n -p  : Specify the build parameters in the key=value format.\n -s  : Wait until "
  },
  "1094": {
    "source_file": "cli.txt",
    "text": "s. Like -s only interrupts are not passed\n       through to the build.\n -p  : Specify the build parameters in the key=value format.\n -s  : Wait until the completion/abortion of the command. Interrupts are passed\n       through to the build.\n -v  : Prints out the console output of the build. Use with -s\n -w  : Wait until the start of the command\n% ssh -l kohsuke -p 53801 localhost build build-all-s"
  },
  "1095": {
    "source_file": "cli.txt",
    "text": "ints out the console output of the build. Use with -s\n -w  : Wait until the start of the command\n% ssh -l kohsuke -p 53801 localhost build build-all-software -f -v\nStarted build-all-software #1\nStarted from command line by admin\nBuilding in workspace /tmp/jenkins/workspace/build-all-software\n[build-all-software] /bin/sh -xe /tmp/hudson1100603797526301795.sh\necho hello world\nhello world\nFinished: S"
  },
  "1096": {
    "source_file": "cli.txt",
    "text": " /tmp/jenkins/workspace/build-all-software\n[build-all-software] /bin/sh -xe /tmp/hudson1100603797526301795.sh\necho hello world\nhello world\nFinished: SUCCESS\nCompleted build-all-software #1 : SUCCESS\n%\n\nSimilarly useful is the `console` command, which retrieves the console output\nfor the specified build or Pipeline run. When no build number is provided, the\n`console` command will output the last co"
  },
  "1097": {
    "source_file": "cli.txt",
    "text": " retrieves the console output\nfor the specified build or Pipeline run. When no build number is provided, the\n`console` command will output the last completed build's console output.\n\n% ssh -l kohsuke -p 53801 localhost help console\n\njava -jar jenkins-cli.jar console JOB [BUILD] [-f] [-n N]\nProduces the console output of a specific build to stdout, as if you are doing 'cat build.log'\n JOB   : Name "
  },
  "1098": {
    "source_file": "cli.txt",
    "text": "-cli.jar console JOB [BUILD] [-f] [-n N]\nProduces the console output of a specific build to stdout, as if you are doing 'cat build.log'\n JOB   : Name of the job\n BUILD : Build number or permalink to point to the build. Defaults to the last\n         build\n -f    : If the build is in progress, stay around and append console output as\n         it comes, like 'tail -f'\n -n N  : Display the last N line"
  },
  "1099": {
    "source_file": "cli.txt",
    "text": "uild\n -f    : If the build is in progress, stay around and append console output as\n         it comes, like 'tail -f'\n -n N  : Display the last N lines\n% ssh -l kohsuke -p 53801 localhost console build-all-software\nStarted from command line by kohsuke\nBuilding in workspace /tmp/jenkins/workspace/build-all-software\n[build-all-software] /bin/sh -xe /tmp/hudson1100603797526301795.sh\necho hello world\n"
  },
  "1100": {
    "source_file": "cli.txt",
    "text": "e\nBuilding in workspace /tmp/jenkins/workspace/build-all-software\n[build-all-software] /bin/sh -xe /tmp/hudson1100603797526301795.sh\necho hello world\nyes\nFinished: SUCCESS\n%\n\nThe `who-am-i` command is helpful for listing the current user's credentials\nand permissions available to the user. This can be useful when debugging the\nabsence of CLI commands due to the lack of certain permissions.\n\n% ssh "
  },
  "1101": {
    "source_file": "cli.txt",
    "text": "s\nand permissions available to the user. This can be useful when debugging the\nabsence of CLI commands due to the lack of certain permissions.\n\n% ssh -l kohsuke -p 53801 localhost help who-am-i\n\njava -jar jenkins-cli.jar who-am-i\nReports your credential and permissions.\n% ssh -l kohsuke -p 53801 localhost who-am-i\nAuthenticated as: kohsuke\nAuthorities:\n  authenticated\n%\n\nWhile the SSH-based CLI is"
  },
  "1102": {
    "source_file": "cli.txt",
    "text": "ial and permissions.\n% ssh -l kohsuke -p 53801 localhost who-am-i\nAuthenticated as: kohsuke\nAuthorities:\n  authenticated\n%\n\nWhile the SSH-based CLI is fast and covers most needs, there may be situations where the CLI\nclient distributed with Jenkins is a better fit. For example, the default transport for the CLI client\nis HTTP which means no additional ports need to be opened in a firewall for its\n"
  },
  "1103": {
    "source_file": "cli.txt",
    "text": "s a better fit. For example, the default transport for the CLI client\nis HTTP which means no additional ports need to be opened in a firewall for its\nuse.\n\nBoth SSH and jenkins-cli.jar provide access to a set of commands that lets you interact with Jenkins from a command line, but they have a few differences:\n\n* Jenkins SSH does not require any custom jar file on the client side, making it easier "
  },
  "1104": {
    "source_file": "cli.txt",
    "text": "enkins from a command line, but they have a few differences:\n\n* Jenkins SSH does not require any custom jar file on the client side, making it easier to access Jenkins from a variety of sources\n* SSH client was build to be a generic tool to serve several purposes.\nIt doesn't offer an easy way to do basic things that are common and specific to Jenkins environments.\nUsing the `jenkins-cli.jar` inste"
  },
  "1105": {
    "source_file": "cli.txt",
    "text": "eral purposes.\nIt doesn't offer an easy way to do basic things that are common and specific to Jenkins environments.\nUsing the `jenkins-cli.jar` instead of the ssh client may increase productivity and improve the development experience\n\nThe CLI client can be downloaded directly from a Jenkins controller at the URL\n`/jnlpJars/jenkins-cli.jar`, in effect  `https://JENKINS_URL/jnlpJars/jenkins-cli.ja"
  },
  "1106": {
    "source_file": "cli.txt",
    "text": "t can be downloaded directly from a Jenkins controller at the URL\n`/jnlpJars/jenkins-cli.jar`, in effect  `https://JENKINS_URL/jnlpJars/jenkins-cli.jar`\n\nWhile a CLI `.jar` can be used against different versions of Jenkins, should\nany compatibility issues arise during use, please re-download the latest `.jar`\nfile from the Jenkins controller.\n\nThe general syntax for invoking the client is as follo"
  },
  "1107": {
    "source_file": "cli.txt",
    "text": "ssues arise during use, please re-download the latest `.jar`\nfile from the Jenkins controller.\n\nThe general syntax for invoking the client is as follows:\n\njava -jar jenkins-cli.jar [-s JENKINS_URL] [global options...] command [command options...] [arguments...]\n\nThe `JENKINS_URL` can be specified via the environment variable `$JENKINS_URL`.\nSummaries of other general options can be displayed by ru"
  },
  "1108": {
    "source_file": "cli.txt",
    "text": "guments...]\n\nThe `JENKINS_URL` can be specified via the environment variable `$JENKINS_URL`.\nSummaries of other general options can be displayed by running the client with no arguments at all.\n\nThere are three basic modes in which the client may be used, selectable by global option:\n`-webSocket`, `-http` and `-ssh`.\n\nThis is the default mode, though you may pass the `-webSocket` option explicitly "
  },
  "1109": {
    "source_file": "cli.txt",
    "text": "sed, selectable by global option:\n`-webSocket`, `-http` and `-ssh`.\n\nThis is the default mode, though you may pass the `-webSocket` option explicitly for clarity.\nThe advantage is that a more standard transport is used, avoiding problems with many reverse proxies or the need for special proxy configuration.\n\nStarting from Jenkins 2.391, the default mode is `-webSocket`.\nTo use the HTTP mode, you m"
  },
  "1110": {
    "source_file": "cli.txt",
    "text": "verse proxies or the need for special proxy configuration.\n\nStarting from Jenkins 2.391, the default mode is `-webSocket`.\nTo use the HTTP mode, you must explicitly pass the `-http` option.\n\nAuthentication is preferably with an `-auth` option, which takes a `username:apitoken` argument.\nGet your API token from `/me/configure`:\n\njava -jar jenkins-cli.jar [-s JENKINS_URL] -auth kohsuke:abc1234ffe4a "
  },
  "1111": {
    "source_file": "cli.txt",
    "text": "takes a `username:apitoken` argument.\nGet your API token from `/me/configure`:\n\njava -jar jenkins-cli.jar [-s JENKINS_URL] -auth kohsuke:abc1234ffe4a command ...\n\n(Actual passwords are also accepted, but this is discouraged.)\n\nYou can also precede the argument with `@` to load the same content from a file:\n\njava -jar jenkins-cli.jar [-s JENKINS_URL] -auth @/home/kohsuke/.jenkins-cli command ...\n\n["
  },
  "1112": {
    "source_file": "cli.txt",
    "text": "e argument with `@` to load the same content from a file:\n\njava -jar jenkins-cli.jar [-s JENKINS_URL] -auth @/home/kohsuke/.jenkins-cli command ...\n\n[WARNING]\n\nFor security reasons the use of a file to load the authentication credentials is the recommended authentication way.\n\nAn alternative authentication method is to configure environment variables in a similar way as the `$JENKINS_URL`\nis used."
  },
  "1113": {
    "source_file": "cli.txt",
    "text": "mended authentication way.\n\nAn alternative authentication method is to configure environment variables in a similar way as the `$JENKINS_URL`\nis used.\nThe `username` can be specified via the environment variable `$JENKINS_USER_ID` while the `apitoken` can\nbe specified via the variable `$JENKINS_API_TOKEN`.\nBoth variables have to be set all at once.\n\nexport JENKINS_USER_ID=kohsuke\nexport JENKINS_AP"
  },
  "1114": {
    "source_file": "cli.txt",
    "text": "` can\nbe specified via the variable `$JENKINS_API_TOKEN`.\nBoth variables have to be set all at once.\n\nexport JENKINS_USER_ID=kohsuke\nexport JENKINS_API_TOKEN=abc1234ffe4a\njava -jar jenkins-cli.jar [-s JENKINS_URL] command ...\n\nIn case these environment variables are configured you could still override the authentication method using different\ncredentials with the `-auth` option, which takes prefer"
  },
  "1115": {
    "source_file": "cli.txt",
    "text": "nt variables are configured you could still override the authentication method using different\ncredentials with the `-auth` option, which takes preference over them.\n\nGenerally no special system configuration need be done to enable HTTP-based CLI connections.\nIf you are running Jenkins behind an HTTP(S) reverse proxy,\nensure it does not buffer request or response bodies.\n\n[WARNING]\n\nThis mode is k"
  },
  "1116": {
    "source_file": "cli.txt",
    "text": "nections.\nIf you are running Jenkins behind an HTTP(S) reverse proxy,\nensure it does not buffer request or response bodies.\n\n[WARNING]\n\nThis mode is known to not work reliably or at all when using certain reverse proxies.\nPrefer WebSocket mode.\n\nAuthentication is via SSH keypair.\nYou must select the Jenkins user ID as well:\n\njava -jar jenkins-cli.jar [-s JENKINS_URL] -ssh -user kohsuke command ..."
  },
  "1117": {
    "source_file": "cli.txt",
    "text": "entication is via SSH keypair.\nYou must select the Jenkins user ID as well:\n\njava -jar jenkins-cli.jar [-s JENKINS_URL] -ssh -user kohsuke command ...\n\nIn this mode, the client acts essentially like a native `ssh` command.\n\nBy default the client will try to connect to an SSH port on the same host as is used in the `JENKINS_URL`.\nIf Jenkins is behind an HTTP reverse proxy, this will not generally w"
  },
  "1118": {
    "source_file": "cli.txt",
    "text": " try to connect to an SSH port on the same host as is used in the `JENKINS_URL`.\nIf Jenkins is behind an HTTP reverse proxy, this will not generally work,\nso run Jenkins with the system property `-Dorg.jenkinsci.main.modules.sshd.SSHD.hostName=ACTUALHOST`\nto define a hostname or IP address for the SSH endpoint.\n\nThere are a number of common problems that may be experienced when running the\nCLI cli"
  },
  "1119": {
    "source_file": "cli.txt",
    "text": "HOST`\nto define a hostname or IP address for the SSH endpoint.\n\nThere are a number of common problems that may be experienced when running the\nCLI client.\n\nYou may get the error below and find a log entry just below that concerning `mismatched keys`:\n\norg.apache.sshd.common.SshException: Server key did not validate\n    at org.apache.sshd.client.session.AbstractClientSession.checkKeys(AbstractClien"
  },
  "1120": {
    "source_file": "cli.txt",
    "text": "\n\norg.apache.sshd.common.SshException: Server key did not validate\n    at org.apache.sshd.client.session.AbstractClientSession.checkKeys(AbstractClientSession.java:523)\n    at org.apache.sshd.common.session.helpers.AbstractSession.handleKexMessage(AbstractSession.java:616)\n    ...\n\nThis means your SSH configuration does not recognize the public key presented by the server.\nIt's often the case when"
  },
  "1121": {
    "source_file": "cli.txt",
    "text": "stractSession.java:616)\n    ...\n\nThis means your SSH configuration does not recognize the public key presented by the server.\nIt's often the case when you run Jenkins in dev mode and multiple instances\nof the application are run under the same SSH port over time.\n\nIn a development context, access your `~/.ssh/known_hosts` (or in `C:/Users/<your_name>/.ssh/known_hosts` for Windows)\nand remove the l"
  },
  "1122": {
    "source_file": "cli.txt",
    "text": "rt over time.\n\nIn a development context, access your `~/.ssh/known_hosts` (or in `C:/Users/<your_name>/.ssh/known_hosts` for Windows)\nand remove the line corresponding to your current SSH port (e.g. `[localhost]:3485`).\nIn a production context, check with the Jenkins administrator if the public key of the server changed recently.\nIf so, ask the administrator to do the steps described above.\n\nIf yo"
  },
  "1123": {
    "source_file": "cli.txt",
    "text": " with the Jenkins administrator if the public key of the server changed recently.\nIf so, ask the administrator to do the steps described above.\n\nIf your client displays a stacktrace that looks like:\n\norg.acegisecurity.userdetails.UsernameNotFoundException: <name_you_used>\n    ...\n\nThis means your SSH keys were recognized and validated against the stored users but the username is not valid for the "
  },
  "1124": {
    "source_file": "cli.txt",
    "text": "ption: <name_you_used>\n    ...\n\nThis means your SSH keys were recognized and validated against the stored users but the username is not valid for the security realm your application is using at the moment.\nThis could occur when you were using the Jenkins database initially, configured your users, and then switched to another security realm (like LDAP, etc.) where the defined users do not exist yet"
  },
  "1125": {
    "source_file": "cli.txt",
    "text": "kins database initially, configured your users, and then switched to another security realm (like LDAP, etc.) where the defined users do not exist yet.\n\nTo solve the problem, ensure your users exist in your configured security realm.\n\nTo get more information about the authentication process:\n\nGo into *Manage Jenkins* > *System Log* > *Add new log recorder*.\nEnter any name you want and click on *Ok"
  },
  "1126": {
    "source_file": "cli.txt",
    "text": "ormation about the authentication process:\n\nGo into *Manage Jenkins* > *System Log* > *Add new log recorder*.\nEnter any name you want and click on *Ok*.\nClick on *Add*\nType `org.jenkinsci.main.modules.sshd.PublicKeyAuthenticatorImpl` (or type `PublicKeyAuth` and then select the full name)\nSet the level to *ALL*.\nRepeat the previous three steps for `hudson.model.User`\nClick on *Save*\n\nWhen you try "
  },
  "1127": {
    "source_file": "cli.txt",
    "text": "KeyAuth` and then select the full name)\nSet the level to *ALL*.\nRepeat the previous three steps for `hudson.model.User`\nClick on *Save*\n\nWhen you try to authenticate, you can then refresh the page and see what happen internally."
  },
  "1128": {
    "source_file": "configuring-content-security-policy.txt",
    "text": "layout: redirect\nredirect_url: \"/doc/book/security/configuring-content-security-policy/\""
  },
  "1129": {
    "source_file": "continuous-integration.txt",
    "text": "title: Continuous Integration - buildPlugin\nlayout: developersection\n\n\nThe Jenkins project runs its own Jenkins controller for CI builds on .\nIt will build all plugin repositories in the `jenkinsci` organization that have a `Jenkinsfile` in the root of the repository.\n\nThe typical plugin build (Maven or Gradle) can be run by just having the following statement in the `Jenkinsfile`:\n\nbuildPlugin(\n "
  },
  "1130": {
    "source_file": "continuous-integration.txt",
    "text": "of the repository.\n\nThe typical plugin build (Maven or Gradle) can be run by just having the following statement in the `Jenkinsfile`:\n\nbuildPlugin(\n  forkCount: '1C', // run this number of tests in parallel for faster feedback.  If the number terminates with a 'C', the value will be multiplied by the number of available CPU cores\n  useContainerAgent: true, // Set to `false` if you need to use Doc"
  },
  "1131": {
    "source_file": "continuous-integration.txt",
    "text": "ates with a 'C', the value will be multiplied by the number of available CPU cores\n  useContainerAgent: true, // Set to `false` if you need to use Docker for containerized tests\n  configurations: [\n    [platform: 'linux', jdk: 21],\n    [platform: 'windows', jdk: 17],\n])\n\n'Gradle support in `buildPlugin()` is deprecated and will be eventually removed. Please use:'\n\nbuildPluginWithGradle(\n  forkCoun"
  },
  "1132": {
    "source_file": "continuous-integration.txt",
    "text": "ndows', jdk: 17],\n])\n\n'Gradle support in `buildPlugin()` is deprecated and will be eventually removed. Please use:'\n\nbuildPluginWithGradle(\n  forkCount: '1C', // run this number of tests in parallel for faster feedback.  If the number terminates with a 'C', the value will be multiplied by the number of available CPU cores\n  useContainerAgent: true, // Set to `false` if you need to use Docker for c"
  },
  "1133": {
    "source_file": "continuous-integration.txt",
    "text": " a 'C', the value will be multiplied by the number of available CPU cores\n  useContainerAgent: true, // Set to `false` if you need to use Docker for containerized tests\n  configurations: [\n    [platform: 'linux', jdk: 21],\n    [platform: 'windows', jdk: 17],\n])\n\nNOTE: If the `Jenkinsfile` configuration includes Java 8, you will receive a low-level class version error when using version 4.52 or lat"
  },
  "1134": {
    "source_file": "continuous-integration.txt",
    "text": "dk: 17],\n])\n\nNOTE: If the `Jenkinsfile` configuration includes Java 8, you will receive a low-level class version error when using version 4.52 or later of the plugin parent POM.\n\nTo learn more about the Pipeline library providing this functionality, see https://github.com/jenkins-infra/pipeline-library[its GitHub repository]."
  },
  "1135": {
    "source_file": "continuous-integration.txt",
    "text": " see https://github.com/jenkins-infra/pipeline-library[its GitHub repository]."
  },
  "1136": {
    "source_file": "controller-isolation.txt",
    "text": "title: Controller Isolation\nlayout: section\n\n\nifdef::env-github[:imagesdir: ../resources]\nifndef::env-github[:imagesdir: ../../resources]\n\nWhat exactly happens during a build is often controlled by people less trusted than a Jenkins administrator:\n\n* Jenkins users with Job/Configure permission\n* Build script authors (`pom.xml`, `Makefile`, etc.)\n* Code authors (for example test code executed durin"
  },
  "1137": {
    "source_file": "controller-isolation.txt",
    "text": " Jenkins users with Job/Configure permission\n* Build script authors (`pom.xml`, `Makefile`, etc.)\n* Code authors (for example test code executed during a build)\n\nThey all have some control over commands executed during a build.\n\nTo ensure the stability of the Jenkins controller, builds should be executed on other nodes than the built-in node.\nThis concept is called _distributed builds_ in Jenkins,"
  },
  "1138": {
    "source_file": "controller-isolation.txt",
    "text": "ty of the Jenkins controller, builds should be executed on other nodes than the built-in node.\nThis concept is called _distributed builds_ in Jenkins, and you can learn more about this .\nSetting up distributed builds in Jenkins is a great start for protecting the Jenkins controller from malicious (or just broken) build scripts, but care needs to be taken for protections to be effective.\n\n[CAUTION]"
  },
  "1139": {
    "source_file": "controller-isolation.txt",
    "text": "rotecting the Jenkins controller from malicious (or just broken) build scripts, but care needs to be taken for protections to be effective.\n\n[CAUTION]\n\nMost Jenkins environments grow over time requiring their trust models to evolve as the environment grows. Please consider scheduling regular \"check-ups\" to review whether any disabled security settings should be re-enabled.\n\nOut of the box, Jenkins"
  },
  "1140": {
    "source_file": "controller-isolation.txt",
    "text": " grows. Please consider scheduling regular \"check-ups\" to review whether any disabled security settings should be re-enabled.\n\nOut of the box, Jenkins is set up to run builds on the built-in node.\nThis is to make it easier to get started with Jenkins, but is inadvisable longer term:\nAny builds running on the built-in node have the same level of access to the controller file system as the Jenkins p"
  },
  "1141": {
    "source_file": "controller-isolation.txt",
    "text": ", but is inadvisable longer term:\nAny builds running on the built-in node have the same level of access to the controller file system as the Jenkins process.\n\nIt is therefore highly advisable to not run any builds on the built-in node, instead using agents (statically configured or provided by _clouds_) to run builds.\n\n// TODO Fix this once https://github.com/jenkinsci/jenkins/pull/5425 is merged "
  },
  "1142": {
    "source_file": "controller-isolation.txt",
    "text": "agents (statically configured or provided by _clouds_) to run builds.\n\n// TODO Fix this once https://github.com/jenkinsci/jenkins/pull/5425 is merged and released:\n\nTo prevent builds from running on the built-in node directly, navigate to _Manage Jenkins \u00bb Nodes and Clouds_.\nSelect _Built-In Node_ in the list, then select _Configure_ in the menu.\nSet the number of executors to 0 and save.\nMake sur"
  },
  "1143": {
    "source_file": "controller-isolation.txt",
    "text": "kins \u00bb Nodes and Clouds_.\nSelect _Built-In Node_ in the list, then select _Configure_ in the menu.\nSet the number of executors to 0 and save.\nMake sure to also set up clouds or build agents to run builds on, otherwise builds won't be able to start.\n\nAlternatively, use a plugin such as plugin:job-restrictions[Job Restrictions Plugin] to limit which jobs can be run on certain nodes (like the built-i"
  },
  "1144": {
    "source_file": "controller-isolation.txt",
    "text": "Alternatively, use a plugin such as plugin:job-restrictions[Job Restrictions Plugin] to limit which jobs can be run on certain nodes (like the built-in node), independent of what your less trusted users may use as label expression in their jobs' configurations.\n\nIf you do not have any other computers to run agents on, you can also run an agent process as a different operating system user on the sa"
  },
  "1145": {
    "source_file": "controller-isolation.txt",
    "text": "igurations.\n\nIf you do not have any other computers to run agents on, you can also run an agent process as a different operating system user on the same system to achieve a similar isolation effect.\nIn this case, ensure that the agent process has no file system access (neither read nor write) to the Jenkins home directory, and that the agent process cannot use `sudo` or similar methods to elevate "
  },
  "1146": {
    "source_file": "controller-isolation.txt",
    "text": "file system access (neither read nor write) to the Jenkins home directory, and that the agent process cannot use `sudo` or similar methods to elevate its own permissions.\n\n//== Infrastructure\n// TODO Don't run agents on the same Docker host as the controller etc.\n\nThe Jenkins controller and agents can be thought of as a distributed process which executes across multiple discrete processes and mach"
  },
  "1147": {
    "source_file": "controller-isolation.txt",
    "text": "ntroller etc.\n\nThe Jenkins controller and agents can be thought of as a distributed process which executes across multiple discrete processes and machines.\nThis allows an agent to ask the controller process for information available to it, for example, the contents of files, etc., and even to have the controller run certain commands when requested by the agent.\n\nSo while not building on the built-"
  },
  "1148": {
    "source_file": "controller-isolation.txt",
    "text": "e, the contents of files, etc., and even to have the controller run certain commands when requested by the agent.\n\nSo while not building on the built-in node is a good general practice to protect from bugs and less sophisticated attackers, an agent process taken over by a malicious user would still be able to obtain data or execute commands on the Jenkins controller.\nTo prevent this, the Agent &ra"
  },
  "1149": {
    "source_file": "controller-isolation.txt",
    "text": "rocess taken over by a malicious user would still be able to obtain data or execute commands on the Jenkins controller.\nTo prevent this, the Agent &rarr; Controller Access Control system prevents agent processes from being able to send malicious commands to the Jenkins controller.\n\n// TODO Also mention first LTS once it's known\nThis system is always enabled since Jenkins 2.326 (see ).\nIn Jenkins 2"
  },
  "1150": {
    "source_file": "controller-isolation.txt",
    "text": "ands to the Jenkins controller.\n\n// TODO Also mention first LTS once it's known\nThis system is always enabled since Jenkins 2.326 (see ).\nIn Jenkins 2.325 and earlier, it is enabled by default, but can be disabled in the web UI by un-checking the box on the _Manage Jenkins \u00bb Security_ page.\n\nIMPORTANT: It is strongly recommended that you not disable the Agent &rarr; Controller Access Control syste"
  },
  "1151": {
    "source_file": "controller-isolation.txt",
    "text": " on the _Manage Jenkins \u00bb Security_ page.\n\nIMPORTANT: It is strongly recommended that you not disable the Agent &rarr; Controller Access Control system.\n\nAs an alternative to disabling Agent &rarr; Controller Access Control, in Jenkins 2.325 and earlier, administrators can selectively allow greater access.\nSee  for details."
  },
  "1152": {
    "source_file": "controller-isolation.txt",
    "text": "ier, administrators can selectively allow greater access.\nSee  for details."
  },
  "1153": {
    "source_file": "convert-api-dependencies-to-plugin-dependencies.txt",
    "text": "layout: developersection\ntitle: Convert API dependencies to plugin dependencies\n\n\nJenkins plugins frequently use libraries for common tasks.\nHTTP communications are often done with the apache-httpcomponents library.\nYAML parsing is often done with snakeyaml.\nBouncycastle is used to provide encryption.\nAWS SDK libraries are used for AWS access.\nGoogle APIs client library is used for Google Cloud Pl"
  },
  "1154": {
    "source_file": "convert-api-dependencies-to-plugin-dependencies.txt",
    "text": "akeyaml.\nBouncycastle is used to provide encryption.\nAWS SDK libraries are used for AWS access.\nGoogle APIs client library is used for Google Cloud Platform access.\n\nMany of those dependencies can be replaced by dependencies on a Jenkins API plugin that provides the same API for multiple plugins.\nWhen an API library dependency is replaced with a plugin dependency, the size of the plugin hpi file d"
  },
  "1155": {
    "source_file": "convert-api-dependencies-to-plugin-dependencies.txt",
    "text": "hat provides the same API for multiple plugins.\nWhen an API library dependency is replaced with a plugin dependency, the size of the plugin hpi file decreases, and the consistency of using the same library version throughout Jenkins will help reliability.\n\n.Jenkins API plugins include:\n* Bouncycastle API\n* Jackson 2 API\n* Trilead API\n* SnakeYAML API\n* JQuery3 API\n* Bootstrap4 API\n* OkHttp API\n* JS"
  },
  "1156": {
    "source_file": "convert-api-dependencies-to-plugin-dependencies.txt",
    "text": "lity.\n\n.Jenkins API plugins include:\n* Bouncycastle API\n* Jackson 2 API\n* Trilead API\n* SnakeYAML API\n* JQuery3 API\n* Bootstrap4 API\n* OkHttp API\n* JSON Web Token API\n* Caffeine API\n* Bootstrap 5 API\n* H2 API\n* Google APIs Client Library\n* AWS SDK APIs\n* Font Awesome API\n* DataTables.net API\n* Kubernetes client API"
  },
  "1157": {
    "source_file": "convert-api-dependencies-to-plugin-dependencies.txt",
    "text": "Is\n* Font Awesome API\n* DataTables.net API\n* Kubernetes client API"
  },
  "1158": {
    "source_file": "convert-translations.txt",
    "text": "layout: developersection\ntitle: Convert translations\n\n\nJava property files provide localizations in the Jenkins project.\nUnfortunately, in the past they had to use ISO-8859-1 encoding, even for files that needed to represent characters outside of ISO-8859-1.\nDue to a risk of character set confusion when Jenkins reads the property files, Jenkins plugin tests will warn developers when existing prope"
  },
  "1159": {
    "source_file": "convert-translations.txt",
    "text": "-8859-1.\nDue to a risk of character set confusion when Jenkins reads the property files, Jenkins plugin tests will warn developers when existing property files include characters that are both valid UTF-8 and valid ISO-8859-1.\nWhen that ambiguity is detected, those files should be encoded to assure they are read correctly.\n\nWhen such a conversion is needed, the Maven build process will frequently "
  },
  "1160": {
    "source_file": "convert-translations.txt",
    "text": "detected, those files should be encoded to assure they are read correctly.\n\nWhen such a conversion is needed, the Maven build process will frequently output a message like:\n\n[ERROR] PropertiesTestSuite$PropertiesTest Time elapsed: 0.001 s <<< FAILURE!\njava.lang.AssertionError: file:config_ja.properties is valid UTF-8 and\nvalid ISO-8859-1. To avoid problems when auto-detecting the encoding,\nuse the"
  },
  "1161": {
    "source_file": "convert-translations.txt",
    "text": "!\njava.lang.AssertionError: file:config_ja.properties is valid UTF-8 and\nvalid ISO-8859-1. To avoid problems when auto-detecting the encoding,\nuse the lowest common denominator of ASCII encoding and express\nnon-ASCII characters with escape sequences using a tool like\n`native2ascii`.\n\n// Create the branch\n\n// Compile the plugin\n\nConfirm that the encoding warning message is displayed:\n\n[ERROR] Prope"
  },
  "1162": {
    "source_file": "convert-translations.txt",
    "text": "using a tool like\n`native2ascii`.\n\n// Create the branch\n\n// Compile the plugin\n\nConfirm that the encoding warning message is displayed:\n\n[ERROR] PropertiesTestSuite$PropertiesTest Time elapsed: 0.001 s <<< FAILURE!\njava.lang.AssertionError: file:config_ja.properties is valid UTF-8 and\nvalid ISO-8859-1. To avoid problems when auto-detecting the encoding,\nuse the lowest common denominator of ASCII e"
  },
  "1163": {
    "source_file": "convert-translations.txt",
    "text": "ig_ja.properties is valid UTF-8 and\nvalid ISO-8859-1. To avoid problems when auto-detecting the encoding,\nuse the lowest common denominator of ASCII encoding and express\nnon-ASCII characters with escape sequences using a tool like\n`native2ascii`.\n\nIf the warning message is not displayed and the plugin is using the most recent parent pom, then no conversion is necessary.\n\nIf the warning message is "
  },
  "1164": {
    "source_file": "convert-translations.txt",
    "text": " the warning message is not displayed and the plugin is using the most recent parent pom, then no conversion is necessary.\n\nIf the warning message is displayed,  use `native2ascii` to convert the files.\nUse the specific files mentioned in the warning message in place of the `.../config_ja.properties` file in the sample below:\n\nnative2ascii .../config_ja.properties x\nmv x .../config_ja.properties\n\n"
  },
  "1165": {
    "source_file": "convert-translations.txt",
    "text": " message in place of the `.../config_ja.properties` file in the sample below:\n\nnative2ascii .../config_ja.properties x\nmv x .../config_ja.properties\n\nReview the change that native2ascii performed with the command:\n\ngit diff\ndiff --git a/.../config_ja.properties b/.../config_ja.properties\nindex 83e3576..e661ac9 100644\n--- a/.../config_ja.properties\n++ b/.../config_ja.properties\n@@ -20,5 +20,5 @@\n #"
  },
  "1166": {
    "source_file": "convert-translations.txt",
    "text": ".properties b/.../config_ja.properties\nindex 83e3576..e661ac9 100644\n--- a/.../config_ja.properties\n++ b/.../config_ja.properties\n@@ -20,5 +20,5 @@\n # OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n # THE SOFTWARE.\n\n-# Authorize\\ Strategy=\u6a29\u9650\u306e\u8a2d\u5b9a\u65b9\u6cd5\n# Authorize\\ Strategy=\\u6a29\\u9650\\u306e\\u8a2d\\u5b9a\\u65b9\\u6cd5\n Authorize\\ Strategy=\\u6a29\\u9650\\u306e\\u8a2d\\u5b9a\\u65b9\\u6c"
  },
  "1167": {
    "source_file": "convert-translations.txt",
    "text": "orize\\ Strategy=\u6a29\u9650\u306e\u8a2d\u5b9a\u65b9\u6cd5\n# Authorize\\ Strategy=\\u6a29\\u9650\\u306e\\u8a2d\\u5b9a\\u65b9\\u6cd5\n Authorize\\ Strategy=\\u6a29\\u9650\\u306e\\u8a2d\\u5b9a\\u65b9\\u6cd5\n\n// Compile the plugin\n\n// Create a pull request"
  },
  "1168": {
    "source_file": "cps-method-mismatches.txt",
    "text": "layout: section\ntitle: Pipeline CPS Method Mismatches\n\n\nifdef::env-github[:imagesdir: ../resources]\nifndef::env-github[:imagesdir: ../../resources]\n\nJenkins Pipeline uses a library called Groovy CPS to run Pipeline scripts.\nWhile Pipeline uses the Groovy parser and compiler, unlike a regular Groovy environment it runs most of the program inside a special interpreter.\nThis uses a continuation-passi"
  },
  "1169": {
    "source_file": "cps-method-mismatches.txt",
    "text": "oovy parser and compiler, unlike a regular Groovy environment it runs most of the program inside a special interpreter.\nThis uses a continuation-passing style (CPS) transform to turn your code into a version that can save its current state to disk (a file called `+program.dat+`\u00a0\u00a0inside your build directory) and continue running even after Jenkins has restarted.\n(You can get some more technical bac"
  },
  "1170": {
    "source_file": "cps-method-mismatches.txt",
    "text": " file called `+program.dat+`\u00a0\u00a0inside your build directory) and continue running even after Jenkins has restarted.\n(You can get some more technical background on the\u00a0plugin:workflow-cps[Pipeline: Groovy plugin page] and the\u00a0https://github.com/cloudbees/groovy-cps/blob/master/README.md[library page].)\n\nWhile the CPS transform is usually transparent to users, there are limitations to what Groovy lang"
  },
  "1171": {
    "source_file": "cps-method-mismatches.txt",
    "text": "s/groovy-cps/blob/master/README.md[library page].)\n\nWhile the CPS transform is usually transparent to users, there are limitations to what Groovy language constructs can be supported, and in some circumstances it can lead to counterintuitive behavior.\nhttps://issues.jenkins.io/browse/JENKINS-31314[JENKINS-31314]\u00a0makes the runtime try to detect the most common mistake: calling CPS-transformed code "
  },
  "1172": {
    "source_file": "cps-method-mismatches.txt",
    "text": ".\nhttps://issues.jenkins.io/browse/JENKINS-31314[JENKINS-31314]\u00a0makes the runtime try to detect the most common mistake: calling CPS-transformed code from non-CPS-transformed code.\nThe following kinds of things are CPS-transformed:\n\n* Almost all of the Pipeline script you write (including in libraries)\n* Most Pipeline steps, including all those which take a block\n\nThe following kinds of things are"
  },
  "1173": {
    "source_file": "cps-method-mismatches.txt",
    "text": "he Pipeline script you write (including in libraries)\n* Most Pipeline steps, including all those which take a block\n\nThe following kinds of things are _not_\u00a0CPS-transformed:\n\n* Compiled Java bytecode, including\n** the Java Platform\n** Jenkins core and plugins\n** the runtime for the Groovy language\n* Constructor bodies in your Pipeline script\n* Any method in your Pipeline script marked with the\u00a0`+@"
  },
  "1174": {
    "source_file": "cps-method-mismatches.txt",
    "text": "d plugins\n** the runtime for the Groovy language\n* Constructor bodies in your Pipeline script\n* Any method in your Pipeline script marked with the\u00a0`+@NonCPS+`\u00a0annotation\n* A few Pipeline steps which take no block and act instantaneously, such as\u00a0`+echo+`\u00a0or\u00a0`+properties+`\n\nCPS-transformed code may call non-CPS-transformed code or other CPS-transformed code, and non-CPS-transformed code may call ot"
  },
  "1175": {
    "source_file": "cps-method-mismatches.txt",
    "text": "ho+`\u00a0or\u00a0`+properties+`\n\nCPS-transformed code may call non-CPS-transformed code or other CPS-transformed code, and non-CPS-transformed code may call other non-CPS-transformed code, but non-CPS-transformed code *may not* call CPS-transformed code.\nIf you try to call CPS-transformed code from non-CPS-transformed code, the CPS interpreter is unable to operate correctly, resulting in incorrect and ofte"
  },
  "1176": {
    "source_file": "cps-method-mismatches.txt",
    "text": "ou try to call CPS-transformed code from non-CPS-transformed code, the CPS interpreter is unable to operate correctly, resulting in incorrect and often confusing results.\n\nSometimes users will apply the\u00a0`+@NonCPS+`\u00a0 annotation to a method definition in order to bypass the CPS transform inside that method.\nThis can be done to work around limitations in Groovy language coverage (since the body of th"
  },
  "1177": {
    "source_file": "cps-method-mismatches.txt",
    "text": "in order to bypass the CPS transform inside that method.\nThis can be done to work around limitations in Groovy language coverage (since the body of the method will execute using the native Groovy semantics), or to get better performance (the interpreter imposes a substantial overhead).\nHowever, such methods must not call CPS-transformed code such as Pipeline steps.\nFor example, the following will "
  },
  "1178": {
    "source_file": "cps-method-mismatches.txt",
    "text": "ter imposes a substantial overhead).\nHowever, such methods must not call CPS-transformed code such as Pipeline steps.\nFor example, the following will not work:\n\n@NonCPS\ndef compileOnPlatforms() {\n  ['linux', 'windows'].each { arch ->\n    node(arch) {\n      sh 'make'\n    }\n  }\n}\ncompileOnPlatforms()\n\nUsing the\u00a0`+node+`\u00a0 or\u00a0`+sh+`\u00a0 steps from this method is illegal, and the behavior will be anomalou"
  },
  "1179": {
    "source_file": "cps-method-mismatches.txt",
    "text": "\n      sh 'make'\n    }\n  }\n}\ncompileOnPlatforms()\n\nUsing the\u00a0`+node+`\u00a0 or\u00a0`+sh+`\u00a0 steps from this method is illegal, and the behavior will be anomalous.\nThe warning in the logs from running this script looks like this:\n\n____\nexpected to call WorkflowScript.compileOnPlatforms but wound up catching node\n____\n\nTo fix this case, simply remove the annotation \u2014 it was not needed.\n(Longtime Pipeline user"
  },
  "1180": {
    "source_file": "cps-method-mismatches.txt",
    "text": "Script.compileOnPlatforms but wound up catching node\n____\n\nTo fix this case, simply remove the annotation \u2014 it was not needed.\n(Longtime Pipeline users might have thought it was, prior to the fix of\u00a0https://issues.jenkins.io/browse/JENKINS-26481[JENKINS-26481].)\n\nSome Groovy and Java methods take complex types as parameters to support dynamic behavior.\nA common case is sorting methods that allow c"
  },
  "1181": {
    "source_file": "cps-method-mismatches.txt",
    "text": "INS-26481].)\n\nSome Groovy and Java methods take complex types as parameters to support dynamic behavior.\nA common case is sorting methods that allow callers to specify a method to use for comparing objects (https://issues.jenkins.io/browse/JENKINS-44924[JENKINS-44924]).\nMany similar methods in the Groovy standard library work correctly after the fix for\u00a0https://issues.jenkins.io/browse/JENKINS-264"
  },
  "1182": {
    "source_file": "cps-method-mismatches.txt",
    "text": "924[JENKINS-44924]).\nMany similar methods in the Groovy standard library work correctly after the fix for\u00a0https://issues.jenkins.io/browse/JENKINS-26481[JENKINS-26481], but some methods remain unfixed.\nFor example, the following will not work:\n\ndef sortByLength(List<String> list) {\n  list.toSorted { a, b -> Integer.valueOf(a.length()).compareTo(b.length()) }\n}\ndef sorted = sortByLength(['333', '1'"
  },
  "1183": {
    "source_file": "cps-method-mismatches.txt",
    "text": "ortByLength(List<String> list) {\n  list.toSorted { a, b -> Integer.valueOf(a.length()).compareTo(b.length()) }\n}\ndef sorted = sortByLength(['333', '1', '4444', '22'])\necho(sorted.toString())\n\nThe closure passed to\u00a0`+Iterable.toSorted+` is CPS-transformed, but `+Iterable.toSorted+` itself is not CPS-transformed internally, so this will not work as intended.\nThe current behavior is that the return v"
  },
  "1184": {
    "source_file": "cps-method-mismatches.txt",
    "text": "rmed, but `+Iterable.toSorted+` itself is not CPS-transformed internally, so this will not work as intended.\nThe current behavior is that the return value of the call to `toSorted` will be the return value of the first call to the closure.\nIn the example, this results in\u00a0`+sorted+` being set to `+-1+`, and the warning in the logs looks like this:\n\n____\nexpected to call java.util.ArrayList.toSorted"
  },
  "1185": {
    "source_file": "cps-method-mismatches.txt",
    "text": "mple, this results in\u00a0`+sorted+` being set to `+-1+`, and the warning in the logs looks like this:\n\n____\nexpected to call java.util.ArrayList.toSorted but wound up catching org.jenkinsci.plugins.workflow.cps.CpsClosure2.call\n____\n\nTo fix this case, any argument passed to these methods must not be CPS-transformed.\nThis can be accomplished by encapsulating\u00a0the problematic method (`+Iterable.toSorted"
  },
  "1186": {
    "source_file": "cps-method-mismatches.txt",
    "text": "ny argument passed to these methods must not be CPS-transformed.\nThis can be accomplished by encapsulating\u00a0the problematic method (`+Iterable.toSorted+` in the example) inside another method, and annotating the outer method with\u00a0`+@NonCPS+`, or by creating an explicit class definition for the closure and annotating all methods on that class with\u00a0`+@NonCPS+`.\n\nOccasionally, users may attempt to use"
  },
  "1187": {
    "source_file": "cps-method-mismatches.txt",
    "text": "eating an explicit class definition for the closure and annotating all methods on that class with\u00a0`+@NonCPS+`.\n\nOccasionally, users may attempt to use CPS-transformed code such as Pipeline steps inside of a constructor in a Pipeline script.\nUnfortunately, the construction of objects via the\u00a0`+new+`\u00a0operator in Groovy is not something that can be CPS-transformed (https://issues.jenkins.io/browse/JE"
  },
  "1188": {
    "source_file": "cps-method-mismatches.txt",
    "text": "tely, the construction of objects via the\u00a0`+new+`\u00a0operator in Groovy is not something that can be CPS-transformed (https://issues.jenkins.io/browse/JENKINS-26313[JENKINS-26313]), and so this will not work.\nHere is an example that calls a CPS-transformed method in a constructor:\n\nclass Test {\n  def x\n  public Test() {\n    setX()\n  }\n  private void setX() {\n    this.x = 1;\n  }\n}\ndef x = new Test().x"
  },
  "1189": {
    "source_file": "cps-method-mismatches.txt",
    "text": "med method in a constructor:\n\nclass Test {\n  def x\n  public Test() {\n    setX()\n  }\n  private void setX() {\n    this.x = 1;\n  }\n}\ndef x = new Test().x\necho \"${x}\"\n\nThe construction of\u00a0`+Test+`\u00a0will fail when the constructor calls `+Test.setX+` because `+setX+`\u00a0is a CPS-transformed method.\nThe warning in the logs from running this script looks like this:\n\n____\nexpected to call Test.<init> but wound"
  },
  "1190": {
    "source_file": "cps-method-mismatches.txt",
    "text": "e `+setX+`\u00a0is a CPS-transformed method.\nThe warning in the logs from running this script looks like this:\n\n____\nexpected to call Test.<init> but wound up catching Test.setX\n____\n\nTo fix this case, ensure that any methods defined in a Pipeline script that are called from inside of a constructor are annotated with\u00a0`+@NonCPS+`\u00a0and that constructors do not call any Pipeline steps.\nIf you must call CPS"
  },
  "1191": {
    "source_file": "cps-method-mismatches.txt",
    "text": "that are called from inside of a constructor are annotated with\u00a0`+@NonCPS+`\u00a0and that constructors do not call any Pipeline steps.\nIf you must call CPS-transformed code such a Pipeline steps from the constructor, you need move the logic related to the CPS-transformed methods out of the constructor, for example into a static factory method that calls the CPS-transformed code and then passes the resu"
  },
  "1192": {
    "source_file": "cps-method-mismatches.txt",
    "text": " CPS-transformed methods out of the constructor, for example into a static factory method that calls the CPS-transformed code and then passes the results to the constructor.\n\nUsers may create a class in a Pipeline Script that extends a preexisting class defined outside of the Pipeline script, for example from the Java or Groovy standard libraries.\nWhen doing so, the subclass must ensure that any o"
  },
  "1193": {
    "source_file": "cps-method-mismatches.txt",
    "text": "ass defined outside of the Pipeline script, for example from the Java or Groovy standard libraries.\nWhen doing so, the subclass must ensure that any overriding methods are annotated with `+@NonCPS+`\u00a0and do not use any CPS-transformed code internally.\nOtherwise, the overriding methods will fail if called from a non-CPS context.\nFor example, the following will not work:\n\nclass Test {\n  @Override\n  p"
  },
  "1194": {
    "source_file": "cps-method-mismatches.txt",
    "text": "\nOtherwise, the overriding methods will fail if called from a non-CPS context.\nFor example, the following will not work:\n\nclass Test {\n  @Override\n  public String toString() {\n    return \"Test\"\n  }\n}\ndef builder = new StringBuilder()\nbuilder.append(new Test())\necho(builder.toString())\n\nCalling the CPS-transformed override of\u00a0`+toString+`\u00a0from non-CPS-transformed code such as `+StringBuilder.append"
  },
  "1195": {
    "source_file": "cps-method-mismatches.txt",
    "text": "ew Test())\necho(builder.toString())\n\nCalling the CPS-transformed override of\u00a0`+toString+`\u00a0from non-CPS-transformed code such as `+StringBuilder.append+` is not permitted and will not work as expected in most cases.\nThe warning in the logs from running this script looks like this:\n\n____\nexpected to call java.lang.StringBuilder.append but wound up catching Test.toString\n____\n\nTo fix this case, add t"
  },
  "1196": {
    "source_file": "cps-method-mismatches.txt",
    "text": "g this script looks like this:\n\n____\nexpected to call java.lang.StringBuilder.append but wound up catching Test.toString\n____\n\nTo fix this case, add the `+@NonCPS+` annotation to the overriding method, and remove any uses of CPS-transformed code such as Pipeline steps from the method.\n\n[[PipelineCPSmethodmismatches-ClosuresinsideGString]]\n\nIn Groovy, it is possible to use a closure in a `+GString+"
  },
  "1197": {
    "source_file": "cps-method-mismatches.txt",
    "text": " as Pipeline steps from the method.\n\n[[PipelineCPSmethodmismatches-ClosuresinsideGString]]\n\nIn Groovy, it is possible to use a closure in a `+GString+` so that the closure is evaluated every time the `+GString+` is used as a `+String+`.\nHowever, in Pipeline scripts, this will not work as expected, because the closure inside of the GString will be CPS-transformed.\nHere is an example:\n\ndef x = 1\ndef"
  },
  "1198": {
    "source_file": "cps-method-mismatches.txt",
    "text": "ipeline scripts, this will not work as expected, because the closure inside of the GString will be CPS-transformed.\nHere is an example:\n\ndef x = 1\ndef s = \"x = ${-> x}\"\nx = 2\necho(s)\n\nUsing a closure inside of a\u00a0`+GString+`\u00a0 as in this example will not work.\nThe warning from the logs when running this script looks like this:\n\n____\nexpected to call WorkflowScript.echo but wound up catching org.jenk"
  },
  "1199": {
    "source_file": "cps-method-mismatches.txt",
    "text": "ot work.\nThe warning from the logs when running this script looks like this:\n\n____\nexpected to call WorkflowScript.echo but wound up catching org.jenkinsci.plugins.workflow.cps.CpsClosure2.call\n____\n\nTo fix this case, replace the original GString with a closure that returns a GString that uses a normal expression rather than a closure, and then call the closure where you would have used the origin"
  },
  "1200": {
    "source_file": "cps-method-mismatches.txt",
    "text": "h a closure that returns a GString that uses a normal expression rather than a closure, and then call the closure where you would have used the original `+GString+`\u00a0as follows:\n\ndef x = 1\ndef s = { -> \"x = ${x}\" }\nx = 2\necho(s())\n\nUnfortunately, some expressions may incorrectly trigger this warning even though they execute correctly.\nIf you run into such a case, please  (after first checking for d"
  },
  "1201": {
    "source_file": "cps-method-mismatches.txt",
    "text": " expressions may incorrectly trigger this warning even though they execute correctly.\nIf you run into such a case, please  (after first checking for duplicates) for `+workflow-cps-plugin+`."
  },
  "1202": {
    "source_file": "create-a-pipeline-in-blue-ocean.txt",
    "text": "layout: documentation\ntitle: Create a Pipeline in Blue Ocean\nsection: doc\n\n\nifdef::env-github[:imagesdir: ../../book/resources]\nifndef::env-github[:imagesdir: ../../book/resources]\n\n// Show 3/3 of the Blue ocean admonitions\n\nThis tutorial shows you how to use the  feature of Jenkins to create a Pipeline that orchestrates building a simple application.\n\nBefore you start this tutorial, be sure to ru"
  },
  "1203": {
    "source_file": "create-a-pipeline-in-blue-ocean.txt",
    "text": "ow to use the  feature of Jenkins to create a Pipeline that orchestrates building a simple application.\n\nBefore you start this tutorial, be sure to run through at least one of the initial tutorials from the  page.\nThis will help you learn about CI/CD concepts, relevant to the technology stack you're most familiar with, and how these concepts are implemented in Jenkins.\n\nThis tutorial uses the same"
  },
  "1204": {
    "source_file": "create-a-pipeline-in-blue-ocean.txt",
    "text": " concepts, relevant to the technology stack you're most familiar with, and how these concepts are implemented in Jenkins.\n\nThis tutorial uses the same application that the  tutorial is based on.\nTherefore, you're building the same application, but this time, completely through Blue Ocean.\nSince Blue Ocean provides a simplified Git-handling experience, you'll be interacting directly with the reposi"
  },
  "1205": {
    "source_file": "create-a-pipeline-in-blue-ocean.txt",
    "text": "is time, completely through Blue Ocean.\nSince Blue Ocean provides a simplified Git-handling experience, you'll be interacting directly with the repository on GitHub, as opposed to a local clone.\n\n*Duration:* This tutorial takes 20-40 minutes to complete if you've already met the <<prerequisites,prerequisites>> below.\nThe exact duration depends on the speed of your machine and whether or not you've"
  },
  "1206": {
    "source_file": "create-a-pipeline-in-blue-ocean.txt",
    "text": "ete if you've already met the <<prerequisites,prerequisites>> below.\nThe exact duration depends on the speed of your machine and whether or not you've already <<run-jenkins-in-docker,run Jenkins in Docker>> from .\n\nYou can stop this tutorial at any point in time and continue from where you left\noff.\n\nIf you've already run though , you can skip the <<prerequisites,prerequisites>> and <<run-jenkins-"
  },
  "1207": {
    "source_file": "create-a-pipeline-in-blue-ocean.txt",
    "text": "oint in time and continue from where you left\noff.\n\nIf you've already run though , you can skip the <<prerequisites,prerequisites>> and <<run-jenkins-in-docker,run Jenkins in Docker>> sections below and proceed to <<fork-sample-repository,forking the sample repository>>.\nIf you need to restart Jenkins, follow the restart instructions in <<stopping-and-restarting-jenkins,stopping and restarting Jen"
  },
  "1208": {
    "source_file": "create-a-pipeline-in-blue-ocean.txt",
    "text": " sample repository>>.\nIf you need to restart Jenkins, follow the restart instructions in <<stopping-and-restarting-jenkins,stopping and restarting Jenkins>> and then proceed.\n\n[[fork-sample-repository]]\n\nFork the simple \"Welcome to React\" Node.js and React application on GitHub into your own GitHub account.\n\nEnsure you are signed in to your GitHub account.\nIf you don't yet have a GitHub account, s"
  },
  "1209": {
    "source_file": "create-a-pipeline-in-blue-ocean.txt",
    "text": " React application on GitHub into your own GitHub account.\n\nEnsure you are signed in to your GitHub account.\nIf you don't yet have a GitHub account, sign up for a free on the https://github.com/[GitHub website].\nFork the https://github.com/jenkins-docs/creating-a-pipeline-in-blue-ocean[`creating-a-pipeline-in-blue-ocean`]\nrepository on GitHub into your local GitHub account.\nIf you need help with t"
  },
  "1210": {
    "source_file": "create-a-pipeline-in-blue-ocean.txt",
    "text": "cs/creating-a-pipeline-in-blue-ocean[`creating-a-pipeline-in-blue-ocean`]\nrepository on GitHub into your local GitHub account.\nIf you need help with this process, refer to the https://help.github.com/articles/fork-a-repo/[fork a repo] documentation on the GitHub website for more information.\n\nNOTE: This is a different repository than the one used in the  tutorial.\nAlthough these repositories conta"
  },
  "1211": {
    "source_file": "create-a-pipeline-in-blue-ocean.txt",
    "text": "n the GitHub website for more information.\n\nNOTE: This is a different repository than the one used in the  tutorial.\nAlthough these repositories contain the same application code, ensure you fork and use the correct one before continuing.\n\nGo back to Jenkins and ensure you have accessed the Blue Ocean interface.\nTo do this, make sure you have:\n* browsed to `http://localhost:8080/blue` and are logg"
  },
  "1212": {
    "source_file": "create-a-pipeline-in-blue-ocean.txt",
    "text": " Jenkins and ensure you have accessed the Blue Ocean interface.\nTo do this, make sure you have:\n* browsed to `http://localhost:8080/blue` and are logged in.\n* browsed to `http://localhost:8080/`, are logged in, and have selected *Open Blue Ocean* on the left side of the screen.\n\nIn the *Welcome to Jenkins* box at the center of the Blue Ocean interface, select *Create a new Pipeline* to start the P"
  },
  "1213": {
    "source_file": "create-a-pipeline-in-blue-ocean.txt",
    "text": "the left side of the screen.\n\nIn the *Welcome to Jenkins* box at the center of the Blue Ocean interface, select *Create a new Pipeline* to start the Pipeline creation wizard.\nIf you don't see this box, select *New Pipeline* in the upper right.\n\nIn *Where do you store your code?*, select *GitHub*.\nIn *Connect to GitHub*, select *Create an access key here*.\nThis opens GitHub in a new browser tab.\nNO"
  },
  "1214": {
    "source_file": "create-a-pipeline-in-blue-ocean.txt",
    "text": "here do you store your code?*, select *GitHub*.\nIn *Connect to GitHub*, select *Create an access key here*.\nThis opens GitHub in a new browser tab.\nNOTE: If you previously configured Blue Ocean to connect to GitHub using a personal access token, Blue Ocean takes you directly to step 9 <<choose-github-account,below>>.\n\nIn the new tab, sign in to your GitHub account if necessary. On the GitHub *New "
  },
  "1215": {
    "source_file": "create-a-pipeline-in-blue-ocean.txt",
    "text": " Ocean takes you directly to step 9 <<choose-github-account,below>>.\n\nIn the new tab, sign in to your GitHub account if necessary. On the GitHub *New Personal Access Token* page, specify a brief *Token description* for your GitHub access token, for example `Blue Ocean`.\nTIP: An access token is usually an alphanumeric string that represents your GitHub account, along with permissions to access vari"
  },
  "1216": {
    "source_file": "create-a-pipeline-in-blue-ocean.txt",
    "text": "xample `Blue Ocean`.\nTIP: An access token is usually an alphanumeric string that represents your GitHub account, along with permissions to access various GitHub features and areas through your account.\nThis access token has the appropriate permissions pre-selected that Blue Ocean requires to access and interact with your GitHub account.\n\nScroll down to the end of the page, while leaving all other "
  },
  "1217": {
    "source_file": "create-a-pipeline-in-blue-ocean.txt",
    "text": "s pre-selected that Blue Ocean requires to access and interact with your GitHub account.\n\nScroll down to the end of the page, while leaving all other *Select scopes* options with their default settings, and select *Generate token*.\nOn the *Personal access tokens* page, copy your newly-generated access token.\nBack in Blue Ocean, paste the access token into the *Your GitHub access token* field, and "
  },
  "1218": {
    "source_file": "create-a-pipeline-in-blue-ocean.txt",
    "text": "ccess tokens* page, copy your newly-generated access token.\nBack in Blue Ocean, paste the access token into the *Your GitHub access token* field, and select *Connect*.\n[.boxshadow]\n\n[[choose-github-account]]Jenkins now has access to your GitHub account, using your access token.\nIn *Which organization does the repository belong to?*, select your GitHub account where you forked the repository <<fork"
  },
  "1219": {
    "source_file": "create-a-pipeline-in-blue-ocean.txt",
    "text": "nt, using your access token.\nIn *Which organization does the repository belong to?*, select your GitHub account where you forked the repository <<fork-sample-repository,above>>.\nIn *Choose a repository*, select your forked repository `creating-a-pipeline-in-blue-ocean`.\nSelect *Create Pipeline*.\n* Blue Ocean detects that there is no Jenkinsfile at the root level of the repository's `master` branch"
  },
  "1220": {
    "source_file": "create-a-pipeline-in-blue-ocean.txt",
    "text": "line-in-blue-ocean`.\nSelect *Create Pipeline*.\n* Blue Ocean detects that there is no Jenkinsfile at the root level of the repository's `master` branch and helps you create one.\nYou must select *Create Pipeline* again at the end of the page to proceed.\n\nTIP: Under the hood, a Pipeline project created through Blue Ocean is actually a \"multibranch Pipeline\".\nTherefore, Jenkins looks for the presence "
  },
  "1221": {
    "source_file": "create-a-pipeline-in-blue-ocean.txt",
    "text": ".\n\nTIP: Under the hood, a Pipeline project created through Blue Ocean is actually a \"multibranch Pipeline\".\nTherefore, Jenkins looks for the presence of at least one Jenkinsfile in any branch of your repository.\n\nFollowing on from creating your Pipeline project <<create-your-pipeline-project-in-blue-ocean,above>>, in the Pipeline editor, select *Docker* from the *Agent* dropdown in the *Pipeline S"
  },
  "1222": {
    "source_file": "create-a-pipeline-in-blue-ocean.txt",
    "text": "ine project <<create-your-pipeline-project-in-blue-ocean,above>>, in the Pipeline editor, select *Docker* from the *Agent* dropdown in the *Pipeline Settings* panel on the right side of the page.\n[.boxshadow]\n\nIn the *Image* and *Args* fields that appear, specify `node:lts-alpine` and `-p 3000:3000` respectively.\n[.boxshadow]\n\nNOTE: For an explanation of these values, refer to annotations *1* and "
  },
  "1223": {
    "source_file": "create-a-pipeline-in-blue-ocean.txt",
    "text": "pear, specify `node:lts-alpine` and `-p 3000:3000` respectively.\n[.boxshadow]\n\nNOTE: For an explanation of these values, refer to annotations *1* and *2* of the Declarative Pipeline in the\n section of the build a Node.js and React app tutorial.\n\nIn the main Pipeline editor, select the *+* icon, to open the new stage panel on the right side of the icon.\n[.boxshadow]\n\nIn this panel, enter `Build` in"
  },
  "1224": {
    "source_file": "create-a-pipeline-in-blue-ocean.txt",
    "text": "he main Pipeline editor, select the *+* icon, to open the new stage panel on the right side of the icon.\n[.boxshadow]\n\nIn this panel, enter `Build` in the *Name your stage* field, and then select the *Add Step* button below.\nThe *Choose step type* panel opens.\n[.boxshadow]\n\nIn this panel, select *Shell Script* near the top of the list to configure that step type, which opens the *Build / Shell Scr"
  },
  "1225": {
    "source_file": "create-a-pipeline-in-blue-ocean.txt",
    "text": "nel opens.\n[.boxshadow]\n\nIn this panel, select *Shell Script* near the top of the list to configure that step type, which opens the *Build / Shell Script* panel.\nHere you can enter this step's values.\n[.boxshadow]\n\nTIP: The most commonly used step types appear closest to the top of this list.\nTo find other steps further down this list, you can filter this list using the *Find steps by name* option"
  },
  "1226": {
    "source_file": "create-a-pipeline-in-blue-ocean.txt",
    "text": "pes appear closest to the top of this list.\nTo find other steps further down this list, you can filter this list using the *Find steps by name* option.\n\nIn the *Build / Shell Script* panel, specify `npm install`.\n[.boxshadow]\n\nNOTE: For an explanation of this step, refer to annotation *4* of the Declarative Pipeline in the  section of the build a Node.js and React app tutorial.\n\n( _Optional_ ) Sel"
  },
  "1227": {
    "source_file": "create-a-pipeline-in-blue-ocean.txt",
    "text": "n of this step, refer to annotation *4* of the Declarative Pipeline in the  section of the build a Node.js and React app tutorial.\n\n( _Optional_ ) Select the back arrow icon  in the upper left to return to the main Pipeline editor.\nSelect *Save* in the upper right side of the screen to begin saving your new Pipeline with its \"Build\" stage.\nIn the *Save Pipeline* dialog box, enter the commit messag"
  },
  "1228": {
    "source_file": "create-a-pipeline-in-blue-ocean.txt",
    "text": "he upper right side of the screen to begin saving your new Pipeline with its \"Build\" stage.\nIn the *Save Pipeline* dialog box, enter the commit message in the *Description* field, for example `Add initial Pipeline (Jenkinsfile)`.\n[.boxshadow]\n\nLeave all other options set to their default, and then select *Save & run*.\nJenkins proceeds to build your Pipeline.\nWhen the main Blue Ocean interface appe"
  },
  "1229": {
    "source_file": "create-a-pipeline-in-blue-ocean.txt",
    "text": "all other options set to their default, and then select *Save & run*.\nJenkins proceeds to build your Pipeline.\nWhen the main Blue Ocean interface appears, select the row to see Jenkins build your Pipeline project.\nYou'll need to wait for this first run to complete before proceeding.\nDuring this time, Jenkins does the following:\n.. Commits your Pipeline as a `Jenkinsfile` to the only branch of your"
  },
  "1230": {
    "source_file": "create-a-pipeline-in-blue-ocean.txt",
    "text": "un to complete before proceeding.\nDuring this time, Jenkins does the following:\n.. Commits your Pipeline as a `Jenkinsfile` to the only branch of your repository.\n.. Initially queues the project to be built on the agent.\n.. Downloads the Node Docker image and runs it in a container on Docker.\n.. Executes the `Build` stage defined in the `Jenkinsfile` on the Node container.\nNOTE: During this time, "
  },
  "1231": {
    "source_file": "create-a-pipeline-in-blue-ocean.txt",
    "text": "image and runs it in a container on Docker.\n.. Executes the `Build` stage defined in the `Jenkinsfile` on the Node container.\nNOTE: During this time, `npm` downloads the dependencies necessary to run your Node.js and React application, which will be stored in the local `node_modules` directory in the Jenkins home directory.\n[.boxshadow]\n\nThe Blue Ocean interface turns green if Jenkins built your a"
  },
  "1232": {
    "source_file": "create-a-pipeline-in-blue-ocean.txt",
    "text": "stored in the local `node_modules` directory in the Jenkins home directory.\n[.boxshadow]\n\nThe Blue Ocean interface turns green if Jenkins built your application successfully.\n[.boxshadow]\n\nSelect the *X* in the upper right corner to return to the main Blue Ocean interface.\n[.boxshadow]\n\nWARNING: Before continuing on, verify that Jenkins has created a `Jenkinsfile` for you at the root of your forke"
  },
  "1233": {
    "source_file": "create-a-pipeline-in-blue-ocean.txt",
    "text": "n Blue Ocean interface.\n[.boxshadow]\n\nWARNING: Before continuing on, verify that Jenkins has created a `Jenkinsfile` for you at the root of your forked GitHub repository, in the repository's sole `master` branch.\n\nFrom the main Blue Ocean interface, select *Branches* in the upper right to access your repository's branches page, where you can access the `master` branch.\n[.boxshadow]\n\nSelect the `ma"
  },
  "1234": {
    "source_file": "create-a-pipeline-in-blue-ocean.txt",
    "text": "select *Branches* in the upper right to access your repository's branches page, where you can access the `master` branch.\n[.boxshadow]\n\nSelect the `master` branch's \"Edit Pipeline\" icon  to open the Pipeline editor for this branch.\nIn the main Pipeline editor, select the *+* icon to the right of the *Build* stage you created <<create-your-initial-pipeline,above>> to open the new stage panel on the"
  },
  "1235": {
    "source_file": "create-a-pipeline-in-blue-ocean.txt",
    "text": "ne editor, select the *+* icon to the right of the *Build* stage you created <<create-your-initial-pipeline,above>> to open the new stage panel on the right.\n[.boxshadow]\n\nIn this panel, enter `Test` in the *Name your stage* field, and then select the *Add Step* button below to open the *Choose step type* panel.\nIn this panel, select *Shell Script* near the top of the list.\nIn the resulting *Test "
  },
  "1236": {
    "source_file": "create-a-pipeline-in-blue-ocean.txt",
    "text": "e *Add Step* button below to open the *Choose step type* panel.\nIn this panel, select *Shell Script* near the top of the list.\nIn the resulting *Test / Shell Script* panel, specify `./jenkins/scripts/test.sh` and then select the back arrow icon  in the upper left to return to the Pipeline stage editor.\nAt the lower right of the panel, select *Settings* to reveal this section of the panel.\nSelect t"
  },
  "1237": {
    "source_file": "create-a-pipeline-in-blue-ocean.txt",
    "text": "he upper left to return to the Pipeline stage editor.\nAt the lower right of the panel, select *Settings* to reveal this section of the panel.\nSelect the *+* icon at the right of the *Environment* heading where you'll configure an environment directive.\nIn the *Name* and *Value* fields that appear, specify `CI` and `true`, respectively.\n[.boxshadow]\n\nNOTE: For an explanation of this directive and i"
  },
  "1238": {
    "source_file": "create-a-pipeline-in-blue-ocean.txt",
    "text": "e.\nIn the *Name* and *Value* fields that appear, specify `CI` and `true`, respectively.\n[.boxshadow]\n\nNOTE: For an explanation of this directive and its step, refer to annotations *1* and *3* of the Declarative Pipeline in the  tutorial.\n( _Optional_ ) Select the back arrow icon  in the upper left to return to the main Pipeline editor.\nSelect *Save* in the top-right corner to begin saving your Pip"
  },
  "1239": {
    "source_file": "create-a-pipeline-in-blue-ocean.txt",
    "text": " ) Select the back arrow icon  in the upper left to return to the main Pipeline editor.\nSelect *Save* in the top-right corner to begin saving your Pipeline with with its new \"Test\" stage.\nIn the *Save Pipeline* dialog box, specify the commit message in the *Description* field, for example `Add 'Test' stage`.\nLeave all other options set to their default, and then select *Save & run*.\nJenkins procee"
  },
  "1240": {
    "source_file": "create-a-pipeline-in-blue-ocean.txt",
    "text": "in the *Description* field, for example `Add 'Test' stage`.\nLeave all other options set to their default, and then select *Save & run*.\nJenkins proceeds to build your amended Pipeline.\nWhen the main Blue Ocean interface appears, select the _top_ row to see Jenkins build your Pipeline project.\n\n* If your amended Pipeline ran successfully, here's what the Blue Ocean interface should look like, notic"
  },
  "1241": {
    "source_file": "create-a-pipeline-in-blue-ocean.txt",
    "text": "to see Jenkins build your Pipeline project.\n\n* If your amended Pipeline ran successfully, here's what the Blue Ocean interface should look like, notice the additional \"Test\" stage.\nYou can select the previous \"Build\" stage circle to access the output from that stage.\n[.boxshadow]\n\nTIP: You'll notice during this run that Jenkins no longer needs to download the Node Docker image.\nInstead, Jenkins on"
  },
  "1242": {
    "source_file": "create-a-pipeline-in-blue-ocean.txt",
    "text": " from that stage.\n[.boxshadow]\n\nTIP: You'll notice during this run that Jenkins no longer needs to download the Node Docker image.\nInstead, Jenkins only needs to run a new container from the Node image downloaded previously.\nSubsequent runs of your Pipeline should be much faster.\n\nSelect the *X* at the top-right corner to return to the main Blue Ocean interface.\n\nFrom the main Blue Ocean interface"
  },
  "1243": {
    "source_file": "create-a-pipeline-in-blue-ocean.txt",
    "text": "ipeline should be much faster.\n\nSelect the *X* at the top-right corner to return to the main Blue Ocean interface.\n\nFrom the main Blue Ocean interface, select *Branches* in the upper right to access your repository's `master` branch.\nSelect the `master` branch's \"Edit Pipeline\" icon  to open the Pipeline editor for this branch.\nIn the main Pipeline editor, select the *+* icon to the right of the *"
  },
  "1244": {
    "source_file": "create-a-pipeline-in-blue-ocean.txt",
    "text": "er` branch's \"Edit Pipeline\" icon  to open the Pipeline editor for this branch.\nIn the main Pipeline editor, select the *+* icon to the right of the *Test* stage you created <<add-a-test-stage-to-your-pipeline,above>> to open the new stage panel.\n[.boxshadow]\n\nIn this panel, enter `Deliver` in the *Name your stage* field, and then select *Add Step* below to open the *Choose step type* panel.\nIn th"
  },
  "1245": {
    "source_file": "create-a-pipeline-in-blue-ocean.txt",
    "text": "oxshadow]\n\nIn this panel, enter `Deliver` in the *Name your stage* field, and then select *Add Step* below to open the *Choose step type* panel.\nIn this panel, select *Shell Script*.\nIn the resulting *Deliver / Shell Script* panel, specify `./jenkins/scripts/deliver.sh`, and then select the back arrow icon  to return to the Pipeline stage editor.\n[.boxshadow]\n\nNOTE: For an explanation of this step"
  },
  "1246": {
    "source_file": "create-a-pipeline-in-blue-ocean.txt",
    "text": "/scripts/deliver.sh`, and then select the back arrow icon  to return to the Pipeline stage editor.\n[.boxshadow]\n\nNOTE: For an explanation of this step, refer to the `deliver.sh` file itself located in the `jenkins/scripts` of your forked repository on GitHub.\n\nSelect *Add Step* again.\nIn the *Choose step type* panel, enter `input` in the *Find steps by name* field.\n[.boxshadow]\n\nSelect the filtere"
  },
  "1247": {
    "source_file": "create-a-pipeline-in-blue-ocean.txt",
    "text": "n GitHub.\n\nSelect *Add Step* again.\nIn the *Choose step type* panel, enter `input` in the *Find steps by name* field.\n[.boxshadow]\n\nSelect the filtered *Wait for interactive input* step type.\nIn the resulting *Deliver / Wait for interactive input* panel, enter `Finished using the web site? (Select \"Proceed\" to continue)` in the *Message* field, and then select the back arrow icon  to return to the"
  },
  "1248": {
    "source_file": "create-a-pipeline-in-blue-ocean.txt",
    "text": "nel, enter `Finished using the web site? (Select \"Proceed\" to continue)` in the *Message* field, and then select the back arrow icon  to return to the Pipeline stage editor.\n[.boxshadow]\n\nNOTE: For an explanation of this step, refer to annotation *4* of the Declarative Pipeline in the  tutorial.\n\nSelect *Add Step*.\nSelect *Shell Script*.\nIn the resulting *Deliver / Shell Script* panel, specify `./"
  },
  "1249": {
    "source_file": "create-a-pipeline-in-blue-ocean.txt",
    "text": " of the Declarative Pipeline in the  tutorial.\n\nSelect *Add Step*.\nSelect *Shell Script*.\nIn the resulting *Deliver / Shell Script* panel, specify `./jenkins/scripts/kill.sh`.\nNOTE: For an explanation of this step, refer to the `kill.sh` file itself located in the `jenkins/scripts` of your forked repository on GitHub.\n\n( _Optional_ ) Select the back arrow icon  to return to the main Pipeline edito"
  },
  "1250": {
    "source_file": "create-a-pipeline-in-blue-ocean.txt",
    "text": "located in the `jenkins/scripts` of your forked repository on GitHub.\n\n( _Optional_ ) Select the back arrow icon  to return to the main Pipeline editor.\nSelect *Save* in the top-right corner to begin saving your Pipeline with with its new \"Deliver\" stage.\nIn the *Save Pipeline* dialog box, enter the commit message in the *Description* field, for example `Add 'Deliver' stage`.\nLeave all other optio"
  },
  "1251": {
    "source_file": "create-a-pipeline-in-blue-ocean.txt",
    "text": "tage.\nIn the *Save Pipeline* dialog box, enter the commit message in the *Description* field, for example `Add 'Deliver' stage`.\nLeave all other options set to their default, and then select *Save & run*.\nJenkins proceeds to build your amended Pipeline.\nWhen the main Blue Ocean interface appears, select the _top_ row to see Jenkins build your Pipeline project.\n* If your amended Pipeline ran succes"
  },
  "1252": {
    "source_file": "create-a-pipeline-in-blue-ocean.txt",
    "text": "ne.\nWhen the main Blue Ocean interface appears, select the _top_ row to see Jenkins build your Pipeline project.\n* If your amended Pipeline ran successfully, here's what the Blue Ocean interface should look like.\nNotice the additional \"Deliver\" stage.\nSelecting the previous \"Test\" and \"Build\" stage circles provides access to the outputs from those stages.\n[.boxshadow]\n\nEnsure you are viewing the \""
  },
  "1253": {
    "source_file": "create-a-pipeline-in-blue-ocean.txt",
    "text": ".\nSelecting the previous \"Test\" and \"Build\" stage circles provides access to the outputs from those stages.\n[.boxshadow]\n\nEnsure you are viewing the \"Deliver\" stage, then select the green *`./jenkins/scripts/deliver.sh`* step to expand its content and scroll down until you see the `http://localhost:3000` link.\n[.boxshadow]\n\nSelect the `http://localhost:3000` link to view your Node.js and React app"
  },
  "1254": {
    "source_file": "create-a-pipeline-in-blue-ocean.txt",
    "text": "d scroll down until you see the `http://localhost:3000` link.\n[.boxshadow]\n\nSelect the `http://localhost:3000` link to view your Node.js and React application running in development mode in a new web browser tab.\nYou should see a page/site with the title *Welcome to React*.\nWhen you are finished viewing the page/site, select *Proceed* to complete the Pipeline's execution.\n[.boxshadow]\n\nSelect the "
  },
  "1255": {
    "source_file": "create-a-pipeline-in-blue-ocean.txt",
    "text": "itle *Welcome to React*.\nWhen you are finished viewing the page/site, select *Proceed* to complete the Pipeline's execution.\n[.boxshadow]\n\nSelect the *X* in the top-right corner to return to the main Blue Ocean interface, which lists your previous Pipeline runs in reverse chronological order.\n[.boxshadow]\n\nIf you check the contents of the `Jenkinsfile` that Blue Ocean created at the root of your f"
  },
  "1256": {
    "source_file": "create-a-pipeline-in-blue-ocean.txt",
    "text": "peline runs in reverse chronological order.\n[.boxshadow]\n\nIf you check the contents of the `Jenkinsfile` that Blue Ocean created at the root of your forked `creating-a-pipeline-in-blue-ocean` repository, note the location of the  directive.\nThis directive's location within the \"Test\" stage means that the environment variable `CI`, with its value of `true`, is only available within the scope of thi"
  },
  "1257": {
    "source_file": "create-a-pipeline-in-blue-ocean.txt",
    "text": "ctive's location within the \"Test\" stage means that the environment variable `CI`, with its value of `true`, is only available within the scope of this \"Test\" stage.\n\nYou can set this directive in Blue Ocean, so that its environment variable is available globally throughout Pipeline.\nThis is also configured in the  tutorial.\n\nTo do this:\n\nFrom the main Blue Ocean interface, select *Branches* in th"
  },
  "1258": {
    "source_file": "create-a-pipeline-in-blue-ocean.txt",
    "text": "able globally throughout Pipeline.\nThis is also configured in the  tutorial.\n\nTo do this:\n\nFrom the main Blue Ocean interface, select *Branches* in the upper right to access your repository's `master` branch.\nSelect the `master` branch's \"Edit Pipeline\" icon  to open the Pipeline editor for this branch.\nIn the main Pipeline editor, select the *Test* stage you created <<add-a-test-stage-to-your-pip"
  },
  "1259": {
    "source_file": "create-a-pipeline-in-blue-ocean.txt",
    "text": "ne\" icon  to open the Pipeline editor for this branch.\nIn the main Pipeline editor, select the *Test* stage you created <<add-a-test-stage-to-your-pipeline,above>> to begin editing it.\nIn the stage panel, select *Settings* to reveal this section of the panel.\nSelect the minus (*-*) icon associated with the `CI` environment directive you created earlier to delete it.\nSelect the back arrow icon  to "
  },
  "1260": {
    "source_file": "create-a-pipeline-in-blue-ocean.txt",
    "text": "he panel.\nSelect the minus (*-*) icon associated with the `CI` environment directive you created earlier to delete it.\nSelect the back arrow icon  to return to the main Pipeline editor.\nIn the *Pipeline Settings* panel, select the *+* icon to the right side of the *Environment* heading.\nHere, you'll configure a _global_ environment directive.\nIn the *Name* and *Value* fields, specify `CI` and `tru"
  },
  "1261": {
    "source_file": "create-a-pipeline-in-blue-ocean.txt",
    "text": "ht side of the *Environment* heading.\nHere, you'll configure a _global_ environment directive.\nIn the *Name* and *Value* fields, specify `CI` and `true`, respectively.\nSelect the *Save* button to begin saving your Pipeline with with its relocated environment directive.\nIn the *Save Pipeline* dialog box, enter the commit message in the *Description* field, for example `Make environment directive gl"
  },
  "1262": {
    "source_file": "create-a-pipeline-in-blue-ocean.txt",
    "text": "ironment directive.\nIn the *Save Pipeline* dialog box, enter the commit message in the *Description* field, for example `Make environment directive global`.\nLeave all other options set to their default, and then select *Save & run*.\nJenkins proceeds to build your amended Pipeline.\nWhen the main Blue Ocean interface appears, select the _top_ row to see Jenkins build your Pipeline project.\nThis star"
  },
  "1263": {
    "source_file": "create-a-pipeline-in-blue-ocean.txt",
    "text": "to build your amended Pipeline.\nWhen the main Blue Ocean interface appears, select the _top_ row to see Jenkins build your Pipeline project.\nThis starts the same build process as when you completed adding the final deliver stage <<add-a-final-deliver-stage-to-your-pipeline,above>>.\nHowever, when you inspect the `Jenkinsfile` again, you'll notice that the `environment` directive is now a sibling of"
  },
  "1264": {
    "source_file": "create-a-pipeline-in-blue-ocean.txt",
    "text": "-stage-to-your-pipeline,above>>.\nHowever, when you inspect the `Jenkinsfile` again, you'll notice that the `environment` directive is now a sibling of the `agent` section.\n\nWell done! You've used the Blue Ocean feature of Jenkins to build a simple Node.js and React application with npm.\n\nThe \"Build,\" \"Test,\" and \"Deliver\" stages you created are the basis for building other applications in Jenkins "
  },
  "1265": {
    "source_file": "create-a-pipeline-in-blue-ocean.txt",
    "text": "de.js and React application with npm.\n\nThe \"Build,\" \"Test,\" and \"Deliver\" stages you created are the basis for building other applications in Jenkins with any technology stack, including more complex applications and ones that combine multiple technology stacks.\n\nBecause Jenkins is extremely extensible, it can be modified and configured to handle almost any aspect of build orchestration and automa"
  },
  "1266": {
    "source_file": "create-a-pipeline-in-blue-ocean.txt",
    "text": "logy stacks.\n\nBecause Jenkins is extremely extensible, it can be modified and configured to handle almost any aspect of build orchestration and automation.\n\nTo learn more about what Jenkins can do, check out:\n\n* The  page for other introductory tutorials.\n* The  for more detailed information about using Jenkins, such as , , and the  interface.\n* The  for the latest events, other tutorials, and upd"
  },
  "1267": {
    "source_file": "create-a-pipeline-in-blue-ocean.txt",
    "text": "ials.\n* The  for more detailed information about using Jenkins, such as , , and the  interface.\n* The  for the latest events, other tutorials, and updates.\n\n'''\n+++\n\n+++"
  },
  "1268": {
    "source_file": "create.txt",
    "text": "layout: developer\ntitle: Create a Plugin\n\n\n-\n-\n-\n-\n\nAfter , the next step is to create a new plugin.\n\nNOTE: If your intention is to publish your plugin on the Jenkins update site, now is a good time to look for plugins that already do something similar.\nSee  for more information.\n\nOpen a command prompt, navigate to the directory you want to store your new Jenkins plugin in, and run the following c"
  },
  "1269": {
    "source_file": "create.txt",
    "text": "ar.\nSee  for more information.\n\nOpen a command prompt, navigate to the directory you want to store your new Jenkins plugin in, and run the following command:\n\nmvn -U archetype:generate -Dfilter=io.jenkins.archetypes:\n\nThis command will let you generate one of several project archetypes related to Jenkins.\nIn this tutorial we're going to use the `hello-world` archetype, so select the most recent ve"
  },
  "1270": {
    "source_file": "create.txt",
    "text": "te one of several project archetypes related to Jenkins.\nIn this tutorial we're going to use the `hello-world` archetype, so select the most recent version of that archetype:\n\n// https://asciidoctor.org/docs/user-manual/#applying-substitutions\n\nmvn -U archetype:generate -Dfilter=io.jenkins.archetypes:\n\u2026\nChoose archetype:\n1: remote -> io.jenkins.archetypes:empty-plugin (Skeleton of a Jenkins plugin"
  },
  "1271": {
    "source_file": "create.txt",
    "text": "U archetype:generate -Dfilter=io.jenkins.archetypes:\n\u2026\nChoose archetype:\n1: remote -> io.jenkins.archetypes:empty-plugin (Skeleton of a Jenkins plugin with a POM and an empty source tree.)\n2: remote -> io.jenkins.archetypes:global-configuration-plugin (Skeleton of a Jenkins plugin with a POM and an example piece of global configuration.)\n3: remote -> io.jenkins.archetypes:global-shared-library (Us"
  },
  "1272": {
    "source_file": "create.txt",
    "text": "n (Skeleton of a Jenkins plugin with a POM and an example piece of global configuration.)\n3: remote -> io.jenkins.archetypes:global-shared-library (Uses the Jenkins Pipeline Unit mock library to test the usage of a Global Shared Library)\n4: remote -> io.jenkins.archetypes:hello-world-plugin (Skeleton of a Jenkins plugin with a POM and an example build step.)\n5: remote -> io.jenkins.archetypes:scri"
  },
  "1273": {
    "source_file": "create.txt",
    "text": " io.jenkins.archetypes:hello-world-plugin (Skeleton of a Jenkins plugin with a POM and an example build step.)\n5: remote -> io.jenkins.archetypes:scripted-pipeline (Uses the Jenkins Pipeline Unit mock library to test the logic inside a Pipeline script.)\nChoose a number or apply filter (format: [groupId:]artifactId, case sensitive contains): : *4* // <1> Choose io.jenkins.archetypes:hello-world-plu"
  },
  "1274": {
    "source_file": "create.txt",
    "text": "t.)\nChoose a number or apply filter (format: [groupId:]artifactId, case sensitive contains): : *4* // <1> Choose io.jenkins.archetypes:hello-world-plugin version:\n1: 1.1\n2: 1.2\n3: 1.3\n4: 1.4\n5: 1.5\n6: 1.6\n7: 1.7\n8: 1.8\n9: 1.9\n10: 1.10\n11: 1.11\n12: 1.12\n13: 1.13\n14: 1.14\n15: 1.15\n16: 1.16\n17: 1.17\n18: 1.19\n19: 1.20\n20: 1.21\n21: 1.22\n22: 1.23\n23: 1.24\n24: 1.25\n25: 1.26\n26: 1.27\n27: 1.28\n28: 1.29\n29:"
  },
  "1275": {
    "source_file": "create.txt",
    "text": "12\n13: 1.13\n14: 1.14\n15: 1.15\n16: 1.16\n17: 1.17\n18: 1.19\n19: 1.20\n20: 1.21\n21: 1.22\n22: 1.23\n23: 1.24\n24: 1.25\n25: 1.26\n26: 1.27\n27: 1.28\n28: 1.29\n29: 1.30\n\nChoose a number: 29: *29* // <2> \u2026\n[INFO] Using property: groupId = unused // <3> [INFO] Using property: package = io.jenkins.plugins.sample\n[INFO] Using property: hostOnJenkinsGitHub = true\nDefine value for property 'artifactId': *demo* // <4"
  },
  "1276": {
    "source_file": "create.txt",
    "text": "g property: package = io.jenkins.plugins.sample\n[INFO] Using property: hostOnJenkinsGitHub = true\nDefine value for property 'artifactId': *demo* // <4> Define value for property 'version' 1.0-SNAPSHOT: : // <5> Confirm properties configuration:\ngroupId: unused\npackage: io.jenkins.plugins.sample\nhostOnJenkinsGitHub: true\nartifactId: demo\nversion: 1.0-SNAPSHOT\n Y: : *y* // <6> <1> Enter the number f"
  },
  "1277": {
    "source_file": "create.txt",
    "text": "Id: unused\npackage: io.jenkins.plugins.sample\nhostOnJenkinsGitHub: true\nartifactId: demo\nversion: 1.0-SNAPSHOT\n Y: : *y* // <6> <1> Enter the number for the `hello-world-plugin` archetype, *4* in this case.\n<2> This tutorial is based on version 1.30 of the *hello-world-plugin* archetype, so enter *29* to select it.\n<3> `groupId` uniquely identifies your project across all projects.\n    A group ID "
  },
  "1278": {
    "source_file": "create.txt",
    "text": "of the *hello-world-plugin* archetype, so enter *29* to select it.\n<3> `groupId` uniquely identifies your project across all projects.\n    A group ID should follow Java's package name rules.\n    This means it starts with a reversed domain name.\n    For example: `io.jenkins.plugins`\n<4> `artifactId` is mandatory and uniquely identifies your plugin in Jenkins.\n    It is the unique base name of the p"
  },
  "1279": {
    "source_file": "create.txt",
    "text": "or example: `io.jenkins.plugins`\n<4> `artifactId` is mandatory and uniquely identifies your plugin in Jenkins.\n    It is the unique base name of the primary artifact being generated by this maven project.\n    This plugin tutorial uses the name `demo` (user input highlighted in bold).\n    If you want to publish your plugin, make sure the name is not already taken, and that the name you choose is fu"
  },
  "1280": {
    "source_file": "create.txt",
    "text": " (user input highlighted in bold).\n    If you want to publish your plugin, make sure the name is not already taken, and that the name you choose is future-proof:\n    the `artifactId` cannot be changed after you've published your first release.\n    Do _not_ use the words `jenkins` or `plugin` in this ID\u2014only the words describing what kind of Jenkins plugin this is.\n<5> There's no need to choose a d"
  },
  "1281": {
    "source_file": "create.txt",
    "text": " _not_ use the words `jenkins` or `plugin` in this ID\u2014only the words describing what kind of Jenkins plugin this is.\n<5> There's no need to choose a different version number here. This is the development version (indicated by `SNAPSHOT`) of version 1.0.\n\n<6> After you enter all the values, Maven will show them again. Review and confirm your selection.\n\nThis creates a directory with the same name a"
  },
  "1282": {
    "source_file": "create.txt",
    "text": ".0.\n\n<6> After you enter all the values, Maven will show them again. Review and confirm your selection.\n\nThis creates a directory with the same name as the plugin\u2019s `artifactId` (`demo` in this case),\nand adds the basic structure for a working plugin.\nLet\u2019s make sure we can build the plugin:\n\nmv demo demo-plugin // <1> cd demo-plugin\nmvn verify\n\n<1> Maven has created the project structure in a dir"
  },
  "1283": {
    "source_file": "create.txt",
    "text": ".\nLet\u2019s make sure we can build the plugin:\n\nmv demo demo-plugin // <1> cd demo-plugin\nmvn verify\n\n<1> Maven has created the project structure in a directory with the same name as you chose for your plugin.\n    We will rename the directory to match the conventional repository names used in the GitHub organization `@jenkinsci`.\n\nMaven will download several more dependencies, and then go through the "
  },
  "1284": {
    "source_file": "create.txt",
    "text": "e conventional repository names used in the GitHub organization `@jenkinsci`.\n\nMaven will download several more dependencies, and then go through the configured build lifecycle, including static analysis (Spotbugs) and tests, until it shows something like this:\n\n[listing]\n[INFO]\n[INFO] BUILD SUCCESS\n[INFO]\n[INFO] Total time:  47.141 s\n[INFO] Finished at: 2022-11-17T10:04:29-07:00\n[INFO]\n\nNOTE: To "
  },
  "1285": {
    "source_file": "create.txt",
    "text": " like this:\n\n[listing]\n[INFO]\n[INFO] BUILD SUCCESS\n[INFO]\n[INFO] Total time:  47.141 s\n[INFO] Finished at: 2022-11-17T10:04:29-07:00\n[INFO]\n\nNOTE: To learn more about what's involved in a plugin build, see .  The  provides helpful information as well.\n\nNot the output you're seeing? See the <<Troubleshooting>> section below.\n\nLet's  and see what it does.\n\nNOTE: Anything not working for you? Ask for"
  },
  "1286": {
    "source_file": "create.txt",
    "text": ".\n\nNot the output you're seeing? See the <<Troubleshooting>> section below.\n\nLet's  and see what it does.\n\nNOTE: Anything not working for you? Ask for help in  or .\n\nIf the `archetype:generate` command hangs, it could be . Try:\n\necho '<settings/>' > /tmp/empty.xml\nmvn -s /tmp/empty.xml -U archetype:generate -Dfilter=io.jenkins.archetypes:"
  },
  "1287": {
    "source_file": "create.txt",
    "text": "/tmp/empty.xml\nmvn -s /tmp/empty.xml -U archetype:generate -Dfilter=io.jenkins.archetypes:"
  },
  "1288": {
    "source_file": "creating-a-pipeline-in-blue-ocean.txt",
    "text": "layout: redirect\nredirect_url: ../create-a-pipeline-in-blue-ocean"
  },
  "1289": {
    "source_file": "creating-pipelines.txt",
    "text": "layout: section\ntitle: Creating a Pipeline\n\n\nifdef::env-github[:imagesdir: ../resources]\nifndef::env-github[:imagesdir: ../../resources]\n\n// Show 3/3 of the Blue ocean admonitions\n\nBlue Ocean makes it easy to create a Pipeline project in Jenkins.\n\nYou can generate a Pipeline from an existing `Jenkinsfile` in source control, or you can use the  to create a Pipeline as a `Jenkinsfile` that is commit"
  },
  "1290": {
    "source_file": "creating-pipelines.txt",
    "text": "u can generate a Pipeline from an existing `Jenkinsfile` in source control, or you can use the  to create a Pipeline as a `Jenkinsfile` that is committed to source control.\n\nTo start setting up your Pipeline project in Blue Ocean, select the *New Pipeline* button at the top-right of the .\n\n[.boxshadow]\n\nIf your Jenkins instance is new or has no Pipeline projects or other items configured, Blue Oce"
  },
  "1291": {
    "source_file": "creating-pipelines.txt",
    "text": "eline* button at the top-right of the .\n\n[.boxshadow]\n\nIf your Jenkins instance is new or has no Pipeline projects or other items configured, Blue Ocean displays a *Welcome to Jenkins* message that allows you to select the *Create a new Pipeline* option to start setting up your Pipeline project.\n\n[.boxshadow]\n\nYou now have a choice of creating your new Pipeline project from a:\n\n*\n*  or GitHub Ente"
  },
  "1292": {
    "source_file": "creating-pipelines.txt",
    "text": "ion to start setting up your Pipeline project.\n\n[.boxshadow]\n\nYou now have a choice of creating your new Pipeline project from a:\n\n*\n*  or GitHub Enterprise\n*  or Bitbucket Server\n\nTo create your Pipeline project for a Git repository, click the *Git* button\nunder *Where do you store your code?*\n\n[.boxshadow]\n\nIn the *Connect to a Git repository* section, enter the URL for your Git repository in th"
  },
  "1293": {
    "source_file": "creating-pipelines.txt",
    "text": " button\nunder *Where do you store your code?*\n\n[.boxshadow]\n\nIn the *Connect to a Git repository* section, enter the URL for your Git repository in the *Repository URL* field.\n\n[.boxshadow]\n\nYou now must specify a  or  repository from which to build your Pipeline project.\n\nIf your URL is a local directory path beginning with a forward slash `/`, such as `/home/cloned-git-repos/my-git-repo.git`, yo"
  },
  "1294": {
    "source_file": "creating-pipelines.txt",
    "text": "your Pipeline project.\n\nIf your URL is a local directory path beginning with a forward slash `/`, such as `/home/cloned-git-repos/my-git-repo.git`, you can proceed to select the *Create Pipeline* option.\n\nBlue Ocean then scans your local repository's branches for a `Jenkinsfile`, and starts a Pipeline run for each branch containing a `Jenkinsfile`.\nIf Blue Ocean cannot find a `Jenkinsfile`, you ar"
  },
  "1295": {
    "source_file": "creating-pipelines.txt",
    "text": " branches for a `Jenkinsfile`, and starts a Pipeline run for each branch containing a `Jenkinsfile`.\nIf Blue Ocean cannot find a `Jenkinsfile`, you are prompted to create one through the <<pipeline-editor#,Pipeline editor>>.\n\nLocal repositories are typically limited to file system access and are normally only available from the controller node.\nLocal repositories are also known to require more com"
  },
  "1296": {
    "source_file": "creating-pipelines.txt",
    "text": "ypically limited to file system access and are normally only available from the controller node.\nLocal repositories are also known to require more complicated path names on Windows than most users want to manage.\nUsers are advised to run jobs on agents, rather than running them directly on the controller.\nTherefore, you should use a remote repository rather than a local repository for the best Blu"
  },
  "1297": {
    "source_file": "creating-pipelines.txt",
    "text": "ts, rather than running them directly on the controller.\nTherefore, you should use a remote repository rather than a local repository for the best Blue Ocean experience.\n\nSince the Pipeline editor saves edited Pipelines to Git repositories as `Jenkinsfile`s, Blue Ocean only supports connections to remote Git repositories over the SSH protocol.\n\nIf your URL is for a remote Git repository, be sure y"
  },
  "1298": {
    "source_file": "creating-pipelines.txt",
    "text": "sfile`s, Blue Ocean only supports connections to remote Git repositories over the SSH protocol.\n\nIf your URL is for a remote Git repository, be sure your URL starts with either:\n\n* `ssh://` - which displays as `ssh://gituser@git-server-url/git-server-repos-group/my-git-repo.git` +\nor\n* `user@host:path/to/git/repo.git` - which displays as\n`gituser@git-server-url:git-server-repos-group/my-git-repo.g"
  },
  "1299": {
    "source_file": "creating-pipelines.txt",
    "text": "-repos-group/my-git-repo.git` +\nor\n* `user@host:path/to/git/repo.git` - which displays as\n`gituser@git-server-url:git-server-repos-group/my-git-repo.git`\n\nBlue Ocean automatically generates an SSH public/private key pair or provides you with an existing pair for the current Jenkins user.\nThis credential is automatically registered in Jenkins with the following details for this Jenkins user:\n\n* *Do"
  },
  "1300": {
    "source_file": "creating-pipelines.txt",
    "text": "ing pair for the current Jenkins user.\nThis credential is automatically registered in Jenkins with the following details for this Jenkins user:\n\n* *Domain*: `blueocean-private-key-domain`\n* *ID*: `jenkins-generated-ssh-key`\n* *Name*: `<jenkins-username> (jenkins-generated-ssh-key)`\n\nYou must ensure that this SSH public/private key pair is registered with your Git server before continuing.\n\nIf you "
  },
  "1301": {
    "source_file": "creating-pipelines.txt",
    "text": "me> (jenkins-generated-ssh-key)`\n\nYou must ensure that this SSH public/private key pair is registered with your Git server before continuing.\n\nIf you have not already done this, follow these two steps.\n\nConfigure the SSH public key component of this key pair (which you can copy and paste from the Blue Ocean interface) for the remote Git server's user  account (e.g., within the `authorized_keys` fi"
  },
  "1302": {
    "source_file": "creating-pipelines.txt",
    "text": "key pair (which you can copy and paste from the Blue Ocean interface) for the remote Git server's user  account (e.g., within the `authorized_keys` file of the machine's `gituser/.ssh` directory).\nNOTE: This process allows your Jenkins user to access the repositories that your Git server's user account has access to. Refer to the  of the .\n\nReturn to the Blue Ocean interface.\n\nSelect the *Create P"
  },
  "1303": {
    "source_file": "creating-pipelines.txt",
    "text": " the repositories that your Git server's user account has access to. Refer to the  of the .\n\nReturn to the Blue Ocean interface.\n\nSelect the *Create Pipeline* option.\n\nBlue Ocean scans your local repository's branches for a `Jenkinsfile` and starts a Pipeline run for each branch containing a `Jenkinsfile`.\nIf Blue Ocean does not find a `Jenkinsfile` you are prompted to create one through the .\n\nTo"
  },
  "1304": {
    "source_file": "creating-pipelines.txt",
    "text": " Pipeline run for each branch containing a `Jenkinsfile`.\nIf Blue Ocean does not find a `Jenkinsfile` you are prompted to create one through the .\n\nTo create your Pipeline project directly for a repository on GitHub, select the *GitHub* option under *Where do you store your code?*.\n\n[.boxshadow]\n\nIn the *Connect to GitHub* section, enter your GitHub access token into the *Your GitHub access token*"
  },
  "1305": {
    "source_file": "creating-pipelines.txt",
    "text": "*Where do you store your code?*.\n\n[.boxshadow]\n\nIn the *Connect to GitHub* section, enter your GitHub access token into the *Your GitHub access token* field. +\nIf you previously configured Blue Ocean to connect to GitHub using a personal access token, Blue Ocean takes you directly to the\n<<choose-your-github-account,GitHub account/organization and repository choice>> steps below:\n\n[.boxshadow]\n\nIf"
  },
  "1306": {
    "source_file": "creating-pipelines.txt",
    "text": ", Blue Ocean takes you directly to the\n<<choose-your-github-account,GitHub account/organization and repository choice>> steps below:\n\n[.boxshadow]\n\nIf you do not have a GitHub access token, select the *Create an access key here* option to open GitHub to the  page.\n\nIn the new tab, sign in to your GitHub account.\nOn the *New Personal Access Token* page, specify a brief *Token description* for your "
  },
  "1307": {
    "source_file": "creating-pipelines.txt",
    "text": " to the  page.\n\nIn the new tab, sign in to your GitHub account.\nOn the *New Personal Access Token* page, specify a brief *Token description* for your GitHub access token, such as `Blue Ocean`.\nNOTE: An access token is usually an alphanumeric string that represents your GitHub account, along with permissions to access various GitHub features and areas through your GitHub account.\nThe new access tok"
  },
  "1308": {
    "source_file": "creating-pipelines.txt",
    "text": "hat represents your GitHub account, along with permissions to access various GitHub features and areas through your GitHub account.\nThe new access token process, initiated by selecting *Create an access key here*, has the appropriate permissions pre-selected that Blue Ocean requires to access and interact with your GitHub account.\n\nScroll down to the end of the page, and select *Generate token*.\nO"
  },
  "1309": {
    "source_file": "creating-pipelines.txt",
    "text": "selected that Blue Ocean requires to access and interact with your GitHub account.\n\nScroll down to the end of the page, and select *Generate token*.\nOn the resulting *Personal access tokens* page, copy your newly generated access token.\nBack in Blue Ocean, paste the access token into the *Your GitHub access token* field, and then select *Connect*.\n\nYour current Jenkins user now has access to your "
  },
  "1310": {
    "source_file": "creating-pipelines.txt",
    "text": "Ocean, paste the access token into the *Your GitHub access token* field, and then select *Connect*.\n\nYour current Jenkins user now has access to your GitHub account and you can now <<choose-your-github-account,choose your GitHub account/organization and repository>>.\nJenkins registers this credential with the following details for this Jenkins user:\n\n* *Domain*: `blueocean-github-domain`\n* *ID*: `"
  },
  "1311": {
    "source_file": "creating-pipelines.txt",
    "text": "and repository>>.\nJenkins registers this credential with the following details for this Jenkins user:\n\n* *Domain*: `blueocean-github-domain`\n* *ID*: `github`\n* *Name*: `+<jenkins-username>/****** (GitHub Access Token)+`\n\n[[choose-your-github-account]]\n\nBlue Ocean prompts you to choose your GitHub account or an organization you are a member of.\nYou are also asked for the repository containing your "
  },
  "1312": {
    "source_file": "creating-pipelines.txt",
    "text": "]\n\nBlue Ocean prompts you to choose your GitHub account or an organization you are a member of.\nYou are also asked for the repository containing your Pipeline project.\n\nIn the *Which organization does the repository belong to?* section, select either:\n* Your GitHub account, to create a Pipeline project for one of your own GitHub repositories or one which you have forked from elsewhere on GitHub. +"
  },
  "1313": {
    "source_file": "creating-pipelines.txt",
    "text": ":\n* Your GitHub account, to create a Pipeline project for one of your own GitHub repositories or one which you have forked from elsewhere on GitHub. +\nor\n* The organization of which you are a member, to create a Pipeline project for a GitHub repository located within this organization.\n\nIn the *Choose a repository* section, select the repository within your GitHub account or organization from whic"
  },
  "1314": {
    "source_file": "creating-pipelines.txt",
    "text": "ry located within this organization.\n\nIn the *Choose a repository* section, select the repository within your GitHub account or organization from which to build your Pipeline project.\nTIP: If your list of repositories is long, you can use the *Search* option to filter your results.\n\n[.boxshadow]\n\nClick *Create Pipeline*.\n\nBlue Ocean scans your local repository's branches for a `Jenkinsfile` and st"
  },
  "1315": {
    "source_file": "creating-pipelines.txt",
    "text": "* option to filter your results.\n\n[.boxshadow]\n\nClick *Create Pipeline*.\n\nBlue Ocean scans your local repository's branches for a `Jenkinsfile` and starts a Pipeline run for each branch containing a `Jenkinsfile`.\nIf Blue Ocean does not find a `Jenkinsfile`, you are prompted to create one through the .\n\nNOTE: Under the hood, a Pipeline project created through Blue Ocean is actually a \"multibranch "
  },
  "1316": {
    "source_file": "creating-pipelines.txt",
    "text": "nsfile`, you are prompted to create one through the .\n\nNOTE: Under the hood, a Pipeline project created through Blue Ocean is actually a \"multibranch Pipeline.\"\nTherefore, Jenkins looks for the presence of at least one Jenkinsfile in any branch of your repository.\n\nTo create your Pipeline project directly for a Git or Mercurial repository on Bitbucket Cloud, select the *Bitbucket Cloud* button und"
  },
  "1317": {
    "source_file": "creating-pipelines.txt",
    "text": "ur repository.\n\nTo create your Pipeline project directly for a Git or Mercurial repository on Bitbucket Cloud, select the *Bitbucket Cloud* button under *Where do you store your code?*\n\n[.boxshadow]\n\nIn the *Connect to Bitbucket* section, enter your Bitbucket email address and password into the *Username* and *Password* fields.\n\n* If you previously configured Blue Ocean to connect to Bitbucket wit"
  },
  "1318": {
    "source_file": "creating-pipelines.txt",
    "text": "Bitbucket email address and password into the *Username* and *Password* fields.\n\n* If you previously configured Blue Ocean to connect to Bitbucket with your email address and password, Blue Ocean takes you directly to the  steps below.\n* If you entered these credentials, Jenkins registers them with the following details for this Jenkins user:\n\n* *Domain*: `blueocean-bitbucket-cloud-domain`\n* *ID*:"
  },
  "1319": {
    "source_file": "creating-pipelines.txt",
    "text": "ed these credentials, Jenkins registers them with the following details for this Jenkins user:\n\n* *Domain*: `blueocean-bitbucket-cloud-domain`\n* *ID*: `bitbucket-cloud`\n* *Name*: `+<bitbucket-user@email.address>/****** (Bitbucket server credentials)`\n\n[.boxshadow]\n\nSelect *Connect* and your current/logged in Jenkins user will now have access to your Bitbucket account.\nYou can now <<choose-your-bit"
  },
  "1320": {
    "source_file": "creating-pipelines.txt",
    "text": "\n\n[.boxshadow]\n\nSelect *Connect* and your current/logged in Jenkins user will now have access to your Bitbucket account.\nYou can now <<choose-your-bitbucket-account,choose your Bitbucket account/team and repository>>.\n\n[[choose-your-bitbucket-account]]\n\nBlue Ocean prompts you to choose your Bitbucket account or a team you are a member of, as well as the repository containing your project to be bui"
  },
  "1321": {
    "source_file": "creating-pipelines.txt",
    "text": "]]\n\nBlue Ocean prompts you to choose your Bitbucket account or a team you are a member of, as well as the repository containing your project to be built.\n\nIn the *Which team does the repository belong to?* section, select either:\n\n* Your Bitbucket account to create a Pipeline project for one of your own Bitbucket repositories, or one which you have forked from elsewhere on Bitbucket.\n* A team of w"
  },
  "1322": {
    "source_file": "creating-pipelines.txt",
    "text": "count to create a Pipeline project for one of your own Bitbucket repositories, or one which you have forked from elsewhere on Bitbucket.\n* A team of which you are a member to create a Pipeline project for a Bitbucket repository located within this team.\n\nIn the *Choose a repository* section, select the repository in your Bitbucket account or team from which to build your Pipeline project.\nTIP: If "
  },
  "1323": {
    "source_file": "creating-pipelines.txt",
    "text": "am.\n\nIn the *Choose a repository* section, select the repository in your Bitbucket account or team from which to build your Pipeline project.\nTIP: If your list of repositories is long, you can filter this list using the *Search* option.\n[.boxshadow]\n\nClick *Create Pipeline*. +\n\nBlue Ocean scans your local repository's branches for a `Jenkinsfile` and starts a Pipeline run for each branch containin"
  },
  "1324": {
    "source_file": "creating-pipelines.txt",
    "text": "\nClick *Create Pipeline*. +\n\nBlue Ocean scans your local repository's branches for a `Jenkinsfile` and starts a Pipeline run for each branch containing a `Jenkinsfile`.\nIf Blue Ocean does not find a `Jenkinsfile`, you are prompted to create one through the .\n\nNOTE: Under the hood, a Pipeline project created through Blue Ocean is actually a \"multibranch Pipeline.\"\nTherefore, Jenkins looks for the p"
  },
  "1325": {
    "source_file": "creating-pipelines.txt",
    "text": "gh the .\n\nNOTE: Under the hood, a Pipeline project created through Blue Ocean is actually a \"multibranch Pipeline.\"\nTherefore, Jenkins looks for the presence of at least one Jenkinsfile in any branch of your repository."
  },
  "1326": {
    "source_file": "credentials.txt",
    "text": "title: Credentials\nlayout: section\n\n\nifdef::env-github[:imagesdir: ../resources]\nifndef::env-github[:imagesdir: ../../resources]\n\nUse credentials to secure access to\nexternal sites and applications that can interact with Jenkins such as artifact repositories, cloud-based storage systems and services, and databases.\nThis is both more secure and more convenient than hard coding username and password"
  },
  "1327": {
    "source_file": "credentials.txt",
    "text": "sitories, cloud-based storage systems and services, and databases.\nThis is both more secure and more convenient than hard coding username and password or other authentication devices in each Pipeline.\n\nThis page summarizes the best practices for securing your credentials.\n\nImplementing credentials has two elements:\n\n* Configure the credential. See\n\non the\n\npage.\n\n* Call credentials in the Pipeline"
  },
  "1328": {
    "source_file": "credentials.txt",
    "text": "ring your credentials.\n\nImplementing credentials has two elements:\n\n* Configure the credential. See\n\non the\n\npage.\n\n* Call credentials in the Pipeline to gain access to an external resource.\nSee\n\non the\n\npage.\n\nLimit the scope of who has access to the credentials.\nThis minimizes the attack surface.\nYou should \"build from the bottom\".\nIn other words, start with no access to the credentials\nand then"
  },
  "1329": {
    "source_file": "credentials.txt",
    "text": "e credentials.\nThis minimizes the attack surface.\nYou should \"build from the bottom\".\nIn other words, start with no access to the credentials\nand then grant access to specific people and projects\nrather than granting access to everyone and then removing some grants.\nSpecifically:\n\n* Severely limit the number of people with *Credentials > Create* permissions.\n\n* Grant access only to specific people"
  },
  "1330": {
    "source_file": "credentials.txt",
    "text": "ing some grants.\nSpecifically:\n\n* Severely limit the number of people with *Credentials > Create* permissions.\n\n* Grant access only to specific people, projects, and items\nthat actually require this access to do their jobs.\n\n* Define each credential at the lowest possible level.\nCredentials defined for the controller\nare available to all Pipelines run by that controller.\nCredentials defined for a "
  },
  "1331": {
    "source_file": "credentials.txt",
    "text": "at the lowest possible level.\nCredentials defined for the controller\nare available to all Pipelines run by that controller.\nCredentials defined for a folder are only available to Pipelines run from that folder.\nThe screens used to add and manage credentials for controllers and folders\nare identical except for their location.\n\nKeys to decrypt secrets are stored\nin the _$JENKINS_HOME/secrets/_ direc"
  },
  "1332": {
    "source_file": "credentials.txt",
    "text": "entials for controllers and folders\nare identical except for their location.\n\nKeys to decrypt secrets are stored\nin the _$JENKINS_HOME/secrets/_ directory.\nThis directory has restrictive Linux file system permissions\nand should be carefully protected:\n\n* You must be able to retrieve your secrets if you need to restore your instance.\n* If someone were to get access to your backups as well as the se"
  },
  "1333": {
    "source_file": "credentials.txt",
    "text": ":\n\n* You must be able to retrieve your secrets if you need to restore your instance.\n* If someone were to get access to your backups as well as the secret,\nthey would have full access to your entire Jenkins instance and everything it accesses.\n\nThe following practices are recommended to ensure that your secrets are kept secret:\n\n* Never include the _secrets_ directory in a backup of your instance."
  },
  "1334": {
    "source_file": "credentials.txt",
    "text": "ollowing practices are recommended to ensure that your secrets are kept secret:\n\n* Never include the _secrets_ directory in a backup of your instance.\n\n* Do not store keys in the SCM where their contents could be breached.\n** A disk crash or data corruption for your application\ncould cause the loss of all the encrypted information for your instance.\n** If someone breaches your SCM and your _secret"
  },
  "1335": {
    "source_file": "credentials.txt",
    "text": "ruption for your application\ncould cause the loss of all the encrypted information for your instance.\n** If someone breaches your SCM and your _secrets_ are there,\nthey have full access to your Jenkins instance.\n\n* Instead, keep a copy of the secrets in a location apart from other backups and copies of your application.\nThe secret is small and never changes after it is created.\nYou can manually re"
  },
  "1336": {
    "source_file": "credentials.txt",
    "text": " in a location apart from other backups and copies of your application.\nThe secret is small and never changes after it is created.\nYou can manually re-add it when restoring from backup.\n\n* Modify the underlying credentials (username/password, secret text, etc) frequently."
  },
  "1337": {
    "source_file": "credentials.txt",
    "text": "text, etc) frequently."
  },
  "1338": {
    "source_file": "crowdin-integration.txt",
    "text": "title: Setup a Crowdin Project\nlayout: developersection\n\n\nCrowdin is an agile translation tool, which provides a modern web interface to propose and review translations with ease, without the need of any prerequisites you normally need, when working with Jenkins views.\n\nThis guide aims to provide guidance for project maintainers, how to prepare and setup their project, in order to use crowdin.jenk"
  },
  "1339": {
    "source_file": "crowdin-integration.txt",
    "text": "with Jenkins views.\n\nThis guide aims to provide guidance for project maintainers, how to prepare and setup their project, in order to use crowdin.jenkins.io.\nThis guide is not needed for people, who want to translate plugins only and aren't plugin maintainers.\nRefer to  if you want to learn more about using Crowdin as a translator.\n\nBefore integrating your project with Crowdin, you should have int"
  },
  "1340": {
    "source_file": "crowdin-integration.txt",
    "text": "intainers.\nRefer to  if you want to learn more about using Crowdin as a translator.\n\nBefore integrating your project with Crowdin, you should have internationalized it.\nInternationalization documentation for Jelly, Java and Groovy can be found .\n\nTo request the creation of a new project,\nfill out a crowdin issue on the .\n\nOn GitHub, open the repository you want to integrate. Navigate to \"Actions\" "
  },
  "1341": {
    "source_file": "crowdin-integration.txt",
    "text": "request the creation of a new project,\nfill out a crowdin issue on the .\n\nOn GitHub, open the repository you want to integrate. Navigate to \"Actions\" -> \"New workflow\" and select \"By Jenkins\" -> \"Crowdin integration\" -> \"Configure\".\n\nThe default workflow requires one modification in order to work. +\nChange `CROWDIN_PROJECT_ID: #` to the actual project ID. You can find it in the URL if you edit the"
  },
  "1342": {
    "source_file": "crowdin-integration.txt",
    "text": "flow requires one modification in order to work. +\nChange `CROWDIN_PROJECT_ID: #` to the actual project ID. You can find it in the URL if you edit the project settings on crowdin.jenkins.io, for example `https://jenkins.crowdin.com/u/projects/4/crowdsource`, in this case, the project ID is `4`. You can find your project ID in your helpdesk issue too, if your project has been created.\n\nTo let the G"
  },
  "1343": {
    "source_file": "crowdin-integration.txt",
    "text": "source`, in this case, the project ID is `4`. You can find your project ID in your helpdesk issue too, if your project has been created.\n\nTo let the GitHub action access the project, you need to create a personal access token (PAT) on  +\nGive the PAT a name, select the scope \"Projects\" and \"Create\" the token. You may have to confirm your credentials again. Copy the token, it'll never be shown agai"
  },
  "1344": {
    "source_file": "crowdin-integration.txt",
    "text": " a name, select the scope \"Projects\" and \"Create\" the token. You may have to confirm your credentials again. Copy the token, it'll never be shown again. +\nReturn to your GitHub repository and select \"Settings\" -> \"Security\" -> \"Secrets\" -> \"Actions\" -> \"New repository secret\" in the upper right corner. For the name of the secret set `CROWDIN_PERSONAL_TOKEN`, for the value you insert the token you "
  },
  "1345": {
    "source_file": "crowdin-integration.txt",
    "text": "-> \"New repository secret\" in the upper right corner. For the name of the secret set `CROWDIN_PERSONAL_TOKEN`, for the value you insert the token you generated on crowdin.\nHit \"Add secret\" and you are done.\n\nCreate a `crowdin.yml` in the root directory of your plugin using the following setup:\n\nfiles:\n  - source: '/src/main/resources/path/to/your/translations/**/*.properties'\n    ignore:\n      - '"
  },
  "1346": {
    "source_file": "crowdin-integration.txt",
    "text": "ry of your plugin using the following setup:\n\nfiles:\n  - source: '/src/main/resources/path/to/your/translations/**/*.properties'\n    ignore:\n      - '/src/main/resources/path/to/your/translations/**/%file_name%_%two_letters_code%.properties'\n      - '/src/main/resources/path/to/your/translations/**/%file_name%_%locale_with_underscore%.properties\"'\n    translation: '/src/main/resources/path/to/your"
  },
  "1347": {
    "source_file": "crowdin-integration.txt",
    "text": "'/src/main/resources/path/to/your/translations/**/%file_name%_%locale_with_underscore%.properties\"'\n    translation: '/src/main/resources/path/to/your/translations/**/%file_name%_%two_letters_code%.properties'\n    escape_quotes: 0\n    escape_special_characters: 0\n\nproject_id_env: CROWDIN_PROJECT_ID\napi_token_env: CROWDIN_PERSONAL_TOKEN\n\nReplace `/path/to/your/translations/` with the appropriate fo"
  },
  "1348": {
    "source_file": "crowdin-integration.txt",
    "text": "characters: 0\n\nproject_id_env: CROWDIN_PROJECT_ID\napi_token_env: CROWDIN_PERSONAL_TOKEN\n\nReplace `/path/to/your/translations/` with the appropriate folder structure of your plugin, take a look at the  for a practice example. +\nLeave the `_env` variables untouched.\n\nRead on  to translate plugins."
  },
  "1349": {
    "source_file": "crowdin-integration.txt",
    "text": "les untouched.\n\nRead on  to translate plugins."
  },
  "1350": {
    "source_file": "csp.txt",
    "text": "title: Content-Security-Policy Compatibility\nlayout: developer\n\n\nFrom https://content-security-policy.com/[content-security-policy.com]:\n\n> _Content-Security-Policy_ is the name of a HTTP response header that modern browsers use to enhance the security of the document (or web page). The Content-Security-Policy header allows you to restrict which resources (such as JavaScript, CSS, Images, etc.) ca"
  },
  "1351": {
    "source_file": "csp.txt",
    "text": "ty of the document (or web page). The Content-Security-Policy header allows you to restrict which resources (such as JavaScript, CSS, Images, etc.) can be loaded, and the URLs that they can be loaded from.\n\nUsing Content-Security-Policy (CSP), injection attacks like  can be prevented.\n\nAs of 2025, the Jenkins (core) UI is compatible with the CSP directives that would allow preventing such injectio"
  },
  "1352": {
    "source_file": "csp.txt",
    "text": "ion attacks like  can be prevented.\n\nAs of 2025, the Jenkins (core) UI is compatible with the CSP directives that would allow preventing such injection attacks, but many plugins are not.\nThis guide documents how to identify components that will be incompatible with CSP rules and how to write and adapt UI code in a manner that is compatible with Jenkins enforcing CSP protections on its UI.\n\nTo chec"
  },
  "1353": {
    "source_file": "csp.txt",
    "text": "compatible with CSP rules and how to write and adapt UI code in a manner that is compatible with Jenkins enforcing CSP protections on its UI.\n\nTo check plugins for CSP compatibility, look for the following code patterns:\n\nInline `<script>` blocks::\nReferencing a file to load JavaScript from is fine, but inline block contents are not.\nAll `<script>` tags without `src` are a problem.\nThey will break"
  },
  "1354": {
    "source_file": "csp.txt",
    "text": "eferencing a file to load JavaScript from is fine, but inline block contents are not.\nAll `<script>` tags without `src` are a problem.\nThey will break without `'unsafe-inline'` in the `script-src` CSP directive.\nStandalone `st:bind` tags with disallowed `var` attribute::\nOnly simple JavaScript identifiers are allowed for CSP-compliant `<st:bind>` tags.\nInline event handler definitions::\nAny occurr"
  },
  "1355": {
    "source_file": "csp.txt",
    "text": "wed `var` attribute::\nOnly simple JavaScript identifiers are allowed for CSP-compliant `<st:bind>` tags.\nInline event handler definitions::\nAny occurrence of `onclick`, `onload`, etc. in HTML files (e.g. Jelly and Groovy views) is a problem.\nLegacy `checkUrl` definitions::\nCheck the `checkUrl` attribute for values that are not simple URLs, but JavaScript expressions.\nWhile the underlying support i"
  },
  "1356": {
    "source_file": "csp.txt",
    "text": "checkUrl` definitions::\nCheck the `checkUrl` attribute for values that are not simple URLs, but JavaScript expressions.\nWhile the underlying support is implemented in Jenkins core rather than in plugins, this will break without `'unsafe-eval'` in the `script-src` CSP directive.\nYou can easily identify them through their use of single quotes inside the double-quoted attribute value (or, rarely, vic"
  },
  "1357": {
    "source_file": "csp.txt",
    "text": " `script-src` CSP directive.\nYou can easily identify them through their use of single quotes inside the double-quoted attribute value (or, rarely, vice versa).\nUse of `eval`::\nCheck for the use of `eval` inside any JS resource files (potentially after applying fixes for the previously listed issues).\nThis will break without `'unsafe-eval'` in the `script-src` CSP directive.\nUse of `FormApply#apply"
  },
  "1358": {
    "source_file": "csp.txt",
    "text": "r applying fixes for the previously listed issues).\nThis will break without `'unsafe-eval'` in the `script-src` CSP directive.\nUse of `FormApply#applyResponse`::\nThis method expects as the argument a JavaScript snippet to be executed.\nResources loaded from other domains::\nAny images, scripts, styles, etc. loaded from other domains cause problems.\nResources should be hosted by Jenkins.\n\nWhen runnin"
  },
  "1359": {
    "source_file": "csp.txt",
    "text": "d from other domains::\nAny images, scripts, styles, etc. loaded from other domains cause problems.\nResources should be hosted by Jenkins.\n\nWhen running Jenkins, you can use the following techniques to identify broken features and the component that defines them:\n\nRunning Jenkins 2.539 or newer in development mode (e.g., `mvn hpi:run`) will have Content Security Policy protections enabled by defaul"
  },
  "1360": {
    "source_file": "csp.txt",
    "text": "efines them:\n\nRunning Jenkins 2.539 or newer in development mode (e.g., `mvn hpi:run`) will have Content Security Policy protections enabled by default.\n\nIn Jenkins before version 2.539,  (1.x) lets you define a Content-Security-Policy that gets applied to the Jenkins web UI.\nIt can operate both as enforcing and to only gather reports.\nBoth modes can be useful with identifying broken functionality"
  },
  "1361": {
    "source_file": "csp.txt",
    "text": "ied to the Jenkins web UI.\nIt can operate both as enforcing and to only gather reports.\nBoth modes can be useful with identifying broken functionality.\n\nWhen set to only report issues but not enforce, the UI can be used as usual while letting the browser report violations, allowing to quickly gather a number of findings while not being blocked by broken functionality.\nAfterwards, the reported viol"
  },
  "1362": {
    "source_file": "csp.txt",
    "text": "wser report violations, allowing to quickly gather a number of findings while not being blocked by broken functionality.\nAfterwards, the reported violations can be reviewed and affected functionality identified this way.\nNavigate to _Manage Jenkins \u00bb Content-Security-Policy Report_ and review the violations there.\n\nNOTE: Make sure to review your browser's console for errors related to reporting CS"
  },
  "1363": {
    "source_file": "csp.txt",
    "text": " Content-Security-Policy Report_ and review the violations there.\n\nNOTE: Make sure to review your browser's console for errors related to reporting CSP violations if you experience problems on the UI, but the report is empty.\nFor example, some browser extensions will disable CSP reporting.\n\nWhen set to enforce the rules, the UI will more readily break if functionality being accessed is impacted by"
  },
  "1364": {
    "source_file": "csp.txt",
    "text": "r extensions will disable CSP reporting.\n\nWhen set to enforce the rules, the UI will more readily break if functionality being accessed is impacted by the rules.\n\nRun the following script in the script console:\n\norg.kohsuke.stapler.jelly.JellyFacet.TRACE = true\n\nThis property is documented on  and emits comments in the rendered HTML of Jelly views that allow you to better understand how the views "
  },
  "1365": {
    "source_file": "csp.txt",
    "text": "RACE = true\n\nThis property is documented on  and emits comments in the rendered HTML of Jelly views that allow you to better understand how the views are composed, and potentially more easily identify which component is responsible for contributing code that violates the CSP rules.\n\nDo not use inline JavaScript (JS) in the Jenkins GUI, i.e., JS embedded in HTML output.\n\nThis is typically done with"
  },
  "1366": {
    "source_file": "csp.txt",
    "text": "ode that violates the CSP rules.\n\nDo not use inline JavaScript (JS) in the Jenkins GUI, i.e., JS embedded in HTML output.\n\nThis is typically done with `<script>` tags, like so:\n\n<script type=\"text/javascript\">\nalert(\"Hello, world!\");\n</script>\n\nThe guidelines in  can be useful to pass arguments to JavaScript, or otherwise control its behavior dynamically.\n\nYou can generally use https://github.com/"
  },
  "1367": {
    "source_file": "csp.txt",
    "text": "uidelines in  can be useful to pass arguments to JavaScript, or otherwise control its behavior dynamically.\n\nYou can generally use https://github.com/jenkinsci/stapler/blob/master/docs/jelly-taglib-ref.adoc#adjunct[Stapler adjuncts] to load files related to UI views and ensure they are loaded only once.\n\nAn example of this is https://github.com/jenkinsci/jenkins/pull/6849[jenkinsci/jenkins#6849].\n"
  },
  "1368": {
    "source_file": "csp.txt",
    "text": "ated to UI views and ensure they are loaded only once.\n\nAn example of this is https://github.com/jenkinsci/jenkins/pull/6849[jenkinsci/jenkins#6849].\n\nIf you're using `<st:bind>` tags inside inline JavaScript, add the `var` attribute to set the variable with the specified name, and reference that variable in your own scripts.\nUse a simple JavaScript identifier (complying with https://github.com/je"
  },
  "1369": {
    "source_file": "csp.txt",
    "text": "ble with the specified name, and reference that variable in your own scripts.\nUse a simple JavaScript identifier (complying with https://github.com/jenkinsci/stapler/blob/92458dd7afca3061956ccf92fedf1782a6e76e39/core/src/main/java/org/kohsuke/stapler/bind/BoundObjectTable.java#L59-L63[this regular expression]) as `var` value, rather than a more complex expression.\n\nMake sure to not reuse the same "
  },
  "1370": {
    "source_file": "csp.txt",
    "text": "/bind/BoundObjectTable.java#L59-L63[this regular expression]) as `var` value, rather than a more complex expression.\n\nMake sure to not reuse the same `var` value when extracting multiple or repeatedly executed `<st:bind/>` tags from inline JS.\nYou can use `${h.generateId()}` to generate a unique value.\n\nAn example of this is https://github.com/jenkinsci/warnings-ng-plugin/pull/1862[warnings-ng-plu"
  },
  "1371": {
    "source_file": "csp.txt",
    "text": "n use `${h.generateId()}` to generate a unique value.\n\nAn example of this is https://github.com/jenkinsci/warnings-ng-plugin/pull/1862[warnings-ng-plugin#1862].\n\n`<st:bind>` generates different output depending on how it is invoked.\nSee the previous section for advice on adding the `var` attribute for standalone use, rather than inside inline JS.\n\nIn addition to adding the `var` attribute, its val"
  },
  "1372": {
    "source_file": "csp.txt",
    "text": "section for advice on adding the `var` attribute for standalone use, rather than inside inline JS.\n\nIn addition to adding the `var` attribute, its value must comply with https://github.com/jenkinsci/stapler/blob/92458dd7afca3061956ccf92fedf1782a6e76e39/core/src/main/java/org/kohsuke/stapler/bind/BoundObjectTable.java#L59-L63[this regular expression] to generate a CSP-compatible `<script>` tag.\n\nSe"
  },
  "1373": {
    "source_file": "csp.txt",
    "text": "39/core/src/main/java/org/kohsuke/stapler/bind/BoundObjectTable.java#L59-L63[this regular expression] to generate a CSP-compatible `<script>` tag.\n\nSee https://github.com/jenkinsci/build-monitor-plugin/pull/830[build-monitor-plugin#830] for an example.\n\nEvent handlers like `onclick` or `onblur` should be defined in separate files.\n\nFor this to work, the element that would have had the inline event"
  },
  "1374": {
    "source_file": "csp.txt",
    "text": "e.\n\nEvent handlers like `onclick` or `onblur` should be defined in separate files.\n\nFor this to work, the element that would have had the inline event handler attribute(s) needs a class or ID by which it can be looked up from JS.\n\nDepending on how that element is added to the UI, you'd use one of the following methods to add event handlers:\n\nYou can use `document.addEventListener('DOMContentLoaded"
  },
  "1375": {
    "source_file": "csp.txt",
    "text": "at element is added to the UI, you'd use one of the following methods to add event handlers:\n\nYou can use `document.addEventListener('DOMContentLoaded', \u2026)` for one or more elements that are present on the page from the moment it is loaded.\nLook up the elements by their ID or class or similar characteristics, then call `#addEventListener` on them.\nBe mindful of Jenkins's extensibility, so consider"
  },
  "1376": {
    "source_file": "csp.txt",
    "text": "he elements by their ID or class or similar characteristics, then call `#addEventListener` on them.\nBe mindful of Jenkins's extensibility, so consider including plugin names in element class names or IDs to prevent unintentional conflicts with other plugins.\n\nUse `Behaviour#specify` to add event handlers to elements that may be dynamically added to the page, for example as part of AJAX responses.\n"
  },
  "1377": {
    "source_file": "csp.txt",
    "text": "plugins.\n\nUse `Behaviour#specify` to add event handlers to elements that may be dynamically added to the page, for example as part of AJAX responses.\nOne common instance of this is in configuration forms: `renderOnDemand` is used by common form elements like `hetero-list` to load parts of the page only as the form is being changed.\nThe code that adds content from AJAX responses dynamically to the "
  },
  "1378": {
    "source_file": "csp.txt",
    "text": "nts like `hetero-list` to load parts of the page only as the form is being changed.\nThe code that adds content from AJAX responses dynamically to the page needs to call `Behaviour#applySubtree` on the newly added content.\n\nFor event handlers like `onclick` that used to call `return false` to prevent the usual action (e.g. link navigation) from happening, add a call to `Event.preventDefault()` in a"
  },
  "1379": {
    "source_file": "csp.txt",
    "text": "click` that used to call `return false` to prevent the usual action (e.g. link navigation) from happening, add a call to `Event.preventDefault()` in a separate event handler on the provided `Event` argument.\n\nExamples of this are: https://github.com/jenkinsci/jenkins/pull/5514[jenkinsci/jenkins#5514]\n\nDo not use \"legacy\" mode form validation, which supports inline JS with manually specified `check"
  },
  "1380": {
    "source_file": "csp.txt",
    "text": "jenkinsci/jenkins/pull/5514[jenkinsci/jenkins#5514]\n\nDo not use \"legacy\" mode form validation, which supports inline JS with manually specified `checkUrl` parameters.\nIt looks like the following:\n\n<f:textbox checkUrl=\"'${rootURL}/${h.jsStringEscape(it.url)}checkText?value='+encodeURIComponent(this.value)+'\" \u2026 />\n\nThis combines inline JS and building parts of the string using JEXL expressions in Je"
  },
  "1381": {
    "source_file": "csp.txt",
    "text": "t.url)}checkText?value='+encodeURIComponent(this.value)+'\" \u2026 />\n\nThis combines inline JS and building parts of the string using JEXL expressions in Jelly, with different ways to escape different parts of the content to prevent injection vulnerabilities.\n\nInstead, use the _modern_ `checkUrl` mode, which as of Jenkins 2.360 requires the `checkDependsOn` attribute to be set (but it can be an empty st"
  },
  "1382": {
    "source_file": "csp.txt",
    "text": "es.\n\nInstead, use the _modern_ `checkUrl` mode, which as of Jenkins 2.360 requires the `checkDependsOn` attribute to be set (but it can be an empty string).\nThis mode will automatically add the current form element's value as the query parameter called `value`, so the above example can be simplified to the following:\n\n<f:textbox checkUrl=\"${rootURL}/${it.url}checkText\" checkDependsOn=\"\" \u2026 />\n\nExam"
  },
  "1383": {
    "source_file": "csp.txt",
    "text": "ed `value`, so the above example can be simplified to the following:\n\n<f:textbox checkUrl=\"${rootURL}/${it.url}checkText\" checkDependsOn=\"\" \u2026 />\n\nExamples of this are: https://github.com/jenkinsci/jenkins/pull/6856[jenkinsci/jenkins#6856] https://github.com/jenkinsci/jenkins/pull/6857[jenkinsci/jenkins#6857]\n\nTo pass additional values, specify the respective form field names as part of the `checkD"
  },
  "1384": {
    "source_file": "csp.txt",
    "text": "hub.com/jenkinsci/jenkins/pull/6857[jenkinsci/jenkins#6857]\n\nTo pass additional values, specify the respective form field names as part of the `checkDependsOn` string.\n\nIf you need to pass parameters that are not represented as form fields, the following options exist as of Jenkins 2.360:\n\n* Define a new form validation endpoint.\n  This can be a viable option when it's a boolean value (2 endpoints"
  },
  "1385": {
    "source_file": "csp.txt",
    "text": "wing options exist as of Jenkins 2.360:\n\n* Define a new form validation endpoint.\n  This can be a viable option when it's a boolean value (2 endpoints instead of one).\n* Define a hidden form field (wrap it in `f:invisibleEntry`) with the expected `name` and `value` and specify it in `checkDependsOn`.\n  Make sure to ignore it otherwise.\n  See https://github.com/jenkinsci/jenkins/pull/6859[jenkinsci"
  },
  "1386": {
    "source_file": "csp.txt",
    "text": "me` and `value` and specify it in `checkDependsOn`.\n  Make sure to ignore it otherwise.\n  See https://github.com/jenkinsci/jenkins/pull/6859[jenkinsci/jenkins#6859] for an example.\n\n`eval` should not be used to interpret a string as JS code.\n\nDepending on your use case, different solutions are possible.\n\nTo parse JSON, use `JSON.parse` instead.\nSee https://github.com/jenkinsci/jenkins/pull/6868[je"
  },
  "1387": {
    "source_file": "csp.txt",
    "text": "ng on your use case, different solutions are possible.\n\nTo parse JSON, use `JSON.parse` instead.\nSee https://github.com/jenkinsci/jenkins/pull/6868[jenkinsci/jenkins#6868] for an example.\n\nTo invoke a callback, have the caller define a global function and pass its name as an argument.\nThen your code can invoke the callback like this:\n\n/* someone else provides this */\nlet callbackName = 'foo';\n/* i"
  },
  "1388": {
    "source_file": "csp.txt",
    "text": "n and pass its name as an argument.\nThen your code can invoke the callback like this:\n\n/* someone else provides this */\nlet callbackName = 'foo';\n/* invoke it with arguments */\nwindow[callbackName](args);\n\nUse `FormApply#showNotification`, which was added in Jenkins 2.482.\n\nMove images, scripts, and styles into the resources of your plugin.\nThis will also make Jenkins work better in environments w"
  },
  "1389": {
    "source_file": "csp.txt",
    "text": "added in Jenkins 2.482.\n\nMove images, scripts, and styles into the resources of your plugin.\nThis will also make Jenkins work better in environments without, or only limited, internet connectivity.\n\nAny dynamically determined images (e.g., \"avatar\" images based on user configuration, like GitHub orgs or user avatars based on the configured security realm) can be handled in the following ways:\n\n* H"
  },
  "1390": {
    "source_file": "csp.txt",
    "text": "mages based on user configuration, like GitHub orgs or user avatars based on the configured security realm) can be handled in the following ways:\n\n* Have Jenkins request (and possibly cache) these images, serving them through a local URL.\n  Be careful to not allow parameterization of the URL serving this image such that it accepts arbitrary parameter values, resulting in arbitrary URLs being proxi"
  },
  "1391": {
    "source_file": "csp.txt",
    "text": "l to not allow parameterization of the URL serving this image such that it accepts arbitrary parameter values, resulting in arbitrary URLs being proxied.\n* For compatibility with Content Security Policy in Jenkins 2.539 and newer, implement `jenkins.security.csp.Contributor` (or `jenkins.security.csp.SimpleContributor` in simple cases).\n  This will allow Jenkins users' browsers to load images from"
  },
  "1392": {
    "source_file": "csp.txt",
    "text": "security.csp.Contributor` (or `jenkins.security.csp.SimpleContributor` in simple cases).\n  This will allow Jenkins users' browsers to load images from a known safe domain.\n  In this case, make sure that only administrators can ultimately configure the domains that images can be loaded from.\n  For example, regular Jenkins users should not be able to, e.g., edit their user profile or configure a job"
  },
  "1393": {
    "source_file": "csp.txt",
    "text": "e domains that images can be loaded from.\n  For example, regular Jenkins users should not be able to, e.g., edit their user profile or configure a job in a certain way to allow a domain of their choice.\n\nJenkins 2.539 and newer supports Content Security Policy out of the box.\nSee the  for information how to set it up.\n\nNOTE: Running Jenkins in development mode will by default enforce Content Secur"
  },
  "1394": {
    "source_file": "csp.txt",
    "text": "ity Policy out of the box.\nSee the  for information how to set it up.\n\nNOTE: Running Jenkins in development mode will by default enforce Content Security Policy, so plugin maintainers will likely encounter incompatibilities in their own testing.\n\n (1.x) lets you define a Content-Security-Policy that gets applied to the Jenkins web UI.\nIt can operate both as enforcing and to only gather reports.\nBo"
  },
  "1395": {
    "source_file": "csp.txt",
    "text": ".x) lets you define a Content-Security-Policy that gets applied to the Jenkins web UI.\nIt can operate both as enforcing and to only gather reports.\nBoth modes can be useful with identifying broken functionality."
  },
  "1396": {
    "source_file": "csrf-protection.txt",
    "text": "title: CSRF Protection\nlayout: section\n\n\nifdef::env-github[:imagesdir: ../resources]\nifndef::env-github[:imagesdir: ../../resources]\n\nhttps://en.wikipedia.org/wiki/Cross-site_request_forgery[Cross-Site Request Forgery] (CSRF or XSRF) is a type of security vulnerability in web applications.\nWithout protection from CSRF, a Jenkins user or administrator visiting some other web site would allow the op"
  },
  "1397": {
    "source_file": "csrf-protection.txt",
    "text": "urity vulnerability in web applications.\nWithout protection from CSRF, a Jenkins user or administrator visiting some other web site would allow the operator of that site to perform actions in Jenkins as the victim.\n\n## CSRF Protection in Jenkins\n\nCSRF protection uses a token (called _crumb_ in Jenkins) that is created by Jenkins and sent to the user.\nAny form submissions or similar action resultin"
  },
  "1398": {
    "source_file": "csrf-protection.txt",
    "text": "F protection uses a token (called _crumb_ in Jenkins) that is created by Jenkins and sent to the user.\nAny form submissions or similar action resulting in modifications, like triggering builds or changing configuration, requires that the crumb be provided.\nThe crumb contains information identifying the user it was created for, so submissions with another user's token would be rejected.\nAll of this"
  },
  "1399": {
    "source_file": "csrf-protection.txt",
    "text": "vided.\nThe crumb contains information identifying the user it was created for, so submissions with another user's token would be rejected.\nAll of this happens in the background and has no visible impact except in rare circumstances, e.g., after a user's session expired and they logged in again.\n\nNOTE: The documentation on this page applies to Jenkins 2.222 or newer.\n\n## Configuring CSRF Protection"
  },
  "1400": {
    "source_file": "csrf-protection.txt",
    "text": "r's session expired and they logged in again.\n\nNOTE: The documentation on this page applies to Jenkins 2.222 or newer.\n\n## Configuring CSRF Protection\n\nIn _Manage Jenkins \u00bb Security \u00bb CSRF Protection_, administrators can configure CSRF Protection.\n\nThe _Default Crumb Issuer_ encodes the following information in the https://en.wikipedia.org/wiki/Cryptographic_hash_function[hash] used as crumb:\n\n* T"
  },
  "1401": {
    "source_file": "csrf-protection.txt",
    "text": "he _Default Crumb Issuer_ encodes the following information in the https://en.wikipedia.org/wiki/Cryptographic_hash_function[hash] used as crumb:\n\n* The user name that the crumb was generated for\n* The web session ID that the crumb was generated in\n* The IP address of the user that the crumb was generated for\n* A https://en.wikipedia.org/wiki/Salt_(cryptography)[salt] unique to this Jenkins instan"
  },
  "1402": {
    "source_file": "csrf-protection.txt",
    "text": " The IP address of the user that the crumb was generated for\n* A https://en.wikipedia.org/wiki/Salt_(cryptography)[salt] unique to this Jenkins instance\n\nAll of this information needs to match when a crumb is sent back to Jenkins for that submission to be considered valid.\n\nThe only supported option _Enable proxy compatibility_ removes information about the user IP address from the token.\nThis can"
  },
  "1403": {
    "source_file": "csrf-protection.txt",
    "text": "to be considered valid.\n\nThe only supported option _Enable proxy compatibility_ removes information about the user IP address from the token.\nThis can be useful when Jenkins is running behind a reverse proxy and a user's IP address as seen from Jenkins would regularly change.\n\nNOTE: The web session ID was added in Jenkins 2.176.2 and 2.186 to cause crumb to expire.\nSee  and .\n\nPlugins may provide "
  },
  "1404": {
    "source_file": "csrf-protection.txt",
    "text": "ns would regularly change.\n\nNOTE: The web session ID was added in Jenkins 2.176.2 and 2.186 to cause crumb to expire.\nSee  and .\n\nPlugins may provide other crumb issuers that use other criteria to determine whether a crumb is valid.\nThe plugin:strict-crumb-issuer[Strict Crumb Issuer] provides an alternative crumb issuer implementation that is more customizable.\n\n## Working with Scripted Clients\n\nR"
  },
  "1405": {
    "source_file": "csrf-protection.txt",
    "text": "-crumb-issuer[Strict Crumb Issuer] provides an alternative crumb issuer implementation that is more customizable.\n\n## Working with Scripted Clients\n\nRequests sent using the `POST` method are subject to CSRF protection in Jenkins and generally need to provide a crumb.\nThis also applies to scripted clients that **authenticate using username and password**.\nSince the crumb includes the web session ID"
  },
  "1406": {
    "source_file": "csrf-protection.txt",
    "text": " provide a crumb.\nThis also applies to scripted clients that **authenticate using username and password**.\nSince the crumb includes the web session ID, clients need to do the following:\n\n* Send a request to the `/crumbIssuer/api` endpoints, requesting a crumb. Note the `Set-Cookie` response header.\n* For all subsequent requests, provide the crumb and the session cookie in addition to username and "
  },
  "1407": {
    "source_file": "csrf-protection.txt",
    "text": "g a crumb. Note the `Set-Cookie` response header.\n* For all subsequent requests, provide the crumb and the session cookie in addition to username and password.\n\nAlternatively **authenticate using username and API token**.\nRequests authenticating with an  are exempt from CSRF protection in Jenkins.\n\n## Disabling CSRF Protection\n\nOutdated plugins that send HTTP requests to Jenkins may not work with "
  },
  "1408": {
    "source_file": "csrf-protection.txt",
    "text": " an  are exempt from CSRF protection in Jenkins.\n\n## Disabling CSRF Protection\n\nOutdated plugins that send HTTP requests to Jenkins may not work with CSRF protection enabled.\nIn this case, it may be necessary to disable CSRF protection temporarily.\n\nIMPORTANT: It is *strongly recommended* that CSRF protection be left *enabled*, including on instances operating on private, fully trusted networks.\n\n"
  },
  "1409": {
    "source_file": "csrf-protection.txt",
    "text": "IMPORTANT: It is *strongly recommended* that CSRF protection be left *enabled*, including on instances operating on private, fully trusted networks.\n\nTo disable CSRF protection, set the system property `hudson.security.csrf.GlobalCrumbIssuerConfiguration.DISABLE_CSRF_PROTECTION` to `true` on startup."
  },
  "1410": {
    "source_file": "csrf-protection.txt",
    "text": "tion.DISABLE_CSRF_PROTECTION` to `true` on startup."
  },
  "1411": {
    "source_file": "custom-converter.txt",
    "text": "title: Registering a Custom Converter\nsummary: How to register a custom XStream converter to serialize complex data structures.\nlayout: developersection\n\n\nNormally, you would register converter to the class you are writing,\nand in that case the easiest thing to do is to write a nested type `ConverterImpl` that gets picked up automatically.\nIf you search by that class name, you will see a number of"
  },
  "1412": {
    "source_file": "custom-converter.txt",
    "text": "st thing to do is to write a nested type `ConverterImpl` that gets picked up automatically.\nIf you search by that class name, you will see a number of implementations.\n\nIf you want to register a custom XStream converter that will convert items that have already been persisted to disk,\nand you do not want to modify the source code for the class you want to convert,\nthen you need to hook it up to Je"
  },
  "1413": {
    "source_file": "custom-converter.txt",
    "text": "ave already been persisted to disk,\nand you do not want to modify the source code for the class you want to convert,\nthen you need to hook it up to Jenkins before it reads in those items.\nHere is one way:\n\npublic class MyPlugin extends Plugin {\n  public void start() throws Exception {\n    Items.XSTREAM.registerConverter(new MyCoolConverter());\n  }\n}\n\nThe `Items#XSTREAM` portion should be adjusted "
  },
  "1414": {
    "source_file": "custom-converter.txt",
    "text": "lic void start() throws Exception {\n    Items.XSTREAM.registerConverter(new MyCoolConverter());\n  }\n}\n\nThe `Items#XSTREAM` portion should be adjusted to point to the right XStream instance (such as `Jenkins#XSTREAM`),\ndepending on the persistence context in which your object participates.\nThe converter would look something like this:\n\nimport com.thoughtworks.xstream.converters.Converter;\n\npublic c"
  },
  "1415": {
    "source_file": "custom-converter.txt",
    "text": "text in which your object participates.\nThe converter would look something like this:\n\nimport com.thoughtworks.xstream.converters.Converter;\n\npublic class MyCoolConverter implements Converter {\n  public void marshal(Object source, HierarchicalStreamWriter writer, MarshallingContext context) {\n    throw new UnsupportedOperationException(\"Sorry, no example for marshalling yet!\");\n  }\n\n  public Objec"
  },
  "1416": {
    "source_file": "custom-converter.txt",
    "text": "riter writer, MarshallingContext context) {\n    throw new UnsupportedOperationException(\"Sorry, no example for marshalling yet!\");\n  }\n\n  public Object unmarshal(HierarchicalStreamReader reader, UnmarshallingContext context) {\n    // Traverse the reader to get structure and attributes of the thing you are converting from\n    return new MyThing(some, attrs, etc);\n  }\n\n  public boolean canConvert(Cl"
  },
  "1417": {
    "source_file": "custom-converter.txt",
    "text": "der to get structure and attributes of the thing you are converting from\n    return new MyThing(some, attrs, etc);\n  }\n\n  public boolean canConvert(Class type) {\n    return my.plugin.special.MyThing.class == type;\n  }\n}"
  },
  "1418": {
    "source_file": "dashboard.txt",
    "text": "layout: section\ntitle: Dashboard\n\n\nifdef::env-github[:imagesdir: ../resources]\nifndef::env-github[:imagesdir: ../../resources]\n\n// Show 1/3 of the Blue ocean admonitions\n// :pipeline-visualization-admonition: true\n// :pipeline-creation-admonition: true\n\nBlue Ocean's \"Dashboard\" is the default view when opening Blue Ocean.\nIt displays an overview of all Pipeline projects configured on a Jenkins con"
  },
  "1419": {
    "source_file": "dashboard.txt",
    "text": "ue\n\nBlue Ocean's \"Dashboard\" is the default view when opening Blue Ocean.\nIt displays an overview of all Pipeline projects configured on a Jenkins controller.\n\nThe Dashboard consists of a blue  at the top, the , and the .\n\n[.boxshadow]\n\nThe Dashboard includes the blue  along the top of the interface.\n\nThe bar is divided into two sections:\n\n* A common section along the top.\n* A contextual section b"
  },
  "1420": {
    "source_file": "dashboard.txt",
    "text": " includes the blue  along the top of the interface.\n\nThe bar is divided into two sections:\n\n* A common section along the top.\n* A contextual section below.\n** The contextual section changes depending on the Blue Ocean page you are viewing.\n\nWhen viewing the Dashboard, the navigation bar's contextual section includes:\n\n* *Search pipelines*: This field allows users to filter the  to match the text y"
  },
  "1421": {
    "source_file": "dashboard.txt",
    "text": "ing the Dashboard, the navigation bar's contextual section includes:\n\n* *Search pipelines*: This field allows users to filter the  to match the text you enter into this field.\n* *New Pipeline*: This option begins the process of .\n\nThe *Pipelines* list is the Dashboard's default list.\nIt is the only list displayed the first time Blue Ocean is accessed.\n\nThe list shows the overall state of each Pipe"
  },
  "1422": {
    "source_file": "dashboard.txt",
    "text": "t is the Dashboard's default list.\nIt is the only list displayed the first time Blue Ocean is accessed.\n\nThe list shows the overall state of each Pipeline configured in the Jenkins controller.\nThe list can include other items configured in the Jenkins controller.\nThe following information is displayed for each Pipeline listed:\n\n* The item's *NAME*\n* The item's\n* The number of *BRANCHES* and pull r"
  },
  "1423": {
    "source_file": "dashboard.txt",
    "text": "s controller.\nThe following information is displayed for each Pipeline listed:\n\n* The item's *NAME*\n* The item's\n* The number of *BRANCHES* and pull requests *(PRs)* that are passing or failing within the Pipeline's source control repository.\n* A &#9734;, indicating whether or not the item has been manually added to your current Jenkins <<favorites-list>>.\n\nSelecting an item's &#9734; will toggle "
  },
  "1424": {
    "source_file": "dashboard.txt",
    "text": "734;, indicating whether or not the item has been manually added to your current Jenkins <<favorites-list>>.\n\nSelecting an item's &#9734; will toggle between:\n\n* Adding the default branch of the item's repository to your Favorites list, which is indicated by a solid &#9733;.\n* Removing the item's default branch from this list, which is indicated by an outlined &#9734;.\n\nSelecting an item in the Pi"
  },
  "1425": {
    "source_file": "dashboard.txt",
    "text": "cated by a solid &#9733;.\n* Removing the item's default branch from this list, which is indicated by an outlined &#9734;.\n\nSelecting an item in the Pipelines list will display that item's .\n\nThe Favorites list appears above the Dashboard's default <<pipelines-list>> when at least one Pipeline/item is present in your Favorites list.\n\nThis list provides key information and actions for a core subset "
  },
  "1426": {
    "source_file": "dashboard.txt",
    "text": "pipelines-list>> when at least one Pipeline/item is present in your Favorites list.\n\nThis list provides key information and actions for a core subset of your accessible items in the <<pipelines-list>>.\nThis key information includes the current  for an item and its repository's branch, the name of the branch, the initial part of the commit hash, and the last run time.\nThis list also includes option"
  },
  "1427": {
    "source_file": "dashboard.txt",
    "text": "n item and its repository's branch, the name of the branch, the initial part of the commit hash, and the last run time.\nThis list also includes options to run or re-run the item on the indicated branch.\n\nYou should only add an item or branch to your Favorites list if it needs regular monitoring.\nAdding an item's specific branch to your Favorites list can be done through the item's .\n\nBlue Ocean au"
  },
  "1428": {
    "source_file": "dashboard.txt",
    "text": "Favorites list if it needs regular monitoring.\nAdding an item's specific branch to your Favorites list can be done through the item's .\n\nBlue Ocean automatically adds branches and PRs to this list when they include a run that contains any modifications you have performed.\n\nYou can also manually remove items from your Favorites list by deselecting the solid &#9733; in this list.\nWhen there are no l"
  },
  "1429": {
    "source_file": "dashboard.txt",
    "text": "ns you have performed.\n\nYou can also manually remove items from your Favorites list by deselecting the solid &#9733; in this list.\nWhen there are no longer items in this list, the list is removed from the Dashboard.\nSelecting the favorite &#9733; for any item will bring the list back to your Dashboard.\n\nSelecting an item in the Favorites list opens the  for the latest run on the branch or PR indic"
  },
  "1430": {
    "source_file": "dashboard.txt",
    "text": " any item will bring the list back to your Dashboard.\n\nSelecting an item in the Favorites list opens the  for the latest run on the branch or PR indicated.\n\n[[pipeline-health]]\n\nBlue Ocean represents the overall health of a Pipeline/item or one of its branches using weather icons.\nThese icons change depending on the number of recent builds that have passed.\n\nHealth icons on the Dashboard represent"
  },
  "1431": {
    "source_file": "dashboard.txt",
    "text": "s branches using weather icons.\nThese icons change depending on the number of recent builds that have passed.\n\nHealth icons on the Dashboard represent overall Pipeline health, whereas the health icons in the  represent the overall health for each branch.\n\n.Health icons (best to worst)\n|===\n|Icon |Health\n\n|\n|*Sunny*, more than 80% of Runs passing\n\n|\n|*Partially Sunny*, 61% to 80% of Runs passing\n\n|"
  },
  "1432": {
    "source_file": "dashboard.txt",
    "text": "nch.\n\n.Health icons (best to worst)\n|===\n|Icon |Health\n\n|\n|*Sunny*, more than 80% of Runs passing\n\n|\n|*Partially Sunny*, 61% to 80% of Runs passing\n\n|\n|*Cloudy*, 41% to 60% of Runs passing\n\n|\n|*Raining*, 21% to 40% of Runs passing\n\n|\n|*Storm*, less than 21% of Runs passing\n|===\n\nBlue Ocean represents the run status of a Pipeline/item or one of its branches using a consistent set of icons throughou"
  },
  "1433": {
    "source_file": "dashboard.txt",
    "text": "han 21% of Runs passing\n|===\n\nBlue Ocean represents the run status of a Pipeline/item or one of its branches using a consistent set of icons throughout.\n\n.Run status icons\n|===\n|Icon |Status\n\n|\n|*In Progress*\n\n|\n|*Passed*\n\n|\n|*Unstable*\n\n|\n|*Failed*\n\n|\n|*Aborted*\n|==="
  },
  "1434": {
    "source_file": "dashboard.txt",
    "text": "\n|\n|*Aborted*\n|==="
  },
  "1435": {
    "source_file": "dependencies-and-class-loading.txt",
    "text": "title: Dependencies and Class Loading\nsummary: How code is physically structured in Jenkins core and plugins, and how this relates to dependencies and Java class loading behavior.\nlayout: developersection\n\n\nJenkins has a complex, modular architecture.\nTo enable plugins to use the rich array of libraries available in the Java ecosystem,\nand build on one another using plugin-to-plugin APIs,\nthe Jenk"
  },
  "1436": {
    "source_file": "dependencies-and-class-loading.txt",
    "text": ".\nTo enable plugins to use the rich array of libraries available in the Java ecosystem,\nand build on one another using plugin-to-plugin APIs,\nthe Jenkins plugin extension mechanism goes beyond simple plugin manifests.\n\nThe de facto build tool for Jenkins plugins is Apache Maven.\nAll examples here will use Maven.\nBuilding plugins using Gradle is also possible but particular capabilities may lag beh"
  },
  "1437": {
    "source_file": "dependencies-and-class-loading.txt",
    "text": "kins plugins is Apache Maven.\nAll examples here will use Maven.\nBuilding plugins using Gradle is also possible but particular capabilities may lag behind.\n\n## Jenkins class loading\n\nBefore diving into _how_ to refer to libraries and other plugins from your plugin,\nit is useful to understand the elements of Java class loading and how that applies to Jenkins.\nIf you are not a Java developer, you can"
  },
  "1438": {
    "source_file": "dependencies-and-class-loading.txt",
    "text": "m your plugin,\nit is useful to understand the elements of Java class loading and how that applies to Jenkins.\nIf you are not a Java developer, you can get away with ignoring all this for simple plugins,\nbut will need to understand class loading to troubleshoot strange errors or perform advanced packaging.\n\n### The plugin class loader hierarchy\n\n\u25a1 Java Platform\n \u2196\n  \u25a1 \u201capplication classpath\u201d (servl"
  },
  "1439": {
    "source_file": "dependencies-and-class-loading.txt",
    "text": "oubleshoot strange errors or perform advanced packaging.\n\n### The plugin class loader hierarchy\n\n\u25a1 Java Platform\n \u2196\n  \u25a1 \u201capplication classpath\u201d (servlet container): java -jar jenkins.war\n   \u2196\n    \u25a1 Jenkins core: jenkins.war!/WEB-INF/lib/*.jar\n     \u2196\n      \u25a1 plugin A: $JENKINS_HOME/plugins/a.jpi!/WEB-INF/lib/*.jar\n       \u2196                                                             \u2196\n        \u25a1 plug"
  },
  "1440": {
    "source_file": "dependencies-and-class-loading.txt",
    "text": "      \u25a1 plugin A: $JENKINS_HOME/plugins/a.jpi!/WEB-INF/lib/*.jar\n       \u2196                                                             \u2196\n        \u25a1 plugin C: $JENKINS_HOME/plugins/c.jpi!/WEB-INF/lib/*.jar  \u2190 \u25a1 UberClassLoader\n     \u2196 \u2199                                                             \u2199\n      \u25a1 plugin B: $JENKINS_HOME/plugins/b.jpi!/WEB-INF/lib/*.jar\n      \u22ee\n\nJava class loaders have _parent"
  },
  "1441": {
    "source_file": "dependencies-and-class-loading.txt",
    "text": "                                           \u2199\n      \u25a1 plugin B: $JENKINS_HOME/plugins/b.jpi!/WEB-INF/lib/*.jar\n      \u22ee\n\nJava class loaders have _parents_ to which they delegate.\nFor purposes of Jenkins, what matters most is that \u201cJenkins core\u201d delegates to the Java Platform,\nand Jenkins plugins all delegate to Jenkins core.\n\nPlugins may also delegate to one another.\nIn the above example, C declares"
  },
  "1442": {
    "source_file": "dependencies-and-class-loading.txt",
    "text": "es to the Java Platform,\nand Jenkins plugins all delegate to Jenkins core.\n\nPlugins may also delegate to one another.\nIn the above example, C declares dependencies on A and B.\nIn its `c.jpi!/META-INF/MANIFEST.MF` this would look something like:\n\nPlugin-Dependencies: a:1.13,b:1.6\n\nThus C can directly refer to classes defined in either A or B, as well as to Jenkins and the Java Platform:\n\npackage or"
  },
  "1443": {
    "source_file": "dependencies-and-class-loading.txt",
    "text": "in-Dependencies: a:1.13,b:1.6\n\nThus C can directly refer to classes defined in either A or B, as well as to Jenkins and the Java Platform:\n\npackage org.jenkinsci.plugins.c;\nimport java.util.Date;\nimport jenkins.model.Jenkins;\nimport org.jenkinsci.plugins.a.Alpha;\nimport org.jenkinsci.plugins.b.Beta;\npublic class Charlie {/* \u2026 */}\n\nEach (enabled) plugin gets its own `ClassLoader`.\nIt is possible fo"
  },
  "1444": {
    "source_file": "dependencies-and-class-loading.txt",
    "text": "gins.a.Alpha;\nimport org.jenkinsci.plugins.b.Beta;\npublic class Charlie {/* \u2026 */}\n\nEach (enabled) plugin gets its own `ClassLoader`.\nIt is possible for two distinct plugins to define a class of the same name, so long as neither depends on the other.\n\nThere is also a single special `UberClassLoader` which delegates to _all_ enabled plugins.\nThis never loads any additional resources but it can be us"
  },
  "1445": {
    "source_file": "dependencies-and-class-loading.txt",
    "text": "\nThere is also a single special `UberClassLoader` which delegates to _all_ enabled plugins.\nThis never loads any additional resources but it can be used to look up any plugin class or resource.\n\n### Initiating vs. defining loaders\n\nWhen you _initiate_ loading of a class\n\nClass<?> alpha = Charlie.class.getClassLoader().loadClass(\"org.jenkinsci.plugins.a.Alpha\");\n\nyou are asking a particular `ClassL"
  },
  "1446": {
    "source_file": "dependencies-and-class-loading.txt",
    "text": "_ loading of a class\n\nClass<?> alpha = Charlie.class.getClassLoader().loadClass(\"org.jenkinsci.plugins.a.Alpha\");\n\nyou are asking a particular `ClassLoader` (here, C\u2019s) to look up a class by name.\n(Normally this will _start_ by asking all of its parents to find that class,\nand only look in `c.jpi!/WEB-INF/lib/*.jar` as a last resort.)\n\nWhat happens if `Alpha.class` refers to various other classes,"
  },
  "1447": {
    "source_file": "dependencies-and-class-loading.txt",
    "text": "nts to find that class,\nand only look in `c.jpi!/WEB-INF/lib/*.jar` as a last resort.)\n\nWhat happens if `Alpha.class` refers to various other classes, for example by using them in `import` statements?\nJava considers the _defining_ loader of `Alpha.class` (A\u2019s), and only asks that class loader.\nThe fact that you started loading in C is irrelevant.\nThis means that C cannot provide some class A might"
  },
  "1448": {
    "source_file": "dependencies-and-class-loading.txt",
    "text": "ass` (A\u2019s), and only asks that class loader.\nThe fact that you started loading in C is irrelevant.\nThis means that C cannot provide some class A might need to link against.\nA needs to be able to \u201csee\u201d any such class on its own.\nOtherwise you will get a `NoClassDefFoundError` at runtime.\n\n### Context class loaders\n\nJava defines a `Thread.getContextClassLoader()`.\nJenkins does not use this much; it "
  },
  "1449": {
    "source_file": "dependencies-and-class-loading.txt",
    "text": " a `NoClassDefFoundError` at runtime.\n\n### Context class loaders\n\nJava defines a `Thread.getContextClassLoader()`.\nJenkins does not use this much; it will normally be set by the servlet container to the Jenkins core loader.\n\nSome Java libraries have a fundamental design flaw, originating in premodular systems with a \u201cflat classpath\u201d,\nwhereby they expect classes defined by clients of the library to"
  },
  "1450": {
    "source_file": "dependencies-and-class-loading.txt",
    "text": "a fundamental design flaw, originating in premodular systems with a \u201cflat classpath\u201d,\nwhereby they expect classes defined by clients of the library to be available by name without any qualification:\n\npackage org.somelib;\npublic class LibClass {\n    public static Object use(String name) throws Exception {\n        return getUserClass(name).newInstance();\n    }\n    private Class<?> getUserClass(Strin"
  },
  "1451": {
    "source_file": "dependencies-and-class-loading.txt",
    "text": "ublic static Object use(String name) throws Exception {\n        return getUserClass(name).newInstance();\n    }\n    private Class<?> getUserClass(String name) throws ClassNotFoundException {\n        return Class.forName(name);\n    }\n}\n\nThis does not work properly in Jenkins because the library `org.somelib` might be defined in plugin A,\nwhile the user class is defined in plugin B depending on A.\n`C"
  },
  "1452": {
    "source_file": "dependencies-and-class-loading.txt",
    "text": "ork properly in Jenkins because the library `org.somelib` might be defined in plugin A,\nwhile the user class is defined in plugin B depending on A.\n`Class.forName(String)` uses the _calling class_ (`LibClass`) to determine the initiating `ClassLoader`;\nsince plugin A cannot load classes from plugin B, this will result in a `ClassNotFoundException`.\n\nOther libraries try to work around the issue as "
  },
  "1453": {
    "source_file": "dependencies-and-class-loading.txt",
    "text": "`;\nsince plugin A cannot load classes from plugin B, this will result in a `ClassNotFoundException`.\n\nOther libraries try to work around the issue as follows:\n\npackage org.somelib;\npublic class LibClass {\n    public static Object use(String name) throws Exception {\n        return getUserClass(name).newInstance();\n    }\n    private Class<?> getUserClass(String name) throws ClassNotFoundException {\n"
  },
  "1454": {
    "source_file": "dependencies-and-class-loading.txt",
    "text": "ows Exception {\n        return getUserClass(name).newInstance();\n    }\n    private Class<?> getUserClass(String name) throws ClassNotFoundException {\n        return Class.forName(name, true, Thread.currentThread().getContextClassLoader());\n    }\n}\n\nThis also fails by default in Jenkins, since the `contextClassLoader` can see only Jenkins core (not even plugin A, much less B).\nJenkins plugin code c"
  },
  "1455": {
    "source_file": "dependencies-and-class-loading.txt",
    "text": "his also fails by default in Jenkins, since the `contextClassLoader` can see only Jenkins core (not even plugin A, much less B).\nJenkins plugin code can work around the issue in some cases:\n\npackage org.jenkinsci.plugins.b;\nimport org.somelib.LibClass;\nclass UsesThatLib {\n    Object someMethod() {\n        Thread t = Thread.currentThread();\n        ClassLoader orig = t.getContextClassLoader();\n    "
  },
  "1456": {
    "source_file": "dependencies-and-class-loading.txt",
    "text": "s;\nclass UsesThatLib {\n    Object someMethod() {\n        Thread t = Thread.currentThread();\n        ClassLoader orig = t.getContextClassLoader();\n        t.setContextClassLoader(UsesThatLib.class.getClassLoader());\n        try {\n            return LibClass.use(UsesThatLib.class.getName());\n        } finally {\n            t.setContextClassLoader(orig);\n        }\n    }\n}\n\n(When the particular class "
  },
  "1457": {
    "source_file": "dependencies-and-class-loading.txt",
    "text": "bClass.use(UsesThatLib.class.getName());\n        } finally {\n            t.setContextClassLoader(orig);\n        }\n    }\n}\n\n(When the particular class loader needed is unclear, `UberClassLoader` can be used as a fallback,\nthough this is not as safe since lookups could be ambiguous in case two unrelated plugins both bundled the same library.)\n\nUltimately however it is a design flaw in the library if"
  },
  "1458": {
    "source_file": "dependencies-and-class-loading.txt",
    "text": "nce lookups could be ambiguous in case two unrelated plugins both bundled the same library.)\n\nUltimately however it is a design flaw in the library if it fails to allow clients to directly specify a `ClassLoader` to use for lookups\n(or preregister `Class` instances for particular names).\nConsider patching the library or looking harder for appropriate APIs that already exist.\nAs an example, `java.i"
  },
  "1459": {
    "source_file": "dependencies-and-class-loading.txt",
    "text": "lass` instances for particular names).\nConsider patching the library or looking harder for appropriate APIs that already exist.\nAs an example, `java.io.ObjectInputStream` (used for deserializing Java objects) by default uses a complicated algorithm to guess at a `ClassLoader`,\nbut you can override `resolveClass` to remove the need for guessing (as `hudson.remoting.ObjectInputStreamEx` in fact does"
  },
  "1460": {
    "source_file": "dependencies-and-class-loading.txt",
    "text": "o guess at a `ClassLoader`,\nbut you can override `resolveClass` to remove the need for guessing (as `hudson.remoting.ObjectInputStreamEx` in fact does).\n\n### Views and other resources\n\nJenkins plugins normally contain \u201cStapler views\u201d like `config.jelly` as well as other resources in `src/main/resources/`.\nWhile you can explicitly load these from Java code:\n\npackage org.jenkinsci.plugins.a;\npublic "
  },
  "1461": {
    "source_file": "dependencies-and-class-loading.txt",
    "text": "ly` as well as other resources in `src/main/resources/`.\nWhile you can explicitly load these from Java code:\n\npackage org.jenkinsci.plugins.a;\npublic class Alpha {\n    /** loads {@code /org/jenkinsci/plugins/a/config.txt} from {@code a.jpi!/WEB-INF/lib/a.jar} */\n    static URL config() throws IOException {\n        return Alpha.class.getResource(\"config.txt\");\n    }\n}\n\nnormally such resources would"
  },
  "1462": {
    "source_file": "dependencies-and-class-loading.txt",
    "text": "ib/a.jar} */\n    static URL config() throws IOException {\n        return Alpha.class.getResource(\"config.txt\");\n    }\n}\n\nnormally such resources would be loaded on your behalf, for example by the convention of Jenkins looking for a view.\nIn such cases the lookup passes through `UberClassLoader`, so your resource path (`/org/jenkinsci/plugins/a/config.txt`)\nhad better be globally unique.\n\n`Messages"
  },
  "1463": {
    "source_file": "dependencies-and-class-loading.txt",
    "text": "s the lookup passes through `UberClassLoader`, so your resource path (`/org/jenkinsci/plugins/a/config.txt`)\nhad better be globally unique.\n\n`Messages.properties` used for localization is a little different,\nsince this is actually compiled to `Messages.class` during the build,\nand thus behaves like any other Java class referred to statically from your plugin code:\n\npackage org.jenkinsci.plugins.a;"
  },
  "1464": {
    "source_file": "dependencies-and-class-loading.txt",
    "text": "es.class` during the build,\nand thus behaves like any other Java class referred to statically from your plugin code:\n\npackage org.jenkinsci.plugins.a;\npublic class Alpha {\n    /** compiled from {@code /org/jenkinsci/plugins/a/Messages.properties#Alpha.message} */\n    static String message() throws IOException {\n        return Messages.Alpha_message();\n    }\n}\n\n## Depending on other plugins\n\nMaking"
  },
  "1465": {
    "source_file": "dependencies-and-class-loading.txt",
    "text": "a.message} */\n    static String message() throws IOException {\n        return Messages.Alpha_message();\n    }\n}\n\n## Depending on other plugins\n\nMaking your plugin depend on other plugins is easy: just declare dependencies in your POM, by hand or using your favorite IDE.\n\n<dependencies>\n    <dependency>\n        <groupId>org.jenkins-ci.plugins</groupId>\n        <artifactId>a</artifactId>\n        <ve"
  },
  "1466": {
    "source_file": "dependencies-and-class-loading.txt",
    "text": "g your favorite IDE.\n\n<dependencies>\n    <dependency>\n        <groupId>org.jenkins-ci.plugins</groupId>\n        <artifactId>a</artifactId>\n        <version>1.13</version>\n    </dependency>\n    <dependency>\n        <groupId>org.jenkins-ci.plugins</groupId>\n        <artifactId>b</artifactId>\n        <version>1.6</version>\n    </dependency>\n</dependencies>\n\nThe Maven packaging type for Jenkins plugin"
  },
  "1467": {
    "source_file": "dependencies-and-class-loading.txt",
    "text": "upId>\n        <artifactId>b</artifactId>\n        <version>1.6</version>\n    </dependency>\n</dependencies>\n\nThe Maven packaging type for Jenkins plugins understands to translate this to the `Plugin-Dependencies` manifest header,\nwhich will be understood by the Jenkins plugin manager, as well as the update center and other tools.\n\nThe Maven compiler plugin similarly understands that `a-1.13.jar` and"
  },
  "1468": {
    "source_file": "dependencies-and-class-loading.txt",
    "text": "od by the Jenkins plugin manager, as well as the update center and other tools.\n\nThe Maven compiler plugin similarly understands that `a-1.13.jar` and `b-1.6.jar` should be added to your classpath when building your plugin.\n\n### Extensions and inversion of control\n\nA \u201cservice locator\u201d pattern is used throughout Jenkins for modularity and extensibility.\nFor example, if a plugin (or core) defines an"
  },
  "1469": {
    "source_file": "dependencies-and-class-loading.txt",
    "text": "ion of control\n\nA \u201cservice locator\u201d pattern is used throughout Jenkins for modularity and extensibility.\nFor example, if a plugin (or core) defines an API\n\npackage org.jenkinsci.plugins.someapi;\nimport hudson.ExtensionPoint;\npublic interface Checker extends ExtensionPoint {\n    boolean doesThisSeemOK(String input);\n}\n\nthen another plugin may declare a dependency on that API\n\n<dependency>\n    <grou"
  },
  "1470": {
    "source_file": "dependencies-and-class-loading.txt",
    "text": "extends ExtensionPoint {\n    boolean doesThisSeemOK(String input);\n}\n\nthen another plugin may declare a dependency on that API\n\n<dependency>\n    <groupId>org.jenkins-ci.plugins</groupId>\n    <artifactId>someapi</artifactId>\n    <version>1.0</version>\n</dependency>\n\nand add an extension:\n\npackage org.jenkinsci.plugins.somethingelse;\nimport hudson.Extension;\nimport org.jenkinsci.plugins.someapi.Chec"
  },
  "1471": {
    "source_file": "dependencies-and-class-loading.txt",
    "text": "\n</dependency>\n\nand add an extension:\n\npackage org.jenkinsci.plugins.somethingelse;\nimport hudson.Extension;\nimport org.jenkinsci.plugins.someapi.Checker;\n@Extension\npublic class MyChecker implements Checker {\n    @Override\n    public boolean doesThisSeemOK(String input) {\n        return !input.contains(\"/\");\n    }\n}\n\nNow any code able to link against `someapi` can use those implementations;\nmost "
  },
  "1472": {
    "source_file": "dependencies-and-class-loading.txt",
    "text": "sSeemOK(String input) {\n        return !input.contains(\"/\");\n    }\n}\n\nNow any code able to link against `someapi` can use those implementations;\nmost commonly this is done inside the same API plugin:\n\npackage org.jenkinsci.plugins.someapi;\nimport hudson.ExtensionList;\nclass RunsChecks {\n    static boolean allFine(String input) {\n        for (Checker c : ExtensionList.lookup(Checker.class)) {\n     "
  },
  "1473": {
    "source_file": "dependencies-and-class-loading.txt",
    "text": "son.ExtensionList;\nclass RunsChecks {\n    static boolean allFine(String input) {\n        for (Checker c : ExtensionList.lookup(Checker.class)) {\n            if (!c.doesThisSeemOK(input)) {\n                return false;\n            }\n        }\n        return true;\n    }\n}\n\nIt is important to understand that while `MyChecker` needs to link against `Checker`, mandating that `dependency`,\n`RunsChecks`"
  },
  "1474": {
    "source_file": "dependencies-and-class-loading.txt",
    "text": " return true;\n    }\n}\n\nIt is important to understand that while `MyChecker` needs to link against `Checker`, mandating that `dependency`,\n`RunsChecks` does _not_ need to be able to link against `MyChecker` (or any of the other implementations).\nWhile the local variable `c`\u2019s implementation class might be in the `somethingelse` plugin,\nit need only care about the _declared type_ `Checker`.\n\n## Bund"
  },
  "1475": {
    "source_file": "dependencies-and-class-loading.txt",
    "text": " the local variable `c`\u2019s implementation class might be in the `somethingelse` plugin,\nit need only care about the _declared type_ `Checker`.\n\n## Bundling third-party libraries\n\nSometimes plugins need to use Java libraries beyond what is available in the Java Platform and Jenkins itself.\nFor example, a plugin connecting to a particular service might use a Java SDK provided by the vendor.\n\nDoing th"
  },
  "1476": {
    "source_file": "dependencies-and-class-loading.txt",
    "text": " the Java Platform and Jenkins itself.\nFor example, a plugin connecting to a particular service might use a Java SDK provided by the vendor.\n\nDoing this is very easy\u2014in principle.\nSimply declare a Maven dependency on that library:\n\n<dependency>\n    <groupId>com.yoyodyne.cloud</groupId>\n    <artifactId>cloud-access-sdk</artifactId>\n    <version>1.0</version>\n</dependency>\n\n(This assumes that the li"
  },
  "1477": {
    "source_file": "dependencies-and-class-loading.txt",
    "text": "groupId>com.yoyodyne.cloud</groupId>\n    <artifactId>cloud-access-sdk</artifactId>\n    <version>1.0</version>\n</dependency>\n\n(This assumes that the library is available in Maven Central.\nIf not, it is possible to upload artifacts to the Jenkins Artifactory repository for use from plugins.\nAsk on the developer list for help.\nDo *not* attempt to keep such binaries in source control.)\n\nBesides making"
  },
  "1478": {
    "source_file": "dependencies-and-class-loading.txt",
    "text": "actory repository for use from plugins.\nAsk on the developer list for help.\nDo *not* attempt to keep such binaries in source control.)\n\nBesides making SDK classes (say, `+com.yoyodyne.cloud.*+`) available during compilation,\nthe `maven-hpi-plugin` used to create Jenkins plugins will notice that this dependency is not itself a Jenkins plugin,\nand instead _bundle_ it inside `yourplugin.hpi` as `WEB-"
  },
  "1479": {
    "source_file": "dependencies-and-class-loading.txt",
    "text": "ed to create Jenkins plugins will notice that this dependency is not itself a Jenkins plugin,\nand instead _bundle_ it inside `yourplugin.hpi` as `WEB-INF/lib/cloud-access-sdk-1.0.jar`.\n\nAt runtime, the plugin class loader will load classes from `WEB-INF/lib/cloud-access-sdk-1.0.jar`,\njust as it would from `WEB-INF/lib/yourplugin.jar` (your plugin\u2019s own code, from `src/main/java/` and `src/main/res"
  },
  "1480": {
    "source_file": "dependencies-and-class-loading.txt",
    "text": "INF/lib/cloud-access-sdk-1.0.jar`,\njust as it would from `WEB-INF/lib/yourplugin.jar` (your plugin\u2019s own code, from `src/main/java/` and `src/main/resources/`).\nThus your plugin\u2019s classes can refer to classes in that library.\nOther plugins depending on your plugin can, too.\n\n### Checking `+WEB-INF/lib/*.jar+` for junk\n\nBeware that Maven dependencies include _all transitive_ dependencies.\nThis can "
  },
  "1481": {
    "source_file": "dependencies-and-class-loading.txt",
    "text": "on your plugin can, too.\n\n### Checking `+WEB-INF/lib/*.jar+` for junk\n\nBeware that Maven dependencies include _all transitive_ dependencies.\nThis can lead to unexpected results when bundling libraries.\nFor example, the POM for `com.yoyodyne.cloud:cloud-access-sdk` might declare that it needs `org.apache.commons:commons-lang3:3.18.0`.\nYour plugin will thus wind up bundling `commons-lang3-3.18.0.jar"
  },
  "1482": {
    "source_file": "dependencies-and-class-loading.txt",
    "text": "ud-access-sdk` might declare that it needs `org.apache.commons:commons-lang3:3.18.0`.\nYour plugin will thus wind up bundling `commons-lang3-3.18.0.jar` as well.\nIf you are not careful, `WEB-INF/lib/` may fill up with megabytes of stuff which is not actually used.\nFor example, you may depend on a plugin which already provides that dependency, or the dependency may be provided by Jenkins core.\n\n### "
  },
  "1483": {
    "source_file": "dependencies-and-class-loading.txt",
    "text": "ctually used.\nFor example, you may depend on a plugin which already provides that dependency, or the dependency may be provided by Jenkins core.\n\n### Build-time validation of bundled artifacts\n\nTo avoid surprises, as long as you are using version 5.22 of the plugin parent POM or newer, you can set the `hpi.strictBundledArtifacts` property in your plugin's `pom.xml` to `true` to enable automatic bu"
  },
  "1484": {
    "source_file": "dependencies-and-class-loading.txt",
    "text": "2 of the plugin parent POM or newer, you can set the `hpi.strictBundledArtifacts` property in your plugin's `pom.xml` to `true` to enable automatic build-time validation of bundled artifacts.\nWhen enabled, the `artifactId` of all bundled artifacts (including both direct and transitive dependencies) must be specified in the property `hpi.bundledArtifacts` as a sorted and comma-separated list.\nIf th"
  },
  "1485": {
    "source_file": "dependencies-and-class-loading.txt",
    "text": "ncluding both direct and transitive dependencies) must be specified in the property `hpi.bundledArtifacts` as a sorted and comma-separated list.\nIf the specified list does not match the actual list of bundled artifacts, the build will fail with an error message showing the mismatch.\nTo resolve the build failure, you will need to review the actual list of bundled artifacts and decide whether to upd"
  },
  "1486": {
    "source_file": "dependencies-and-class-loading.txt",
    "text": "ror message showing the mismatch.\nTo resolve the build failure, you will need to review the actual list of bundled artifacts and decide whether to update `hpi.bundledArtifacts` to match, or to adjust the plugin's dependencies, for example by adding `exclusions`.\n\nHere is an example configuration:\n\n<properties>\n    <hpi.strictBundledArtifacts>true</hpi.strictBundledArtifacts>\n    <hpi.bundledArtifa"
  },
  "1487": {
    "source_file": "dependencies-and-class-loading.txt",
    "text": "exclusions`.\n\nHere is an example configuration:\n\n<properties>\n    <hpi.strictBundledArtifacts>true</hpi.strictBundledArtifacts>\n    <hpi.bundledArtifacts>cloud-access-sdk,cloud-access-sdk-transitive-dep</hpi.bundledArtifacts>\n</properties>\n<dependencies>\n    <dependency>\n        <groupId>com.yoyodyne.cloud</groupId>\n        <artifactId>cloud-access-sdk</artifactId>\n        <version>1.0</version>\n "
  },
  "1488": {
    "source_file": "dependencies-and-class-loading.txt",
    "text": "ies>\n    <dependency>\n        <groupId>com.yoyodyne.cloud</groupId>\n        <artifactId>cloud-access-sdk</artifactId>\n        <version>1.0</version>\n        <exclusions>\n            <exclusion>\n                <!-- Picked up via plugin commons-lang3-api -->\n                <groupId>org.apache.commons</groupId>\n                <artifactId>commons-lang3</artifactId>\n            </exclusion>\n        "
  },
  "1489": {
    "source_file": "dependencies-and-class-loading.txt",
    "text": "api -->\n                <groupId>org.apache.commons</groupId>\n                <artifactId>commons-lang3</artifactId>\n            </exclusion>\n        </exclusions>\n    </dependency>\n    <dependency>\n        <groupId>io.jenkins.plugins</groupId>\n        <artifactId>commons-lang3-api</artifactId>\n    </dependency>\n</dependencies>\n\n### Using library wrapper plugins\n\nIn practice it is undesirable for "
  },
  "1490": {
    "source_file": "dependencies-and-class-loading.txt",
    "text": "   <artifactId>commons-lang3-api</artifactId>\n    </dependency>\n</dependencies>\n\n### Using library wrapper plugins\n\nIn practice it is undesirable for Jenkins feature plugins to bundle assorted third-party libraries.\nTypically other plugins will need some of the same libraries, so multiple plugins will wind up bundling copies.\nEven if all of these copies happen to be the exact same version, \u201cdownst"
  },
  "1491": {
    "source_file": "dependencies-and-class-loading.txt",
    "text": "some of the same libraries, so multiple plugins will wind up bundling copies.\nEven if all of these copies happen to be the exact same version, \u201cdownstream\u201d plugins can wind up getting linkage errors.\nAnd users will wind up downloading multiple copies of the same code,\nincreasing product and `$JENKINS_HOME/plugins/` sizes, update center load, HotSpot compiler delays, etc.\n\nAnother problem is that u"
  },
  "1492": {
    "source_file": "dependencies-and-class-loading.txt",
    "text": " of the same code,\nincreasing product and `$JENKINS_HOME/plugins/` sizes, update center load, HotSpot compiler delays, etc.\n\nAnother problem is that updating library versions becomes harder to centralize when they are bundled independently in multiple plugins.\nWhile having each plugin define an exact version of a library does reduce the risk of API compatibility errors,\nthis is outweighed by the n"
  },
  "1493": {
    "source_file": "dependencies-and-class-loading.txt",
    "text": "e plugins.\nWhile having each plugin define an exact version of a library does reduce the risk of API compatibility errors,\nthis is outweighed by the need to update a library with assurance when new security vulnerabilities (or other critical fixes) are announced.\n\nTo centralize library management, you can instead define a _wrapper_ plugin, or find one someone else has already defined.\nThis is a Je"
  },
  "1494": {
    "source_file": "dependencies-and-class-loading.txt",
    "text": "re announced.\n\nTo centralize library management, you can instead define a _wrapper_ plugin, or find one someone else has already defined.\nThis is a Jenkins plugin which contains no sources of its own and simply includes a `dependency` on some library.\nAfter being published on the update center, other \u201cfeature\u201d plugins can declare plain plugin-to-plugin dependencies on it and thus use the library.\n"
  },
  "1495": {
    "source_file": "dependencies-and-class-loading.txt",
    "text": ".\nAfter being published on the update center, other \u201cfeature\u201d plugins can declare plain plugin-to-plugin dependencies on it and thus use the library.\n\nOccasionally it can make sense to include a few API classes in the wrapper plugin itself,\nwhere any Jenkins code using the library would reasonably need some boilerplate adapters to standard Jenkins facilities.\n\nTo mitigate the risk of library plugi"
  },
  "1496": {
    "source_file": "dependencies-and-class-loading.txt",
    "text": " Jenkins code using the library would reasonably need some boilerplate adapters to standard Jenkins facilities.\n\nTo mitigate the risk of library plugin updates with incompatible changes breaking plugin functionality,\nit is suggested to include the major version of the library in the wrapper plugin\u2019s `artifactId`: for example, `commons-lang3`.\n(This assumes that the library follows something like h"
  },
  "1497": {
    "source_file": "dependencies-and-class-loading.txt",
    "text": "jor version of the library in the wrapper plugin\u2019s `artifactId`: for example, `commons-lang3`.\n(This assumes that the library follows something like https://semver.org/[Semantic Versioning].)\nThus there could be multiple major releases loaded simultaneously.\nOf course this means that critical fixes must be issued as updates to all release lines, so only do this for _supported_ versions of the libr"
  },
  "1498": {
    "source_file": "dependencies-and-class-loading.txt",
    "text": "neously.\nOf course this means that critical fixes must be issued as updates to all release lines, so only do this for _supported_ versions of the library.\n\n### `pluginFirstClassLoader` and its discontents\n\nThe default behavior of Java class loaders, and of Jenkins plugin class loaders as well,\nis to service `loadClass` requests first by asking the parent loader(s) for the class of that name,\nand o"
  },
  "1499": {
    "source_file": "dependencies-and-class-loading.txt",
    "text": "and of Jenkins plugin class loaders as well,\nis to service `loadClass` requests first by asking the parent loader(s) for the class of that name,\nand only if that fails to check whether the class could be defined among JARs present in the initiating loader.\nThis is generally sensible since it ensures that types mentioned in bytecode from different plugins\nare resolved at runtime to the same `Class`"
  },
  "1500": {
    "source_file": "dependencies-and-class-loading.txt",
    "text": "oader.\nThis is generally sensible since it ensures that types mentioned in bytecode from different plugins\nare resolved at runtime to the same `Class` objects and thus allowing APIs to work using shared type signatures.\n\nSometimes, however, it is not wanted for the parent to be searched first.\nFor example, Jenkins core currently bundles a plethora of third-party libraries and exposes all of their "
  },
  "1501": {
    "source_file": "dependencies-and-class-loading.txt",
    "text": " wanted for the parent to be searched first.\nFor example, Jenkins core currently bundles a plethora of third-party libraries and exposes all of their packages to plugins.\nFor that matter, some plugins bundle third-party libraries that are then incidentally exposed\nto other plugins needing a dependency on APIs defined in the bundling plugins.\nIf a plugin also needs some variant of the same library "
  },
  "1502": {
    "source_file": "dependencies-and-class-loading.txt",
    "text": "ntally exposed\nto other plugins needing a dependency on APIs defined in the bundling plugins.\nIf a plugin also needs some variant of the same library for its own use, it will surprisingly not be able to load it,\nbecause the parent class loader will find it first.\n\nTo avoid that behavior, it is possible to set a flag  in the plugin\u2019s Maven POM.\n(This simply produces a JAR manifest entry that is int"
  },
  "1503": {
    "source_file": "dependencies-and-class-loading.txt",
    "text": "ind it first.\n\nTo avoid that behavior, it is possible to set a flag  in the plugin\u2019s Maven POM.\n(This simply produces a JAR manifest entry that is interpreted by the Jenkins plugin system at runtime.)\nThis flag instructs the plugin class loader to check its own JARs _first_ for any mentioned class names.\nYou must be very careful when using this mode, since any type normally defined in core (or an "
  },
  "1504": {
    "source_file": "dependencies-and-class-loading.txt",
    "text": "eck its own JARs _first_ for any mentioned class names.\nYou must be very careful when using this mode, since any type normally defined in core (or an \u201cupstream\u201d plugin)\nwhich is mentioned in any part of the Java signature of a method you are calling must not be duplicated in your JARs, or linkage errors will result.\nThus it is best reserved to libraries used purely by internal implementation.\n\nA m"
  },
  "1505": {
    "source_file": "dependencies-and-class-loading.txt",
    "text": "must not be duplicated in your JARs, or linkage errors will result.\nThus it is best reserved to libraries used purely by internal implementation.\n\nA more limited flag is `maskClasses`, which blocks only selected classes or packages from the parent loader, rather than everything.\nYou must manually verify that the masked classes are complete under the transitive closure of the Java linker:\nfor examp"
  },
  "1506": {
    "source_file": "dependencies-and-class-loading.txt",
    "text": "ader, rather than everything.\nYou must manually verify that the masked classes are complete under the transitive closure of the Java linker:\nfor example, masking one package but not another from a library bundled in core could make classes in the masked package unresolvable.\n\nIf you did not understand any part of this section, do not use these options. Even if you did, think twice.\n\n### Shading\n\nA"
  },
  "1507": {
    "source_file": "dependencies-and-class-loading.txt",
    "text": "ked package unresolvable.\n\nIf you did not understand any part of this section, do not use these options. Even if you did, think twice.\n\n### Shading\n\nAnother approach to taming the complexity of library dependencies and class loading is loosely referred to as _shading_,\nexemplified by the https://maven.apache.org/plugins/maven-shade-plugin/[Maven Shade plugin] (though multiple techniques are possib"
  },
  "1508": {
    "source_file": "dependencies-and-class-loading.txt",
    "text": "ed to as _shading_,\nexemplified by the https://maven.apache.org/plugins/maven-shade-plugin/[Maven Shade plugin] (though multiple techniques are possible).\nIn this case, rather than trying to control where a given `classLoader.loadClass(\"org.apache.commons.lang.StringUtils\")` call finds the defining loader,\nthe idea is to bundle the entire library under a distinct package prefix, rewriting all stat"
  },
  "1509": {
    "source_file": "dependencies-and-class-loading.txt",
    "text": "mmons.lang.StringUtils\")` call finds the defining loader,\nthe idea is to bundle the entire library under a distinct package prefix, rewriting all static and reflective class (or resource) loads,\nboth within the library and from code defined in the plugin doing the bundling.\nThus `your-plugin.hpi!/WEB-INF/lib/commons-lang-shaded.jar` might contain entries like `org/jenkinsci/plugins/yourplugin/comm"
  },
  "1510": {
    "source_file": "dependencies-and-class-loading.txt",
    "text": "ugin doing the bundling.\nThus `your-plugin.hpi!/WEB-INF/lib/commons-lang-shaded.jar` might contain entries like `org/jenkinsci/plugins/yourplugin/commonslang/StringUtils.class`;\nand plugin source code like\n\nimport org.apache.commons.lang.StringUtils;\n// \u2026\nif (StringUtils.isEmpty(arg)) {/* \u2026 */}\n\nwould result in bytecode in `your-plugin.hpi!/WEB-INF/lib/classes.jar` referring in its constant pool t"
  },
  "1511": {
    "source_file": "dependencies-and-class-loading.txt",
    "text": "\n// \u2026\nif (StringUtils.isEmpty(arg)) {/* \u2026 */}\n\nwould result in bytecode in `your-plugin.hpi!/WEB-INF/lib/classes.jar` referring in its constant pool to the type `org.jenkinsci.plugins.yourplugin.commonslang.StringUtils`.\nSince that type name is unique in the whole Jenkins JVM, there is no risk of it being loaded from the wrong place;\nfrom the perspective of Jenkins, it is as if you copied and past"
  },
  "1512": {
    "source_file": "dependencies-and-class-loading.txt",
    "text": "e in the whole Jenkins JVM, there is no risk of it being loaded from the wrong place;\nfrom the perspective of Jenkins, it is as if you copied and pasted the whole Commons Lang library into some sources in your plugin.\n\nWhile this system does address the risk of linkage errors, it does nothing to reduce the profusion of library versions in Jenkins,\nas described in the section on library wrappers.\nI"
  },
  "1513": {
    "source_file": "dependencies-and-class-loading.txt",
    "text": "the risk of linkage errors, it does nothing to reduce the profusion of library versions in Jenkins,\nas described in the section on library wrappers.\nIn some cases, however, library wrappers themselves will use this same trick for official purposes,\nso that the wrapped library will be present under a package name indicating the major release version.\nPlugins using the wrapped library therefore woul"
  },
  "1514": {
    "source_file": "dependencies-and-class-loading.txt",
    "text": "o that the wrapped library will be present under a package name indicating the major release version.\nPlugins using the wrapped library therefore would refer to the repackaged name:\n\nimport org.jenkinsci.commons_lang2.StringUtils;\n\n## `@Restricted` annotations\n\nThe `public` modifier in Java allows types, methods, constructors, and fields to be accessed from any other class in the system capable of"
  },
  "1515": {
    "source_file": "dependencies-and-class-loading.txt",
    "text": "nnotations\n\nThe `public` modifier in Java allows types, methods, constructors, and fields to be accessed from any other class in the system capable of linking against the defining type.\nThus it forms part of the API, as do `protected` members.\n\nHowever in some cases use of these access modifiers are forced for technical reasons rather than out of an intent to define an API:\na method might need to "
  },
  "1516": {
    "source_file": "dependencies-and-class-loading.txt",
    "text": "er in some cases use of these access modifiers are forced for technical reasons rather than out of an intent to define an API:\na method might need to be accessed from a class in another package in the same plugin, preventing use of default package access;\nan `@Extension` needs to be `public` to allow the Jenkins service loader to instantiate it;\na `FormValidation doCheckName(@QueryParameter String"
  },
  "1517": {
    "source_file": "dependencies-and-class-loading.txt",
    "text": "cess;\nan `@Extension` needs to be `public` to allow the Jenkins service loader to instantiate it;\na `FormValidation doCheckName(@QueryParameter String value)` method must be `public` to expose it as a Stapler web method and thus to JavaScript on a form.\n\nIn such cases you should block the member from being used by outside code:\nnonessential API additions are at risk of being used in unintended way"
  },
  "1518": {
    "source_file": "dependencies-and-class-loading.txt",
    "text": "rm.\n\nIn such cases you should block the member from being used by outside code:\nnonessential API additions are at risk of being used in unintended ways\nand forcing your plugin to maintain the member more or less forever lest backward compatibility be broken.\nThis can be accomplished by use of a special annotation available in Jenkins code:\n\n@Restricted(NoExternalUse.class)\n@Extension\npublic class "
  },
  "1519": {
    "source_file": "dependencies-and-class-loading.txt",
    "text": " broken.\nThis can be accomplished by use of a special annotation available in Jenkins code:\n\n@Restricted(NoExternalUse.class)\n@Extension\npublic class MyListener extends ItemListener {/* \u2026 */}\n\nOther plugins attempting to refer to `MyListener` will receive a build-time error.\nTherefore you are free to rename, move, delete, or otherwise modify `MyListener` at any time.\n\nSeveral kinds of restriction "
  },
  "1520": {
    "source_file": "dependencies-and-class-loading.txt",
    "text": "ceive a build-time error.\nTherefore you are free to rename, move, delete, or otherwise modify `MyListener` at any time.\n\nSeveral kinds of restriction are available; consult Javadoc for details.\n\nThis system has no effect on accesses using `java.lang.reflect`.\n\n## `JenkinsRule` vs. `acceptance-test-harness` class loading\n\nThere are three main categories of automated test used in Jenkins:\n\n* Unit te"
  },
  "1521": {
    "source_file": "dependencies-and-class-loading.txt",
    "text": "reflect`.\n\n## `JenkinsRule` vs. `acceptance-test-harness` class loading\n\nThere are three main categories of automated test used in Jenkins:\n\n* Unit tests, including mocking frameworks such as PowerMock.\n* Functional tests based on the `JenkinsRule` API defined in `jenkins-test-harness`.\n* Acceptance tests located in the `acceptance-test-harness` repository.\n\nThese have different levels of fidelity"
  },
  "1522": {
    "source_file": "dependencies-and-class-loading.txt",
    "text": "PI defined in `jenkins-test-harness`.\n* Acceptance tests located in the `acceptance-test-harness` repository.\n\nThese have different levels of fidelity to the class loading behavior of plugin code running in production Jenkins servers.\nUnit tests simply pick up the Java classpath (java.class.path) defined by Maven\u2019s `test` scope.\n\nAcceptance tests run a full Jenkins server and install plugins (incl"
  },
  "1523": {
    "source_file": "dependencies-and-class-loading.txt",
    "text": "ly pick up the Java classpath (java.class.path) defined by Maven\u2019s `test` scope.\n\nAcceptance tests run a full Jenkins server and install plugins (including the plugin(s) being tested) using Jenkins\u2019 normal mechanisms.\nSince the test does not compile or link against any types defined in the Jenkins runtime (only against the Selenium web driver),\nand does not even run in the same JVM as Jenkins, it "
  },
  "1524": {
    "source_file": "dependencies-and-class-loading.txt",
    "text": "or link against any types defined in the Jenkins runtime (only against the Selenium web driver),\nand does not even run in the same JVM as Jenkins, it has no interaction with the class loading of Jenkins.\nThus the class loading behavior of plugins running in an acceptance test can be assumed to be the same as in production.\n\nClass loading in functional tests is intermediate in behavior, but closer "
  },
  "1525": {
    "source_file": "dependencies-and-class-loading.txt",
    "text": "ning in an acceptance test can be assumed to be the same as in production.\n\nClass loading in functional tests is intermediate in behavior, but closer to that of unit tests.\nTest code _does_ link against Jenkins core and (`test`-scoped) plugin types,\nand everything in the Java classpath is in fact loaded in Java\u2019s application class loader\u2014including plugins in `test` scope.\nThis means that certain m"
  },
  "1526": {
    "source_file": "dependencies-and-class-loading.txt",
    "text": "and everything in the Java classpath is in fact loaded in Java\u2019s application class loader\u2014including plugins in `test` scope.\nThis means that certain mistakes in plugin metadata (for example, misuse of `pluginFirstClassLoader`) may go unnoticed.\n\n(`JenkinsRule` does start a real Jenkins service, and in some cases other plugins can get installed which were not in the Java classpath.\nThese get their "
  },
  "1527": {
    "source_file": "dependencies-and-class-loading.txt",
    "text": "nkinsRule` does start a real Jenkins service, and in some cases other plugins can get installed which were not in the Java classpath.\nThese get their own class loaders.)\n\nWhenever there is any doubt about whether class loading behavior could affect plugin or core code,\nuse `RealJenkinsRule` which launches Jenkins in a separate JVM with the regular class loader hierarchy.\n\n## Jenkins modules\n\nHisto"
  },
  "1528": {
    "source_file": "dependencies-and-class-loading.txt",
    "text": "lugin or core code,\nuse `RealJenkinsRule` which launches Jenkins in a separate JVM with the regular class loader hierarchy.\n\n## Jenkins modules\n\nHistorical versions of `jenkins.war` included a few components called _modules_ which are built and packaged just like plugins, and can refer to types defined in Jenkins core,\nbut which are bundled alongside core and cannot be managed by users in the plug"
  },
  "1529": {
    "source_file": "dependencies-and-class-loading.txt",
    "text": "ged just like plugins, and can refer to types defined in Jenkins core,\nbut which are bundled alongside core and cannot be managed by users in the plugin manager.\nThe usual reason for this design is to include features which either cannot be disabled,\nor must be present early in the Jenkins startup sequence, before plugins have been fully initialized.\n\nFor purposes of class loading, these component"
  },
  "1530": {
    "source_file": "dependencies-and-class-loading.txt",
    "text": "\nor must be present early in the Jenkins startup sequence, before plugins have been fully initialized.\n\nFor purposes of class loading, these components behave like anything else bundled inside core: modules do not get their own class loaders.\nFor Maven dependency management purposes, plugins can declare `provided`-scope dependencies on these modules if they wish to use their APIs,\ntaking care to s"
  },
  "1531": {
    "source_file": "dependencies-and-class-loading.txt",
    "text": "en dependency management purposes, plugins can declare `provided`-scope dependencies on these modules if they wish to use their APIs,\ntaking care to select the same version as is bundled in the baseline version of core.\n\njep:230[] removed this system at least from the default Jenkins distribution."
  },
  "1532": {
    "source_file": "dependencies-and-class-loading.txt",
    "text": " at least from the default Jenkins distribution."
  },
  "1533": {
    "source_file": "dependency-management.txt",
    "text": "layout: developersection\ntitle: Dependency Management\nreferences:\n- url: https://github.com/jenkinsci/plugin-pom/\n  title: Plugin parent POM 4.0 and up\n- url: https://github.com/jenkinsci/jenkins/blob/master/bom/pom.xml\n  title: Jenkins Core BOM\n\n\nPlugins depend on specific versions of libraries and of other plugins, each of which is versioned independently.\nEach dependency may have dependencies o"
  },
  "1534": {
    "source_file": "dependency-management.txt",
    "text": "ugins depend on specific versions of libraries and of other plugins, each of which is versioned independently.\nEach dependency may have dependencies of its own, and different versions of different libraries and plugins may not be compatible with each other.\nMoreover, the dependencies can change with each Jenkins release, so managing these dependencies manually can be difficult and time consuming.\n"
  },
  "1535": {
    "source_file": "dependency-management.txt",
    "text": " other.\nMoreover, the dependencies can change with each Jenkins release, so managing these dependencies manually can be difficult and time consuming.\nAvoid using version ranges when developing plugins, as this reduces the repeatability of builds and can create dependency management problems.\nThe expected pattern for dependencies is to have pinned dependencies updated by <<Dependabot>> or .\n\nJenkin"
  },
  "1536": {
    "source_file": "dependency-management.txt",
    "text": "can create dependency management problems.\nThe expected pattern for dependencies is to have pinned dependencies updated by <<Dependabot>> or .\n\nJenkins has tools that simplify dependency management:\n\n* <<jenkins-core-bom,Jenkins core Bill of Materials (BOM)>> centrally defines the **library versions** provided by Jenkins core\n* <<jenkins-plugin-bom,Plugin Bill of Materials (BOM)>> centrally define"
  },
  "1537": {
    "source_file": "dependency-management.txt",
    "text": "s (BOM)>> centrally defines the **library versions** provided by Jenkins core\n* <<jenkins-plugin-bom,Plugin Bill of Materials (BOM)>> centrally defines a set of **plugin versions** that have been tested together\n* <<Dependabot>> automatically proposes a pull request when a new version of a dependency is released\n\nJenkins core provides a  that centrally defines versions of various libraries used by"
  },
  "1538": {
    "source_file": "dependency-management.txt",
    "text": "s a pull request when a new version of a dependency is released\n\nJenkins core provides a  that centrally defines versions of various libraries used by Jenkins.\nIf you are using Maven to build your plugin, then you can simplify dependency management by importing this BOM, at `jenkins.version`.\nDependency versions are then automatically  synchronized with the version of Jenkins against which you are"
  },
  "1539": {
    "source_file": "dependency-management.txt",
    "text": "y importing this BOM, at `jenkins.version`.\nDependency versions are then automatically  synchronized with the version of Jenkins against which you are building.\n\nLibrary dependency issues may cause `Require upper bound dependencies` build errors such as:\n\n[WARNING] Rule 4: org.apache.maven.plugins.enforcer.RequireUpperBoundDeps failed with message:\nFailed while enforcing RequireUpperBoundDeps. The"
  },
  "1540": {
    "source_file": "dependency-management.txt",
    "text": " as:\n\n[WARNING] Rule 4: org.apache.maven.plugins.enforcer.RequireUpperBoundDeps failed with message:\nFailed while enforcing RequireUpperBoundDeps. The error(s) are [\nRequire upper bound dependencies error for commons-codec:commons-codec:1.9 paths to dependency are:\n-org.jenkins-ci.plugins:blueocean-display-url:2.3.1-SNAPSHOT\n  +-commons-codec:commons-codec:1.9\nand\n-org.jenkins-ci.plugins:blueocean"
  },
  "1541": {
    "source_file": "dependency-management.txt",
    "text": "dependency are:\n-org.jenkins-ci.plugins:blueocean-display-url:2.3.1-SNAPSHOT\n  +-commons-codec:commons-codec:1.9\nand\n-org.jenkins-ci.plugins:blueocean-display-url:2.3.1-SNAPSHOT\n  +-org.jenkins-ci.main:jenkins-core:2.195\n    +-commons-codec:commons-codec:1.12\n,\nRequire upper bound dependencies error for org.slf4j:jcl-over-slf4j:1.7.25 paths to dependency are:\n-org.jenkins-ci.plugins:blueocean-disp"
  },
  "1542": {
    "source_file": "dependency-management.txt",
    "text": "odec:1.12\n,\nRequire upper bound dependencies error for org.slf4j:jcl-over-slf4j:1.7.25 paths to dependency are:\n-org.jenkins-ci.plugins:blueocean-display-url:2.3.1-SNAPSHOT\n  +-org.slf4j:jcl-over-slf4j:1.7.25\nand\n-org.jenkins-ci.plugins:blueocean-display-url:2.3.1-SNAPSHOT\n  +-org.jenkins-ci.main:jenkins-core:2.195\n    +-org.slf4j:jcl-over-slf4j:1.7.26\n\nThis error says that a conflict exists betwe"
  },
  "1543": {
    "source_file": "dependency-management.txt",
    "text": "play-url:2.3.1-SNAPSHOT\n  +-org.jenkins-ci.main:jenkins-core:2.195\n    +-org.slf4j:jcl-over-slf4j:1.7.26\n\nThis error says that a conflict exists between the versions of `commons-codec` and `jcl-over-slf4j` specified by the plugin versus Jenkins core.\nSee  for more information.\n\nIn many cases, upper bounds dependencies errors are best resolved by updating the Jenkins core Bill of Materials and by u"
  },
  "1544": {
    "source_file": "dependency-management.txt",
    "text": "\nSee  for more information.\n\nIn many cases, upper bounds dependencies errors are best resolved by updating the Jenkins core Bill of Materials and by using the Jenkins plugin Bill of Materials.\n\nUpdate the parent pom version with the following commands:\n\nmvn versions:update-parent\nmvn clean verify\n\nIf the command reports an error that the `Project does not have a parent`, please configure `~/.m2/se"
  },
  "1545": {
    "source_file": "dependency-management.txt",
    "text": "s:\n\nmvn versions:update-parent\nmvn clean verify\n\nIf the command reports an error that the `Project does not have a parent`, please configure `~/.m2/settings.xml` as noted in the .\n\nSee the video below for a step by step guide to updating the parent pom.\n\n.Update the parent pom\nvideo::Fev8KfFsPZE[youtube, width=852, height=480,start=807]\n\nThe plugin bill of materials (BOM) defines the versions of v"
  },
  "1546": {
    "source_file": "dependency-management.txt",
    "text": "om.\n\n.Update the parent pom\nvideo::Fev8KfFsPZE[youtube, width=852, height=480,start=807]\n\nThe plugin bill of materials (BOM) defines the versions of various plugins used by specific Jenkins versions.\nThe plugin bill of materials includes many commonly used plugins\nand simplifies dependency management for plugins that depend on other plugins.\n\nA plugin that tests its Pipeline implementation typical"
  },
  "1547": {
    "source_file": "dependency-management.txt",
    "text": "y used plugins\nand simplifies dependency management for plugins that depend on other plugins.\n\nA plugin that tests its Pipeline implementation typically depends on several Pipeline plugins.\nThe plugin BOM provides Pipeline plugin version numbers so that the developer does not need to maintain the independent version numbers of the Pipeline plugins.\n\nThe plugin bill of materials is defined in the `"
  },
  "1548": {
    "source_file": "dependency-management.txt",
    "text": "hat the developer does not need to maintain the independent version numbers of the Pipeline plugins.\n\nThe plugin bill of materials is defined in the `dependencyManagement` section of your _pom.xml_ file.\nTo use the Jenkins plugin BOM in your plugin:\n\nConfirm that you are using the  with the command `mvn versions:update-parent`\nLocate the most recent plugin bom version number on the\nCopy the `depen"
  },
  "1549": {
    "source_file": "dependency-management.txt",
    "text": "\nConfirm that you are using the  with the command `mvn versions:update-parent`\nLocate the most recent plugin bom version number on the\nCopy the `dependencyManagement` section from the _pom.xml_ file in that directory\nInsert this `dependencyManagement` section into the _pom.xml_ file for your plugin\n<dependencyManagement>\n    <dependencies>\n        <dependency>\n            <groupId>io.jenkins.tools"
  },
  "1550": {
    "source_file": "dependency-management.txt",
    "text": "` section into the _pom.xml_ file for your plugin\n<dependencyManagement>\n    <dependencies>\n        <dependency>\n            <groupId>io.jenkins.tools.bom</groupId>\n            <artifactId>bom-2.504.x</artifactId>\n            <!-- Latest version goes here -->\n            <version>5701.va_b_018a_a_6b_0d3</version>\n            <scope>import</scope>\n            <type>pom</type>\n        </dependency>\n"
  },
  "1551": {
    "source_file": "dependency-management.txt",
    "text": " here -->\n            <version>5701.va_b_018a_a_6b_0d3</version>\n            <scope>import</scope>\n            <type>pom</type>\n        </dependency>\n    </dependencies>\n</dependencyManagement>\n\nRemove the `<version>` values from plugin dependencies in your plugin's _pom.xml_\nRebuild your plugin to see if this solves your dependency issues.\n  Many commonly used plugins are included in the plugin p"
  },
  "1552": {
    "source_file": "dependency-management.txt",
    "text": "in your plugin's _pom.xml_\nRebuild your plugin to see if this solves your dependency issues.\n  Many commonly used plugins are included in the plugin pom.\n  However, not **all** plugins are included.\n  You may need to iterate on removing `<version>` values from specific plugins\n\nSee the  for further details.\nThe video below demonstrates how to add the plugin BOM to a Jenkins plugin.\n\n.Simplify plug"
  },
  "1553": {
    "source_file": "dependency-management.txt",
    "text": "alues from specific plugins\n\nSee the  for further details.\nThe video below demonstrates how to add the plugin BOM to a Jenkins plugin.\n\n.Simplify plugin dependency management with the plugin BOM\nvideo::pk1gweLvcEI[youtube, width=852, height=480, start=1771]\n\nGitHub  can automate plugin dependency management.\nNewly created plugins built from the  include Dependabot by default.\n\nExisting plugins nee"
  },
  "1554": {
    "source_file": "dependency-management.txt",
    "text": "t=1771]\n\nGitHub  can automate plugin dependency management.\nNewly created plugins built from the  include Dependabot by default.\n\nExisting plugins need to configure Dependabot in their existing plugin repository.\nSee the video below for an example that adds Dependabot to an existing plugin repository:\n\n.Automate dependency management with Dependabot\nvideo::2c8wK2jkcIA[youtube, width=852, height=48"
  },
  "1555": {
    "source_file": "dependency-management.txt",
    "text": "at adds Dependabot to an existing plugin repository:\n\n.Automate dependency management with Dependabot\nvideo::2c8wK2jkcIA[youtube, width=852, height=480, start=980]"
  },
  "1556": {
    "source_file": "deployment.txt",
    "text": "layout: documentation\ntitle: Deployment\n\n\nThe most basic continuous delivery pipeline will have, at minimum, three stages\nwhich should be defined in a `Jenkinsfile`: Build, Test, and Deploy. For this\nsection we will focus primarily on the Deploy stage, but it should be noted\nthat stable Build and Test stages are an important precursor to any deployment\nactivity.\n\n[pipeline]\n\n// Declarative //\npipe"
  },
  "1557": {
    "source_file": "deployment.txt",
    "text": "e, but it should be noted\nthat stable Build and Test stages are an important precursor to any deployment\nactivity.\n\n[pipeline]\n\n// Declarative //\npipeline {\n    agent any\n    options {\n        skipStagesAfterUnstable()\n    }\n    stages {\n        stage('Build') {\n            steps {\n                echo 'Building'\n            }\n        }\n        stage('Test') {\n            steps {\n                e"
  },
  "1558": {
    "source_file": "deployment.txt",
    "text": "e('Build') {\n            steps {\n                echo 'Building'\n            }\n        }\n        stage('Test') {\n            steps {\n                echo 'Testing'\n            }\n        }\n        stage('Deploy') {\n            steps {\n                echo 'Deploying'\n            }\n        }\n    }\n}\n// Scripted //\nnode {\n    stage('Build') {\n        echo 'Building'\n    }\n    stage('Test') {\n        "
  },
  "1559": {
    "source_file": "deployment.txt",
    "text": "echo 'Deploying'\n            }\n        }\n    }\n}\n// Scripted //\nnode {\n    stage('Build') {\n        echo 'Building'\n    }\n    stage('Test') {\n        echo 'Testing'\n    }\n    if (currentBuild.currentResult == 'SUCCESS') {\n        stage('Deploy') {\n            echo 'Deploying'\n        }\n    }\n}\n\nOne common pattern is to extend the number of stages to capture additional\ndeployment environments, like"
  },
  "1560": {
    "source_file": "deployment.txt",
    "text": "          echo 'Deploying'\n        }\n    }\n}\n\nOne common pattern is to extend the number of stages to capture additional\ndeployment environments, like \"staging\" or \"production\", as shown in the\nfollowing snippet.\n\nstage('Deploy - Staging') {\n    steps {\n        sh './deploy staging'\n        sh './run-smoke-tests'\n    }\n}\nstage('Deploy - Production') {\n    steps {\n        sh './deploy production'\n "
  },
  "1561": {
    "source_file": "deployment.txt",
    "text": "s {\n        sh './deploy staging'\n        sh './run-smoke-tests'\n    }\n}\nstage('Deploy - Production') {\n    steps {\n        sh './deploy production'\n    }\n}\n\nIn this example, we're assuming that whatever \"smoke tests\" are run by our\n`./run-smoke-tests` script are sufficient to qualify or validate a release to\nthe production environment. This kind of pipeline that automatically deploys\ncode all the"
  },
  "1562": {
    "source_file": "deployment.txt",
    "text": "s` script are sufficient to qualify or validate a release to\nthe production environment. This kind of pipeline that automatically deploys\ncode all the way through to production can be considered an implementation of\n\"continuous deployment.\" While this is a noble ideal, for many there are\ngood reasons why continuous _deployment_ might not be practical, but those can\nstill enjoy the benefits of cont"
  },
  "1563": {
    "source_file": "deployment.txt",
    "text": "s is a noble ideal, for many there are\ngood reasons why continuous _deployment_ might not be practical, but those can\nstill enjoy the benefits of continuous _delivery_.\nfootnote:[https://en.wikipedia.org/wiki/Continuous_delivery]\nJenkins Pipeline readily supports both.\n\nOften when passing between stages, especially environment stages, you may want\nhuman input before continuing. For example, to jud"
  },
  "1564": {
    "source_file": "deployment.txt",
    "text": "dily supports both.\n\nOften when passing between stages, especially environment stages, you may want\nhuman input before continuing. For example, to judge if the application is in a\ngood enough state to \"promote\" to the production environment. This can be\naccomplished with the `input` step. In the example below, the \"Sanity check\"\nstage actually blocks for input and won't proceed without a person co"
  },
  "1565": {
    "source_file": "deployment.txt",
    "text": " be\naccomplished with the `input` step. In the example below, the \"Sanity check\"\nstage actually blocks for input and won't proceed without a person confirming\nthe progress.\n\n[pipeline]\n\n// Declarative //\npipeline {\n    agent any\n    stages {\n        /* \"Build\" and \"Test\" stages omitted */\n\n        stage('Deploy - Staging') {\n            steps {\n                sh './deploy staging'\n               "
  },
  "1566": {
    "source_file": "deployment.txt",
    "text": "/* \"Build\" and \"Test\" stages omitted */\n\n        stage('Deploy - Staging') {\n            steps {\n                sh './deploy staging'\n                sh './run-smoke-tests'\n            }\n        }\n\n        stage('Sanity check') {\n            steps {\n                input \"Does the staging environment look ok?\"\n            }\n        }\n\n        stage('Deploy - Production') {\n            steps {\n   "
  },
  "1567": {
    "source_file": "deployment.txt",
    "text": "\n                input \"Does the staging environment look ok?\"\n            }\n        }\n\n        stage('Deploy - Production') {\n            steps {\n                sh './deploy production'\n            }\n        }\n    }\n}\n// Scripted //\nnode {\n    /* \"Build\" and \"Test\" stages omitted */\n\n    stage('Deploy - Staging') {\n        sh './deploy staging'\n        sh './run-smoke-tests'\n    }\n\n    stage('Sa"
  },
  "1568": {
    "source_file": "deployment.txt",
    "text": "Build\" and \"Test\" stages omitted */\n\n    stage('Deploy - Staging') {\n        sh './deploy staging'\n        sh './run-smoke-tests'\n    }\n\n    stage('Sanity check') {\n        input \"Does the staging environment look ok?\"\n    }\n\n    stage('Deploy - Production') {\n        sh './deploy production'\n    }\n}\n\nThis Guided Tour introduced you to the basics of using Jenkins and Jenkins\nPipeline. Because Jenk"
  },
  "1569": {
    "source_file": "deployment.txt",
    "text": "uction') {\n        sh './deploy production'\n    }\n}\n\nThis Guided Tour introduced you to the basics of using Jenkins and Jenkins\nPipeline. Because Jenkins is extremely extensible, it can be modified and\nconfigured to handle practically _any_ aspect of automation. To learn more\nabout what Jenkins can do, check out the\n,\nor the\n for the latest events, tutorials, and updates.\n\n'''\n+++\n\n+++"
  },
  "1570": {
    "source_file": "deployment.txt",
    "text": " automation. To learn more\nabout what Jenkins can do, check out the\n,\nor the\n for the latest events, tutorials, and updates.\n\n'''\n+++\n\n+++"
  },
  "1571": {
    "source_file": "deprecated-reflective-access.txt",
    "text": "title: Deprecated reflective access\nlayout: developersection\n\n\nBefore Jenkins 2.272 Stapler would access all fields ignoring visibility restrictions.\n\nStapler now tries to access a field first and only if it gets access denied then will it force access via javadoc:java.lang.reflect.AccessibleObject#setAccessible-boolean-[setAccessible(true)].\n\nThis behavior is not recommended anymore, and will tri"
  },
  "1572": {
    "source_file": "deprecated-reflective-access.txt",
    "text": "ss via javadoc:java.lang.reflect.AccessibleObject#setAccessible-boolean-[setAccessible(true)].\n\nThis behavior is not recommended anymore, and will trigger `IllegalReflectiveAccess` warnings when running Jenkins on Java 11 or newer.\n\nIf you see a warning message about this then you should  to the respective plugin.\n\nDec 15, 2020 9:22:33 PM org.kohsuke.stapler.lang.FieldRef$1 get\nWARNING: java.lang."
  },
  "1573": {
    "source_file": "deprecated-reflective-access.txt",
    "text": "ing message about this then you should  to the respective plugin.\n\nDec 15, 2020 9:22:33 PM org.kohsuke.stapler.lang.FieldRef$1 get\nWARNING: java.lang.IllegalAccessException: Processing this request relies on deprecated behavior that will be disallowed in future releases of Java. See https://jenkins.io/redirect/stapler-reflective-access/ for more information. Details: class org.kohsuke.stapler.lang"
  },
  "1574": {
    "source_file": "deprecated-reflective-access.txt",
    "text": "d in future releases of Java. See https://jenkins.io/redirect/stapler-reflective-access/ for more information. Details: class org.kohsuke.stapler.lang.FieldRef$1 cannot access a member of class org.kohsuke.stapler.AncestorImplTest$Foo with modifiers \"public\""
  },
  "1575": {
    "source_file": "deprecated-reflective-access.txt",
    "text": "\"public\""
  },
  "1576": {
    "source_file": "deprecating-or-removing-plugin.txt",
    "text": "layout: developersection\ntitle: Deprecating or removing a Plugin\nreferences:\n- url: https://github.com/jenkins-infra/update-center2\n  title: Jenkins Update Center generator\n- url: https://plugins.jenkins.io/ui/search/?labels=deprecated\n  title: List of the deprecated Jenkins plugins\n\n\nSome plugins may be replaced by others or just become irrelevant.\nBecoming irrelevant can include an integration w"
  },
  "1577": {
    "source_file": "deprecating-or-removing-plugin.txt",
    "text": "of the deprecated Jenkins plugins\n\n\nSome plugins may be replaced by others or just become irrelevant.\nBecoming irrelevant can include an integration with a service that was shut down or a new plugin combining multiple plugins into one.\nWe do not recommend deleting source code outright, even a stale or no-longer-relevant code can still be educational.\nHowever, we do have a mechanism for deprecating"
  },
  "1578": {
    "source_file": "deprecating-or-removing-plugin.txt",
    "text": "mmend deleting source code outright, even a stale or no-longer-relevant code can still be educational.\nHowever, we do have a mechanism for deprecating or hiding plugins in the Jenkins update centers.\nThis page describes the processes for marking a plugin as deprecated or suspending its distribution entirely.\n\nSet a `deprecated` label for the plugin that will be visible on plugins.jenkins.io and in"
  },
  "1579": {
    "source_file": "deprecating-or-removing-plugin.txt",
    "text": "ugin as deprecated or suspending its distribution entirely.\n\nSet a `deprecated` label for the plugin that will be visible on plugins.jenkins.io and in the Jenkins plugin manager. This can be done in two ways:\n** Put a `deprecated` topic in the plugin's GitHub repository.\n   If you have multiple plugins inside a single repository, it will apply to all of them.\n   This is the preferred approach.\n** "
  },
  "1580": {
    "source_file": "deprecating-or-removing-plugin.txt",
    "text": "'s GitHub repository.\n   If you have multiple plugins inside a single repository, it will apply to all of them.\n   This is the preferred approach.\n** Add a `deprecated` label to the plugin entry in the Update Center's  file.\n   Choose this approach if the GitHub repository contains multiple plugins and only some of the plugins in the repository are to be deprecated.\nUpdate the plugin's documentati"
  },
  "1581": {
    "source_file": "deprecating-or-removing-plugin.txt",
    "text": "f the GitHub repository contains multiple plugins and only some of the plugins in the repository are to be deprecated.\nUpdate the plugin's documentation to explain the reason of the deprecation.\n\nOptionally, you can archive the GitHub repository of the plugin if it has reached the end of its lifecycle or has been superseded by another plugin.\n\nLeave a note in the repository's README file explainin"
  },
  "1582": {
    "source_file": "deprecating-or-removing-plugin.txt",
    "text": "he plugin if it has reached the end of its lifecycle or has been superseded by another plugin.\n\nLeave a note in the repository's README file explaining the reason for archiving and providing a link to the replacement plugin if available.\nClose all open issues and pull requests.\nArchive the repository.\n\nSubmit a pull request to the Update Center's https://github.com/jenkins-infra/update-center2/blo"
  },
  "1583": {
    "source_file": "deprecating-or-removing-plugin.txt",
    "text": "en issues and pull requests.\nArchive the repository.\n\nSubmit a pull request to the Update Center's https://github.com/jenkins-infra/update-center2/blob/master/resources/artifact-ignores.properties[artifact-ignores.properties] file.\n  Use the artifact ID as key.\n  As value, provide a URL to a web page (usually documentation) that explains to users why distribution is suspended.\n  Specifying a URL w"
  },
  "1584": {
    "source_file": "deprecating-or-removing-plugin.txt",
    "text": " ID as key.\n  As value, provide a URL to a web page (usually documentation) that explains to users why distribution is suspended.\n  Specifying a URL will also cause a deprecation message to appear.\nArchive the plugin's GitHub repository.\n** If you have admin permissions in the repository, it is possible to do it from the GitHub's web interface.\n** Otherwise, create a  ticket to archive the plugin'"
  },
  "1585": {
    "source_file": "deprecating-or-removing-plugin.txt",
    "text": "ve admin permissions in the repository, it is possible to do it from the GitHub's web interface.\n** Otherwise, create a  ticket to archive the plugin's repository.\n\nIf required, it is possible to revert all the actions above.\nA helpdesk ticket is required to unarchive a plugin, but the rest can be done via pull requests to the respective update center files mentioned above."
  },
  "1586": {
    "source_file": "deprecating-or-removing-plugin.txt",
    "text": "uired to unarchive a plugin, but the rest can be done via pull requests to the respective update center files mentioned above."
  },
  "1587": {
    "source_file": "development.txt",
    "text": "layout: section\ntitle: Pipeline Development Tools\n\n\nifdef::env-github[:imagesdir: ../resources]\nifndef::env-github[:imagesdir: ../../resources]\n\nifdef::basebackend-dockbook[:imagesdir: doc/book/resources]\n// Show 2/3 of the Blue ocean admonitions\n// :pipeline-visualization-admonition: true\n\nJenkins Pipeline includes\n<<getting-started#built-in-documentation, built-in documentation>> and the\n<<getti"
  },
  "1588": {
    "source_file": "development.txt",
    "text": ":pipeline-visualization-admonition: true\n\nJenkins Pipeline includes\n<<getting-started#built-in-documentation, built-in documentation>> and the\n<<getting-started#snippet-generator, Snippet Generator>> which are key resources\nwhen developing Pipelines. They provide detailed help and information that is customized\nto the currently installed version of Jenkins and related plugins.\nIn this section, we'"
  },
  "1589": {
    "source_file": "development.txt",
    "text": " They provide detailed help and information that is customized\nto the currently installed version of Jenkins and related plugins.\nIn this section, we'll discuss other tools and resources\nthat may help with development of Jenkins Pipelines.\n\n[[linter]]\n\nJenkins can validate, or\n\"\",\na Declarative Pipeline from the command line before actually running it.\nThis can be done using a Jenkins CLI command "
  },
  "1590": {
    "source_file": "development.txt",
    "text": "]\n\nJenkins can validate, or\n\"\",\na Declarative Pipeline from the command line before actually running it.\nThis can be done using a Jenkins CLI command or by making an\nHTTP POST\nrequest with appropriate parameters.\nWe recommended using the\n<<../managing/cli#ssh, SSH interface>>\nto run the linter. See the <<../managing/cli#, Jenkins CLI documentation>> for details on how to properly configure\nJenkins"
  },
  "1591": {
    "source_file": "development.txt",
    "text": "g/cli#ssh, SSH interface>>\nto run the linter. See the <<../managing/cli#, Jenkins CLI documentation>> for details on how to properly configure\nJenkins for secure command-line access.\n\n.Linting via the CLI with SSH\n\n# ssh (Jenkins CLI)\n# JENKINS_PORT=[sshd port on controller]\n# JENKINS_HOST=[Jenkins controller hostname]\nssh -p $JENKINS_PORT $JENKINS_HOST declarative-linter < Jenkinsfile\n\n.Linting v"
  },
  "1592": {
    "source_file": "development.txt",
    "text": "[sshd port on controller]\n# JENKINS_HOST=[Jenkins controller hostname]\nssh -p $JENKINS_PORT $JENKINS_HOST declarative-linter < Jenkinsfile\n\n.Linting via HTTP POST using `curl`\n\n# curl (REST API)\n# These instructions assume that the security realm of Jenkins is something other than \"None\" and you have an account.\n# JENKINS_URL=[root URL of Jenkins controller]\n# JENKINS_AUTH=[your Jenkins username a"
  },
  "1593": {
    "source_file": "development.txt",
    "text": "Jenkins is something other than \"None\" and you have an account.\n# JENKINS_URL=[root URL of Jenkins controller]\n# JENKINS_AUTH=[your Jenkins username and an API token in the following format: your_username:api_token]\ncurl -X POST --user \"$JENKINS_AUTH\" -F \"jenkinsfile=<Jenkinsfile\" \"$JENKINS_URL/pipeline-model-converter/validate\"\n\nBelow are two examples of the Pipeline Linter in action.\nThis first "
  },
  "1594": {
    "source_file": "development.txt",
    "text": "\" -F \"jenkinsfile=<Jenkinsfile\" \"$JENKINS_URL/pipeline-model-converter/validate\"\n\nBelow are two examples of the Pipeline Linter in action.\nThis first example shows the output of the linter when it is passed\nan invalid `Jenkinsfile`, one that is missing part of the `agent` declaration.\n\n.Jenkinsfile\n\npipeline {\n  agent\n  stages {\n    stage ('Initialize') {\n      steps {\n        echo 'Placeholder.'\n"
  },
  "1595": {
    "source_file": "development.txt",
    "text": "ng part of the `agent` declaration.\n\n.Jenkinsfile\n\npipeline {\n  agent\n  stages {\n    stage ('Initialize') {\n      steps {\n        echo 'Placeholder.'\n      }\n    }\n  }\n}\n\n.Linter output for invalid Jenkinsfile\n\n# pass a Jenkinsfile that does not contain an \"agent\" section\nssh -p 8675 localhost declarative-linter < ./Jenkinsfile\nErrors encountered validating Jenkinsfile:\nWorkflowScript: 2: Not a va"
  },
  "1596": {
    "source_file": "development.txt",
    "text": "ain an \"agent\" section\nssh -p 8675 localhost declarative-linter < ./Jenkinsfile\nErrors encountered validating Jenkinsfile:\nWorkflowScript: 2: Not a valid section definition: \"agent\". Some extra configuration is required. @ line 2, column 3.\n     agent\n     ^\n\nWorkflowScript: 1: Missing required section \"agent\" @ line 1, column 1.\n   pipeline &#125;\n   ^\n\nIn this second example, the `Jenkinsfile` h"
  },
  "1597": {
    "source_file": "development.txt",
    "text": "t\n     ^\n\nWorkflowScript: 1: Missing required section \"agent\" @ line 1, column 1.\n   pipeline &#125;\n   ^\n\nIn this second example, the `Jenkinsfile` has been updated to include the\nmissing `any` on `agent`.  The linter now reports that the Pipeline is valid.\n\n.Jenkinsfile\n\npipeline {\n  agent any\n  stages {\n    stage ('Initialize') {\n      steps {\n        echo 'Placeholder.'\n      }\n    }\n  }\n}\n\n.L"
  },
  "1598": {
    "source_file": "development.txt",
    "text": "s valid.\n\n.Jenkinsfile\n\npipeline {\n  agent any\n  stages {\n    stage ('Initialize') {\n      steps {\n        echo 'Placeholder.'\n      }\n    }\n  }\n}\n\n.Linter output for valid Jenkinsfile\n\nssh -p 8675 localhost declarative-linter < ./Jenkinsfile\nJenkinsfile successfully validated.\n\nThe <<../blueocean/pipeline-editor#, Blue Ocean Pipeline Editor>> provides a  way to create Declarative Pipelines.\nThe e"
  },
  "1599": {
    "source_file": "development.txt",
    "text": "file successfully validated.\n\nThe <<../blueocean/pipeline-editor#, Blue Ocean Pipeline Editor>> provides a  way to create Declarative Pipelines.\nThe editor offers a structural view of all the stages, parallel branches, and steps in a Pipeline.\nThe editor validates Pipeline changes as they are made, eliminating many errors before they are even committed.\nBehind the scenes it still generates Declara"
  },
  "1600": {
    "source_file": "development.txt",
    "text": "itor validates Pipeline changes as they are made, eliminating many errors before they are even committed.\nBehind the scenes it still generates Declarative Pipeline code.\n\n[[replay]]\n\nTypically a Pipeline will be defined inside of the classic Jenkins web UI,\nor by committing to a `Jenkinsfile` in source control. Unfortunately,\nneither approach is ideal for rapid iteration, or prototyping, of a Pipe"
  },
  "1601": {
    "source_file": "development.txt",
    "text": "web UI,\nor by committing to a `Jenkinsfile` in source control. Unfortunately,\nneither approach is ideal for rapid iteration, or prototyping, of a Pipeline.\nThe \"Replay\" feature allows for quick modifications and execution of an existing\nPipeline without changing the Pipeline configuration or creating a new commit.\n\nTo use the \"Replay\" feature:\n\nSelect a previously completed run in the build histor"
  },
  "1602": {
    "source_file": "development.txt",
    "text": "out changing the Pipeline configuration or creating a new commit.\n\nTo use the \"Replay\" feature:\n\nSelect a previously completed run in the build history.\nClick \"Replay\" in the left menu.\nMake modifications and click \"Run\". In this example, we changed \"ruby-2.3\" to \"ruby-2.4\".\nCheck the results of changes.\n\nOnce you are satisfied with the changes,\nyou can use Replay to view them again, copy them bac"
  },
  "1603": {
    "source_file": "development.txt",
    "text": "\"ruby-2.3\" to \"ruby-2.4\".\nCheck the results of changes.\n\nOnce you are satisfied with the changes,\nyou can use Replay to view them again, copy them back to your Pipeline job\nor `Jenkinsfile`, and then commit them using your usual engineering processes.\n\n* *Can be called multiple times on the same run* -\nallows for easy parallel testing of different changes.\n* *Can also be called on Pipeline runs th"
  },
  "1604": {
    "source_file": "development.txt",
    "text": ".\n\n* *Can be called multiple times on the same run* -\nallows for easy parallel testing of different changes.\n* *Can also be called on Pipeline runs that are still in-progress* -\nAs long as a Pipeline contained syntactically correct Groovy and was able to start,\nit can be Replayed.\n* *Referenced Shared Library code is also modifiable* - If a Pipeline run references a\n<<shared-libraries#, Shared Lib"
  },
  "1605": {
    "source_file": "development.txt",
    "text": "e to start,\nit can be Replayed.\n* *Referenced Shared Library code is also modifiable* - If a Pipeline run references a\n<<shared-libraries#, Shared Library>>, the code from the shared library will\nalso be shown and modifiable as part of the Replay page.\n* *Access Control via dedicated \"Run / Replay\" permission* -\nimplied by \"Job / Configure\". If Pipeline is not configurable (e.g. Branch Pipeline of"
  },
  "1606": {
    "source_file": "development.txt",
    "text": "e.\n* *Access Control via dedicated \"Run / Replay\" permission* -\nimplied by \"Job / Configure\". If Pipeline is not configurable (e.g. Branch Pipeline of a Multibranch) or \"Job / Configure\" is not granted, users still can experiment with Pipeline Definition via Replay\n* *Can be used for Re-run* -\nusers lacking \"Run / Replay\" but who are granted \"Job / Build\" can still use Replay to run a build again "
  },
  "1607": {
    "source_file": "development.txt",
    "text": "tion via Replay\n* *Can be used for Re-run* -\nusers lacking \"Run / Replay\" but who are granted \"Job / Build\" can still use Replay to run a build again with the same definition.\n*Note*: The label switches to \"Rebuild\" in that case.\n\n* *Pipeline runs with syntax errors cannot be replayed* -\nmeaning their code cannot be viewed and any changes made in them cannot be retrieved.\nWhen using Replay for mor"
  },
  "1608": {
    "source_file": "development.txt",
    "text": "th syntax errors cannot be replayed* -\nmeaning their code cannot be viewed and any changes made in them cannot be retrieved.\nWhen using Replay for more significant modifications, save your changes\nto a file or editor outside of Jenkins before running them.\nSee\n* *Replayed Pipeline behavior may differ from runs started by other methods* -\nFor Pipelines that are not part of a Multi-branch Pipeline,\n"
  },
  "1609": {
    "source_file": "development.txt",
    "text": " them.\nSee\n* *Replayed Pipeline behavior may differ from runs started by other methods* -\nFor Pipelines that are not part of a Multi-branch Pipeline,\nthe commit information may differ for the original run and the Replayed run.\nSee\n\nThe `Jenkins Editor` Eclipse plugin can be found on\nThis special text editor provides some features for defining pipelines e.g:\n\n- Validate pipeline scripts by <<#linte"
  },
  "1610": {
    "source_file": "development.txt",
    "text": "r` Eclipse plugin can be found on\nThis special text editor provides some features for defining pipelines e.g:\n\n- Validate pipeline scripts by <<#linter,Jenkins Linter Validation>>. Failures are shown as eclipse markers\n- An Outline with dedicated icons (for declarative Jenkins pipelines )\n- Syntax / keyword highlighting\n- Groovy validation\n\nNOTE: The Jenkins Editor Plugin is a third-party tool tha"
  },
  "1611": {
    "source_file": "development.txt",
    "text": "ns (for declarative Jenkins pipelines )\n- Syntax / keyword highlighting\n- Groovy validation\n\nNOTE: The Jenkins Editor Plugin is a third-party tool that is not supported\nby the Jenkins Project.\n\nThe `Jenkins Pipeline Linter Connector` extension for\n\ntakes the file that you have currently opened, pushes it to your Jenkins Server and displays the validation result in VS Code.\n\n\u200bYou can find the exten"
  },
  "1612": {
    "source_file": "development.txt",
    "text": "akes the file that you have currently opened, pushes it to your Jenkins Server and displays the validation result in VS Code.\n\n\u200bYou can find the extension from within the VS Code extension browser or at the following url: https://marketplace.visualstudio.com/items?itemName=janjoerke.jenkins-pipeline-linter-connector\n\nThe extension adds four settings entries to VS Code which select the Jenkins serv"
  },
  "1613": {
    "source_file": "development.txt",
    "text": "udio.com/items?itemName=janjoerke.jenkins-pipeline-linter-connector\n\nThe extension adds four settings entries to VS Code which select the Jenkins server you want to use for validation.\n\n* `jenkins.pipeline.linter.connector.url` is the endpoint at which your Jenkins Server expects the POST request, containing your Jenkinsfile which you want to validate. Typically this points to __http://<your_jenki"
  },
  "1614": {
    "source_file": "development.txt",
    "text": "ch your Jenkins Server expects the POST request, containing your Jenkinsfile which you want to validate. Typically this points to __http://<your_jenkins_server:port>/pipeline-model-converter/validate__.\n* `jenkins.pipeline.linter.connector.user` allows you to specify your Jenkins username.\n* `jenkins.pipeline.linter.connector.pass` allows you to specify your Jenkins password.\n* `jenkins.pipeline.l"
  },
  "1615": {
    "source_file": "development.txt",
    "text": "ws you to specify your Jenkins username.\n* `jenkins.pipeline.linter.connector.pass` allows you to specify your Jenkins password.\n* `jenkins.pipeline.linter.connector.crumbUrl` has to be specified if your Jenkins Server has CRSF protection enabled. Typically this points to __http://<your_jenkins_server:port>/crumbIssuer/api/xml?xpath=concat(//crumbRequestField,%22:%22,//crumb)__.\n\nThe\nNeovim plugin"
  },
  "1616": {
    "source_file": "development.txt",
    "text": "pically this points to __http://<your_jenkins_server:port>/crumbIssuer/api/xml?xpath=concat(//crumbRequestField,%22:%22,//crumb)__.\n\nThe\nNeovim plugin allows you to validate a Jenkinsfile by using the Pipeline Linter API\nof your Jenkins controller and report any existing diagnostics in your editor.\n\nThe  Atom package allows\nyou to validate a Jenkins file by using the Pipeline Linter API of a runni"
  },
  "1617": {
    "source_file": "development.txt",
    "text": "d report any existing diagnostics in your editor.\n\nThe  Atom package allows\nyou to validate a Jenkins file by using the Pipeline Linter API of a running Jenkins.\nYou can install it directly from the Atom package manager. It needs also to install\n\nThe  Sublime Text package allows\nyou to validate a Jenkinsfile by using the Pipeline Linter API of a running Jenkins controller over\na secure channel (SS"
  },
  "1618": {
    "source_file": "development.txt",
    "text": "  Sublime Text package allows\nyou to validate a Jenkinsfile by using the Pipeline Linter API of a running Jenkins controller over\na secure channel (SSH).  You can install it directly from the Sublime Text package manager.\n\n\u200bYou can find the package from within the Sublime Text interface via the Package Control package, at GitHub, or packagecontrol.io:\n\n*\n*\n\n[[unit-test]]\n\nThe\nallows you to\n\nPipeli"
  },
  "1619": {
    "source_file": "development.txt",
    "text": "rom within the Sublime Text interface via the Package Control package, at GitHub, or packagecontrol.io:\n\n*\n*\n\n[[unit-test]]\n\nThe\nallows you to\n\nPipelines and <<shared-libraries#, Shared Libraries>>\nbefore running them in full. It provides a mock execution environment where real\nPipeline steps are replaced with mock objects that you can use to check for expected\nbehavior. New and rough around the e"
  },
  "1620": {
    "source_file": "development.txt",
    "text": "ution environment where real\nPipeline steps are replaced with mock objects that you can use to check for expected\nbehavior. New and rough around the edges, but promising.\nThe\nfor that project contains examples and usage instructions."
  },
  "1621": {
    "source_file": "diagnosing-errors.txt",
    "text": "layout: section\n\n\nifndef::env-github[:imagesdir: ../../resources]\n\nThis page provides guidelines about diagnosing the most common types of errors you may see when using Jenkins.\n\n[[out-of-memory-error]]\n\n`OutOfMemoryError` errors may happen for many different reasons:\n\n- Your Jenkins is growing in data size, requiring a bigger heap space. In this case you just want to give it a bigger heap.\n- Your"
  },
  "1622": {
    "source_file": "diagnosing-errors.txt",
    "text": "different reasons:\n\n- Your Jenkins is growing in data size, requiring a bigger heap space. In this case you just want to give it a bigger heap.\n- Your Jenkins is temporarily processing a large amount of data (like test reports), requiring a bigger head room in memory. In this case you just want to give it a bigger heap.\n- Your Jenkins is leaking memory, in which case we need to fix that.\n- The Ope"
  },
  "1623": {
    "source_file": "diagnosing-errors.txt",
    "text": "ad room in memory. In this case you just want to give it a bigger heap.\n- Your Jenkins is leaking memory, in which case we need to fix that.\n- The Operating System kernel is running out of virtual memory.\n\nWhich category your `OutOfMemoryError` falls into is not always obvious, but here are a few useful techniques to diagnose the problem.\n\n- Use https://visualvm.github.io/[VisualVM], attach to the"
  },
  "1624": {
    "source_file": "diagnosing-errors.txt",
    "text": " into is not always obvious, but here are a few useful techniques to diagnose the problem.\n\n- Use https://visualvm.github.io/[VisualVM], attach to the running instance, and observe the memory usage. Does the memory max out while loading Jenkins? If so, it probably just needs a bigger memory space. Or is it slowing creeping up? If so, maybe it is a memory leak.\n- Do you consistently see `OutOfMemor"
  },
  "1625": {
    "source_file": "diagnosing-errors.txt",
    "text": "o, it probably just needs a bigger memory space. Or is it slowing creeping up? If so, maybe it is a memory leak.\n- Do you consistently see `OutOfMemoryError` around the same phase in a build? If so, maybe it just needs a bigger memory.\n- In cases where virtual memory is running short the kernel `OutOfMemoryError` killer may forcibly kill Jenkins or individual builds. If this occurs on Linux you ma"
  },
  "1626": {
    "source_file": "diagnosing-errors.txt",
    "text": "re virtual memory is running short the kernel `OutOfMemoryError` killer may forcibly kill Jenkins or individual builds. If this occurs on Linux you may see builds terminate with exit code `137` (`128` + signal number for `SIGKILL`). The `dmesg` command output will show log messages that will confirm the action that the kernel took.\n\nIf you think it's a memory leak, the Jenkins team needs to get th"
  },
  "1627": {
    "source_file": "diagnosing-errors.txt",
    "text": "nd output will show log messages that will confirm the action that the kernel took.\n\nIf you think it's a memory leak, the Jenkins team needs to get the heap dump to be able to fix the problem. There are several ways to go about this.\n\n- Run JVM with `-XX:+HeapDumpOnOutOfMemoryError` so that JVM will automatically produce a heap dump when it hits `OutOfMemoryError`.\n- You can run `jmap -dump:live,f"
  },
  "1628": {
    "source_file": "diagnosing-errors.txt",
    "text": "`-XX:+HeapDumpOnOutOfMemoryError` so that JVM will automatically produce a heap dump when it hits `OutOfMemoryError`.\n- You can run `jmap -dump:live,file=/tmp/jenkins.hprof pid` where pid is the process ID of the target Java process.\n- Use https://visualvm.github.io/[VisualVM], attach to the running instance, and obtain a heap dump\n- If your Jenkins runs at `http://server/jenkins/`, request `http:"
  },
  "1629": {
    "source_file": "diagnosing-errors.txt",
    "text": "sualvm.github.io/[VisualVM], attach to the running instance, and obtain a heap dump\n- If your Jenkins runs at `http://server/jenkins/`, request `http://server/jenkins/heapDump` with your browser and you'll get the heap dump downloaded.\n- If you are familiar with one of many Java profilers, they normally offer this capability, too.\n\nOnce you obtain the heap dump, please post it somewhere, then open"
  },
  "1630": {
    "source_file": "diagnosing-errors.txt",
    "text": "amiliar with one of many Java profilers, they normally offer this capability, too.\n\nOnce you obtain the heap dump, please post it somewhere, then open an issue (or look for a duplicate issue), and attach a pointer to it. Please be aware that heap dumps may contain confidential information of various sorts.\n\nIf the full heap dump is too big, please try to get us the heap histogram (`jmap -histo:liv"
  },
  "1631": {
    "source_file": "diagnosing-errors.txt",
    "text": "ps may contain confidential information of various sorts.\n\nIf the full heap dump is too big, please try to get us the heap histogram (`jmap -histo:live pid`).\n\nIn the past, the distributed build support has often been a source of leakage (as this involves in a distributed garbage collection.) To check for this possibility, visit links like `http://yourserver/jenkins/computer/YOURAGENTNAME/dumpExpo"
  },
  "1632": {
    "source_file": "diagnosing-errors.txt",
    "text": "olves in a distributed garbage collection.) To check for this possibility, visit links like `http://yourserver/jenkins/computer/YOURAGENTNAME/dumpExportTable`. If this show too many objects, they may be leaks.\n\nIf you cannot let us inspect your heap dump, we need to ask you to diagnose the leak.\n\n- First, find the objects with biggest retention size. Often they are various Maps, arrays, or buffers"
  },
  "1633": {
    "source_file": "diagnosing-errors.txt",
    "text": "dump, we need to ask you to diagnose the leak.\n\n- First, find the objects with biggest retention size. Often they are various Maps, arrays, or buffers.\n- Next, find the path from that object to GC root, so that you can see which Jenkins object owns those big objects.\n\nReport the summary of those findings to the list and we'll take it from there.\n\nUnless you already have a preferred memory profilin"
  },
  "1634": {
    "source_file": "diagnosing-errors.txt",
    "text": "hose big objects.\n\nReport the summary of those findings to the list and we'll take it from there.\n\nUnless you already have a preferred memory profiling tool, VisualVM is recommended for analyzing heap dumps. It is a standalone version of the NetBeans profiler, distributed with the Oracle JDK.\n\nRun `jvisualvm` and use *File \u00bb Load* and select the heap dump. In the\n*Classes* tab, look for a class wi"
  },
  "1635": {
    "source_file": "diagnosing-errors.txt",
    "text": " profiler, distributed with the Oracle JDK.\n\nRun `jvisualvm` and use *File \u00bb Load* and select the heap dump. In the\n*Classes* tab, look for a class with a suspiciously large number of instances, if not already identified by `jmap -histo`. For example, to debug a Groovy script leak, type `GroovyClassLoader` in the filter field and double-click the line with no `$` in it (just `groovy.lang.GroovyCla"
  },
  "1636": {
    "source_file": "diagnosing-errors.txt",
    "text": ", to debug a Groovy script leak, type `GroovyClassLoader` in the filter field and double-click the line with no `$` in it (just `groovy.lang.GroovyClassLoader`).\n\nIn the *Instances* tab you should now see all instances. Click on some at random. (If there are more than 500, they will be broken into groups of 500, with the first expanded; so to get a representative instance \"from the middle\", collap"
  },
  "1637": {
    "source_file": "diagnosing-errors.txt",
    "text": "here are more than 500, they will be broken into groups of 500, with the first expanded; so to get a representative instance \"from the middle\", collapse the first group, expand a group in the middle, and select some instance from that group.)\n\nUnder *References*, right-click `this` and select *Show Nearest GC Root*. Right-click the selected item in the tree and select *Copy Path From Root*. Paste "
  },
  "1638": {
    "source_file": "diagnosing-errors.txt",
    "text": "*References*, right-click `this` and select *Show Nearest GC Root*. Right-click the selected item in the tree and select *Copy Path From Root*. Paste this text, for several examples, into a text file and attach it to a bug report\u2014or continue your investigation into plugin source code.\n\nFor easier bug reporting, you can get the full list of plugins with this Groovy script that you can run in **Jenk"
  },
  "1639": {
    "source_file": "diagnosing-errors.txt",
    "text": "estigation into plugin source code.\n\nFor easier bug reporting, you can get the full list of plugins with this Groovy script that you can run in **Jenkins > Manage Jenkins > Script Console**:\n\nprintln(\"Jenkins: ${Jenkins.instance.getVersion()}\")\nprintln(\"OS: ${System.getProperty('os.name')} - ${System.getProperty('os.version')}\")\nprintln(\"Java: ${System.getProperty('java.version')} - ${System.getPr"
  },
  "1640": {
    "source_file": "diagnosing-errors.txt",
    "text": "ln(\"OS: ${System.getProperty('os.name')} - ${System.getProperty('os.version')}\")\nprintln(\"Java: ${System.getProperty('java.version')} - ${System.getProperty('java.vm.vendor')} (${System.getProperty('java.vm.name')})\")\nprintln \"---\"\n\nJenkins.instance.pluginManager.plugins\n    .collect()\n    .sort { it.getShortName() }\n    .each {\n        plugin -> println(\"${plugin.getShortName()}:${plugin.getVersi"
  },
  "1641": {
    "source_file": "diagnosing-errors.txt",
    "text": "pluginManager.plugins\n    .collect()\n    .sort { it.getShortName() }\n    .each {\n        plugin -> println(\"${plugin.getShortName()}:${plugin.getVersion()}\")\n    }\nreturn"
  },
  "1642": {
    "source_file": "disable.txt",
    "text": "title: Disable Access Control\nlayout: documentation\n\n\nAdministrators may accidentally set up a security realm or authorization strategy in such a way that they are no longer able to administer or even access Jenkins.\n\nWhen this happens, there are ways to reset the access control configuration to allow anyone to administer Jenkins.\nThe exact steps to do this depend on how you manage the Jenkins con"
  },
  "1643": {
    "source_file": "disable.txt",
    "text": "s to reset the access control configuration to allow anyone to administer Jenkins.\nThe exact steps to do this depend on how you manage the Jenkins configuration.\nThe sections below explain how to disable access control in multiple different ways.\n\n[WARNING]\n\nAfter applying the advice below, Jenkins will be in an entirely unsecured mode after it starts, allowing anyone full access.\nIf you are able "
  },
  "1644": {
    "source_file": "disable.txt",
    "text": "ARNING]\n\nAfter applying the advice below, Jenkins will be in an entirely unsecured mode after it starts, allowing anyone full access.\nIf you are able to, consider making Jenkins accessible only by you while the configuration is being reset.\n\nOne way to do this is to make sure that Jenkins is only accessible from the server it is running on.\nIf Jenkins is run using the built-in Winstone/Jetty conta"
  },
  "1645": {
    "source_file": "disable.txt",
    "text": "to do this is to make sure that Jenkins is only accessible from the server it is running on.\nIf Jenkins is run using the built-in Winstone/Jetty container, set the `--httpListenAddress` or `--httpsListenAddress` (depending on whether you previously set up HTTPS in Winstone/Jetty) to `127.0.0.1`.\nWhere to change this depends on how you installed Jenkins.\nLook up the documentation for your package o"
  },
  "1646": {
    "source_file": "disable.txt",
    "text": "et up HTTPS in Winstone/Jetty) to `127.0.0.1`.\nWhere to change this depends on how you installed Jenkins.\nLook up the documentation for your package or installer.\n\nUse these instructions if your Jenkins configuration is _not_ managed using Configuration as Code plugin or .\n\n[NOTE]\nThe following steps will delete the configuration for security realm and authorization strategy.\nMake sure you have a "
  },
  "1647": {
    "source_file": "disable.txt",
    "text": "ion as Code plugin or .\n\n[NOTE]\nThe following steps will delete the configuration for security realm and authorization strategy.\nMake sure you have a backup, to be able to restore the configuration to as close to the original state (except one where you\u2019re not locked out) as possible.\n\nStop Jenkins.\nGo to the Jenkins home directory.\nOpen the file `config.xml` in this directory in a text editor.\n  "
  },
  "1648": {
    "source_file": "disable.txt",
    "text": "you\u2019re not locked out) as possible.\n\nStop Jenkins.\nGo to the Jenkins home directory.\nOpen the file `config.xml` in this directory in a text editor.\n  Make sure you use an editor that supports Unix line breaks.\nLook for the `<useSecurity>true</useSecurity>` element in this file.\nLook for the elements `<securityRealm>` and `<authorizationStrategy>` and remove them.\n  Either may span multiple lines, "
  },
  "1649": {
    "source_file": "disable.txt",
    "text": "rity>` element in this file.\nLook for the elements `<securityRealm>` and `<authorizationStrategy>` and remove them.\n  Either may span multiple lines, delete everything up to and including `</securityRealm>` and `</authorizationStrategy>`, respectively.\nReplace `true` with `false`.\nStart Jenkins.\n\n// db: Pretty certain this is unnecessary advice unless proven to be necessary: If this is still not w"
  },
  "1650": {
    "source_file": "disable.txt",
    "text": "y.\nReplace `true` with `false`.\nStart Jenkins.\n\n// db: Pretty certain this is unnecessary advice unless proven to be necessary: If this is still not working, trying renaming or deleting `config.xml`.\n\nIf you configure Jenkins using plugin:configuration-as-code[Configuration as Code Plugin] (JCasC), choose this approach.\n\nLocate your JCasC configuration file.\nThe default location is `jenkins.yaml` "
  },
  "1651": {
    "source_file": "disable.txt",
    "text": "on-as-code[Configuration as Code Plugin] (JCasC), choose this approach.\n\nLocate your JCasC configuration file.\nThe default location is `jenkins.yaml` in the Jenkins home directory, but it can be located in a number of places.\nReview the https://github.com/jenkinsci/configuration-as-code-plugin/blob/master/README.md[Jenkins Configuration as Code plugin documentation for details].\n\nOnce you have loc"
  },
  "1652": {
    "source_file": "disable.txt",
    "text": "b.com/jenkinsci/configuration-as-code-plugin/blob/master/README.md[Jenkins Configuration as Code plugin documentation for details].\n\nOnce you have located the file:\n\n1. Modify the `authorizationStrategy` directive in the `jenkins` section so that it configures the _Anyone can do anything_ authorization strategy:\njenkins:\n  authorizationStrategy: unsecured\n\n2. Restart your Jenkins instance to re-ap"
  },
  "1653": {
    "source_file": "disable.txt",
    "text": "configures the _Anyone can do anything_ authorization strategy:\njenkins:\n  authorizationStrategy: unsecured\n\n2. Restart your Jenkins instance to re-apply the modified configuration."
  },
  "1654": {
    "source_file": "distribution-process.txt",
    "text": "layout: developersection\ntitle: Plugin Distribution Process\nreferences:\n- url: /projects/infrastructure/\n  title: Jenkins infrastructure\n- url: https://updates.jenkins.io/\n  title: Jenkins update sites\n- url: https://github.com/jenkinsci/maven-hpi-plugin/\n  title: Maven Jenkins plugin (HPI) source code\n- url: https://jenkinsci.github.io/maven-hpi-plugin/\n  title: Maven Jenkins plugin (HPI) plugin "
  },
  "1655": {
    "source_file": "distribution-process.txt",
    "text": "ugin/\n  title: Maven Jenkins plugin (HPI) source code\n- url: https://jenkinsci.github.io/maven-hpi-plugin/\n  title: Maven Jenkins plugin (HPI) plugin documentation\n\n\nJenkins plugin distribution provides available updates, security status, dependency information, and much more to Jenkins controllers.\nJenkins plugin initial releases and updates are distributed to users from the Jenkins update center"
  },
  "1656": {
    "source_file": "distribution-process.txt",
    "text": "information, and much more to Jenkins controllers.\nJenkins plugin initial releases and updates are distributed to users from the Jenkins update center.\nThe  allows administrators to choose their plugins.\nThe  provides a command line interface to install plugins.\n\nPlugins use the  to run their continuous integration processes.\nPlugins use the  in the  to build and test multiple configurations.\nComm"
  },
  "1657": {
    "source_file": "distribution-process.txt",
    "text": "all plugins.\n\nPlugins use the  to run their continuous integration processes.\nPlugins use the  in the  to build and test multiple configurations.\nCommon configurations include mixtures of Linux and Windows and mixtures of Java versions.\n\nTroubleshooting of issues with plugin build and test depends on the location of the failure.\nIf a plugin fails to build and test locally, check the status of the "
  },
  "1658": {
    "source_file": "distribution-process.txt",
    "text": "ing of issues with plugin build and test depends on the location of the failure.\nIf a plugin fails to build and test locally, check the status of the matching job on ci.jenkins.io.\nIf it is passing on ci.jenkins.io, then ask in the .\nIf a plugin passes build and test locally but fails on ci.jenkins.io, open a ticket with the .\n\nAutomated release is the preferred release process for most plugins.\n\n"
  },
  "1659": {
    "source_file": "distribution-process.txt",
    "text": "es build and test locally but fails on ci.jenkins.io, open a ticket with the .\n\nAutomated release is the preferred release process for most plugins.\n\nPlugins may choose to release automatically each time a relevant change is merged to the primary branch of the repository.\nIn an automated release, a GitHub Action builds and releases the plugin after it has confirmed that the most recent ci.jenkins."
  },
  "1660": {
    "source_file": "distribution-process.txt",
    "text": "nch of the repository.\nIn an automated release, a GitHub Action builds and releases the plugin after it has confirmed that the most recent ci.jenkins.io job is passing.\nRefer to   for detailed instructions to configure automated release..\n\nMaintainers may choose to release plugins manually.\nIn a manual release, the maintainer builds, tests, and releases the plugin with `mvn release:prepare release"
  },
  "1661": {
    "source_file": "distribution-process.txt",
    "text": "s may choose to release plugins manually.\nIn a manual release, the maintainer builds, tests, and releases the plugin with `mvn release:prepare release:perform`.\nRefer to   for detailed manual release instructions.\n\nPlugins often depend on other plugins for functionality.\nFor example, the  depends on the  for its Git API implementation.\nOften, a change is needed in both a plugin dependency and the "
  },
  "1662": {
    "source_file": "distribution-process.txt",
    "text": "ns for functionality.\nFor example, the  depends on the  for its Git API implementation.\nOften, a change is needed in both a plugin dependency and the plugin itself.\n allow plugins to use an unreleased pull request build of a dependency.\n\nMore details are available in .\n\n is hosted by  for the Jenkins project.\nIt hosts all the Jenkins released artifacts, including Jenkins core, Jenkins plugins, Jen"
  },
  "1663": {
    "source_file": "distribution-process.txt",
    "text": " are available in .\n\n is hosted by  for the Jenkins project.\nIt hosts all the Jenkins released artifacts, including Jenkins core, Jenkins plugins, Jenkins tools, and many other Jenkins components.\nIt also hosts security fixes privately while they are being developed and tested.\n\nPlugin releases are uploaded to Artifactory whether they are automated, manual, or incremental releases.\n\nManual release"
  },
  "1664": {
    "source_file": "distribution-process.txt",
    "text": " being developed and tested.\n\nPlugin releases are uploaded to Artifactory whether they are automated, manual, or incremental releases.\n\nManual releases require that the maintainer must have a valid, active .\nMaintainers must login to  at least once to create their account.\nArtifactory credentials are a frequent source of confusion for plugin maintainers.\n\nTroubleshooting of  is sometimes required."
  },
  "1665": {
    "source_file": "distribution-process.txt",
    "text": "o create their account.\nArtifactory credentials are a frequent source of confusion for plugin maintainers.\n\nTroubleshooting of  is sometimes required.\nIf the  is insufficient, ask in the .\n\nThe  generates the  with release details for Jenkins plugins.\nThe update center detects manual and automated plugin releases to Artifactory and includes them in the generated update site.\n\nSecurity issues are a"
  },
  "1666": {
    "source_file": "distribution-process.txt",
    "text": ".\nThe update center detects manual and automated plugin releases to Artifactory and includes them in the generated update site.\n\nSecurity issues are also included in the Jenkins update site so that Jenkins controllers can display vulnerability information to Jenkins administrators.\n\nThe  is described in the update center .\n\nLinks to the latest releases of Jenkins core and Jenkins plugins are avail"
  },
  "1667": {
    "source_file": "distribution-process.txt",
    "text": "ation to Jenkins administrators.\n\nThe  is described in the update center .\n\nLinks to the latest releases of Jenkins core and Jenkins plugins are available from the .\n\nDonors provide worldwide mirrors for Jenkins core releases and Jenkins plugin releases.\nMirrors are available in North America, Europe, and Asia.\n\nMirrors are updated by `rsync` from one or more other mirrors.\nThe current list of mir"
  },
  "1668": {
    "source_file": "distribution-process.txt",
    "text": "ses.\nMirrors are available in North America, Europe, and Asia.\n\nMirrors are updated by `rsync` from one or more other mirrors.\nThe current list of mirrors for a particular file is available by appending `?mirrorlist` to the URL of the that item on the mirror.\nFor example, the mirrors of the latest release of the Git plugin are available at .\n\nThe  provides searching and browsing for Jenkins plugin"
  },
  "1669": {
    "source_file": "distribution-process.txt",
    "text": "e mirror.\nFor example, the mirrors of the latest release of the Git plugin are available at .\n\nThe  provides searching and browsing for Jenkins plugins.\nIt also provides detailed information for each plugin, including:\n\n* Documentation\n* Releases and their changelogs\n* Dependencies\n* Health score\n* Link to the detailed version information (how many Jenkins controllers have installed each version o"
  },
  "1670": {
    "source_file": "distribution-process.txt",
    "text": " their changelogs\n* Dependencies\n* Health score\n* Link to the detailed version information (how many Jenkins controllers have installed each version of the plugin, ...)\n* Links to the GitHub repository, open issues, Pipeline steps reference, Javadoc, and more\n\nThe plugins site is updated roughly every three hours.\nNew releases should be visible on the plugins site within six hours of release.\nIf t"
  },
  "1671": {
    "source_file": "distribution-process.txt",
    "text": " and more\n\nThe plugins site is updated roughly every three hours.\nNew releases should be visible on the plugins site within six hours of release.\nIf they are not available as expected, open a ticket with the .\n\nPlugin documentation is written as either Markdown or Asciidoc in the plugin repository.\nDocumentation pages on the plugins site are generated from the plugin documentation in the repositor"
  },
  "1672": {
    "source_file": "distribution-process.txt",
    "text": "er Markdown or Asciidoc in the plugin repository.\nDocumentation pages on the plugins site are generated from the plugin documentation in the repository.\nRefer to the  page for detailed instructions."
  },
  "1673": {
    "source_file": "docker.txt",
    "text": "layout: section\ntitle: Using Docker with Pipeline\n\n\nifdef::env-github[:imagesdir: ../resources]\nifndef::env-github[:imagesdir: ../../resources]\n\nMany organizations use  to unify their build and test environments across machines, and to provide an efficient mechanism for deploying applications.\nStarting with Pipeline versions 2.5 and higher, Pipeline has built-in support for interacting with Docker"
  },
  "1674": {
    "source_file": "docker.txt",
    "text": "icient mechanism for deploying applications.\nStarting with Pipeline versions 2.5 and higher, Pipeline has built-in support for interacting with Docker from within a `Jenkinsfile`.\n\nWhile this page covers the basics of utilizing Docker from within a `Jenkinsfile`, it will not cover the fundamentals of Docker, which you can refer to in the .\n\n[[execution-environment]]\n\nPipeline is designed to easily"
  },
  "1675": {
    "source_file": "docker.txt",
    "text": "Jenkinsfile`, it will not cover the fundamentals of Docker, which you can refer to in the .\n\n[[execution-environment]]\n\nPipeline is designed to easily use  images as the execution environment for a single  or the entire Pipeline.\nMeaning that a user can define the tools required for their Pipeline, without having to manually configure agents.\nAny tool that can be  can be used with ease, by making "
  },
  "1676": {
    "source_file": "docker.txt",
    "text": "can define the tools required for their Pipeline, without having to manually configure agents.\nAny tool that can be  can be used with ease, by making only minor edits to a `Jenkinsfile`.\n\n[pipeline]\n\n// Declarative //\npipeline {\n    agent {\n        docker { image 'node:24.11.1-alpine3.22' }\n    }\n    stages {\n        stage('Test') {\n            steps {\n                sh 'node --eval \"console.log("
  },
  "1677": {
    "source_file": "docker.txt",
    "text": "ocker { image 'node:24.11.1-alpine3.22' }\n    }\n    stages {\n        stage('Test') {\n            steps {\n                sh 'node --eval \"console.log(process.platform,process.env.CI)\"'\n            }\n        }\n    }\n}\n// Script //\nnode {\n    /* Requires the Docker Pipeline plugin to be installed */\n    docker.image('node:24.11.1-alpine3.22').inside {\n        stage('Test') {\n            sh 'node --e"
  },
  "1678": {
    "source_file": "docker.txt",
    "text": "es the Docker Pipeline plugin to be installed */\n    docker.image('node:24.11.1-alpine3.22').inside {\n        stage('Test') {\n            sh 'node --eval \"console.log(process.platform,process.env.CI)\"'\n        }\n    }\n}\n\nWhen the Pipeline executes, Jenkins will automatically start the specified container and execute the defined steps within:\n\n[Pipeline] stage\n[Pipeline] { (Test)\n[Pipeline] sh\n[gui"
  },
  "1679": {
    "source_file": "docker.txt",
    "text": "enkins will automatically start the specified container and execute the defined steps within:\n\n[Pipeline] stage\n[Pipeline] { (Test)\n[Pipeline] sh\n[guided-tour] Running shell script\nnode --eval 'console.log(process.platform,process.env.CI)'\nlinux true\n[Pipeline] }\n[Pipeline] // stage\n[Pipeline] }\n\nAdditional arguments, such as the `registryUrl`, are described in the  syntax documentation.\n\nIf it is"
  },
  "1680": {
    "source_file": "docker.txt",
    "text": "\n[Pipeline] }\n[Pipeline] // stage\n[Pipeline] }\n\nAdditional arguments, such as the `registryUrl`, are described in the  syntax documentation.\n\nIf it is important to keep the workspace synchronized with other stages, use `reuseNode true`.\nOtherwise, a dockerized stage can be run on the same agent or any other agent, but in a temporary workspace.\n\nBy default, for a containerized stage, Jenkins:\n\n* Pi"
  },
  "1681": {
    "source_file": "docker.txt",
    "text": "dockerized stage can be run on the same agent or any other agent, but in a temporary workspace.\n\nBy default, for a containerized stage, Jenkins:\n\n* Picks an agent.\n* Creates a new empty workspace.\n* Clones pipeline code into it.\n* Mounts this new workspace into the container.\n\nIf you have multiple Jenkins agents, your containerized stage can be started on any of them.\n\nWhen `reuseNode` is set to `"
  },
  "1682": {
    "source_file": "docker.txt",
    "text": "kspace into the container.\n\nIf you have multiple Jenkins agents, your containerized stage can be started on any of them.\n\nWhen `reuseNode` is set to `true`, no new workspace will be created, and the current workspace from the current agent will be mounted into the container.\nAfter this, the container will be started on the same node, so all of the data will be synchronized.\n\n[pipeline]\n\n// Declara"
  },
  "1683": {
    "source_file": "docker.txt",
    "text": "unted into the container.\nAfter this, the container will be started on the same node, so all of the data will be synchronized.\n\n[pipeline]\n\n// Declarative //\npipeline {\n    agent any\n    stages {\n        stage('Build') {\n            agent {\n                docker {\n                    image 'gradle:8.14.0-jdk21-alpine'\n                    // Run the container on the node specified at the\n         "
  },
  "1684": {
    "source_file": "docker.txt",
    "text": "       docker {\n                    image 'gradle:8.14.0-jdk21-alpine'\n                    // Run the container on the node specified at the\n                    // top-level of the Pipeline, in the same workspace,\n                    // rather than on a new node entirely:\n                    reuseNode true\n                }\n            }\n            steps {\n                sh 'gradle -g gradle-use"
  },
  "1685": {
    "source_file": "docker.txt",
    "text": "n a new node entirely:\n                    reuseNode true\n                }\n            }\n            steps {\n                sh 'gradle -g gradle-user-home --version'\n            }\n        }\n    }\n}\n// Script //\n// Option \"reuseNode true\" currently unsupported in scripted pipeline\n\nMany build tools will download external dependencies and cache them locally for future re-use.\nSince containers are "
  },
  "1686": {
    "source_file": "docker.txt",
    "text": "unsupported in scripted pipeline\n\nMany build tools will download external dependencies and cache them locally for future re-use.\nSince containers are initially created with \"clean\" file systems, this can result in slower Pipelines, as they may not take advantage of on-disk caches between subsequent Pipeline runs.\n\nPipeline supports adding custom arguments that are passed to Docker, allowing users "
  },
  "1687": {
    "source_file": "docker.txt",
    "text": "ke advantage of on-disk caches between subsequent Pipeline runs.\n\nPipeline supports adding custom arguments that are passed to Docker, allowing users to specify custom  to mount, which can be used for caching data on the  between Pipeline runs.\nThe following example will cache `~/.m2` between Pipeline runs utilizing the , avoiding the need to re-download dependencies for subsequent Pipeline runs.\n"
  },
  "1688": {
    "source_file": "docker.txt",
    "text": "ollowing example will cache `~/.m2` between Pipeline runs utilizing the , avoiding the need to re-download dependencies for subsequent Pipeline runs.\n\n[pipeline]\n\n// Declarative //\npipeline {\n    agent {\n        docker {\n            image 'maven:3.9.9-eclipse-temurin-21'\n            args '-v $HOME/.m2:/root/.m2'\n        }\n    }\n    stages {\n        stage('Build') {\n            steps {\n            "
  },
  "1689": {
    "source_file": "docker.txt",
    "text": "9-eclipse-temurin-21'\n            args '-v $HOME/.m2:/root/.m2'\n        }\n    }\n    stages {\n        stage('Build') {\n            steps {\n                sh 'mvn -B'\n            }\n        }\n    }\n}\n// Script //\nnode {\n    /* Requires the Docker Pipeline plugin to be installed */\n    docker.image('maven:3.9.11-eclipse-temurin-21-alpine').inside('-v $HOME/.m2:/root/.m2') {\n        stage('Build') {\n "
  },
  "1690": {
    "source_file": "docker.txt",
    "text": "ine plugin to be installed */\n    docker.image('maven:3.9.11-eclipse-temurin-21-alpine').inside('-v $HOME/.m2:/root/.m2') {\n        stage('Build') {\n            sh 'mvn -B'\n        }\n    }\n}\n\nIt has become increasingly common for code bases to rely on multiple different technologies.\nFor example, a repository might have both a Java-based back-end API implementation _and_ a JavaScript-based front-e"
  },
  "1691": {
    "source_file": "docker.txt",
    "text": "n multiple different technologies.\nFor example, a repository might have both a Java-based back-end API implementation _and_ a JavaScript-based front-end implementation.\nCombining Docker and Pipeline allows a `Jenkinsfile` to use *multiple* types of technologies, by combining the `agent {}` directive with different stages.\n\n[pipeline]\n\n// Declarative //\npipeline {\n    agent none\n    stages {\n      "
  },
  "1692": {
    "source_file": "docker.txt",
    "text": "echnologies, by combining the `agent {}` directive with different stages.\n\n[pipeline]\n\n// Declarative //\npipeline {\n    agent none\n    stages {\n        stage('Back-end') {\n            agent {\n                docker { image 'maven:3.9.11-eclipse-temurin-21-alpine' }\n            }\n            steps {\n                sh 'mvn --version'\n            }\n        }\n        stage('Front-end') {\n            "
  },
  "1693": {
    "source_file": "docker.txt",
    "text": "in-21-alpine' }\n            }\n            steps {\n                sh 'mvn --version'\n            }\n        }\n        stage('Front-end') {\n            agent {\n                docker { image 'node:24.11.1-alpine3.22' }\n            }\n            steps {\n                sh 'node --version'\n            }\n        }\n    }\n}\n// Script //\nnode {\n    /* Requires the Docker Pipeline plugin to be installed */"
  },
  "1694": {
    "source_file": "docker.txt",
    "text": "\n                sh 'node --version'\n            }\n        }\n    }\n}\n// Script //\nnode {\n    /* Requires the Docker Pipeline plugin to be installed */\n\n    stage('Back-end') {\n        docker.image('maven:3.9.11-eclipse-temurin-21-alpine').inside {\n            sh 'mvn --version'\n        }\n    }\n\n    stage('Front-end') {\n        docker.image('node:24.11.1-alpine3.22').inside {\n            sh 'node -"
  },
  "1695": {
    "source_file": "docker.txt",
    "text": "          sh 'mvn --version'\n        }\n    }\n\n    stage('Front-end') {\n        docker.image('node:24.11.1-alpine3.22').inside {\n            sh 'node --version'\n        }\n    }\n}\n\n[[dockerfile]]\n\nFor projects requiring a more customized execution environment, Pipeline also supports building and running a container from a `Dockerfile` in the source repository.\nIn contrast to the <<execution-environm"
  },
  "1696": {
    "source_file": "docker.txt",
    "text": "ronment, Pipeline also supports building and running a container from a `Dockerfile` in the source repository.\nIn contrast to the <<execution-environment,previous approach>> of using an \"off-the-shelf\" container, using the `agent { dockerfile true }` syntax builds a new image from a `Dockerfile`, rather than pulling one from .\n\nReusing an example from above, with a more custom `Dockerfile`:\n\n.Dock"
  },
  "1697": {
    "source_file": "docker.txt",
    "text": " syntax builds a new image from a `Dockerfile`, rather than pulling one from .\n\nReusing an example from above, with a more custom `Dockerfile`:\n\n.Dockerfile\n\nFROM node:24.11.1-alpine3.22\n\nRUN apk add -U subversion\n\nBy committing this to the root of the source repository, the `Jenkinsfile` can be changed to build a container based on this `Dockerfile`, and then run the defined steps using that cont"
  },
  "1698": {
    "source_file": "docker.txt",
    "text": "he source repository, the `Jenkinsfile` can be changed to build a container based on this `Dockerfile`, and then run the defined steps using that container:\n\n[pipeline]\n\n// Declarative //\npipeline {\n    agent { dockerfile true }\n    stages {\n        stage('Test') {\n            steps {\n                sh 'node --version'\n                sh 'svn --version'\n            }\n        }\n    }\n}\n// Script /"
  },
  "1699": {
    "source_file": "docker.txt",
    "text": "stage('Test') {\n            steps {\n                sh 'node --version'\n                sh 'svn --version'\n            }\n        }\n    }\n}\n// Script //\n\nThe `agent { dockerfile true }` syntax supports a number of other options, which are described in more detail in the  section.\n\n.Using a Dockerfile with Jenkins Pipeline\nvideo::Pi2kJ2RJS50[youtube, width=852, height=480]\n\nBy default, Pipeline assu"
  },
  "1700": {
    "source_file": "docker.txt",
    "text": " more detail in the  section.\n\n.Using a Dockerfile with Jenkins Pipeline\nvideo::Pi2kJ2RJS50[youtube, width=852, height=480]\n\nBy default, Pipeline assumes that _any_ configured  is capable of running Docker-based Pipelines.\nFor Jenkins environments that have macOS, Windows, or other agents that are unable to run the Docker daemon, this default setting may be problematic.\nPipeline provides a global "
  },
  "1701": {
    "source_file": "docker.txt",
    "text": "at have macOS, Windows, or other agents that are unable to run the Docker daemon, this default setting may be problematic.\nPipeline provides a global option on the *Manage Jenkins* page and on the  level, for specifying which agents (by ) to use for running Docker-based Pipelines. To enable this option for Docker labels, the plugin:docker-workflow[*Docker Pipeline*] plugin must be installed.\n\nThe "
  },
  "1702": {
    "source_file": "docker.txt",
    "text": "running Docker-based Pipelines. To enable this option for Docker labels, the plugin:docker-workflow[*Docker Pipeline*] plugin must be installed.\n\nThe `/usr/local/bin` directory is not included in the macOS `PATH` for Docker images by default.\nIf executables from `/usr/local/bin` need to be called from within Jenkins, the `PATH` needs to be extended to include `/usr/local/bin`.\nAdd a path node in t"
  },
  "1703": {
    "source_file": "docker.txt",
    "text": "utables from `/usr/local/bin` need to be called from within Jenkins, the `PATH` needs to be extended to include `/usr/local/bin`.\nAdd a path node in the file \"/usr/local/Cellar/jenkins-lts/XXX/homebrew.mxcl.jenkins-lts.plist\" like this:\n\n.Contents of homebrew.mxcl.jenkins-lts.plist\n\n<key>EnvironmentVariables</key>\n<dict>\n<key>PATH</key>\n<string><!-- insert revised path here --></string>\n</dict>\n\nT"
  },
  "1704": {
    "source_file": "docker.txt",
    "text": " homebrew.mxcl.jenkins-lts.plist\n\n<key>EnvironmentVariables</key>\n<dict>\n<key>PATH</key>\n<string><!-- insert revised path here --></string>\n</dict>\n\nThe revised `PATH` `string` should be a colon separated list of directories in the same format as the `PATH` environment variable and should include:\n\n* `/usr/local/bin`\n* `/usr/bin`\n* `/bin`\n* `/usr/sbin`\n* `/sbin`\n* `/Applications/Docker.app/Content"
  },
  "1705": {
    "source_file": "docker.txt",
    "text": " `PATH` environment variable and should include:\n\n* `/usr/local/bin`\n* `/usr/bin`\n* `/bin`\n* `/usr/sbin`\n* `/sbin`\n* `/Applications/Docker.app/Contents/Resources/bin/`\n* `/Users/XXX/Library/Group\\ Containers/group.com.docker/Applications/Docker.app/Contents/Resources/bin` (where `XXX` is replaced by your user name)\n\nNow, restart jenkins using `brew services restart jenkins-lts`.\n\nUsing Docker in P"
  },
  "1706": {
    "source_file": "docker.txt",
    "text": "ontents/Resources/bin` (where `XXX` is replaced by your user name)\n\nNow, restart jenkins using `brew services restart jenkins-lts`.\n\nUsing Docker in Pipeline is an effective way to run a service on which the build, or a set of tests, may rely.\nSimilar to the , Docker Pipeline can run one container \"in the background\", while performing work in another.\nUtilizing this sidecar approach, a Pipeline ca"
  },
  "1707": {
    "source_file": "docker.txt",
    "text": "r to the , Docker Pipeline can run one container \"in the background\", while performing work in another.\nUtilizing this sidecar approach, a Pipeline can have a \"clean\" container provisioned for each Pipeline run.\n\nConsider a hypothetical integration test suite that relies on a local MySQL database to be running.\nUsing the `withRun` method, implemented in the plugin:docker-workflow[Docker Pipeline] "
  },
  "1708": {
    "source_file": "docker.txt",
    "text": "est suite that relies on a local MySQL database to be running.\nUsing the `withRun` method, implemented in the plugin:docker-workflow[Docker Pipeline] plugin's support for Scripted Pipeline, a `Jenkinsfile` can run MySQL as a sidecar:\n\nnode {\n    checkout scm\n    /*\n     * In order to communicate with the MySQL server, this Pipeline explicitly\n     * maps the port (`3306`) to a known port on the ho"
  },
  "1709": {
    "source_file": "docker.txt",
    "text": "kout scm\n    /*\n     * In order to communicate with the MySQL server, this Pipeline explicitly\n     * maps the port (`3306`) to a known port on the host machine.\n     */\n    docker.image('mysql:8-oracle').withRun('-e \"MYSQL_ROOT_PASSWORD=my-secret-pw\"' +\n                                           ' -p 3306:3306') { c ->\n        /* Wait until mysql service is up */\n        sh 'while ! mysqladmin pi"
  },
  "1710": {
    "source_file": "docker.txt",
    "text": "\"' +\n                                           ' -p 3306:3306') { c ->\n        /* Wait until mysql service is up */\n        sh 'while ! mysqladmin ping -h0.0.0.0 --silent; do sleep 1; done'\n        /* Run some tests which require MySQL */\n        sh 'make check'\n    }\n}\n\nThis example can be taken further, utilizing two containers simultaneously.\nOne \"sidecar\" running MySQL, and another providing "
  },
  "1711": {
    "source_file": "docker.txt",
    "text": " 'make check'\n    }\n}\n\nThis example can be taken further, utilizing two containers simultaneously.\nOne \"sidecar\" running MySQL, and another providing the <<execution-environment,execution environment>> by using the Docker .\n\nnode {\n    checkout scm\n    docker.image('mysql:8-oracle').withRun('-e \"MYSQL_ROOT_PASSWORD=my-secret-pw\"') { c ->\n        docker.image('mysql:8-oracle').inside(\"--link ${c.id"
  },
  "1712": {
    "source_file": "docker.txt",
    "text": "   docker.image('mysql:8-oracle').withRun('-e \"MYSQL_ROOT_PASSWORD=my-secret-pw\"') { c ->\n        docker.image('mysql:8-oracle').inside(\"--link ${c.id}:db\") {\n            /* Wait until mysql service is up */\n            sh 'while ! mysqladmin ping -hdb --silent; do sleep 1; done'\n        }\n        docker.image('oraclelinux:9').inside(\"--link ${c.id}:db\") {\n            /*\n             * Run some te"
  },
  "1713": {
    "source_file": "docker.txt",
    "text": "db --silent; do sleep 1; done'\n        }\n        docker.image('oraclelinux:9').inside(\"--link ${c.id}:db\") {\n            /*\n             * Run some tests that require MySQL, and assume that it is\n             * available on the host name `db`\n             */\n            sh 'make check'\n        }\n    }\n}\n\nThe above example uses the object exposed by `withRun`, which has the running container's ID a"
  },
  "1714": {
    "source_file": "docker.txt",
    "text": "      */\n            sh 'make check'\n        }\n    }\n}\n\nThe above example uses the object exposed by `withRun`, which has the running container's ID available via the `id` property.\nUsing the container's ID, the Pipeline can create a link by passing custom Docker arguments to the `inside()` method.\n\nThe `id` property can also be useful for inspecting logs from a running Docker container before the"
  },
  "1715": {
    "source_file": "docker.txt",
    "text": "custom Docker arguments to the `inside()` method.\n\nThe `id` property can also be useful for inspecting logs from a running Docker container before the Pipeline exits:\n\nsh \"docker logs ${c.id}\"\n\nIn order to create a Docker image, the plugin:docker-workflow[Docker Pipeline] plugin also provides a `build()` method for creating a new image from a `Dockerfile` in the repository during a Pipeline run.\n\n"
  },
  "1716": {
    "source_file": "docker.txt",
    "text": "kflow[Docker Pipeline] plugin also provides a `build()` method for creating a new image from a `Dockerfile` in the repository during a Pipeline run.\n\nOne major benefit of using the syntax `docker.build(\"my-image-name\")` is that a Scripted Pipeline can use the return value for subsequent Docker Pipeline calls, for example:\n\nnode {\n    checkout scm\n\n    def customImage = docker.build(\"my-image:${env"
  },
  "1717": {
    "source_file": "docker.txt",
    "text": "n use the return value for subsequent Docker Pipeline calls, for example:\n\nnode {\n    checkout scm\n\n    def customImage = docker.build(\"my-image:${env.BUILD_ID}\")\n\n    customImage.inside {\n        sh 'make test'\n    }\n}\n\nThe return value can also be used to publish the Docker image to  or a <<custom-registry, custom Registry>>, via the `push()` method, for example:\n\nnode {\n    checkout scm\n    def"
  },
  "1718": {
    "source_file": "docker.txt",
    "text": "used to publish the Docker image to  or a <<custom-registry, custom Registry>>, via the `push()` method, for example:\n\nnode {\n    checkout scm\n    def customImage = docker.build(\"my-image:${env.BUILD_ID}\")\n    customImage.push()\n}\n\nOne common usage of image \"tags\" is to specify a `latest` tag for the most recently validated version of a Docker image.\nThe `push()` method accepts an optional `tag` p"
  },
  "1719": {
    "source_file": "docker.txt",
    "text": "f image \"tags\" is to specify a `latest` tag for the most recently validated version of a Docker image.\nThe `push()` method accepts an optional `tag` parameter, allowing the Pipeline to push the `customImage` with different tags, for example:\n\nnode {\n    checkout scm\n    def customImage = docker.build(\"my-image:${env.BUILD_ID}\")\n    customImage.push()\n\n    customImage.push('latest')\n}\n\nThe `build()"
  },
  "1720": {
    "source_file": "docker.txt",
    "text": "    checkout scm\n    def customImage = docker.build(\"my-image:${env.BUILD_ID}\")\n    customImage.push()\n\n    customImage.push('latest')\n}\n\nThe `build()` method builds the `Dockerfile` in the current directory by default.\nThis can be overridden by providing a directory path containing a `Dockerfile` as the second argument of the `build()` method, for example:\n\nnode {\n    checkout scm\n    def testIma"
  },
  "1721": {
    "source_file": "docker.txt",
    "text": "iding a directory path containing a `Dockerfile` as the second argument of the `build()` method, for example:\n\nnode {\n    checkout scm\n    def testImage = docker.build(\"test-image\", \"./dockerfiles/test\") // <1> testImage.inside {\n        sh 'make test'\n    }\n}\n\n<1> Builds `test-image` from the Dockerfile found at `./dockerfiles/test/Dockerfile`.\n\nIt is possible to pass other arguments to  by addin"
  },
  "1722": {
    "source_file": "docker.txt",
    "text": "t'\n    }\n}\n\n<1> Builds `test-image` from the Dockerfile found at `./dockerfiles/test/Dockerfile`.\n\nIt is possible to pass other arguments to  by adding them to the second argument of the `build()` method.\nWhen passing arguments this way, the last value in the string must be the path to the docker file, and should end with the folder to use as the build context.\n\nThis example overrides the default "
  },
  "1723": {
    "source_file": "docker.txt",
    "text": "ue in the string must be the path to the docker file, and should end with the folder to use as the build context.\n\nThis example overrides the default `Dockerfile` by passing the `-f` flag:\n\nnode {\n    checkout scm\n    def dockerfile = 'Dockerfile.test'\n    def customImage = docker.build(\"my-image:${env.BUILD_ID}\",\n                                   \"-f ${dockerfile} ./dockerfiles\") // <1> }\n\n<1> B"
  },
  "1724": {
    "source_file": "docker.txt",
    "text": "t'\n    def customImage = docker.build(\"my-image:${env.BUILD_ID}\",\n                                   \"-f ${dockerfile} ./dockerfiles\") // <1> }\n\n<1> Builds `my-image:${env.BUILD_ID}` from the Dockerfile found at `./dockerfiles/Dockerfile.test`.\n\nBy default, the plugin:docker-workflow[Docker Pipeline] plugin will communicate with a local Docker daemon, typically accessed through `/var/run/docker.so"
  },
  "1725": {
    "source_file": "docker.txt",
    "text": "efault, the plugin:docker-workflow[Docker Pipeline] plugin will communicate with a local Docker daemon, typically accessed through `/var/run/docker.sock`.\n\nTo select a non-default Docker server, such as with , use the `withServer()` method.\n\nYou can pass a URI, and optionally the Credentials ID of a *Docker Server Certificate Authentication* pre-configured in Jenkins, to the method with:\n\nnode {\n "
  },
  "1726": {
    "source_file": "docker.txt",
    "text": "pass a URI, and optionally the Credentials ID of a *Docker Server Certificate Authentication* pre-configured in Jenkins, to the method with:\n\nnode {\n    checkout scm\n\n    docker.withServer('tcp://swarm.example.com:2376', 'swarm-certs') {\n        docker.image('mysql:8-oracle').withRun('-p 3306:3306') {\n            /* do things */\n        }\n    }\n}\n\n[CAUTION]\n\n`inside()` and `build()` will not work "
  },
  "1727": {
    "source_file": "docker.txt",
    "text": "er.image('mysql:8-oracle').withRun('-p 3306:3306') {\n            /* do things */\n        }\n    }\n}\n\n[CAUTION]\n\n`inside()` and `build()` will not work properly with a Docker Swarm server out of the box.\n\nFor `inside()` to work, the Docker server and the Jenkins agent must use the same filesystem, so that the workspace can be mounted.\n\nCurrently, neither the Jenkins plugin nor the Docker CLI will au"
  },
  "1728": {
    "source_file": "docker.txt",
    "text": "he Jenkins agent must use the same filesystem, so that the workspace can be mounted.\n\nCurrently, neither the Jenkins plugin nor the Docker CLI will automatically detect the case that the server is running remotely.\nA typical symptom of this would be errors from nested `sh` commands such as:\n\ncannot create /\u2026@tmp/durable-\u2026/pid: Directory nonexistent\n\nWhen Jenkins detects that the agent is itself ru"
  },
  "1729": {
    "source_file": "docker.txt",
    "text": "errors from nested `sh` commands such as:\n\ncannot create /\u2026@tmp/durable-\u2026/pid: Directory nonexistent\n\nWhen Jenkins detects that the agent is itself running inside a Docker container, it will automatically pass the `--volumes-from` argument to the `inside` container, ensuring that it can share a workspace with the agent.\n\nAdditionally, some versions of Docker Swarm do not support custom Registries."
  },
  "1730": {
    "source_file": "docker.txt",
    "text": "side` container, ensuring that it can share a workspace with the agent.\n\nAdditionally, some versions of Docker Swarm do not support custom Registries.\n\n[[custom-registry]]\n\nBy default, the plugin:docker-workflow[Docker Pipeline] plugin assumes the default Docker Registry of .\n\nIn order to use a custom Docker Registry, users of Scripted Pipeline can wrap steps with the `withRegistry()` method, pass"
  },
  "1731": {
    "source_file": "docker.txt",
    "text": "fault Docker Registry of .\n\nIn order to use a custom Docker Registry, users of Scripted Pipeline can wrap steps with the `withRegistry()` method, passing in the custom Registry URL, for example:\n\nnode {\n    checkout scm\n\n    docker.withRegistry('https://registry.example.com') {\n\n        docker.image('my-custom-image').inside {\n            sh 'make test'\n        }\n    }\n}\n\nFor a Docker Registry req"
  },
  "1732": {
    "source_file": "docker.txt",
    "text": "s://registry.example.com') {\n\n        docker.image('my-custom-image').inside {\n            sh 'make test'\n        }\n    }\n}\n\nFor a Docker Registry requiring authentication, add a \"Username/Password\" Credentials item from the Jenkins home page and use the Credentials ID as a second argument to `withRegistry()`:\n\nnode {\n    checkout scm\n\n    docker.withRegistry('https://registry.example.com', 'crede"
  },
  "1733": {
    "source_file": "docker.txt",
    "text": " the Credentials ID as a second argument to `withRegistry()`:\n\nnode {\n    checkout scm\n\n    docker.withRegistry('https://registry.example.com', 'credentials-id') {\n\n        def customImage = docker.build(\"my-image:${env.BUILD_ID}\")\n\n        /* Push the container to the custom Registry */\n        customImage.push()\n    }\n}"
  },
  "1734": {
    "source_file": "docker.txt",
    "text": "he container to the custom Registry */\n        customImage.push()\n    }\n}"
  },
  "1735": {
    "source_file": "documentation.txt",
    "text": "title: Plugin Documentation\nlayout: developersection\nreferences:\n- url: https://plugins.jenkins.io/\n  title: Plugin site\n- url: ../plugin-site/\n  title: Plugin site documentation\n\n\nDocumentation is an important part of any Jenkins plugin.\nIt includes user documentation (plugin pages, changelogs, user guidelines, etc.) and the contributor documentation (how to contribute, developer guidelines, etc."
  },
  "1736": {
    "source_file": "documentation.txt",
    "text": " user documentation (plugin pages, changelogs, user guidelines, etc.) and the contributor documentation (how to contribute, developer guidelines, etc.).\nThis section provides an overview of these documentation types.\n\nPlugin pages are hosted on the .\nThese pages are generated automatically using the metadata from the latest plugin release and an external documentation page.\nExternal documentation "
  },
  "1737": {
    "source_file": "documentation.txt",
    "text": "\nThese pages are generated automatically using the metadata from the latest plugin release and an external documentation page.\nExternal documentation can be retrieved from GitHub or from the https://wiki.jenkins.io[Jenkins Wiki].\n\nWe recommend storing documentation in the GitHub repository of the plugin.\nIt allows plugin maintainers to provide the same documentation from README pages and the Jenki"
  },
  "1738": {
    "source_file": "documentation.txt",
    "text": "g documentation in the GitHub repository of the plugin.\nIt allows plugin maintainers to provide the same documentation from README pages and the Jenkins plugin site,\nand at the same time it allows using the Documentation-as-Code techniques when the documentation is a part of the\nrepository and hence all common practices can be applied:\n\n* Pull requests and reviews\n* Creating documentation in paral"
  },
  "1739": {
    "source_file": "documentation.txt",
    "text": "ocumentation is a part of the\nrepository and hence all common practices can be applied:\n\n* Pull requests and reviews\n* Creating documentation in parallel with features\n* Editing docs from GitHub Web UI, with preview support\n* Versioning, documentation for previous plugin versions can be easily accessed\n\n[[documenting-plugins]]\n\nThe plugin site can pull documentation from the root README pages or f"
  },
  "1740": {
    "source_file": "documentation.txt",
    "text": "n for previous plugin versions can be easily accessed\n\n[[documenting-plugins]]\n\nThe plugin site can pull documentation from the root README pages or from other locations defined by the plugin URL (see below).\nMultiple formats are supported: GitHub Flavored Markdown, Asciidoc or raw text.\n\nTo publish the plugin documentation on GitHub:\n\nCreate a README page and put the plugin documentation there.\n "
  },
  "1741": {
    "source_file": "documentation.txt",
    "text": "avored Markdown, Asciidoc or raw text.\n\nTo publish the plugin documentation on GitHub:\n\nCreate a README page and put the plugin documentation there.\n  This page will become a landing page for the .\n** More documentation pages can be introduced inside the repository and\nlinked from the README, the plugin site will display both absolute and\nrelative links\n** Images from pages will be displayed by th"
  },
  "1742": {
    "source_file": "documentation.txt",
    "text": " the repository and\nlinked from the README, the plugin site will display both absolute and\nrelative links\n** Images from pages will be displayed by the plugin site as well\nModify your project URL to point to the GitHub repository, e.g. `https://github.com/jenkinsci/your-plugin`.\n  See the guidelines for Maven and Gradle below.\nRelease the new plugin version.\n  Once the  picks up the release (which"
  },
  "1743": {
    "source_file": "documentation.txt",
    "text": "b.com/jenkinsci/your-plugin`.\n  See the guidelines for Maven and Gradle below.\nRelease the new plugin version.\n  Once the  picks up the release (which can take up to a few hours) it will also display the documentation from GitHub.\n\nDocumentation examples:\n\n* https://plugins.jenkins.io/configuration-as-code using maven and README.md\n* https://plugins.jenkins.io/gradle using gradle and README.adoc\n*"
  },
  "1744": {
    "source_file": "documentation.txt",
    "text": "ples:\n\n* https://plugins.jenkins.io/configuration-as-code using maven and README.md\n* https://plugins.jenkins.io/gradle using gradle and README.adoc\n* https://plugins.jenkins.io/mailer using maven and README.adoc\n// Include this example after scm-api release 2.6.5 or later\n// * https://plugins.jenkins.io/scm-api using maven and a non-default adoc file\n\n[[valid-url-formats]]\nValid URL formats for G"
  },
  "1745": {
    "source_file": "documentation.txt",
    "text": " release 2.6.5 or later\n// * https://plugins.jenkins.io/scm-api using maven and a non-default adoc file\n\n[[valid-url-formats]]\nValid URL formats for GitHub based documentation are\n\nhttps&#58;//github.com/jenkinsci/YOUR-PLUGIN::\nLoads README located in the root of `YOUR-PLUGIN` repository from the master branch\nhttps&#58;//github.com/jenkinsci/YOUR-PLUGIN/tree/REF::\nLoads README located in the root"
  },
  "1746": {
    "source_file": "documentation.txt",
    "text": "n the root of `YOUR-PLUGIN` repository from the master branch\nhttps&#58;//github.com/jenkinsci/YOUR-PLUGIN/tree/REF::\nLoads README located in the root of `YOUR-PLUGIN` repository from the tag or branch `REF`\nhttps&#58;//github.com/jenkinsci/YOUR-PLUGIN/blob/REF/path/to/readme.md::\nLoads a Markdown or AsciiDoc file specified by path from `YOUR-PLUGIN` repository's tag or branch `REF`.\n\nIf you use g"
  },
  "1747": {
    "source_file": "documentation.txt",
    "text": "IN/blob/REF/path/to/readme.md::\nLoads a Markdown or AsciiDoc file specified by path from `YOUR-PLUGIN` repository's tag or branch `REF`.\n\nIf you use git tag for releases, you can make sure the plugin site loads a snapshot of your README relevant for the last release by setting the URL to e.g. `+https://github.com/jenkinsci/${project.artifactId}/tree/${project.artifactId}-${revision}+`.\n\n[[labeling"
  },
  "1748": {
    "source_file": "documentation.txt",
    "text": "the last release by setting the URL to e.g. `+https://github.com/jenkinsci/${project.artifactId}/tree/${project.artifactId}-${revision}+`.\n\n[[labeling-plugins]]\n\nPlugin labels are assigned to plugin repositories by their maintainers as .\nGitHub topics that match entries from the  are displayed on the https://plugins.jenkins.io[plugin site].\nDevelopers are encouraged to submit pull requests to the "
  },
  "1749": {
    "source_file": "documentation.txt",
    "text": "s that match entries from the  are displayed on the https://plugins.jenkins.io[plugin site].\nDevelopers are encouraged to submit pull requests to the  when they detect gaps in the list.\n\nPlugin maintainers are encouraged to apply GitHub topics to the plugins they maintain.\nTopics should be assigned to plugins when the plugin relationship to the label is well above average.\nFor example, the git plu"
  },
  "1750": {
    "source_file": "documentation.txt",
    "text": " plugins they maintain.\nTopics should be assigned to plugins when the plugin relationship to the label is well above average.\nFor example, the git plugin is labeled with `git` and `scm-connections` but is not labeled with `bitbucket`, `github`, `gitlab`, or `gitea`.\nAs another example, the configuration as code plugin allows configuration of many plugins but does not include labels for all the plu"
  },
  "1751": {
    "source_file": "documentation.txt",
    "text": "ab`, or `gitea`.\nAs another example, the configuration as code plugin allows configuration of many plugins but does not include labels for all the plugins it can configure.\n\nDevelopers should not apply labels that are so broad they lose value due to overuse.\nFor example, a plugin that adds a few Pipeline steps should generally not be labeled with `pipeline`.\nPlugins with the `pipeline` label shoul"
  },
  "1752": {
    "source_file": "documentation.txt",
    "text": "overuse.\nFor example, a plugin that adds a few Pipeline steps should generally not be labeled with `pipeline`.\nPlugins with the `pipeline` label should be significant contributors to the Jenkins Pipeline.\n\n// Need a section on categorizing plugins - how are plugin categories assigned?\n\n became read-only in November, 2019.\nRequests to plugin documentation pages on the wiki now redirect to the https"
  },
  "1753": {
    "source_file": "documentation.txt",
    "text": "how are plugin categories assigned?\n\n became read-only in November, 2019.\nRequests to plugin documentation pages on the wiki now redirect to the https://plugins.jenkins.io[plugins site].\nSee  for more information.\nIt also include Wiki=>GitHub migration guidelines.\n\nYou should link to your plugin's documentation, whether on the wiki or elsewhere, in your plugin's pom.xml, (using one of the ) like t"
  },
  "1754": {
    "source_file": "documentation.txt",
    "text": "on guidelines.\n\nYou should link to your plugin's documentation, whether on the wiki or elsewhere, in your plugin's pom.xml, (using one of the ) like this:\n\n```xml\n<project>\n  ...\n  <url>https://github.com/jenkinsci/your-plugin</url>\n  ...\n</project>\n```\n\nIf you're building your plugin with https://github.com/jenkinsci/gradle-jpi-plugin[Gradle],\nyou can set the URL in your `+build.gradle+` like so:"
  },
  "1755": {
    "source_file": "documentation.txt",
    "text": "```\n\nIf you're building your plugin with https://github.com/jenkinsci/gradle-jpi-plugin[Gradle],\nyou can set the URL in your `+build.gradle+` like so:\n\n```groovy\njenkinsPlugin {\n  // ...\n  url = 'https://github.com/jenkinsci/your-plugin'\n  // ...\n}\n```\n\nMaintainer information is listed for every plugin on the https://plugins.jenkins.io/[plugin site].\nThe maintainer metadata in https://github.com/j"
  },
  "1756": {
    "source_file": "documentation.txt",
    "text": "``\n\nMaintainer information is listed for every plugin on the https://plugins.jenkins.io/[plugin site].\nThe maintainer metadata in https://github.com/jenkins-infra/repository-permissions-updater[jenkins-infra/repository-permissions-updater] is the information source about _who_ is a maintainer (e.g. `kohsuke`), and information from https://issues.jenkins.io/[Jira] is used to show their actual name "
  },
  "1757": {
    "source_file": "documentation.txt",
    "text": "ormation source about _who_ is a maintainer (e.g. `kohsuke`), and information from https://issues.jenkins.io/[Jira] is used to show their actual name (e.g. `Kohsuke Kawaguchi`).\n\nMaintainer information in the Maven POM was used in the past, but is no longer used.\n\nOnce you have made your first release, you should add release notes to your plugin.\nYou have many options how to do it:\n\n* use GitHub R"
  },
  "1758": {
    "source_file": "documentation.txt",
    "text": " longer used.\n\nOnce you have made your first release, you should add release notes to your plugin.\nYou have many options how to do it:\n\n* use GitHub Releases (possibly with the help of\nhttps://github.com/jenkinsci/.github/blob/master/.github/release-drafter.adoc[Release Drafter]),\nadd a link to releases page to your documentation page\n(recommended)\n* create a CHANGELOG file (Markdown, Asciidoc) in"
  },
  "1759": {
    "source_file": "documentation.txt",
    "text": "drafter.adoc[Release Drafter]),\nadd a link to releases page to your documentation page\n(recommended)\n* create a CHANGELOG file (Markdown, Asciidoc) in the repository root and link it from the documentation page\n* include the changelog content in the documentation page\n\nFor open-source plugins it is important to have contributor guidelines to attract more contributors.\nGitHub offers standard ways t"
  },
  "1760": {
    "source_file": "documentation.txt",
    "text": "documentation page\n\nFor open-source plugins it is important to have contributor guidelines to attract more contributors.\nGitHub offers standard ways to define guidelines and to show them to contributors, including contributing guidelines, code of conduct, pull request templates, etc.\n\nSome notes:\n\n* `CONTRIBUTING` guidelines can be defined by plugin maintainers, we do not set a default guide at th"
  },
  "1761": {
    "source_file": "documentation.txt",
    "text": "duct, pull request templates, etc.\n\nSome notes:\n\n* `CONTRIBUTING` guidelines can be defined by plugin maintainers, we do not set a default guide at the moment.\n  See  for more information\n* Jenkins has a  which applies to all contributors and to all components hosted by the project.\n  It is defined for all repositories using the  repository,\n  plugin maintainers do not need to set it up.\n* Pull re"
  },
  "1762": {
    "source_file": "documentation.txt",
    "text": "components hosted by the project.\n  It is defined for all repositories using the  repository,\n  plugin maintainers do not need to set it up.\n* Pull request templates: see .\n\nPlugins that create their documentation in  may automatically generate a  for the documentation.\nThe generated table of contents includes level 2 and level 3 headings by default.\nThe table of contents is requested by assigning"
  },
  "1763": {
    "source_file": "documentation.txt",
    "text": "r the documentation.\nThe generated table of contents includes level 2 and level 3 headings by default.\nThe table of contents is requested by assigning the value `macro` to the `toc` variable and by inserting a reference to the `toc` variable at the location where the table of contents should be inserted in the page.\n\n```adoc\n\n[[Introduction]]\n\nSome introductory text that is placed before the table"
  },
  "1764": {
    "source_file": "documentation.txt",
    "text": "ocation where the table of contents should be inserted in the page.\n\n```adoc\n\n[[Introduction]]\n\nSome introductory text that is placed before the table of contents.\n\ntoc:[]\n\n[[other-heading]]\n\nText that describes more about the plugin and is placed after the table of contents.\n```\n\nSee the  as a table of contents example."
  },
  "1765": {
    "source_file": "documentation.txt",
    "text": "ter the table of contents.\n```\n\nSee the  as a table of contents example."
  },
  "1766": {
    "source_file": "embedded-container.txt",
    "text": "layout: developersection\nsummary: Why java -jar jenkins.war works\nreferences:\n- url: \"https://github.com/jenkinsci/winstone/\"\n  title: \"Winstone-Jetty on GitHub\"\nwip: true"
  },
  "1767": {
    "source_file": "enable-incrementals.txt",
    "text": "layout: developersection\ntitle: Enable incrementals\n\n\nJenkins evaluation of pull request builds is faster and easier when incremental builds are enabled.\nSee the jenkins.io  for more details.\n\n// Create the branch\n\nRun the Maven command to enable incrementals:\n\nmvn incrementals:incrementalify\n\n// Create a pull request"
  },
  "1768": {
    "source_file": "enable-incrementals.txt",
    "text": "rementals:\n\nmvn incrementals:incrementalify\n\n// Create a pull request"
  },
  "1769": {
    "source_file": "environment-variables.txt",
    "text": "layout: redirect\nredirect_url: \"/doc/book/security/environment-variables/\""
  },
  "1770": {
    "source_file": "environment.txt",
    "text": "layout: documentation\ntitle: Using environment variables\n\n\nEnvironment variables can be set globally, like the example below, or per\nstage. As you might expect, setting environment variables per stage means they\nwill only apply to the stage in which they're defined.\n\n[pipeline]\n\n// Declarative //\npipeline {\n    agent {\n        label '!windows'\n    }\n\n    environment {\n        DISABLE_AUTH = 'true'"
  },
  "1771": {
    "source_file": "environment.txt",
    "text": "they're defined.\n\n[pipeline]\n\n// Declarative //\npipeline {\n    agent {\n        label '!windows'\n    }\n\n    environment {\n        DISABLE_AUTH = 'true'\n        DB_ENGINE    = 'sqlite'\n    }\n\n    stages {\n        stage('Build') {\n            steps {\n                echo \"Database engine is ${DB_ENGINE}\"\n                echo \"DISABLE_AUTH is ${DISABLE_AUTH}\"\n                sh 'printenv'\n            "
  },
  "1772": {
    "source_file": "environment.txt",
    "text": "              echo \"Database engine is ${DB_ENGINE}\"\n                echo \"DISABLE_AUTH is ${DISABLE_AUTH}\"\n                sh 'printenv'\n            }\n        }\n    }\n}\n// Scripted //\nnode('!windows') {\n    withEnv(['DISABLE_AUTH=true',\n             'DB_ENGINE=sqlite']) {\n        stage('Build') {\n            echo \"Database engine is ${DB_ENGINE}\"\n            echo \"DISABLE_AUTH is ${DISABLE_AUTH}\""
  },
  "1773": {
    "source_file": "environment.txt",
    "text": " 'DB_ENGINE=sqlite']) {\n        stage('Build') {\n            echo \"Database engine is ${DB_ENGINE}\"\n            echo \"DISABLE_AUTH is ${DISABLE_AUTH}\"\n            sh 'printenv'\n        }\n    }\n}\n\nThis approach to defining environment variables from within the `Jenkinsfile`\ncan be very useful for instructing scripts, such as a `Makefile`, to configure\nthe build or tests differently to run them insi"
  },
  "1774": {
    "source_file": "environment.txt",
    "text": "ithin the `Jenkinsfile`\ncan be very useful for instructing scripts, such as a `Makefile`, to configure\nthe build or tests differently to run them inside of Jenkins.\n\nSee ** for more details on using environment variables in Pipelines.\n\nEnvironment variables may also be set by Jenkins plugins.\nRefer to the documentation of the specific plugins for environment variable names and descriptions for tho"
  },
  "1775": {
    "source_file": "environment.txt",
    "text": "riables may also be set by Jenkins plugins.\nRefer to the documentation of the specific plugins for environment variable names and descriptions for those plugins.\n\nAnother common use for environment variables is to set or override \"dummy\"\ncredentials in build or test scripts. Because it's (_obviously_) a bad idea to\nput credentials directly into a `Jenkinsfile`, Jenkins Pipeline allows users to qui"
  },
  "1776": {
    "source_file": "environment.txt",
    "text": "in build or test scripts. Because it's (_obviously_) a bad idea to\nput credentials directly into a `Jenkinsfile`, Jenkins Pipeline allows users to quickly\nand safely access pre-defined credentials in the `Jenkinsfile` without ever\nneeding to know their values.\n\nSee  in the  for more information.\n\n\n\n'''\n+++\n\n+++"
  },
  "1777": {
    "source_file": "environment.txt",
    "text": "ir values.\n\nSee  in the  for more information.\n\n\n\n'''\n+++\n\n+++"
  },
  "1778": {
    "source_file": "executor-starvation.txt",
    "text": "layout: section\ntitle: Executor Starvation\n\n\nIf you see a little black clock icon in the build queue as shown below,\nit is an indication that your job is sitting in the queue unnecessarily.\n\nThe tool tip of the job name link next to the clock icon should tell you\nexactly why it is not building, but the common symptoms are as follows:\n\n1.  **Agents are offline**: your build needs to run on a partic"
  },
  "1779": {
    "source_file": "executor-starvation.txt",
    "text": "ould tell you\nexactly why it is not building, but the common symptoms are as follows:\n\n1.  **Agents are offline**: your build needs to run on a particular\n    agent, but the agent is offline. Go to\n    http://server/jenkins/computer/AGENTNAME to understand why, and\n    bring it back online. Or better yet, use labels and do not tie\n    builds to specific agents, so that a single offline agents will"
  },
  "1780": {
    "source_file": "executor-starvation.txt",
    "text": "rstand why, and\n    bring it back online. Or better yet, use labels and do not tie\n    builds to specific agents, so that a single offline agents will not\n    prevent your builds from starving.\n2.  **Waiting for an available executor on an agent**: your build needs\n    to run on a particular agent, but the agent is already fully busy\n    building other things, and your build is waiting for \"too lo"
  },
  "1781": {
    "source_file": "executor-starvation.txt",
    "text": "our build needs\n    to run on a particular agent, but the agent is already fully busy\n    building other things, and your build is waiting for \"too long\"\n    compared to the time it takes to execute it \u2014 in other words, it\n    does not make sense to wait for 5 minutes when the build itself\n    finishes in 2 minutes. Use labels so that builds can run on any\n    machine that satisfies the system req"
  },
  "1782": {
    "source_file": "executor-starvation.txt",
    "text": "wait for 5 minutes when the build itself\n    finishes in 2 minutes. Use labels so that builds can run on any\n    machine that satisfies the system requirements, and in this way you\n    can add more agents to improve the turn-around time.\n3.  **Waiting for an available executor on a label**: all the agents\n    that have the given label are fully busy doing other things. It is\n    time to add more a"
  },
  "1783": {
    "source_file": "executor-starvation.txt",
    "text": "g for an available executor on a label**: all the agents\n    that have the given label are fully busy doing other things. It is\n    time to add more agents."
  },
  "1784": {
    "source_file": "exposing-bundled-resources.txt",
    "text": "title: Exposing bundled resources\nlayout: developer\n\n\nResource files bundled with Jenkins and plugins are by default exposed through several different mechanisms.\n\nJenkins exposes static resource files of allowed file types (`.js`, `.css`, `.jpeg`, `.jpg`, `.png`, `.gif`, `.html`, `.htm` as of Jenkins 2.290) in core and plugins at the `/resources/` URL.\nThis is implemented by jenkinsdoc:jenkins.mo"
  },
  "1785": {
    "source_file": "exposing-bundled-resources.txt",
    "text": ".jpg`, `.png`, `.gif`, `.html`, `.htm` as of Jenkins 2.290) in core and plugins at the `/resources/` URL.\nThis is implemented by jenkinsdoc:jenkins.model.Jenkins#doResources[`Jenkins#doResources`].\n\nIn views, the URL prefix to use is available as `app.VIEW_RESOURCE_PATH`.\nThe full path can be computed using jenkinsdoc:hudson.Functions#getViewResource-java.lang.Object-java.lang.String-[`h.getViewRe"
  },
  "1786": {
    "source_file": "exposing-bundled-resources.txt",
    "text": "p.VIEW_RESOURCE_PATH`.\nThe full path can be computed using jenkinsdoc:hudson.Functions#getViewResource-java.lang.Object-java.lang.String-[`h.getViewResource(...)`].\n`https://github.com/jenkinsci/jenkins/blob/master/core/src/main/resources/lib/layout/breadcrumb.gif` is exposed at, e.g., `https://ci.jenkins.io/resources/cachekey/lib/layout/breadcrumb.gif`.\n\nThe URL should not be hardcoded, as header"
  },
  "1787": {
    "source_file": "exposing-bundled-resources.txt",
    "text": "breadcrumb.gif` is exposed at, e.g., `https://ci.jenkins.io/resources/cachekey/lib/layout/breadcrumb.gif`.\n\nThe URL should not be hardcoded, as headers controlling caching are set; and the computed cache key will result in different Jenkins versions having a different prefix.\n\nThese resources are available to users with _Overall/Read_ permissions.\n\nThe Stapler web framework provides a mechanism ca"
  },
  "1788": {
    "source_file": "exposing-bundled-resources.txt",
    "text": "having a different prefix.\n\nThese resources are available to users with _Overall/Read_ permissions.\n\nThe Stapler web framework provides a mechanism called _adjuncts_ that is intended to be used to include CSS and JS files related to a view being rendered.\nUsing this mechanism ensures that each adjunct file is only included once.\nThrough the same URL space, some static resource files like images ar"
  },
  "1789": {
    "source_file": "exposing-bundled-resources.txt",
    "text": "ered.\nUsing this mechanism ensures that each adjunct file is only included once.\nThrough the same URL space, some static resource files like images are accessible.\nSee staplerdoc:org.kohsuke.stapler.framework.adjunct.AdjunctManager#allowResourceToBeServed[`AdjunctManager#allowResourceToBeServed`] for supported file types (`.css`, `.js`, `.gif`, `.png` as of Jenkins 2.290).\nThese resources are typi"
  },
  "1790": {
    "source_file": "exposing-bundled-resources.txt",
    "text": "erved[`AdjunctManager#allowResourceToBeServed`] for supported file types (`.css`, `.js`, `.gif`, `.png` as of Jenkins 2.290).\nThese resources are typically exposed through the `st:adjunct` tag in Jelly or Groovy views, but the URLs are predictable:\n`https://github.com/jenkinsci/jenkins/blob/master/core/src/main/resources/lib/layout/breadcrumb.gif` is exposed at, e.g., `https://ci.jenkins.io/adjunc"
  },
  "1791": {
    "source_file": "exposing-bundled-resources.txt",
    "text": "https://github.com/jenkinsci/jenkins/blob/master/core/src/main/resources/lib/layout/breadcrumb.gif` is exposed at, e.g., `https://ci.jenkins.io/adjuncts/cachekey/lib/layout/breadcrumb.gif`.\n\nThe URL should not be hardcoded, as headers controlling caching are set; and the computed cache key will result in different Jenkins versions having a different prefix.\n\nThese resources are available to any us"
  },
  "1792": {
    "source_file": "exposing-bundled-resources.txt",
    "text": "hing are set; and the computed cache key will result in different Jenkins versions having a different prefix.\n\nThese resources are available to any user without authentication, not requiring _Overall/Read_ permission.\n\n`Messages_??.properties` (including `Messages.properties`) files contain localized message strings.\n\nFor the classic Jenkins UI, they are generally used directly as described in .\n\n"
  },
  "1793": {
    "source_file": "exposing-bundled-resources.txt",
    "text": "ding `Messages.properties`) files contain localized message strings.\n\nFor the classic Jenkins UI, they are generally used directly as described in .\n\nAdditionally for modern web UIs, localized resources are exposed at `/i18n/resourceBundle/`, at URLs like `https://ci.jenkins.io/i18n/resourceBundle?baseName=hudson.Messages`.\nSee jenkinsdoc:jenkins.I18n[I18n] for details.\n\nThese resources are availa"
  },
  "1794": {
    "source_file": "exposing-bundled-resources.txt",
    "text": " like `https://ci.jenkins.io/i18n/resourceBundle?baseName=hudson.Messages`.\nSee jenkinsdoc:jenkins.I18n[I18n] for details.\n\nThese resources are available to users with _Overall/Read_ permissions.\n\n`Descriptor#doHelp` will serve corresponding `help.jelly` views, if they exist, and lets Stapler localize them (i.e. uses `help_??.jelly` with locale suffix, if it exists).\n\nAn example of such a Stapler "
  },
  "1795": {
    "source_file": "exposing-bundled-resources.txt",
    "text": "lly` views, if they exist, and lets Stapler localize them (i.e. uses `help_??.jelly` with locale suffix, if it exists).\n\nAn example of such a Stapler view is `https://github.com/jenkinsci/jenkins/blob/master/core/src/main/resources/hudson/tasks/Maven/help.jelly` available at `https://ci.jenkins.io/descriptor/hudson.tasks.Maven/help`.\n\nThese are usually used by the automatically determined help URL"
  },
  "1796": {
    "source_file": "exposing-bundled-resources.txt",
    "text": "/help.jelly` available at `https://ci.jenkins.io/descriptor/hudson.tasks.Maven/help`.\n\nThese are usually used by the automatically determined help URL corresponding to the descriptor (and optionally form field name), and a help link will be shown on the UI if this file exists.\n\nThese help views are available to users with _Overall/Read_ permissions.\n\n`Descriptor#doHelp` looks up `com/acme/package/"
  },
  "1797": {
    "source_file": "exposing-bundled-resources.txt",
    "text": "the UI if this file exists.\n\nThese help views are available to users with _Overall/Read_ permissions.\n\n`Descriptor#doHelp` looks up `com/acme/package/MyDescribable/help-fieldname_??.html` HTML files and serves them at `/descriptor/myDescriptorSymbol/help/fieldname`, typically corresponding to specific fields in views. It also supports com/acme/package/MyDescribable/help_??.html at `/descriptor/myD"
  },
  "1798": {
    "source_file": "exposing-bundled-resources.txt",
    "text": "help/fieldname`, typically corresponding to specific fields in views. It also supports com/acme/package/MyDescribable/help_??.html at `/descriptor/myDescriptorSymbol/help`.\n\nAn example of such an HTML file is `https://github.com/jenkinsci/jenkins/blob/master/core/src/main/resources/hudson/tasks/Shell/help.html`, which is exposed at `https://ci.jenkins.io/descriptor/hudson.tasks.Shell/help`.\n\nThese"
  },
  "1799": {
    "source_file": "exposing-bundled-resources.txt",
    "text": "b/master/core/src/main/resources/hudson/tasks/Shell/help.html`, which is exposed at `https://ci.jenkins.io/descriptor/hudson.tasks.Shell/help`.\n\nThese are usually used by the automatically determined help URL corresponding to the descriptor (and optionally form field name), and a help link will be shown on the UI if this file exists.\n\nThese help files are available to users with _Overall/Read_ per"
  },
  "1800": {
    "source_file": "exposing-bundled-resources.txt",
    "text": "onally form field name), and a help link will be shown on the UI if this file exists.\n\nThese help files are available to users with _Overall/Read_ permissions.\n\nJenkins core `webapp/` resources are exposed at their expected path relative to the context root directory.\nExample: https://github.com/jenkinsci/jenkins/blob/master/war/src/main/webapp/robots.txt is exposed at https://ci.jenkins.io/robots"
  },
  "1801": {
    "source_file": "exposing-bundled-resources.txt",
    "text": "xt root directory.\nExample: https://github.com/jenkinsci/jenkins/blob/master/war/src/main/webapp/robots.txt is exposed at https://ci.jenkins.io/robots.txt\n\nThis is implemented by `Stapler#service` invoking `#openResourcePathByLocale`.\nThis in turn ends up invoking `LocaleDrivenResourceProvider#lookupResource`, an SPI implemented in Jenkins core as `MetaLocaleDrivenResourceProvider` from 2.173.\nThi"
  },
  "1802": {
    "source_file": "exposing-bundled-resources.txt",
    "text": "ds up invoking `LocaleDrivenResourceProvider#lookupResource`, an SPI implemented in Jenkins core as `MetaLocaleDrivenResourceProvider` from 2.173.\nThis in turn looks up implementations of `PluginLocaleDrivenResourceProvider` in plugins.\nplugin:localization-support[Localization Support Plugin] provides `PluginLocaleDrivenResourceProviderImpl`.\n\nThese resources are available to any user without auth"
  },
  "1803": {
    "source_file": "exposing-bundled-resources.txt",
    "text": "zation-support[Localization Support Plugin] provides `PluginLocaleDrivenResourceProviderImpl`.\n\nThese resources are available to any user without authentication, not requiring _Overall/Read_ permission.\n\nPlugins expose `src/main/webapp/` resource files directly packaged into the `jpi` file via `Plugin#doDynamic` at `/plugin/namehere/` invoking `StaplerResponse#serveLocalizedFile`.\nThis calls `#sel"
  },
  "1804": {
    "source_file": "exposing-bundled-resources.txt",
    "text": "es directly packaged into the `jpi` file via `Plugin#doDynamic` at `/plugin/namehere/` invoking `StaplerResponse#serveLocalizedFile`.\nThis calls `#selectResourceByLocale` which ends up invoking `LocaleDrivenResourceProvider#lookupResource`.\nSee the section on core webapp resources for further details.\n\nThese resources are available to users with _Overall/Read_ permissions.\n\nJenkins core exposes _a"
  },
  "1805": {
    "source_file": "exposing-bundled-resources.txt",
    "text": "ection on core webapp resources for further details.\n\nThese resources are available to users with _Overall/Read_ permissions.\n\nJenkins core exposes _assets_ (any static resource files visible to the Jenkins core classloader with the `asset/` package prefix) at the `/assets/` URL.\nThis is implemented by the jenkinsdoc:AssetManager[`AssetManager`] class.\n\nThese resources are available to any user wi"
  },
  "1806": {
    "source_file": "exposing-bundled-resources.txt",
    "text": "prefix) at the `/assets/` URL.\nThis is implemented by the jenkinsdoc:AssetManager[`AssetManager`] class.\n\nThese resources are available to any user without authentication, not requiring _Overall/Read_ permission.\n\nThis was used from Jenkins 2.0 to 2.288 (inclusive) to serve JavaScript assets (jQuery, Handlebars, etc.).\nThe infrastructure remains in place after 2.288.\n\nNOTE: Assets from plugins are"
  },
  "1807": {
    "source_file": "exposing-bundled-resources.txt",
    "text": "288 (inclusive) to serve JavaScript assets (jQuery, Handlebars, etc.).\nThe infrastructure remains in place after 2.288.\n\nNOTE: Assets from plugins are served by reusing the plugin webapp resources serving feature `Plugin#doDynamic`."
  },
  "1808": {
    "source_file": "extend.txt",
    "text": "layout: developer\ntitle: Extend the Plugin\n\n\n-\n-\n-\n-\n\nNOTE: While possible to follow with a plain text editor, this section is much easier to follow along by using a Java IDE with Maven support.\n// TODO tools references\n\nIt's time to extend the sample plugin with new features:\n\n* Record the name used in the greeting not just in the build log, but a proper data structure.\n* Add a new page to the bu"
  },
  "1809": {
    "source_file": "extend.txt",
    "text": "e plugin with new features:\n\n* Record the name used in the greeting not just in the build log, but a proper data structure.\n* Add a new page to the build that shows the name used in the greeting.\n\nIt is important that we store the name that was used when the build was run, rather than use the one in the configuration, as the configuration may change.\n\nFirst, create a class called `HelloWorldAction"
  },
  "1810": {
    "source_file": "extend.txt",
    "text": "when the build was run, rather than use the one in the configuration, as the configuration may change.\n\nFirst, create a class called `HelloWorldAction` in the same package as `HelloWorldBuilder`. That class needs to implement jenkinsdoc:Action[]. _Actions_ are a basic building block for extensibility in Jenkins: They can be attached to many model objects, get stored with them, and optionally add t"
  },
  "1811": {
    "source_file": "extend.txt",
    "text": "tions_ are a basic building block for extensibility in Jenkins: They can be attached to many model objects, get stored with them, and optionally add to their UI.\n\npackage io.jenkins.plugins.sample;\n\nimport hudson.model.Action;\n\npublic class HelloWorldAction implements Action {\n\n    @Override\n    public String getIconFileName() {\n        return null;\n    }\n\n    @Override\n    public String getDispla"
  },
  "1812": {
    "source_file": "extend.txt",
    "text": "dAction implements Action {\n\n    @Override\n    public String getIconFileName() {\n        return null;\n    }\n\n    @Override\n    public String getDisplayName() {\n        return null;\n    }\n\n    @Override\n    public String getUrlName() {\n        return null;\n    }\n}\n\nSince we want to store the name used in the greeting, we'll need to add a field with getter to this class. We'll also add a constructor"
  },
  "1813": {
    "source_file": "extend.txt",
    "text": "null;\n    }\n}\n\nSince we want to store the name used in the greeting, we'll need to add a field with getter to this class. We'll also add a constructor that takes the name as argument.\n\n(...)\n\npublic class HelloWorldAction implements Action {\n\n    private String name;\n\n    public HelloWorldAction(String name) {\n        this.name = name;\n    }\n\n    public String getName() {\n        return name;\n    "
  },
  "1814": {
    "source_file": "extend.txt",
    "text": "vate String name;\n\n    public HelloWorldAction(String name) {\n        this.name = name;\n    }\n\n    public String getName() {\n        return name;\n    }\n\n    (...)\n\nNow, we actually need to create an instance of this class when the build step is executed. We need to extend the `perform` method in the `HelloWorldBuilder` class to add an instance of the action we created to the build that's being run"
  },
  "1815": {
    "source_file": "extend.txt",
    "text": "ted. We need to extend the `perform` method in the `HelloWorldBuilder` class to add an instance of the action we created to the build that's being run:\n\n(...)\n    @Override\n    public void perform(Run<?, ?> run, FilePath workspace, Launcher launcher, TaskListener listener) throws InterruptedException, IOException {\n        run.addAction(new HelloWorldAction(name)); // <1> if (useFrench) {\n        "
  },
  "1816": {
    "source_file": "extend.txt",
    "text": " TaskListener listener) throws InterruptedException, IOException {\n        run.addAction(new HelloWorldAction(name)); // <1> if (useFrench) {\n            listener.getLogger().println(\"Bonjour, \" + name + \"!\");\n        } else {\n            listener.getLogger().println(\"Hello, \" + name + \"!\");\n        }\n    }\n(...)\n\n<1> This is the line that was added, everything else can remain as is.\n\nSave these c"
  },
  "1817": {
    "source_file": "extend.txt",
    "text": "tLogger().println(\"Hello, \" + name + \"!\");\n        }\n    }\n(...)\n\n<1> This is the line that was added, everything else can remain as is.\n\nSave these changes, and run the plugin again using `mvn hpi:run`.\n\nNOTE: Whenever changing the Java source code or adding or removing resource files, you will need to restart the Jenkins controller for the changes to take effect. Only some resource files can be "
  },
  "1818": {
    "source_file": "extend.txt",
    "text": "or adding or removing resource files, you will need to restart the Jenkins controller for the changes to take effect. Only some resource files can be edited while Jenkins is running via `hpi:run`.\n\nNow, when running a build with this build step, the action will be added to the build data. We can confirm this by looking at the `build.xml` file corresponding to the build in the `work/jobs/_JOBNAME_/"
  },
  "1819": {
    "source_file": "extend.txt",
    "text": "action will be added to the build data. We can confirm this by looking at the `build.xml` file corresponding to the build in the `work/jobs/_JOBNAME_/builds/_BUILDNUMBER_/` directory.\n\nAs we can see, there are two actions in this build:\n\n<build>\n  <actions>\n    <hudson.model.CauseAction> // <1> <causes>\n        <hudson.model.Cause_-UserIdCause/>\n      </causes>\n    </hudson.model.CauseAction>\n    "
  },
  "1820": {
    "source_file": "extend.txt",
    "text": "ctions>\n    <hudson.model.CauseAction> // <1> <causes>\n        <hudson.model.Cause_-UserIdCause/>\n      </causes>\n    </hudson.model.CauseAction>\n    <io.jenkins.plugins.sample.HelloWorldAction plugin=\"demo@1.0-SNAPSHOT\"> // <2> <name>Jenkins</name> // <3> </io.jenkins.plugins.sample.HelloWorldAction>\n  </actions>\n  (...)\n</build>\n\n<1> Build causes (how the build was triggered) are also stored as "
  },
  "1821": {
    "source_file": "extend.txt",
    "text": "// <3> </io.jenkins.plugins.sample.HelloWorldAction>\n  </actions>\n  (...)\n</build>\n\n<1> Build causes (how the build was triggered) are also stored as actions. In this case, the anonymous user started the build.\n<2> This is the action we created,\n<3> and this is the name that was used when the build was created.\n\nNext, we need to make the action we're storing with the build visible.\n\nFirst, we need"
  },
  "1822": {
    "source_file": "extend.txt",
    "text": "and this is the name that was used when the build was created.\n\nNext, we need to make the action we're storing with the build visible.\n\nFirst, we need to go back to the `HelloWorldAction` and define an icon, title, and URL name:\n\n    @Override\n    public String getIconFileName() {\n        return \"document.png\"; // <1> }\n\n    @Override\n    public String getDisplayName() {\n        return \"Greeting\";"
  },
  "1823": {
    "source_file": "extend.txt",
    "text": "blic String getIconFileName() {\n        return \"document.png\"; // <1> }\n\n    @Override\n    public String getDisplayName() {\n        return \"Greeting\"; // <2> }\n\n    @Override\n    public String getUrlName() {\n        return \"greeting\"; // <3> }\n\n<1> This is the icon used for the side panel item. `document.png` is one of the predefined icons bundled with Jenkins.\n<2> This is the label used for the s"
  },
  "1824": {
    "source_file": "extend.txt",
    "text": "his is the icon used for the side panel item. `document.png` is one of the predefined icons bundled with Jenkins.\n<2> This is the label used for the side panel item.\n<3> This is the URL fragment used for this action.\n\nWith these changes, the action will show in the build's side panel, and link to the URL `http://_JENKINS_/job/_JOBNAME_/_BUILDNUMBER_/greeting/`.\n\nNext, the page appearing at that UR"
  },
  "1825": {
    "source_file": "extend.txt",
    "text": "ill show in the build's side panel, and link to the URL `http://_JENKINS_/job/_JOBNAME_/_BUILDNUMBER_/greeting/`.\n\nNext, the page appearing at that URL needs to be defined.\nTo create such _views_ in Jenkins,  is typically used.\nJelly allows defining XML and XHTML output in XML.\nIt has many features useful for this purpose: It:\n\n* supports conditions and loops\n* allows inclusion of _view fragments_"
  },
  "1826": {
    "source_file": "extend.txt",
    "text": "XML and XHTML output in XML.\nIt has many features useful for this purpose: It:\n\n* supports conditions and loops\n* allows inclusion of _view fragments_ defined elsewhere\n* can be used to define reusable UI components\n\nIn the directory `src/main/resources/io/jenkins/plugins/sample/`, we need to create a new directory called `HelloWorldAction/`.\nThis directory corresponds to the `HelloWorldAction` cl"
  },
  "1827": {
    "source_file": "extend.txt",
    "text": "ces/io/jenkins/plugins/sample/`, we need to create a new directory called `HelloWorldAction/`.\nThis directory corresponds to the `HelloWorldAction` class and contains related resources.\n\nNOTE: This is a directory in `src/main/resources`, not `src/main/java`.\n\nNOTE: We can see that resources related to the build step `HelloWorldBuilder` are stored in the `src/main/resources/io/jenkins/plugins/sampl"
  },
  "1828": {
    "source_file": "extend.txt",
    "text": "n/java`.\n\nNOTE: We can see that resources related to the build step `HelloWorldBuilder` are stored in the `src/main/resources/io/jenkins/plugins/sample/HelloWorldBuilder/` directory:\n`config.jelly` is the build step configuration form,\nthe various `config*.properties` files contain the localizations for the build step configuration\nand the `help*.html` files provide the localized inline help for t"
  },
  "1829": {
    "source_file": "extend.txt",
    "text": "onfig*.properties` files contain the localizations for the build step configuration\nand the `help*.html` files provide the localized inline help for the configuration.\n\nCreate a file named `index.jelly` in `src/main/resources/io/jenkins/plugins/sample/HelloWorldAction/`.\nThis will be what gets shown at the `http://_JENKINS_/job/_JOBNAME_/_BUILDNUMBER_/greeting/` URL.\nAdd the following content:\n\n<?"
  },
  "1830": {
    "source_file": "extend.txt",
    "text": "e/HelloWorldAction/`.\nThis will be what gets shown at the `http://_JENKINS_/job/_JOBNAME_/_BUILDNUMBER_/greeting/` URL.\nAdd the following content:\n\n<?jelly escape-by-default='true'?>\n<j:jelly xmlns:j=\"jelly:core\" xmlns:l=\"/lib/layout\" xmlns:st=\"jelly:stapler\">\n    <l:layout title=\"Greeting\"> // <1> <l:main-panel> // <2> <h1> // <3> Name: ${it.name} // <4> </h1>\n        </l:main-panel>\n    </l:layo"
  },
  "1831": {
    "source_file": "extend.txt",
    "text": ":stapler\">\n    <l:layout title=\"Greeting\"> // <1> <l:main-panel> // <2> <h1> // <3> Name: ${it.name} // <4> </h1>\n        </l:main-panel>\n    </l:layout>\n</j:jelly>\n\n<1> `layout` is a reusable _tag_ defined in Jenkins core that provides the basic page layout with header, side panel, main content area, and footer.\n<2> To make the name show up in the main content area (rather than e.g. the side pane"
  },
  "1832": {
    "source_file": "extend.txt",
    "text": "e layout with header, side panel, main content area, and footer.\n<2> To make the name show up in the main content area (rather than e.g. the side panel), we need to wrap our output in a `main-panel` tag.\n<3> We can use any HTML tags and they will be used for the output.\n<4> This is a https://commons.apache.org/proper/commons-jexl/[JEXL] expression. `it` refers to the Java object the view belongs t"
  },
  "1833": {
    "source_file": "extend.txt",
    "text": "used for the output.\n<4> This is a https://commons.apache.org/proper/commons-jexl/[JEXL] expression. `it` refers to the Java object the view belongs to (similar to `this` in Java), in this case the `HelloWorldAction` instance. `it.name` is equivalent to a getter call (`getName()`).\n\nThe resulting page will look similar to this:\n\nIn the output above, there is no side panel. As this view is related "
  },
  "1834": {
    "source_file": "extend.txt",
    "text": " to a getter call (`getName()`).\n\nThe resulting page will look similar to this:\n\nIn the output above, there is no side panel. As this view is related to a specific build, that build's side panel should be shown as well. To do that, we first need to obtain a reference to the corresponding build in our action, and then include the build's side panel view _fragment_ in the action's view.\n\nTo obtain a"
  },
  "1835": {
    "source_file": "extend.txt",
    "text": "btain a reference to the corresponding build in our action, and then include the build's side panel view _fragment_ in the action's view.\n\nTo obtain a reference to the build (or, more generally, the `jenkinsdoc:Run[]`) the `HelloWorldAction` belongs to, we need to change the existing class to make it implement `jenkinsdoc:RunAction2[]`.\nThis interface adds two methods that are called when the run "
  },
  "1836": {
    "source_file": "extend.txt",
    "text": "to, we need to change the existing class to make it implement `jenkinsdoc:RunAction2[]`.\nThis interface adds two methods that are called when the run is first attached to a build (`onAttached(Run)`), and when the action and run are loaded from disk (`onLoad(Run)`), respectively.\n\n(...)\nimport hudson.model.Run;\nimport jenkins.model.RunAction2;\n\npublic class HelloWorldAction implements RunAction2 { "
  },
  "1837": {
    "source_file": "extend.txt",
    "text": "`onLoad(Run)`), respectively.\n\n(...)\nimport hudson.model.Run;\nimport jenkins.model.RunAction2;\n\npublic class HelloWorldAction implements RunAction2 { // <1> private transient Run run; // <2> @Override\n    public void onAttached(Run<?, ?> run) {\n        this.run = run; // <3> }\n\n    @Override\n    public void onLoad(Run<?, ?> run) {\n        this.run = run; // <4> }\n\n    public Run getRun() { // <5> "
  },
  "1838": {
    "source_file": "extend.txt",
    "text": "   this.run = run; // <3> }\n\n    @Override\n    public void onLoad(Run<?, ?> run) {\n        this.run = run; // <4> }\n\n    public Run getRun() { // <5> return run;\n    }\n(...)\n\n<1> `RunAction2` is the interface to implement so that actions added to `jenkinsdoc:Run[]` properly get references to the `Run`.\n<2> The `Run` is stored in a transient action so this field won't be serialized to disk with the"
  },
  "1839": {
    "source_file": "extend.txt",
    "text": "nkinsdoc:Run[]` properly get references to the `Run`.\n<2> The `Run` is stored in a transient action so this field won't be serialized to disk with the action.\n<3> Setting the field when first attaching this action to the `Run`.\n<4> Setting the field when loading this action from disk.\n<5> This will make the `Run` available for use in the Jelly view -- it cannot access private fields.\n\nOnce this is"
  },
  "1840": {
    "source_file": "extend.txt",
    "text": "when loading this action from disk.\n<5> This will make the `Run` available for use in the Jelly view -- it cannot access private fields.\n\nOnce this is done, we need to extend the view to _include_ the side panel view fragment of the `Run`:\n\n(...)\n    <l:layout title=\"Greeting\">\n        <l:side-panel> // <1> <st:include page=\"sidepanel.jelly\" it=\"${it.run}\" optional=\"true\" /> // <2> </l:side-panel>"
  },
  "1841": {
    "source_file": "extend.txt",
    "text": " <l:layout title=\"Greeting\">\n        <l:side-panel> // <1> <st:include page=\"sidepanel.jelly\" it=\"${it.run}\" optional=\"true\" /> // <2> </l:side-panel>\n        <l:main-panel>\n          (...)\n        </l:main-panel>\n    </l:layout>\n(...)\n\n<1> Similar to `main-panel`, we want the contents to show up only in the side panel, so we need to wrap them in this element.\n<2> This _includes_ a view fragment ("
  },
  "1842": {
    "source_file": "extend.txt",
    "text": "o `main-panel`, we want the contents to show up only in the side panel, so we need to wrap them in this element.\n<2> This _includes_ a view fragment (`sidepanel.jelly`) of another object (the `Run`) at this location. We mark this as optional so no error is shown if this view fragment doesn't exist, as the abstract class `Run` does not define such a view, only its subclass `jenkinsdoc:AbstractBuild"
  },
  "1843": {
    "source_file": "extend.txt",
    "text": "ror is shown if this view fragment doesn't exist, as the abstract class `Run` does not define such a view, only its subclass `jenkinsdoc:AbstractBuild[]`.\n\nWith these changes, the view we created properly integrates with the Jenkins UI, appearing no different from built-in pages related to a build:\n\nCongratulations, you've successfully created and substantially extended a Jenkins plugin!\n\nNOTE: An"
  },
  "1844": {
    "source_file": "extend.txt",
    "text": "different from built-in pages related to a build:\n\nCongratulations, you've successfully created and substantially extended a Jenkins plugin!\n\nNOTE: Anything not working for you? Ask for help in  or ."
  },
  "1845": {
    "source_file": "extensions.txt",
    "text": "title: Extensions\nlayout: developer\nwip: true\n\n\nJenkins defines extension points, which are interfaces or abstract classes that model an aspect of its behavior.\nThe interface or class defines contracts of what needs implementation, and Jenkins allows plugins to contribute those implementations.\n\nTo register an implementation, make sure you mark it with `@Extension`.\n\n is a useful list of the exten"
  },
  "1846": {
    "source_file": "extensions.txt",
    "text": " plugins to contribute those implementations.\n\nTo register an implementation, make sure you mark it with `@Extension`.\n\n is a useful list of the extension points used in Jenkins and Jenkins plugins.\n\nMore information can be found in the ."
  },
  "1847": {
    "source_file": "feedback-form.txt",
    "text": "layout: documentation\ntitle: Jenkins User Documentation\nsection: doc\n\n\n+++\n<!-- Feedback form functionality in JavaScript - refer to comments in this file\n     for details on the functionality. -->\n<script>\nvar feedbackForm = {\n    formKey : 'e/1FAIpQLSfewAhW-679vSTEaIHYi3K8MV3jmoYg2sXEhjMn1Q-Cg4tnRg'\n};\n$(document).ready(function() {\n    window.onload = feedbackForm.start(document.referrer);\n});\n"
  },
  "1848": {
    "source_file": "feedback-form.txt",
    "text": "QLSfewAhW-679vSTEaIHYi3K8MV3jmoYg2sXEhjMn1Q-Cg4tnRg'\n};\n$(document).ready(function() {\n    window.onload = feedbackForm.start(document.referrer);\n});\n</script>\n<script src=\"/js/feedback-form-functionality.js\"></script>\n\n<!-- This CSS sets the size of textareas (allowing them to be fully resizable)\n     and widens the width of the email field. -->\n<style>\n  textarea {\n    width: 300px;\n    height: "
  },
  "1849": {
    "source_file": "feedback-form.txt",
    "text": " textareas (allowing them to be fully resizable)\n     and widens the width of the email field. -->\n<style>\n  textarea {\n    width: 300px;\n    height: 150px;\n    resize: both;\n  }\n  #email {\n    width: 300px;\n  }\n  span {\n    color: red;\n    font-weight: bold;\n  }\n</style>\n\n<p/>\n\n<h2>Page and Content Feedback</h2>\n\n<p/>\n\n<p>The Jenkins Community greatly appreciates your feedback on the Jenkins User"
  },
  "1850": {
    "source_file": "feedback-form.txt",
    "text": "ht: bold;\n  }\n</style>\n\n<p/>\n\n<h2>Page and Content Feedback</h2>\n\n<p/>\n\n<p>The Jenkins Community greatly appreciates your feedback on the Jenkins User\nDocumentation.<br/>\nThis form only takes a few moments to complete.</p>\n\n<p>Questions/fields marked <span>*</span> are <em>required</em>.</p>\n\n<!-- Redirects to custom \"thank you\" page once form is submitted. -->\n<script type=\"text/javascript\">\nvar "
  },
  "1851": {
    "source_file": "feedback-form.txt",
    "text": " <span>*</span> are <em>required</em>.</p>\n\n<!-- Redirects to custom \"thank you\" page once form is submitted. -->\n<script type=\"text/javascript\">\nvar submitted=false;\n</script>\n<iframe name=\"hidden_iframe\" id=\"hidden_iframe\" style=\"display:none;\"\nonload=\"if(submitted) {window.location='/doc/thank-you-for-your-feedback/';}\">\n</iframe>\n<form action=\"https://docs.google.com/forms/d/e/1FAIpQLSfewAhW-6"
  },
  "1852": {
    "source_file": "feedback-form.txt",
    "text": "oad=\"if(submitted) {window.location='/doc/thank-you-for-your-feedback/';}\">\n</iframe>\n<form action=\"https://docs.google.com/forms/d/e/1FAIpQLSfewAhW-679vSTEaIHYi3K8MV3jmoYg2sXEhjMn1Q-Cg4tnRg/formResponse\" method=\"POST\" id=\"ss-form\" target=\"hidden_iframe\" onsubmit=\"submitted=true;\">\n\n<!-- Set the value of the referrer URL into the form. -->\n<input type=\"hidden\" name=\"entry.322173973\" id=\"current-ur"
  },
  "1853": {
    "source_file": "feedback-form.txt",
    "text": "ame\" onsubmit=\"submitted=true;\">\n\n<!-- Set the value of the referrer URL into the form. -->\n<input type=\"hidden\" name=\"entry.322173973\" id=\"current-url\" value=\"\"/>\n\n<!-- Next question -->\n\n<p><strong>Overall, how helpful was the page you were viewing?</strong>\n<span>*</span></p>\n\n<p><input type=\"radio\" name=\"entry.640207764\" id=\"h1\" value=\"Very helpful\" required/>\n<label for=\"h1\">Very helpful</lab"
  },
  "1854": {
    "source_file": "feedback-form.txt",
    "text": "?</strong>\n<span>*</span></p>\n\n<p><input type=\"radio\" name=\"entry.640207764\" id=\"h1\" value=\"Very helpful\" required/>\n<label for=\"h1\">Very helpful</label></p>\n<p><input type=\"radio\" name=\"entry.640207764\" id=\"h2\" value=\"Moderately helpful\"/>\n<label for=\"h2\">Moderately helpful</label></p>\n<p><input type=\"radio\" name=\"entry.640207764\" id=\"h3\" value=\"Neutral\"/>\n<label for=\"h3\">Neutral</label></p>\n<p><"
  },
  "1855": {
    "source_file": "feedback-form.txt",
    "text": "r=\"h2\">Moderately helpful</label></p>\n<p><input type=\"radio\" name=\"entry.640207764\" id=\"h3\" value=\"Neutral\"/>\n<label for=\"h3\">Neutral</label></p>\n<p><input type=\"radio\" name=\"entry.640207764\" id=\"h4\" value=\"Not that helpful\"/>\n<label for=\"h4\">Not that helpful</label></p>\n<p><input type=\"radio\" name=\"entry.640207764\" id=\"h5\" value=\"Unhelpful\"/>\n<label for=\"h4\">Unhelpful</label></p>\n\n<!-- Next quest"
  },
  "1856": {
    "source_file": "feedback-form.txt",
    "text": "t helpful</label></p>\n<p><input type=\"radio\" name=\"entry.640207764\" id=\"h5\" value=\"Unhelpful\"/>\n<label for=\"h4\">Unhelpful</label></p>\n\n<!-- Next question -->\n\n<p><label for=\"page-improvements\"><strong>What suggestions do you have to\nimprove this page?</strong> <span>*</span><br/>\n(If you answered \"Very helpful\" above, feel free to write \"None\" to indicate no\nfurther feedback.)</label><br/>\n<textar"
  },
  "1857": {
    "source_file": "feedback-form.txt",
    "text": "?</strong> <span>*</span><br/>\n(If you answered \"Very helpful\" above, feel free to write \"None\" to indicate no\nfurther feedback.)</label><br/>\n<textarea name=\"entry.1588294104\" id=\"page-improvements\" required/></textarea></p>\n\n<!-- Next question -->\n\n<p><label for=\"other-area-improvements\"><strong>Are there any other aspects of\nthe Jenkins User Documentation that you'd like to see improved?</stron"
  },
  "1858": {
    "source_file": "feedback-form.txt",
    "text": "\n<p><label for=\"other-area-improvements\"><strong>Are there any other aspects of\nthe Jenkins User Documentation that you'd like to see improved?</strong><br/>\n(Please be as specific as possible.)</label><br/>\n<textarea name=\"entry.1858374341\" id=\"other-area-improvements\"/></textarea></p>\n\n<!-- The CAPTCHA bit -->\n\n<p><label id=\"ssTestLabel\" for=\"ssTestValue\"></label> <span>*</span><br/>\n<input type"
  },
  "1859": {
    "source_file": "feedback-form.txt",
    "text": "r-area-improvements\"/></textarea></p>\n\n<!-- The CAPTCHA bit -->\n\n<p><label id=\"ssTestLabel\" for=\"ssTestValue\"></label> <span>*</span><br/>\n<input type=\"text\" name=\"ssTestValue\" value=\"\" id=\"ssTestValue\"/></p>\n\n<!-- Submit button -->\n\n<p><input class=\"button\" type=\"submit\" value=\"Submit\"/></p>\n\n<p>See existing feedback <a href=\"https://docs.google.com/spreadsheets/d/1nA8xVOkyKmZ8oTYSLdwjborT0w-BpBN"
  },
  "1860": {
    "source_file": "feedback-form.txt",
    "text": "\"button\" type=\"submit\" value=\"Submit\"/></p>\n\n<p>See existing feedback <a href=\"https://docs.google.com/spreadsheets/d/1nA8xVOkyKmZ8oTYSLdwjborT0w-BpBNNZT0nxR9deZ8/edit?usp=sharing\" target=\"_blank\" rel=\"noreferrer noopener\">here</a>.</p>\n\n</form>\n+++"
  },
  "1861": {
    "source_file": "fingerprints.txt",
    "text": "layout: section\ntitle: Fingerprints\n\n\nWhen you have interdependent projects on Jenkins, it often becomes hard\nto keep track of which version of a file is used by which version of a\ndependency on that file.\nJenkins supports *file fingerprinting* to track dependencies.\n\nFor example, suppose you have a TOP project that depends on a MIDDLE\nproject, which in turn depends on a BOTTOM project.\nYou are wo"
  },
  "1862": {
    "source_file": "fingerprints.txt",
    "text": "ack dependencies.\n\nFor example, suppose you have a TOP project that depends on a MIDDLE\nproject, which in turn depends on a BOTTOM project.\nYou are working on the BOTTOM project.\nThe TOP team reported that the `+bottom.jar+` that they are using causes\nan NPE, which you (a member of the BOTTOM team) thought you fixed in\nBOTTOM #32.\nJenkins can tell you which MIDDLE builds and TOP builds are using ("
  },
  "1863": {
    "source_file": "fingerprints.txt",
    "text": "s\nan NPE, which you (a member of the BOTTOM team) thought you fixed in\nBOTTOM #32.\nJenkins can tell you which MIDDLE builds and TOP builds are using (or not\nusing) your `+bottom.jar+` #32.\n\nTo make this work, all the relevant projects need to be configured to\n*Record fingerprints* of the jar files (in the above case,\n`+bottom.jar+`).\n\nFor example, if you just want to track which BOTTOM builds are "
  },
  "1864": {
    "source_file": "fingerprints.txt",
    "text": "igured to\n*Record fingerprints* of the jar files (in the above case,\n`+bottom.jar+`).\n\nFor example, if you just want to track which BOTTOM builds are used by\nwhich TOP builds, configure TOP and BOTTOM to record the fingerprint\nof `+bottom.jar+`.\nIf you also want to know which MIDDLE builds are using which\n`+bottom.jar+`, also configure MIDDLE.\n\nSince recording fingerprints is a cheap operation, th"
  },
  "1865": {
    "source_file": "fingerprints.txt",
    "text": "ou also want to know which MIDDLE builds are using which\n`+bottom.jar+`, also configure MIDDLE.\n\nSince recording fingerprints is a cheap operation, the simplest thing to\ndo is just blindly record all fingerprints of the followings:\n\njar files that your project produce\njar files that your project rely on\n\nThe disk usage is affected more by the number of files fingerprinted, as\nopposed to the size o"
  },
  "1866": {
    "source_file": "fingerprints.txt",
    "text": "ur project produce\njar files that your project rely on\n\nThe disk usage is affected more by the number of files fingerprinted, as\nopposed to the size of files or the number of builds they are used.\nSo unless you have a plenty of disk space, you don't want to fingerprint\n`+**/*+`.\n\nGo to your project, click *Configure* in the left navigation bar, then\nscroll down to the *Post-build Actions* section "
  },
  "1867": {
    "source_file": "fingerprints.txt",
    "text": "want to fingerprint\n`+**/*+`.\n\nGo to your project, click *Configure* in the left navigation bar, then\nscroll down to the *Post-build Actions* section of the job\n\nClick on the button to add a *Post-build* action.\n\nSelect *Record fingerprints of files to track usage*.\n\nThe post-build action configuration fields provide you with a pattern\noption to match the files you want to fingerprint as well as a"
  },
  "1868": {
    "source_file": "fingerprints.txt",
    "text": "to track usage*.\n\nThe post-build action configuration fields provide you with a pattern\noption to match the files you want to fingerprint as well as a couple\ncheck-box selections to do your file fingerprinting.\n\nMaven job type does this automatically for its dependencies and\nartifacts.\n\nThe fingerprint of a file is simply an MD5 checksum. Jenkins maintains a\ndatabase of MD5 checksums, and for each"
  },
  "1869": {
    "source_file": "fingerprints.txt",
    "text": " for its dependencies and\nartifacts.\n\nThe fingerprint of a file is simply an MD5 checksum. Jenkins maintains a\ndatabase of MD5 checksums, and for each MD5 checksum, Jenkins records\nwhich builds of which projects used it.\nThis database is updated every time a build runs and files are\nfingerprinted.\n\nTo avoid excessive disk usage, Jenkins does not store the actual\nfile.\nInstead, it just stores MD5 c"
  },
  "1870": {
    "source_file": "fingerprints.txt",
    "text": "y time a build runs and files are\nfingerprinted.\n\nTo avoid excessive disk usage, Jenkins does not store the actual\nfile.\nInstead, it just stores MD5 checksums and their usages.\nThese files can be seen in\n\n*$JENKINS_HOME/fingerprints*\n\nPlugins can store additional information in these records.\nFor example,\nhttps://plugins.jenkins.io/deployment-notification/[Deployment Notification Plugin]\ntracks fi"
  },
  "1871": {
    "source_file": "fingerprints.txt",
    "text": "re additional information in these records.\nFor example,\nhttps://plugins.jenkins.io/deployment-notification/[Deployment Notification Plugin]\ntracks files deployed on servers via chef/puppet through fingerprints.\n\nHere are a few typical scenarios that benefit from this feature:\n\nYou develop the BOTTOM project and you want to know who is using BOTTOM\n#13 in which builds\n\nGo to BOTTOM #13 build page."
  },
  "1872": {
    "source_file": "fingerprints.txt",
    "text": " benefit from this feature:\n\nYou develop the BOTTOM project and you want to know who is using BOTTOM\n#13 in which builds\n\nGo to BOTTOM #13 build page.\nClick the \"fingerprint\" icon of `+bottom.jar+` in the build artifacts\nYou'll see all the projects and builds that use it.\n\nYou develop the TOP project and you want to know which build of\n`+bottom.jar+` and `+middle.jar+` you are using in TOP #10.\n\nG"
  },
  "1873": {
    "source_file": "fingerprints.txt",
    "text": "nd builds that use it.\n\nYou develop the TOP project and you want to know which build of\n`+bottom.jar+` and `+middle.jar+` you are using in TOP #10.\n\nGo to TOP #10 build page.\nClick \"see fingerprints\"\nYou'll see all the files fingerprinted in TOP #10, along with where\nthey came from.\n\nYou have the TOP project that builds a jar.\nYou also have the TOP-TEST project that runs after the TOP project and "
  },
  "1874": {
    "source_file": "fingerprints.txt",
    "text": " along with where\nthey came from.\n\nYou have the TOP project that builds a jar.\nYou also have the TOP-TEST project that runs after the TOP project and does extensive\nintegration tests on the latest TOP bits. You want to know the test results of TOP\n#7.\n\nGo to TOP #7 build page.\nClick the \"fingerprint\" icon of `+top.jar+` in the build artifacts\nYou'll see all the TOP-TEST builds that used it.\nClick "
  },
  "1875": {
    "source_file": "fingerprints.txt",
    "text": ".\n\nGo to TOP #7 build page.\nClick the \"fingerprint\" icon of `+top.jar+` in the build artifacts\nYou'll see all the TOP-TEST builds that used it.\nClick it and you'll be taken to the appropriate TOP-TEST build page,\nwhich will show you test reports.\nIf there's no TOP-TEST builds displayed, then that means TOP-TEST\nbuild didn't run against TOP #7. Maybe it skipped TOP #7 (this can\nhappen if there are "
  },
  "1876": {
    "source_file": "fingerprints.txt",
    "text": "there's no TOP-TEST builds displayed, then that means TOP-TEST\nbuild didn't run against TOP #7. Maybe it skipped TOP #7 (this can\nhappen if there are a lot of TOP builds in a short period of time), or\nmaybe a new TOP-TEST build is in progress."
  },
  "1877": {
    "source_file": "FIPS-140.txt",
    "text": "layout: section\n\n\nifndef::env-github[:imagesdir: ../../resources/managing]\n\nIt may be possible to run Jenkins in a FIPS-140 compliant manner when the <<../managing/system-properties#jenkins-security-fips140-compliance, compliance flag>> is enabled, and the servlet container, the JVM, and the host OS are all appropriately configured.\nHow to configure the servlet container, JVM and host are out of s"
  },
  "1878": {
    "source_file": "FIPS-140.txt",
    "text": "nd the servlet container, the JVM, and the host OS are all appropriately configured.\nHow to configure the servlet container, JVM and host are out of scope of the Jenkins community project as this is a complex area with many pitfalls and gotchas.\nSome Jenkins features may not work or be disabled.\n\n[IMPORTANT]\n\nThe Jenkins community does not actively check Jenkins or Plugins for  compliance issues.\n"
  },
  "1879": {
    "source_file": "FIPS-140.txt",
    "text": " Jenkins features may not work or be disabled.\n\n[IMPORTANT]\n\nThe Jenkins community does not actively check Jenkins or Plugins for  compliance issues.\n\nPlugins may or may not honour a request to run in FIPS-140 compliance mode.\nBefore you install or upgrade any plugin, you should check the plugin's code to ensure it adheres to the FIPS-140 standard.\n\nIf you enable <<../managing/system-properties#je"
  },
  "1880": {
    "source_file": "FIPS-140.txt",
    "text": "pgrade any plugin, you should check the plugin's code to ensure it adheres to the FIPS-140 standard.\n\nIf you enable <<../managing/system-properties#jenkins-security-fips140-compliance, FIPS-140 mode>>, it provides a hint to Jenkins and any plugins that have opted in that they should prefer cryptographic algorithms that *may*.footnote:[Algorithms are not approved, rather a specific implementation o"
  },
  "1881": {
    "source_file": "FIPS-140.txt",
    "text": "at have opted in that they should prefer cryptographic algorithms that *may*.footnote:[Algorithms are not approved, rather a specific implementation of a specific algorithm is approved.\nHowever, the implementation used at runtime depends on the JVM, JVM configuration, and the host OS.\nAs this is outside the scope of the Jenkins project, the algorithms targeted are available from at least one , nam"
  },
  "1882": {
    "source_file": "FIPS-140.txt",
    "text": "JVM configuration, and the host OS.\nAs this is outside the scope of the Jenkins project, the algorithms targeted are available from at least one , namely the .] be FIPS-140 approved.\nThis may mean that some features are disabled entirely, or may use a less secure (but compliant) form of cryptography than normal.\n\nIf any code from the JVM, servlet container, Jenkins, or any plugin requests a non-co"
  },
  "1883": {
    "source_file": "FIPS-140.txt",
    "text": "a less secure (but compliant) form of cryptography than normal.\n\nIf any code from the JVM, servlet container, Jenkins, or any plugin requests a non-compliant algorithm, this will still be the case, and the request may be honoured.\nFor example, this mode cannot configure the JVM, so TLS connections to external secure web sites might still use non-compliant cryptography.\nAdditionally, Jenkins cannot"
  },
  "1884": {
    "source_file": "FIPS-140.txt",
    "text": "ode cannot configure the JVM, so TLS connections to external secure web sites might still use non-compliant cryptography.\nAdditionally, Jenkins cannot ensure that plugins will even use encryption at all, when appropriate.\nAt the end of the day, just because Jenkins and plugins run when FIPS-140 mode is enabled does not mean that it adheres to the USA government standard.\n\nAs previously mentioned, "
  },
  "1885": {
    "source_file": "FIPS-140.txt",
    "text": "because Jenkins and plugins run when FIPS-140 mode is enabled does not mean that it adheres to the USA government standard.\n\nAs previously mentioned, the host, JVM, and the servlet container all need to be configured appropriately to ensure that Jenkins is FIPS-140 compliant.\nExtreme care should be taken when installing or upgrading plugins as they may or may not be FIPS-140 compliant, and they ma"
  },
  "1886": {
    "source_file": "FIPS-140.txt",
    "text": "ins is FIPS-140 compliant.\nExtreme care should be taken when installing or upgrading plugins as they may or may not be FIPS-140 compliant, and they may introduce code that is non-compliant or otherwise change the JVM configuration so that it breaks compliance.\n\nThe Jenkins community does not support Jenkins FIPS-140 mode, and due to the complex nature of JVM and servlet configuration that can chan"
  },
  "1887": {
    "source_file": "FIPS-140.txt",
    "text": "ompliance.\n\nThe Jenkins community does not support Jenkins FIPS-140 mode, and due to the complex nature of JVM and servlet configuration that can change between versions, does not provide documentation for the full configuration required to run Jenkins in a fully FIPS-140 compliant manner.\nIf you need to run Jenkins in a way that it is FIPS-140 compliant, it is recommended that you obtain support "
  },
  "1888": {
    "source_file": "FIPS-140.txt",
    "text": "ns in a fully FIPS-140 compliant manner.\nIf you need to run Jenkins in a way that it is FIPS-140 compliant, it is recommended that you obtain support from a commercial vendor.\nThe Jenkins community may be able to fix issues relating to FIPS-140 compliance; these will be treated as any other bug report or feature request."
  },
  "1889": {
    "source_file": "FIPS-140.txt",
    "text": "iance; these will be treated as any other bug report or feature request."
  },
  "1890": {
    "source_file": "forks.txt",
    "text": "title: GitHub Forked Repositories\nlayout: developersection\n\n\nThe canonical source code repository is in the `jenkinsci` GitHub organization to ensure source code access and project continuity in case previous maintainers move on.\nSome plugins we distribute are currently maintained outside the `jenkinsci` GitHub organization for historical reasons, but this is discouraged.\n\nThis page lists all fork"
  },
  "1891": {
    "source_file": "forks.txt",
    "text": "ribute are currently maintained outside the `jenkinsci` GitHub organization for historical reasons, but this is discouraged.\n\nThis page lists all forked repositories in the `jenkinsci` GitHub organization and their source repositories.\n\n+++\n    <style type=\"text/css\">\n    @import url(https://cdn.datatables.net/1.13.4/css/jquery.dataTables.min.css);\n    </style>\n    <script type=\"text/javascript\" s"
  },
  "1892": {
    "source_file": "forks.txt",
    "text": "e type=\"text/css\">\n    @import url(https://cdn.datatables.net/1.13.4/css/jquery.dataTables.min.css);\n    </style>\n    <script type=\"text/javascript\" src=\"https://cdn.datatables.net/1.13.4/js/jquery.dataTables.min.js\"></script>\n    <script type=\"text/javascript\">\n$(document).ready(function() {\n    $('#forks').DataTable( {\n        ajax: {\n            url: 'https://reports.jenkins.io/github-jenkinsci"
  },
  "1893": {
    "source_file": "forks.txt",
    "text": "javascript\">\n$(document).ready(function() {\n    $('#forks').DataTable( {\n        ajax: {\n            url: 'https://reports.jenkins.io/github-jenkinsci-fork-report.json',\n            dataSrc: ''\n        },\n        columns: [\n            {\n                title: \"Fork\",\n                render: function(data, type, row, metadata) {\n                    return '<a href=\"https://github.com/' + data + '\""
  },
  "1894": {
    "source_file": "forks.txt",
    "text": "    title: \"Fork\",\n                render: function(data, type, row, metadata) {\n                    return '<a href=\"https://github.com/' + data + '\" target=\"_blank\" rel=\"noreferrer noopener\">' + data + '</a>';\n                }\n            },\n            {\n                title: \"Origin\",\n                render: function(data, type, row, metadata) {\n                    return '<a href=\"https://g"
  },
  "1895": {
    "source_file": "forks.txt",
    "text": "       {\n                title: \"Origin\",\n                render: function(data, type, row, metadata) {\n                    return '<a href=\"https://github.com/' + data + '\" target=\"_blank\" rel=\"noreferrer noopener\">' + data + '</a>';\n                }\n            }\n        ]\n    } );\n} );\n    </script>\n    <table id=\"forks\" class=\"display\" cellspacing=\"0\" width=\"100%\">\n        <thead>\n        <tr"
  },
  "1896": {
    "source_file": "forks.txt",
    "text": " }\n            }\n        ]\n    } );\n} );\n    </script>\n    <table id=\"forks\" class=\"display\" cellspacing=\"0\" width=\"100%\">\n        <thead>\n        <tr>\n            <th>Fork</th>\n            <th>Origin</th>\n        </tr>\n        </thead>\n        <tfoot>\n        <tr>\n            <th>Fork</th>\n            <th>Origin</th>\n        </tr>\n    </tfoot>\n    </table>\n\n+++"
  },
  "1897": {
    "source_file": "forks.txt",
    "text": "t>\n        <tr>\n            <th>Fork</th>\n            <th>Origin</th>\n        </tr>\n    </tfoot>\n    </table>\n\n+++"
  },
  "1898": {
    "source_file": "form-validation.txt",
    "text": "title: Securely implementing form validation\nlayout: developer\n\n\nThis guide looks at form validation from a security point of view:\nWhat are the considerations for securing form validation, and how can they be best implemented?\n\nFirst, let's look at a typical form field defined in Jelly, and its validation method in the object's descriptor.\nThis forms the basis for the rest of this guide.\n\n<f:entr"
  },
  "1899": {
    "source_file": "form-validation.txt",
    "text": "a typical form field defined in Jelly, and its validation method in the object's descriptor.\nThis forms the basis for the rest of this guide.\n\n<f:entry field=\"foo\">\n  <f:textbox />\n</f:entry>\n\npublic FormValidation doCheckFoo(@QueryParameter String value) {\n  if (Util.fixEmptyAndTrim(value) == null) {\n    return FormValidation.error(\"foo cannot be empty\");\n  }\n  return FormValidation.ok();\n}\n\nStap"
  },
  "1900": {
    "source_file": "form-validation.txt",
    "text": "alue) {\n  if (Util.fixEmptyAndTrim(value) == null) {\n    return FormValidation.error(\"foo cannot be empty\");\n  }\n  return FormValidation.ok();\n}\n\nStapler routing and Jenkins behavior will result in this method being routed at a URL like `/descriptorByName/f.q.ClassName/checkFoo`.\nThis URL will contain a minimal HTML snippet with a form validation message (if present) based on the presence and valu"
  },
  "1901": {
    "source_file": "form-validation.txt",
    "text": "yName/f.q.ClassName/checkFoo`.\nThis URL will contain a minimal HTML snippet with a form validation message (if present) based on the presence and value of the `value` query parameter.\n\nBy default, any user with Overall/Read access can access form validation methods like the example method above.\nSome form validation methods could be used to infer private information, and as such may need to be pro"
  },
  "1902": {
    "source_file": "form-validation.txt",
    "text": "idation methods like the example method above.\nSome form validation methods could be used to infer private information, and as such may need to be protected from unauthorized access.\n\nIf a form validation method is supposed to only be accessible to users with specific permissions, a permission check should be added.\n\nForm validation can become quite complex and have side effects.\nFor example, Jenk"
  },
  "1903": {
    "source_file": "form-validation.txt",
    "text": "sers with specific permissions, a permission check should be added.\n\nForm validation can become quite complex and have side effects.\nFor example, Jenkins might evaluate a Groovy script passed as parameter, or access a URL passed as parameter.\nThese behaviors could be exploited to result in arbitrary code execution and server-side request forgery, respectively.\n\nEnsuring that form validation code s"
  },
  "1904": {
    "source_file": "form-validation.txt",
    "text": "ehaviors could be exploited to result in arbitrary code execution and server-side request forgery, respectively.\n\nEnsuring that form validation code such as this is protected with appropriate permission checks, it might not be enough:\n is an attack on users with the necessary privileges and exploits the trust Jenkins has in these legitimate users' web browsers.\nProtecting from these attacks requir"
  },
  "1905": {
    "source_file": "form-validation.txt",
    "text": "n users with the necessary privileges and exploits the trust Jenkins has in these legitimate users' web browsers.\nProtecting from these attacks requires that form validation methods with side effects only accept `POST` requests.\n\nTo check for global permissions like `Administer`, add a call to `Jenkins#checkPermission`. Note that Overall/Read permission is always implied (unless you specifically i"
  },
  "1906": {
    "source_file": "form-validation.txt",
    "text": "permissions like `Administer`, add a call to `Jenkins#checkPermission`. Note that Overall/Read permission is always implied (unless you specifically implement jenkinsdoc:UnprotectedRootAction[]).\n\npublic FormValidation doCheckFoo(@QueryParameter String value) {\n  Jenkins.get().checkPermission(Jenkins.ADMINISTER); // or Jenkins.getInstance() on older core baselines\n  if (Util.fixEmptyAndTrim(value)"
  },
  "1907": {
    "source_file": "form-validation.txt",
    "text": "ng value) {\n  Jenkins.get().checkPermission(Jenkins.ADMINISTER); // or Jenkins.getInstance() on older core baselines\n  if (Util.fixEmptyAndTrim(value) == null) {\n    return FormValidation.error(\"foo cannot be empty\");\n  }\n  return FormValidation.ok();\n}\n\nIf a different jenkinsdoc:AccessControlled[]'s permissions are to be checked, as the form validation depends on the context in which the method i"
  },
  "1908": {
    "source_file": "form-validation.txt",
    "text": ";\n}\n\nIf a different jenkinsdoc:AccessControlled[]'s permissions are to be checked, as the form validation depends on the context in which the method is invoked (e.g. when writing a build step and validation depends on the identity of the item), you may need to add an jenkinsdoc:AncestorInPath[`@AncestorInPath`] annotated parameter to get to the necessary context.\n\npublic FormValidation doCheckFoo("
  },
  "1909": {
    "source_file": "form-validation.txt",
    "text": "ay need to add an jenkinsdoc:AncestorInPath[`@AncestorInPath`] annotated parameter to get to the necessary context.\n\npublic FormValidation doCheckFoo(@QueryParameter String value, @AncestorInPath Item item) {\n  if (item == null) { // no context\n    return FormValidation.ok();\n  }\n  item.checkPermission(Item.CONFIGURE);\n\n  if (Util.fixEmptyAndTrim(value) == null) {\n    return FormValidation.error(\""
  },
  "1910": {
    "source_file": "form-validation.txt",
    "text": "eturn FormValidation.ok();\n  }\n  item.checkPermission(Item.CONFIGURE);\n\n  if (Util.fixEmptyAndTrim(value) == null) {\n    return FormValidation.error(\"foo cannot be empty\");\n  }\n  return FormValidation.ok();\n}\n\nStapler web methods, like form validation, can be invoked using any HTTP verb by default.\nThis can be used by malicious users to attack an application by way of its legitimate users:\nCross-s"
  },
  "1911": {
    "source_file": "form-validation.txt",
    "text": "n, can be invoked using any HTTP verb by default.\nThis can be used by malicious users to attack an application by way of its legitimate users:\nCross-site request forgery is the result of a web application (Jenkins) trusting legitimate users' browser.\n\nTo prevent this, Jenkins includes CSRF protection that requires actions with side effects (POST requests) to submit a user-specific secret, called a"
  },
  "1912": {
    "source_file": "form-validation.txt",
    "text": "\n\nTo prevent this, Jenkins includes CSRF protection that requires actions with side effects (POST requests) to submit a user-specific secret, called a _crumb_.\nTo ensure this protection is relevant, web methods with side effects need to reject requests not sent via POST.\nThere are two options to achieve this in general:\n\n* staplerdoc:org.kohsuke.stapler.verb.POST[`POST`] limits processing to just "
  },
  "1913": {
    "source_file": "form-validation.txt",
    "text": "ts not sent via POST.\nThere are two options to achieve this in general:\n\n* staplerdoc:org.kohsuke.stapler.verb.POST[`POST`] limits processing to just the POST verb, and all other verbs will receive a 404 response. This is recommended approach for form validation methods.\n* staplerdoc:org.kohsuke.stapler.interceptor.RequirePOST[`RequirePOST`] is the older (and more common) approach. It will show a "
  },
  "1914": {
    "source_file": "form-validation.txt",
    "text": "m validation methods.\n* staplerdoc:org.kohsuke.stapler.interceptor.RequirePOST[`RequirePOST`] is the older (and more common) approach. It will show a form allowing users to resubmit the request using POST if they used a different verb. This is mostly useful for simple API actions.\n\nApplying this protection is as simple as adding the annotation to the method:\n\n@POST\npublic FormValidation doCheckFoo"
  },
  "1915": {
    "source_file": "form-validation.txt",
    "text": " useful for simple API actions.\n\nApplying this protection is as simple as adding the annotation to the method:\n\n@POST\npublic FormValidation doCheckFoo(@QueryParameter String value) {\n  if (Util.fixEmptyAndTrim(value) == null) {\n    return FormValidation.error(\"foo cannot be empty\");\n  }\n  return FormValidation.ok();\n}\n\nDepending on the versions of Jenkins supported by your plugin, these form valid"
  },
  "1916": {
    "source_file": "form-validation.txt",
    "text": "ion.error(\"foo cannot be empty\");\n  }\n  return FormValidation.ok();\n}\n\nDepending on the versions of Jenkins supported by your plugin, these form validation methods may be invoked using HTTP GET, however, so the form may need to be adapted as well.\nThe Jenkins form Jelly controls support the `checkMethod` attribute, which, if set to `post`, will result in form validation being invoked via HTTP POST"
  },
  "1917": {
    "source_file": "form-validation.txt",
    "text": "e Jenkins form Jelly controls support the `checkMethod` attribute, which, if set to `post`, will result in form validation being invoked via HTTP POST.\n\n<f:entry field=\"foo\">\n  <f:textbox checkMethod=\"post\" />\n</f:entry>\n\nThe default behavior of form controls has changed over time, so you may not need to add the `checkMethod` attribute depending on the versions of Jenkins supported by your plugin "
  },
  "1918": {
    "source_file": "form-validation.txt",
    "text": " controls has changed over time, so you may not need to add the `checkMethod` attribute depending on the versions of Jenkins supported by your plugin and the types of form controls that have validation:\n\n* Historically, form validation requests were sent using GET by default (with the exception of `f:validateButton`, which always used POST).\n* Since Jenkins 2.84 and 2.73.3, `f:password` always sen"
  },
  "1919": {
    "source_file": "form-validation.txt",
    "text": "sent using GET by default (with the exception of `f:validateButton`, which always used POST).\n* Since Jenkins 2.84 and 2.73.3, `f:password` always sends form validation as `POST`.\n* Since Jenkins 2.285, most other form controls send form validation requests as `POST` by default, and `checkMethod` would only opt out.\n* As of Jenkins 2.300 `f:checkbox` does not support the `checkMethod` attribute at"
  },
  "1920": {
    "source_file": "form-validation.txt",
    "text": "equests as `POST` by default, and `checkMethod` would only opt out.\n* As of Jenkins 2.300 `f:checkbox` does not support the `checkMethod` attribute at all and requests are always sent using GET.\n\nNOTE: Some basic form controls may not declare the `checkMethod` attribute in older versions of Jenkins. Depending on the control it could still work, despite an error shown in your IDE."
  },
  "1921": {
    "source_file": "form-validation.txt",
    "text": "eckMethod` attribute in older versions of Jenkins. Depending on the control it could still work, despite an error shown in your IDE."
  },
  "1922": {
    "source_file": "getting-started.txt",
    "text": "layout: documentation\ntitle: Getting started with the Guided Tour\nsection: doc\n\n\nThis guided tour introduces you to the basics of using Jenkins and its main\nfeature, Jenkins Pipeline. This tour uses the \"standalone\" Jenkins distribution,\nwhich runs locally on your own machine.\n\nFor this tour, you will require:\n\n* A machine with:\n** 256 MB of RAM, although more than 2 GB is recommended\n** 10 GB of "
  },
  "1923": {
    "source_file": "getting-started.txt",
    "text": "ocally on your own machine.\n\nFor this tour, you will require:\n\n* A machine with:\n** 256 MB of RAM, although more than 2 GB is recommended\n** 10 GB of drive space (for Jenkins and your Docker image)\n* The following software installed:\n** Java 17 or 21\n** https://docs.docker.com/[Docker] (navigate to https://docs.docker.com/get-docker/[*Get Docker*] site to access the Docker download that's suitable"
  },
  "1924": {
    "source_file": "getting-started.txt",
    "text": "\n** https://docs.docker.com/[Docker] (navigate to https://docs.docker.com/get-docker/[*Get Docker*] site to access the Docker download that's suitable for your platform)\n\nOpen up a terminal in the download directory\nRun `java -jar jenkins.war --httpPort=8080`\nBrowse to `http://localhost:8080`\nFollow the instructions to complete the installation\n\nWhen the installation is complete, you can start put"
  },
  "1925": {
    "source_file": "getting-started.txt",
    "text": "ort=8080`\nBrowse to `http://localhost:8080`\nFollow the instructions to complete the installation\n\nWhen the installation is complete, you can start putting Jenkins to work!\n\n\n\n\n'''\n+++\n\n+++"
  },
  "1926": {
    "source_file": "groovy-hook-scripts.txt",
    "text": "layout: section\nwip: true\n\n\nIn several places inside Jenkins, a series of \"hook scripts\" get executed to allow some actions to take place in reaction to some key\nevents.\n\nThese scripts are written in Groovy, and get executed inside the same JVM as Jenkins, allowing full access to the domain model of Jenkins.\nFor given hook _HOOK_, the following locations are searched:\n\n* `+WEB-INF/HOOK.groovy+` in"
  },
  "1927": {
    "source_file": "groovy-hook-scripts.txt",
    "text": "nkins, allowing full access to the domain model of Jenkins.\nFor given hook _HOOK_, the following locations are searched:\n\n* `+WEB-INF/HOOK.groovy+` in `+jenkins.war+`\n* `+WEB-INF/HOOK.groovy.d/*.groovy+` in the lexical order in `+jenkins.war+`\n* `+$JENKINS_HOME/HOOK.groovy+`\n* `+$JENKINS_HOME/HOOK.groovy.d/*.groovy+` in the lexical order\n\n`+HOOK.groovy.d+` is suitable to avoid conflicts \u2014 multiple"
  },
  "1928": {
    "source_file": "groovy-hook-scripts.txt",
    "text": "ENKINS_HOME/HOOK.groovy+`\n* `+$JENKINS_HOME/HOOK.groovy.d/*.groovy+` in the lexical order\n\n`+HOOK.groovy.d+` is suitable to avoid conflicts \u2014 multiple entities can\ninsert stuff into the hook without worrying about overwriting each\nother's code.\n\nThe following events use this mechanism by replacing `+HOOK+` in `+HOOK.groovy.d+` or `+HOOK.groovy+` by one of the below mentioned types:\n\n* *init*: Post"
  },
  "1929": {
    "source_file": "groovy-hook-scripts.txt",
    "text": "following events use this mechanism by replacing `+HOOK+` in `+HOOK.groovy.d+` or `+HOOK.groovy+` by one of the below mentioned types:\n\n* *init*: Post-initialization script\n* *boot-failure*: Boot failure hook\n\nYou can create a Groovy script file `+$JENKINS_HOME/init.groovy+`, or\nany `+.groovy+` file in the directory `+$JENKINS_HOME/init.groovy.d/+`,\nto run some additional things right after Jenkin"
  },
  "1930": {
    "source_file": "groovy-hook-scripts.txt",
    "text": "ENKINS_HOME/init.groovy+`, or\nany `+.groovy+` file in the directory `+$JENKINS_HOME/init.groovy.d/+`,\nto run some additional things right after Jenkins starts up.\nThe groovy scripts are executed at the end of Jenkins initialization.\nThis script can access classes in Jenkins and all the plugins.\nSo for example, you can write something like:\n\n....\nimport jenkins.model.Jenkins;\n\n// start in the state"
  },
  "1931": {
    "source_file": "groovy-hook-scripts.txt",
    "text": "ccess classes in Jenkins and all the plugins.\nSo for example, you can write something like:\n\n....\nimport jenkins.model.Jenkins;\n\n// start in the state that doesn't do any build.\nJenkins.instance.doQuietDown();\n....\n\nOutput is logged to the Jenkins log file. For Debian based users, this\nis\u00a0/var/log/jenkins/jenkins.log\n\nNOTE: If you are using the Jenkins Docker image, `$JENKINS_HOME/init.groovy.d/` "
  },
  "1932": {
    "source_file": "groovy-hook-scripts.txt",
    "text": "g file. For Debian based users, this\nis\u00a0/var/log/jenkins/jenkins.log\n\nNOTE: If you are using the Jenkins Docker image, `$JENKINS_HOME/init.groovy.d/` does not exist.\nInstead, you should place the Groovy script files in `/usr/share/jenkins/ref/init.groovy.d/`, as this directory is copied when the Docker container starts.\nFor more details, refer to the .\n\nWhen Jenkins encounters a fatal problem duri"
  },
  "1933": {
    "source_file": "groovy-hook-scripts.txt",
    "text": "oovy.d/`, as this directory is copied when the Docker container starts.\nFor more details, refer to the .\n\nWhen Jenkins encounters a fatal problem during boot, it'll invoke\n\"boot-failure\" hook script to allow automatic corrective actions to be taken\n(such as notifying somebody, raising alerts, restarting, and so on.)\n\nThese scripts get the cause of the problem as the \"exception\" variable\nwhen run."
  },
  "1934": {
    "source_file": "groovy-hook-scripts.txt",
    "text": "such as notifying somebody, raising alerts, restarting, and so on.)\n\nThese scripts get the cause of the problem as the \"exception\" variable\nwhen run."
  },
  "1935": {
    "source_file": "hardware-recommendations.txt",
    "text": "layout: section\n\n\nSizing a Jenkins environment depends on a number of factors, which makes it a\nvery inexact science. Achieving an optimal configuration requires some\nexperience and experimentation. It is, however, possible to make a smart\napproximation to start - especially when designing with best practices\nin mind.\n\nThe following outlines these factors and how you can account for them when\nsizi"
  },
  "1936": {
    "source_file": "hardware-recommendations.txt",
    "text": "ion to start - especially when designing with best practices\nin mind.\n\nThe following outlines these factors and how you can account for them when\nsizing your configuration. You are also provided sample configurations and the\nhardwares behind some of the largest Jenkins installations presented in a\nJenkins Scalability Summit.\n\n[[choosing-the-right-hardware-for-masters]]\n\nOne of the greatest challen"
  },
  "1937": {
    "source_file": "hardware-recommendations.txt",
    "text": "the largest Jenkins installations presented in a\nJenkins Scalability Summit.\n\n[[choosing-the-right-hardware-for-masters]]\n\nOne of the greatest challenges of properly setting up a Jenkins controller is that\nthere is no _one size fits all_ answer - the exact specifications of the\nhardware that you will need will depend heavily on your organization's current\nand future needs.\n\nYour Jenkins controller"
  },
  "1938": {
    "source_file": "hardware-recommendations.txt",
    "text": " exact specifications of the\nhardware that you will need will depend heavily on your organization's current\nand future needs.\n\nYour Jenkins controller will be serving HTTP requests and storing all of the\nimportant information for your Jenkins controller in its _$JENKINS_HOME_ folder\n(configurations, build histories and plugins).\n\nMore information on sizing controllers based on organizational needs"
  },
  "1939": {
    "source_file": "hardware-recommendations.txt",
    "text": "ler in its _$JENKINS_HOME_ folder\n(configurations, build histories and plugins).\n\nMore information on sizing controllers based on organizational needs can be found in\nthe  section.\n\n[[memory-requirements-for-the-controller]]\n\nThe amount of memory Jenkins needs is largely dependent on many factors, which\nis why the RAM allotted for it can range from 200 MB for a small installation to\n70+ GB for a s"
  },
  "1940": {
    "source_file": "hardware-recommendations.txt",
    "text": "kins needs is largely dependent on many factors, which\nis why the RAM allotted for it can range from 200 MB for a small installation to\n70+ GB for a single and massive Jenkins controller. However, you should be able to\nestimate the RAM required based on your project build needs.\n\nEach build node connection will take 2-3 threads, which equals about 2 MB or\nmore of memory. You will also need to fact"
  },
  "1941": {
    "source_file": "hardware-recommendations.txt",
    "text": " on your project build needs.\n\nEach build node connection will take 2-3 threads, which equals about 2 MB or\nmore of memory. You will also need to factor in CPU overhead for Jenkins if\nthere are a lot of users who will be accessing the Jenkins user interface.\n\nIt is generally a bad practice to allocate executors on a controller, as builds can\nquickly overload a controller's CPU/memory/etc and crash"
  },
  "1942": {
    "source_file": "hardware-recommendations.txt",
    "text": "terface.\n\nIt is generally a bad practice to allocate executors on a controller, as builds can\nquickly overload a controller's CPU/memory/etc and crash the controller, causing\nunnecessary downtime. Instead, it is advisable to set up agents that the Jenkins\ncontroller can delegate jobs to, keeping the bulk of the work off of the\ncontroller itself.\n\nThe backbone of Jenkins is its ability to orchestra"
  },
  "1943": {
    "source_file": "hardware-recommendations.txt",
    "text": "nkins\ncontroller can delegate jobs to, keeping the bulk of the work off of the\ncontroller itself.\n\nThe backbone of Jenkins is its ability to orchestrate builds, but installations\nwhich do not leverage Jenkins' distributed builds architecture are artificially\nlimiting the number of builds that their controllers can orchestrate. More\ninformation on\n\ncan be found in the\n section.\n\n[[fungibility]]\nAge"
  },
  "1944": {
    "source_file": "hardware-recommendations.txt",
    "text": "ficially\nlimiting the number of builds that their controllers can orchestrate. More\ninformation on\n\ncan be found in the\n section.\n\n[[fungibility]]\nAgents are typically generic x86 machines with enough memory to run\nspecific build types. The agent's configuration depends on the builds it\nwill be used for and on the tools required by the same builds.\n\nConfiguring a machine to act as an agent inside "
  },
  "1945": {
    "source_file": "hardware-recommendations.txt",
    "text": "onfiguration depends on the builds it\nwill be used for and on the tools required by the same builds.\n\nConfiguring a machine to act as an agent inside your infrastructure can be tedious\nand time consuming. This is especially true when the same set-up has to be\nreplicated on a large pool of agents. Because of this, is ideal to have fungible\nagents, which are agents that are easily replaceable. Agent"
  },
  "1946": {
    "source_file": "hardware-recommendations.txt",
    "text": "has to be\nreplicated on a large pool of agents. Because of this, is ideal to have fungible\nagents, which are agents that are easily replaceable. Agents should be generic\nfor all builds rather customized for a specific job or a set of jobs. The more\ngeneric the agents, the more easily they are interchanged, which in turn\nallows for a better use of resources and a reduced impact on productivity if\ns"
  },
  "1947": {
    "source_file": "hardware-recommendations.txt",
    "text": "eneric the agents, the more easily they are interchanged, which in turn\nallows for a better use of resources and a reduced impact on productivity if\nsome agents suffer an outage. Andrew Bayer introduced this concept of\n\"fungibility\" as applied to agents during his presentation\nhttps://www.slideshare.net/andrewbayer/seven-habits-of-highly-effective-jenkins-users-2014-edition[\"Seven Habits of Highly"
  },
  "1948": {
    "source_file": "hardware-recommendations.txt",
    "text": "nts during his presentation\nhttps://www.slideshare.net/andrewbayer/seven-habits-of-highly-effective-jenkins-users-2014-edition[\"Seven Habits of Highly Effective Jenkins Users\" at the Jenkins User Conference (Europe, 2014)].\n\nThe more automated the environment configuration is, the easier it is to\nreplicate a configuration onto a new agent machine. Tools for configuration\nmanagement or a pre-baked "
  },
  "1949": {
    "source_file": "hardware-recommendations.txt",
    "text": "vironment configuration is, the easier it is to\nreplicate a configuration onto a new agent machine. Tools for configuration\nmanagement or a pre-baked image can be excellent solutions to this end.\nContainers and virtualization are also popular tools for creating generic agent\nenvironments.\n\nMore information on estimating the number of executors needed in a given\nenvironment can be found in the  sec"
  },
  "1950": {
    "source_file": "hardware-recommendations.txt",
    "text": "or creating generic agent\nenvironments.\n\nMore information on estimating the number of executors needed in a given\nenvironment can be found in the  section."
  },
  "1951": {
    "source_file": "hello-world.txt",
    "text": "layout: documentation\ntitle: Creating your first Pipeline\nsection: doc\n\n\nJenkins Pipeline (or simply \"Pipeline\") is a suite of plugins which supports\nimplementing and integrating _continuous delivery pipelines_ into Jenkins.\n\nA _continuous delivery pipeline_ is an automated expression of your process for\ngetting software from version control right through to your users and customers.\n\nJenkins Pipe"
  },
  "1952": {
    "source_file": "hello-world.txt",
    "text": "ipeline_ is an automated expression of your process for\ngetting software from version control right through to your users and customers.\n\nJenkins Pipeline provides an extensible set of tools for modeling\nsimple-to-complex delivery pipelines \"as code\". The definition of a Jenkins\nPipeline is typically written into a text file (called a `Jenkinsfile`) which in\nturn is checked into a project's source"
  },
  "1953": {
    "source_file": "hello-world.txt",
    "text": ". The definition of a Jenkins\nPipeline is typically written into a text file (called a `Jenkinsfile`) which in\nturn is checked into a project's source control repository.\nfootnote:scm[]\n\nFor more information about Pipeline and what a `Jenkinsfile` is, refer to the\nrespective  and\n sections of the User\nHandbook.\n\nTo get started quickly with Pipeline:\n\nInstall the  through the *Manage Jenkins > Plug"
  },
  "1954": {
    "source_file": "hello-world.txt",
    "text": ", refer to the\nrespective  and\n sections of the User\nHandbook.\n\nTo get started quickly with Pipeline:\n\nInstall the  through the *Manage Jenkins > Plugins* page\nAfter installing the plugin, restart Jenkins so that the plugin is ready to use\nCopy one of the <<examples, examples below>> into your repository and name it `Jenkinsfile`\nClick the *New Item* menu within Jenkins\n\nProvide a name for your ne"
  },
  "1955": {
    "source_file": "hello-world.txt",
    "text": "f the <<examples, examples below>> into your repository and name it `Jenkinsfile`\nClick the *New Item* menu within Jenkins\n\nProvide a name for your new item (e.g. *My-Pipeline*) and select *Multibranch Pipeline*\nClick the *Add Source* button, choose the type of repository you want to use and fill in the details\nClick the *Save* button and watch your first Pipeline run\n\nYou may need to modify one o"
  },
  "1956": {
    "source_file": "hello-world.txt",
    "text": "the type of repository you want to use and fill in the details\nClick the *Save* button and watch your first Pipeline run\n\nYou may need to modify one of the example ``Jenkinsfile``'s to make it run with your project. Try modifying the `sh` command to run the same command you would run on your local machine.\n\nAfter you have setup your Pipeline, Jenkins will automatically detect any new Branches or P"
  },
  "1957": {
    "source_file": "hello-world.txt",
    "text": "run the same command you would run on your local machine.\n\nAfter you have setup your Pipeline, Jenkins will automatically detect any new Branches or Pull Requests that are created in your repository and start running Pipelines for them.\n\n\n\n[[examples]]\n\nBelow are some easily copied and pasted examples of a simple Pipeline with\nvarious languages.\n\n[pipeline]\n\n// Declarative //\n/* Requires the Docke"
  },
  "1958": {
    "source_file": "hello-world.txt",
    "text": "]]\n\nBelow are some easily copied and pasted examples of a simple Pipeline with\nvarious languages.\n\n[pipeline]\n\n// Declarative //\n/* Requires the Docker Pipeline plugin */\npipeline {\n    agent { docker { image 'maven:3.9.11-eclipse-temurin-21-alpine' } }\n    stages {\n        stage('build') {\n            steps {\n                sh 'mvn --version'\n            }\n        }\n    }\n}\n// Scripted //\n/* Req"
  },
  "1959": {
    "source_file": "hello-world.txt",
    "text": "} }\n    stages {\n        stage('build') {\n            steps {\n                sh 'mvn --version'\n            }\n        }\n    }\n}\n// Scripted //\n/* Requires the Docker Pipeline plugin */\nnode {\n    stage('Build') {\n        docker.image('maven:3.9.11-eclipse-temurin-21-alpine').inside {\n            sh 'mvn --version'\n        }\n    }\n}\n\n[pipeline]\n\n// Declarative //\n/* Requires the Docker Pipeline pl"
  },
  "1960": {
    "source_file": "hello-world.txt",
    "text": "clipse-temurin-21-alpine').inside {\n            sh 'mvn --version'\n        }\n    }\n}\n\n[pipeline]\n\n// Declarative //\n/* Requires the Docker Pipeline plugin */\npipeline {\n    agent { docker { image 'node:24.11.1-alpine3.22' } }\n    stages {\n        stage('build') {\n            steps {\n                sh 'node --version'\n            }\n        }\n    }\n}\n// Scripted //\n/* Requires the Docker Pipeline p"
  },
  "1961": {
    "source_file": "hello-world.txt",
    "text": "ge('build') {\n            steps {\n                sh 'node --version'\n            }\n        }\n    }\n}\n// Scripted //\n/* Requires the Docker Pipeline plugin */\nnode {\n    stage('Build') {\n        docker.image('node:24.11.1-alpine3.22').inside {\n            sh 'node --version'\n        }\n    }\n}\n\n[pipeline]\n\n// Declarative //\n/* Requires the Docker Pipeline plugin */\npipeline {\n    agent { docker { i"
  },
  "1962": {
    "source_file": "hello-world.txt",
    "text": "      sh 'node --version'\n        }\n    }\n}\n\n[pipeline]\n\n// Declarative //\n/* Requires the Docker Pipeline plugin */\npipeline {\n    agent { docker { image 'ruby:3.4.7-alpine3.22' } }\n    stages {\n        stage('build') {\n            steps {\n                sh 'ruby --version'\n            }\n        }\n    }\n}\n// Scripted //\n/* Requires the Docker Pipeline plugin */\nnode {\n    stage('Build') {\n      "
  },
  "1963": {
    "source_file": "hello-world.txt",
    "text": "       sh 'ruby --version'\n            }\n        }\n    }\n}\n// Scripted //\n/* Requires the Docker Pipeline plugin */\nnode {\n    stage('Build') {\n        docker.image('ruby:3.4.7-alpine3.22').inside {\n            sh 'ruby --version'\n        }\n    }\n}\n\n[pipeline]\n\n// Declarative //\n/* Requires the Docker Pipeline plugin */\npipeline {\n    agent { docker { image 'python:3.14.0-alpine3.22' } }\n    stage"
  },
  "1964": {
    "source_file": "hello-world.txt",
    "text": "[pipeline]\n\n// Declarative //\n/* Requires the Docker Pipeline plugin */\npipeline {\n    agent { docker { image 'python:3.14.0-alpine3.22' } }\n    stages {\n        stage('build') {\n            steps {\n                sh 'python --version'\n            }\n        }\n    }\n}\n// Scripted //\n/* Requires the Docker Pipeline plugin */\nnode {\n    stage('Build') {\n        docker.image('python:3.14.0-alpine3.22"
  },
  "1965": {
    "source_file": "hello-world.txt",
    "text": "\n        }\n    }\n}\n// Scripted //\n/* Requires the Docker Pipeline plugin */\nnode {\n    stage('Build') {\n        docker.image('python:3.14.0-alpine3.22').inside {\n            sh 'python --version'\n        }\n    }\n}\n\n[pipeline]\n\n// Declarative //\n/* Requires the Docker Pipeline plugin */\npipeline {\n    agent { docker { image 'php:8.5.0-alpine3.22' } }\n    stages {\n        stage('build') {\n          "
  },
  "1966": {
    "source_file": "hello-world.txt",
    "text": "quires the Docker Pipeline plugin */\npipeline {\n    agent { docker { image 'php:8.5.0-alpine3.22' } }\n    stages {\n        stage('build') {\n            steps {\n                sh 'php --version'\n            }\n        }\n    }\n}\n// Scripted //\n/* Requires the Docker Pipeline plugin */\nnode {\n    stage('Build') {\n        docker.image('php:8.3.8-alpine3.20').inside {\n            sh 'php --version'\n   "
  },
  "1967": {
    "source_file": "hello-world.txt",
    "text": "res the Docker Pipeline plugin */\nnode {\n    stage('Build') {\n        docker.image('php:8.3.8-alpine3.20').inside {\n            sh 'php --version'\n        }\n    }\n}\n\n[pipeline]\n\n// Declarative //\n/* Requires the Docker Pipeline plugin */\npipeline {\n    agent { docker { image 'golang:1.25.4-alpine3.22' } }\n    stages {\n        stage('build') {\n            steps {\n                sh 'go version'\n   "
  },
  "1968": {
    "source_file": "hello-world.txt",
    "text": "   agent { docker { image 'golang:1.25.4-alpine3.22' } }\n    stages {\n        stage('build') {\n            steps {\n                sh 'go version'\n            }\n        }\n    }\n}\n// Scripted //\n/* Requires the Docker Pipeline plugin */\nnode {\n    stage('Build') {\n        docker.image('golang:1.22.4-alpine3.20').inside {\n            sh 'go version'\n        }\n    }\n}\n\n\n\n\n* See more detailed instruct"
  },
  "1969": {
    "source_file": "hello-world.txt",
    "text": "ge('Build') {\n        docker.image('golang:1.22.4-alpine3.20').inside {\n            sh 'go version'\n        }\n    }\n}\n\n\n\n\n* See more detailed instructions on\n* Review other\n\n.How to Write a Pipeline Script in Jenkins\nvideo::TiTrcFEsj7A[youtube,width=800,height=420]\n\n'''\n+++\n\n+++"
  },
  "1970": {
    "source_file": "hello-world.txt",
    "text": "800,height=420]\n\n'''\n+++\n\n+++"
  },
  "1971": {
    "source_file": "i18n-groovy-views.txt",
    "text": "title: Internationalizing Messages in Groovy Views\nlayout: developersection\n\n\nWARNING: We do not encourage creating views in Groovy for internationalization, Jelly is the preferred way to do this.\n\nIn Jenkins, you need add a similar `.properties` file with the `.groovy` file in the same directory. Any changes of `.properties` does not need restart Jenkins or plugins.\n\nAs an example, consider the f"
  },
  "1972": {
    "source_file": "i18n-groovy-views.txt",
    "text": "e with the `.groovy` file in the same directory. Any changes of `.properties` does not need restart Jenkins or plugins.\n\nAs an example, consider the following groovy page:\n\n`src/main/resources/org/example/package/index.groovy`:\n\npackage jenkins.security.DownloadSettings\n\ndef f = namespace(lib.FormTagLib)\n\nf.section(title:_(\"title.pluginManager\")) {\n\tf.entry(field: \"useBrowser\", title:_(\"useBrowser"
  },
  "1973": {
    "source_file": "i18n-groovy-views.txt",
    "text": "ity.DownloadSettings\n\ndef f = namespace(lib.FormTagLib)\n\nf.section(title:_(\"title.pluginManager\")) {\n\tf.entry(field: \"useBrowser\", title:_(\"useBrowser\"))\n\t\tf.checkbox(title: _(\"title.browserCheckbox\"))\n\t}\n}\n\nThen you could add, for example, a Chinese localization file simply as:\n\n`src/main/resources/org/example/package/index_zh_CN.properties`:\n\ntitle.pluginManager=\\u63D2\\u4EF6\\u7BA1\\u7406\nfield.us"
  },
  "1974": {
    "source_file": "i18n-groovy-views.txt",
    "text": " localization file simply as:\n\n`src/main/resources/org/example/package/index_zh_CN.properties`:\n\ntitle.pluginManager=\\u63D2\\u4EF6\\u7BA1\\u7406\nfield.useBrowser=\\u4F7F\\u7528\\u6D4F\\u89C8\\u5668\ntitle.browserCheckbox=\\u4F7F\\u7528\\u6D4F\\u89C8\\u5668\\u4E0B\\u8F7D\\u5143\\u6570\\u636E\n\nIn property files all non-ASCII characters need to be converted into hexcode. Modern IDEs do it automatically, so you can be j"
  },
  "1975": {
    "source_file": "i18n-groovy-views.txt",
    "text": "8F7D\\u5143\\u6570\\u636E\n\nIn property files all non-ASCII characters need to be converted into hexcode. Modern IDEs do it automatically, so you can be just writing localizations in the target languages there."
  },
  "1976": {
    "source_file": "i18n-jelly-views.txt",
    "text": "title: Internationalizing Messages in Jelly Views\nlayout: developersection\nreferences:\n- url: https://github.com/stapler/stapler/blob/master/docs/i18n.adoc\n  title: Internalization support in Jelly\n- url: https://commons.apache.org/proper/commons-jexl/\n  title: Apache JEXL\n\n\nJenkins supports internationalizing messages in .\n\nIn Jenkins, you add a `.properties` file with the `.jelly` file in the sa"
  },
  "1977": {
    "source_file": "i18n-jelly-views.txt",
    "text": "l/\n  title: Apache JEXL\n\n\nJenkins supports internationalizing messages in .\n\nIn Jenkins, you add a `.properties` file with the `.jelly` file in the same directory.\nAny changes of `.properties` do not require a restart of Jenkins.\n\nAs an example, consider the following jelly page:\n\n`src/main/resources/org/example/package/index.jelly`:\n\n<?jelly escape-by-default='true'?>\n<j:jelly xmlns:j=\"jelly:core"
  },
  "1978": {
    "source_file": "i18n-jelly-views.txt",
    "text": "ider the following jelly page:\n\n`src/main/resources/org/example/package/index.jelly`:\n\n<?jelly escape-by-default='true'?>\n<j:jelly xmlns:j=\"jelly:core\" xmlns:st=\"jelly:stapler\" xmlns:s=\"/lib/form\">\n<div>${%message}</div>\n</j:jelly>\n\nThen you could add, for example, a Chinese localization file simply as:\n\n`src/main/resources/org/example/package/index_zh_CN.properties`\n\nmessage=\\u6D88\\u606F\n\nPropert"
  },
  "1979": {
    "source_file": "i18n-jelly-views.txt",
    "text": "d, for example, a Chinese localization file simply as:\n\n`src/main/resources/org/example/package/index_zh_CN.properties`\n\nmessage=\\u6D88\\u606F\n\nProperties files should be UTF-8 encoded, at least for core or plugins which already use Java 11 or newer and a core version greater than 2.358.\nMore details can be found in .\nFor older plugins, all non-ASCII characters need to be converted into hexcode.\nMo"
  },
  "1980": {
    "source_file": "i18n-jelly-views.txt",
    "text": "nd a core version greater than 2.358.\nMore details can be found in .\nFor older plugins, all non-ASCII characters need to be converted into hexcode.\nModern IDEs do it automatically, so you can be just writing localizations in the target languages there.\n\nIn some objects a help section can be defined, which loads `html` files. Consider this small example:\n\n`src/main/resources/org/example/package/ind"
  },
  "1981": {
    "source_file": "i18n-jelly-views.txt",
    "text": "e.\n\nIn some objects a help section can be defined, which loads `html` files. Consider this small example:\n\n`src/main/resources/org/example/package/index.jelly`:\n\n<?jelly escape-by-default='true'?>\n<j:jelly xmlns:j=\"jelly:core\" xmlns:st=\"jelly:stapler\" xmlns:s=\"/lib/form\">\n<s:optionalBlock title=\"${%message}\"\n                        help=\"/plugin/PLUGIN_NAME/help-message.html\"\n                     "
  },
  "1982": {
    "source_file": "i18n-jelly-views.txt",
    "text": "\" xmlns:s=\"/lib/form\">\n<s:optionalBlock title=\"${%message}\"\n                        help=\"/plugin/PLUGIN_NAME/help-message.html\"\n                        checked=\"${it.config.message}\"\n                        name=\"message-name\" />\n</j:jelly>\n\nThe `help-message.html` file and localized versions, such as `help-message_de.html` for the german version, should be placed in the `webapp` folder, so that "
  },
  "1983": {
    "source_file": "i18n-jelly-views.txt",
    "text": "lp-message.html` file and localized versions, such as `help-message_de.html` for the german version, should be placed in the `webapp` folder, so that these get copied over to the plugin directory.\nJenkins will take care of loading the correct html to the corresponding language."
  },
  "1984": {
    "source_file": "i18n-jelly-views.txt",
    "text": " the corresponding language."
  },
  "1985": {
    "source_file": "i18n-source-code.txt",
    "text": "title: Internationalizing Messages in Java Source Code\nlayout: developersection\nreferences:\n- url: https://github.com/kohsuke/localizer\n  title: Localizer project on GitHub\n\n\nJenkins uses the https://github.com/kohsuke/localizer[Localizer] library and Maven plugin to implement internationalization.\n\nIts purpose is to generate classes corresponding to groups of Java `.properties` files during the b"
  },
  "1986": {
    "source_file": "i18n-source-code.txt",
    "text": "d Maven plugin to implement internationalization.\n\nIts purpose is to generate classes corresponding to groups of Java `.properties` files during the build process that make the localized texts available in code.\n\nIn Jenkins, Localizer is configured to operate on resource files named `Messages.properties` (and `Messages_XX.properties` for the localized variants).\nDuring the build process of Jenkins"
  },
  "1987": {
    "source_file": "i18n-source-code.txt",
    "text": "o operate on resource files named `Messages.properties` (and `Messages_XX.properties` for the localized variants).\nDuring the build process of Jenkins core and plugins, it generates `Messages` classes from each group of `Messages.properties` files.\n\nAs an example, consider the following resource files:\n\n`src/main/resources/org/example/package/Messages.properties`:\n\nExample.Description = A simple e"
  },
  "1988": {
    "source_file": "i18n-source-code.txt",
    "text": "As an example, consider the following resource files:\n\n`src/main/resources/org/example/package/Messages.properties`:\n\nExample.Description = A simple example for localization\n\n`src/main/resources/org/example/package/Messages_de.properties`:\n\nExample.Description = Ein einfaches Beispiel f\u00fcr Lokalisierung\n\nThe first file is the default localization for the _key_ `description` (used unless a more spec"
  },
  "1989": {
    "source_file": "i18n-source-code.txt",
    "text": "escription = Ein einfaches Beispiel f\u00fcr Lokalisierung\n\nThe first file is the default localization for the _key_ `description` (used unless a more specific localization is available), while the second file provides the German localization. UTF-8 is supported since Jenkins 2.361.1 (Java 11).\n\nLocalizer will generate a class that looks similar to the following from these resource files:\n\npackage org."
  },
  "1990": {
    "source_file": "i18n-source-code.txt",
    "text": "pported since Jenkins 2.361.1 (Java 11).\n\nLocalizer will generate a class that looks similar to the following from these resource files:\n\npackage org.example.package;\n\npublic class Messages {\n    private final static ResourceBundleHolder holder = ResourceBundleHolder.get(Messages.class); // <1> public static String Example_Description() { // <2> return holder.format(\"Example.Description\");\n    }\n\n"
  },
  "1991": {
    "source_file": "i18n-source-code.txt",
    "text": "ourceBundleHolder.get(Messages.class); // <1> public static String Example_Description() { // <2> return holder.format(\"Example.Description\");\n    }\n\n    public static Localizable _Example_Description() { // <3> return new Localizable(holder, \"Example.Description\");\n    }\n}\n\n<1> `ResourceBundleHolder` is an internal utility class wrapping access to the localized `.properties` files\n<2> Generated m"
  },
  "1992": {
    "source_file": "i18n-source-code.txt",
    "text": "e.Description\");\n    }\n}\n\n<1> `ResourceBundleHolder` is an internal utility class wrapping access to the localized `.properties` files\n<2> Generated method returning the localized string for the `Example.Description` property files entry\n<3> Generated method returning the `Localizable` instance for the `Example.Description` property files entry\n\nThe generated methods names  correspond to the key i"
  },
  "1993": {
    "source_file": "i18n-source-code.txt",
    "text": "d method returning the `Localizable` instance for the `Example.Description` property files entry\n\nThe generated methods names  correspond to the key in the properties files (but don't match exactly due to Java identifier constraints).\nEach key in the resource files will result in the generation of a pair of methods: One returning `String`, the other returning `Localizable`.\n`Localizable` is a type"
  },
  "1994": {
    "source_file": "i18n-source-code.txt",
    "text": " resource files will result in the generation of a pair of methods: One returning `String`, the other returning `Localizable`.\n`Localizable` is a type provided by the Localizer library that allows localizing a message to a specific locale.\nThis is rarely needed however, as a call to `Messages.Example_Description()` will return the localized message for the current locale.\n\nIf the values in `Messag"
  },
  "1995": {
    "source_file": "i18n-source-code.txt",
    "text": "rely needed however, as a call to `Messages.Example_Description()` will return the localized message for the current locale.\n\nIf the values in `Messages.properties` reference placeholders, then the static methods will be generated with arguments.\nSee the following example for a `Messages.properties` excerpt and one static method generated from that.\n\n`Messages.properties` content:\n\nItemGroupMixIn."
  },
  "1996": {
    "source_file": "i18n-source-code.txt",
    "text": " the following example for a `Messages.properties` excerpt and one static method generated from that.\n\n`Messages.properties` content:\n\nItemGroupMixIn.may_not_copy_as_it_contains_secrets_and_=May not copy {0} as it contains secrets and {1} has {2}/{3} but not /{4}\n\nGenerated source code:\n\npublic static String ItemGroupMixIn_may_not_copy_as_it_contains_secrets_and_(Object arg0, Object arg1, Object a"
  },
  "1997": {
    "source_file": "i18n-source-code.txt",
    "text": " but not /{4}\n\nGenerated source code:\n\npublic static String ItemGroupMixIn_may_not_copy_as_it_contains_secrets_and_(Object arg0, Object arg1, Object arg2, Object arg3, Object arg4) {\n    return holder.format(\"ItemGroupMixIn.may_not_copy_as_it_contains_secrets_and_\", arg0, arg1, arg2, arg3, arg4);\n}\n\nFor more advanced usage of parameters in localized messages, see ."
  },
  "1998": {
    "source_file": "i18n-source-code.txt",
    "text": "s_secrets_and_\", arg0, arg1, arg2, arg3, arg4);\n}\n\nFor more advanced usage of parameters in localized messages, see ."
  },
  "1999": {
    "source_file": "icon-path-to-icon-class-migration.txt",
    "text": "title: Icon path to icon class migration\nlayout: developer\n\n\nJenkins core has removed `GIF` and `PNG` icons as of Jenkins v2.333, in favor of the previously added SVG icons.\n\nPlugins, that don't interact with icons at all, are unaffected by this change.\n\n* If a plugin reads icons from its icon path, it typically does the following in jelly:\n\n<img src=\"${imagesURL}/16x16/fingerprint.png\" alt=\"\" hei"
  },
  "2000": {
    "source_file": "icon-path-to-icon-class-migration.txt",
    "text": "ge.\n\n* If a plugin reads icons from its icon path, it typically does the following in jelly:\n\n<img src=\"${imagesURL}/16x16/fingerprint.png\" alt=\"\" height=\"16\" width=\"16\" />\n<!-- or -->\n<l:task icon=\"images/24x24/document.png\" href=\"\" title=\"${%Modules}\" />\n\n* or in groovy:\n\nimg(width:\"16\", height:\"16\", src:\"${imagesURL}/16x16/next.gif\")\n\n* A plugin can do that in Java too, but that is, by far, les"
  },
  "2001": {
    "source_file": "icon-path-to-icon-class-migration.txt",
    "text": "s}\" />\n\n* or in groovy:\n\nimg(width:\"16\", height:\"16\", src:\"${imagesURL}/16x16/next.gif\")\n\n* A plugin can do that in Java too, but that is, by far, less common.\n\nJelly offers a couple of properties to access an icon class instead of an icon path. Jenkins core will display a GIF, a PNG or an SVG, based on the Jenkins version used. The properties `<l:icon class>` and `<l:task icon>` are used based on"
  },
  "2002": {
    "source_file": "icon-path-to-icon-class-migration.txt",
    "text": "ins core will display a GIF, a PNG or an SVG, based on the Jenkins version used. The properties `<l:icon class>` and `<l:task icon>` are used based on the location the icon is displayed in.\n\nThe format is `icon-<icon> icon-<size>`. `<icon>` represents the name of the icon that used to be read from a path.\n`<size>` represents the icon size.\nThe following values for `<size>` are available:\n[options="
  },
  "2003": {
    "source_file": "icon-path-to-icon-class-migration.txt",
    "text": "s the name of the icon that used to be read from a path.\n`<size>` represents the icon size.\nThe following values for `<size>` are available:\n[options=\"header\"]\n|=======================\n|Path size attribute|`<size>` attribute\n|16x16    |sm\n|24x24    |md\n|32x32    |lg\n|48x48    |xlg\n|=======================\n\nPick the appropriate `<size>` attribute according to the path size the icon has.\n\nJelly exam"
  },
  "2004": {
    "source_file": "icon-path-to-icon-class-migration.txt",
    "text": "md\n|32x32    |lg\n|48x48    |xlg\n|=======================\n\nPick the appropriate `<size>` attribute according to the path size the icon has.\n\nJelly example:\n\n<l:icon class=\"icon-fingerprint icon-sm\" />\n<!-- or -->\n<l:task icon=\"icon-document icon-md\" href=\"\" title=\"${%Modules}\" />\n\nGroovy example:\n\nl.task(icon:\"icon-next icon-sm\")\n\nMore information about Jelly tags provided by core to display icons "
  },
  "2005": {
    "source_file": "icon-path-to-icon-class-migration.txt",
    "text": "ref=\"\" title=\"${%Modules}\" />\n\nGroovy example:\n\nl.task(icon:\"icon-next icon-sm\")\n\nMore information about Jelly tags provided by core to display icons can be found in its .\n\nContact the  on ."
  },
  "2006": {
    "source_file": "ide-configuration.txt",
    "text": "layout: developersection\ntitle: IDE Configuration\nreferences:\n- url: https://wiki.jenkins.io/display/JENKINS/Developing+with+JRebel\n  title: Developing with JRebel # TODO find someone who can write actual documentation for this\n\n\n (source code https://github.com/jenkinsci/idea-stapler-plugin)\n\nThis IDEA plugin makes it easy to develop Jenkins and its plugins on IntelliJ IDEA\n\nThis plugin has the f"
  },
  "2007": {
    "source_file": "ide-configuration.txt",
    "text": "//github.com/jenkinsci/idea-stapler-plugin)\n\nThis IDEA plugin makes it easy to develop Jenkins and its plugins on IntelliJ IDEA\n\nThis plugin has the following features:\n\n* Cmd+B navigation from the Jelly tags to their definitions\n* Error checks and auto completion on attributes and elements of taglibs\n* Syntax error checks on JEXL expressions\n* \"Go to stapler view\" to jump from a Java class to its"
  },
  "2008": {
    "source_file": "ide-configuration.txt",
    "text": "uto completion on attributes and elements of taglibs\n* Syntax error checks on JEXL expressions\n* \"Go to stapler view\" to jump from a Java class to its views (Cmd+Shift+P)\n* Select a string expression, then \"Refactor\" > \"i18n for Stapler\" to create a message resource\n\nhttp://plugins.netbeans.org/plugin/43938/?show=true\n\nSee: https://code.visualstudio.com/docs/languages/java for useful extensions\n\nC"
  },
  "2009": {
    "source_file": "ide-configuration.txt",
    "text": "message resource\n\nhttp://plugins.netbeans.org/plugin/43938/?show=true\n\nSee: https://code.visualstudio.com/docs/languages/java for useful extensions\n\nCreate the following 2 files in your project:\n\n`~/.vscode/tasks.json`:\n\n{\n    \"version\" : \"2.0.0\",\n    \"tasks\": [\n        {\n            \"label\": \"mvnDebug\",\n            \"type\": \"shell\",\n            \"command\": \"mvnDebug hpi:run\",\n            \"isBackgro"
  },
  "2010": {
    "source_file": "ide-configuration.txt",
    "text": "  \"tasks\": [\n        {\n            \"label\": \"mvnDebug\",\n            \"type\": \"shell\",\n            \"command\": \"mvnDebug hpi:run\",\n            \"isBackground\": true,\n            \"problemMatcher\": [{\n                \"pattern\": [{\n                    \"regexp\": \"\\\\b\\\\B\",\n                    \"file\": 1,\n                    \"location\": 2,\n                    \"message\": 3\n                }],\n                "
  },
  "2011": {
    "source_file": "ide-configuration.txt",
    "text": "xp\": \"\\\\b\\\\B\",\n                    \"file\": 1,\n                    \"location\": 2,\n                    \"message\": 3\n                }],\n                \"background\": {\n                    \"activeOnStart\": true,\n                    \"beginsPattern\": \"^.*Preparing to execute Maven in debug mode.*\",\n                    \"endsPattern\": \"^.*Listening for transport dt_socket at address.*\"\n                }\n"
  },
  "2012": {
    "source_file": "ide-configuration.txt",
    "text": "Preparing to execute Maven in debug mode.*\",\n                    \"endsPattern\": \"^.*Listening for transport dt_socket at address.*\"\n                }\n            }]\n        }\n    ]\n}\n\n`~/.vscode/launch.json`:\n\n{\n    \"configurations\": [\n        {\n            \"type\": \"java\",\n            \"name\": \"Debug (Attach)\",\n            \"request\": \"attach\",\n            \"hostName\": \"localhost\",\n            \"port\""
  },
  "2013": {
    "source_file": "ide-configuration.txt",
    "text": "        \"type\": \"java\",\n            \"name\": \"Debug (Attach)\",\n            \"request\": \"attach\",\n            \"hostName\": \"localhost\",\n            \"port\": \"8000\",\n            \"preLaunchTask\": \"mvnDebug\"\n        }\n    ]\n}\n\n`F5` to start your debug session.\n\nIf there isn't a plugin available for your IDE you can manually add the taglib to your IDE.\n\nXML schemas for tag libraries defined in Jelly, stapl"
  },
  "2014": {
    "source_file": "ide-configuration.txt",
    "text": "n.\n\nIf there isn't a plugin available for your IDE you can manually add the taglib to your IDE.\n\nXML schemas for tag libraries defined in Jelly, stapler, and Jenkins are available. Most modern IDEs and other XML editors can use them to provide auto-completion, which improves your productivity.\nSee  for links to the up-to date schemas."
  },
  "2015": {
    "source_file": "ide-configuration.txt",
    "text": "ompletion, which improves your productivity.\nSee  for links to the up-to date schemas."
  },
  "2016": {
    "source_file": "improve-pipeline-documentation.txt",
    "text": "layout: developersection\ntitle: Improve Pipeline documentation\n\n\nJenkins Pipeline users often  that  more information on specific Pipeline steps and how they are used is needed.\nSee the  for the techniques used there to identify Pipeline documentation issues and improve the Pipeline documentation.\nImprove the help of a Pipeline step in a single plugin to help users of that Pipeline step.\n\nRemind u"
  },
  "2017": {
    "source_file": "improve-pipeline-documentation.txt",
    "text": "n issues and improve the Pipeline documentation.\nImprove the help of a Pipeline step in a single plugin to help users of that Pipeline step.\n\nRemind users that the Pipeline Syntax Snippet Generator is available and can answer many questions."
  },
  "2018": {
    "source_file": "incompatible-releases.txt",
    "text": "title: Marking Incompatible Releases\nsummary: How to mark a plugin release as having incompatible on-disk format changes.\nlayout: developersection\n\n\nNOTE: The need for this should be rare. Jenkins has an automatic data format upgrade capability, which should be used whenever possible for the best user experience.\n\nAt times, changes will be made to a plugin which result in the new version of the pl"
  },
  "2019": {
    "source_file": "incompatible-releases.txt",
    "text": "h should be used whenever possible for the best user experience.\n\nAt times, changes will be made to a plugin which result in the new version of the plugin no longer being compatible with the configuration used for older versions.\nWhen this is the case, you will probably want to be sure that your plugin's users are aware of this incompatibility.\nThere is now (as of version 1.322 of Jenkins and vers"
  },
  "2020": {
    "source_file": "incompatible-releases.txt",
    "text": "e, you will probably want to be sure that your plugin's users are aware of this incompatibility.\nThere is now (as of version 1.322 of Jenkins and version 1.42 of `maven-hpi-plugin`) support for marking the oldest version which is compatible with the configuration of your plugin's current version.\n\nStarting with https://github.com/jenkinsci/plugin-pom/blob/master/CHANGELOG.md#333[plugin parent POM "
  },
  "2021": {
    "source_file": "incompatible-releases.txt",
    "text": "configuration of your plugin's current version.\n\nStarting with https://github.com/jenkinsci/plugin-pom/blob/master/CHANGELOG.md#333[plugin parent POM 3.33],\nit is possible to set the `hpi.compatibleSinceVersion` property to define the oldest compatible version.\n\n<properties>\n  <jenkins.version>2.289.3</jenkins.version>\n  <hpi.compatibleSinceVersion>1.0</hpi.compatibleSinceVersion>\n</properties>\n\nI"
  },
  "2022": {
    "source_file": "incompatible-releases.txt",
    "text": "le version.\n\n<properties>\n  <jenkins.version>2.289.3</jenkins.version>\n  <hpi.compatibleSinceVersion>1.0</hpi.compatibleSinceVersion>\n</properties>\n\nIf you use an older plugin parent POM (not recommended), add the following to your plugin's POM file:\n\n<build>\n  <plugins>\n    <plugin>\n      <groupId>org.jenkins-ci.tools</groupId>\n      <artifactId>maven-hpi-plugin</artifactId>\n      <extensions>tru"
  },
  "2023": {
    "source_file": "incompatible-releases.txt",
    "text": "\n\n<build>\n  <plugins>\n    <plugin>\n      <groupId>org.jenkins-ci.tools</groupId>\n      <artifactId>maven-hpi-plugin</artifactId>\n      <extensions>true</extensions>\n      <configuration>\n        <compatibleSinceVersion>1.0</compatibleSinceVersion>\n      </configuration>\n    </plugin>\n  </plugins>\n</build>\n\nYou only need to specify the `maven-hpi-plugin` version if your plugin's parent POM is versi"
  },
  "2024": {
    "source_file": "incompatible-releases.txt",
    "text": "    </configuration>\n    </plugin>\n  </plugins>\n</build>\n\nYou only need to specify the `maven-hpi-plugin` version if your plugin's parent POM is version 1.321 or earlier.\nLater versions of the plugin parent POM will get the proper `maven-hpi-plugin` version automatically.\n`compatibleSinceVersion` should be the oldest version which is compatible with the configuration for the new version of your pl"
  },
  "2025": {
    "source_file": "incompatible-releases.txt",
    "text": "version automatically.\n`compatibleSinceVersion` should be the oldest version which is compatible with the configuration for the new version of your plugin.\nIf your new version is not configuration-compatible with any previous versions, `compatibleSinceVersion` would use the new version number.\n\nWhen a new plugin version is available as an update, and that new plugin version has a `compatibleSinceV"
  },
  "2026": {
    "source_file": "incompatible-releases.txt",
    "text": "ceVersion` would use the new version number.\n\nWhen a new plugin version is available as an update, and that new plugin version has a `compatibleSinceVersion` defined,\nthe Update Center will check to see whether the installed version of the plugin is compatible with the new plugin.\nIf the installed version is not configuration-compatible,\nthe plugin will show up in the available updates list with a"
  },
  "2027": {
    "source_file": "incompatible-releases.txt",
    "text": "compatible with the new plugin.\nIf the installed version is not configuration-compatible,\nthe plugin will show up in the available updates list with a note, in red, that jobs may need to be reconfigured."
  },
  "2028": {
    "source_file": "incrementals.txt",
    "text": "layout: developersection\ntitle: \"Incrementals: Developing Components in Parallel\"\ntags:\n- jenkins\n- incrementals\n- core\n- plugin\ndescription: \"This article explains how to use Incrementals for developing plugins in parallel with Jenkins core\"\n\n\nA problem one might stumble upon is developing an API in Jenkins core and simultaneously building a reference\nimplementation inside a plugin.\nAnother simil"
  },
  "2029": {
    "source_file": "incrementals.txt",
    "text": "blem one might stumble upon is developing an API in Jenkins core and simultaneously building a reference\nimplementation inside a plugin.\nAnother similar but maybe more common problem could be developing an API in a base plugin (upstream) and consuming it\nin a more specific plugin (downstream).\nWhat to do, one might ask.\n\nWorry not, incrementals are here to the rescue!\n\nWith incrementals, we can cr"
  },
  "2030": {
    "source_file": "incrementals.txt",
    "text": "g it\nin a more specific plugin (downstream).\nWhat to do, one might ask.\n\nWorry not, incrementals are here to the rescue!\n\nWith incrementals, we can create incremental versions of Jenkins core or an upstream plugin on which the under\ndevelopment downstream plugin can depend upon.\nIt also allows keeping track and switching between incremental versions.\nAnother advantage is that it allows others to t"
  },
  "2031": {
    "source_file": "incrementals.txt",
    "text": "tream plugin can depend upon.\nIt also allows keeping track and switching between incremental versions.\nAnother advantage is that it allows others to test and collaborate more easily on the project!\n\nSounds cool? Let's see how to go about it.\nIn this tutorial, we explain with the example of developing an API in core and consuming it in a plugin.\nHowever these steps are very similar for when using a"
  },
  "2032": {
    "source_file": "incrementals.txt",
    "text": "tutorial, we explain with the example of developing an API in core and consuming it in a plugin.\nHowever these steps are very similar for when using an upstream plugin instead of Jenkins core.\n\nThis article is meant to be a quickstart for the consumption of incrementals.\nFor more details, please refer to the .\n\nInside the (downstream) plugin, which is supposed to be the API consumer, you can enabl"
  },
  "2033": {
    "source_file": "incrementals.txt",
    "text": "tion of incrementals.\nFor more details, please refer to the .\n\nInside the (downstream) plugin, which is supposed to be the API consumer, you can enable incrementals by running:\n\nmvn incrementals:incrementalify\n\nNext step is to  by clicking the \"New Pull\nRequest\" button and push the changes (your new API) to Jenkins core.\nIf instead you are developing the API inside an upstream plugin, then do the "
  },
  "2034": {
    "source_file": "incrementals.txt",
    "text": "ull\nRequest\" button and push the changes (your new API) to Jenkins core.\nIf instead you are developing the API inside an upstream plugin, then do the above in the upstream plugin repository.\n\nNote: Make sure that your branch has the latest changes from master, otherwise incrementals version\nwill NOT be created.\nYou can do this either by rebasing or by merging the latest changes from the master bra"
  },
  "2035": {
    "source_file": "incrementals.txt",
    "text": "om master, otherwise incrementals version\nwill NOT be created.\nYou can do this either by rebasing or by merging the latest changes from the master branch.\n\nWait for Jenkins to perform checks.\n\nAfter the checks are completed, you should get a message like below:\n\nClick on 'Details' adjacent to 'continuous-integration/jenkins/incrementals \u2014 Deployed to Incrementals.'\n\nNote: If you only see one Githu"
  },
  "2036": {
    "source_file": "incrementals.txt",
    "text": "like below:\n\nClick on 'Details' adjacent to 'continuous-integration/jenkins/incrementals \u2014 Deployed to Incrementals.'\n\nNote: If you only see one Github check 'continuous-integration/jenkins/pr-merge \u2014 This commit looks good' then there\nis an error due to which incrementals version was not created.\nOne of the most likely reasons is that latest changes from master have not been pulled into the branc"
  },
  "2037": {
    "source_file": "incrementals.txt",
    "text": "e to which incrementals version was not created.\nOne of the most likely reasons is that latest changes from master have not been pulled into the branch.\nYou can click on 'Details' adjacent to it to investigate this error from the logs.\n\nYou should be redirected to a page like below:\n\nCopy the version ID, which in this example would be `2.238-rc29961.5c3c5871cca6`.\n\nInstead, you can also run the fo"
  },
  "2038": {
    "source_file": "incrementals.txt",
    "text": " redirected to a page like below:\n\nCopy the version ID, which in this example would be `2.238-rc29961.5c3c5871cca6`.\n\nInstead, you can also run the following in the upstream repository to obtain the incrementals version:\n```\nmvn -Dset.changelist validate\n```\n\nThere are two changes you want to make to your plugin POM.\n\nFirst, update the Jenkins version to the version ID copied in the previous step:"
  },
  "2039": {
    "source_file": "incrementals.txt",
    "text": "date\n```\n\nThere are two changes you want to make to your plugin POM.\n\nFirst, update the Jenkins version to the version ID copied in the previous step:\n\n```\n...\n    <properties>\n        <jenkins.version>2.238-rc29961.5c3c5871cca6</jenkins.version>\n        ...\n    </properties>\n...\n```\n\nIn case of upstream plugin, add its version in the `<version>` of your `<dependency>` inside the downstream plugin"
  },
  "2040": {
    "source_file": "incrementals.txt",
    "text": "     ...\n    </properties>\n...\n```\n\nIn case of upstream plugin, add its version in the `<version>` of your `<dependency>` inside the downstream plugin.\n\nNow you can run your project like you normally do (say using `hpi:run`), and Jenkins will it automatically run it\nagainst the incrementals version of the upstream project you specified."
  },
  "2041": {
    "source_file": "incrementals.txt",
    "text": "matically run it\nagainst the incrementals version of the upstream project you specified."
  },
  "2042": {
    "source_file": "index.txt",
    "text": "layout: documentation\ntitle: Tutorials overview\nsection: doc\n\n\nThis part of the Jenkins User Documentation contains a series of introductory\ntutorials to help you begin building your applications in an automated fashion\nwith Jenkins.\n\nIf you're a developer who wants to improve your understanding of Continuous\nIntegration (CI) / Continuous Delivery (CD) concepts, or you might already be\nfamiliar wi"
  },
  "2043": {
    "source_file": "index.txt",
    "text": "eloper who wants to improve your understanding of Continuous\nIntegration (CI) / Continuous Delivery (CD) concepts, or you might already be\nfamiliar with these concepts but don't yet know how to implement them in\nJenkins, then these tutorials are a great place to start.\n\n[[getting-started]]\n\n*\n\n[[pipeline]]\n\nThe following tutorials show how to use key features of Jenkins to facilitate implementing "
  },
  "2044": {
    "source_file": "index.txt",
    "text": "eat place to start.\n\n[[getting-started]]\n\n*\n\n[[pipeline]]\n\nThe following tutorials show how to use key features of Jenkins to facilitate implementing CI/CD\nprocesses to build your applications:\n\n*\n* Publishing HTML Reports in Pipeline (, )\n* Sending Notifications in Pipeline (, )\n*\n*\n*\n*\n*\n\n[[tools]]\n\nThe following tutorials show how to use Jenkins to cover the basics of CI/CD\nconcepts based on sp"
  },
  "2045": {
    "source_file": "index.txt",
    "text": "Notifications in Pipeline (, )\n*\n*\n*\n*\n*\n\n[[tools]]\n\nThe following tutorials show how to use Jenkins to cover the basics of CI/CD\nconcepts based on specific technology stacks.\n\nChoose the tutorial that's relevant to your technology stack or one that you're\nmost familiar with:\n\n*\n*\n*\n*\n*\n*\n*\n\nCloud tutorials are available including:\n\n*\n*\n\nYou may find more tutorials in .\n\n*\n*\n*\n\n[[blueocean]]\n\nNOTE"
  },
  "2046": {
    "source_file": "index.txt",
    "text": "you're\nmost familiar with:\n\n*\n*\n*\n*\n*\n*\n*\n\nCloud tutorials are available including:\n\n*\n*\n\nYou may find more tutorials in .\n\n*\n*\n*\n\n[[blueocean]]\n\nNOTE: Blue Ocean is no longer being actively maintained.\nThese tutorials will continue to work until Blue Ocean is completely deprecated, at which point the tutorials will be removed from the documentation.\n\n*\n* Getting Started with Blue Ocean's Visual P"
  },
  "2047": {
    "source_file": "index.txt",
    "text": "e Ocean is completely deprecated, at which point the tutorials will be removed from the documentation.\n\n*\n* Getting Started with Blue Ocean's Visual Pipeline Editor (, )\n*\n*\n\n'''\n+++\n\n+++"
  },
  "2048": {
    "source_file": "initial-settings.txt",
    "text": "layout: section\ntitle: Initial Settings\n\n\nifdef::env-github[:imagesdir: ../resources]\nifndef::env-github[:imagesdir: ../../resources]\n\nMost Jenkins configuration changes can be made through the Jenkins user interface or through the plugin:configuration-as-code[configuration as code plugin].\nThere are some configuration values that can only be modified while Jenkins is starting.\nThis section descri"
  },
  "2049": {
    "source_file": "initial-settings.txt",
    "text": "on-as-code[configuration as code plugin].\nThere are some configuration values that can only be modified while Jenkins is starting.\nThis section describes those settings and how you can use them.\n\nJenkins initialization can also be controlled by run time parameters passed as arguments.\nCommand line arguments can adjust networking, security, monitoring, and other settings."
  },
  "2050": {
    "source_file": "initial-settings.txt",
    "text": "ime parameters passed as arguments.\nCommand line arguments can adjust networking, security, monitoring, and other settings."
  },
  "2051": {
    "source_file": "installing.txt",
    "text": "layout: redirect\nredirect_url: ../../installing"
  },
  "2052": {
    "source_file": "intellij.txt",
    "text": "layout: developersection\ntitle: \"IntelliJ Setup for Jenkins Core Development\"\ntags:\n- jenkins\n- tutorial\n- intellij\n- setup\n- ide\ndescription: \"This article is a walk-through guide on how to setup IntelliJ IDEA to develop and debug Jenkins core.\"\n\n\nThis article is a walk-through guide on how to setup IntelliJ IDEA to develop and debug Jenkins core.\n\nIndex:\n\n1. Installation and Cloning\n2. Setting u"
  },
  "2053": {
    "source_file": "intellij.txt",
    "text": "his article is a walk-through guide on how to setup IntelliJ IDEA to develop and debug Jenkins core.\n\nIndex:\n\n1. Installation and Cloning\n2. Setting up IntelliJ IDEA\n3. Building Jenkins\n4. Debugging\n\n** Install IntelliJ using the .\n** The minimum Apache Maven version for Jenkins development is 3.9.6.\nRefer to  if needed.\n** Fork from the .\n** Clone the forked repository to your machine.\nIn this tu"
  },
  "2054": {
    "source_file": "intellij.txt",
    "text": "che Maven version for Jenkins development is 3.9.6.\nRefer to  if needed.\n** Fork from the .\n** Clone the forked repository to your machine.\nIn this tutorial, IntelliJ IDEA Version 2019.3.1 is used.\n\nOpen IntelliJ IDEA.\n\nClick on Import Project, and in the popup, choose the directory where Jenkins had been cloned.\n\nSelect \u2018Create project from existing sources\u2019, and click on Next.\n\nClick on Next\n\nCl"
  },
  "2055": {
    "source_file": "intellij.txt",
    "text": "n the popup, choose the directory where Jenkins had been cloned.\n\nSelect \u2018Create project from existing sources\u2019, and click on Next.\n\nClick on Next\n\nClick on Next\n\nClick on Next\n\nClick on Finish. IntelliJ should be ready like below.\n\nNow we want to build Jenkins. Run the following: (This will prepare the jenkins.war file without running tests)\n\n mvn -am -pl war,bom -DskipTests -Dspotbugs.skip clean"
  },
  "2056": {
    "source_file": "intellij.txt",
    "text": "ild Jenkins. Run the following: (This will prepare the jenkins.war file without running tests)\n\n mvn -am -pl war,bom -DskipTests -Dspotbugs.skip clean install\n\nThis may take a little time. If everything works well, you should get a successful build result like below:\n\nNow, we can run Jenkins on our local machine using the following command:\n\n mvn -pl war jetty:run\n\nIf it runs successfully, you sho"
  },
  "2057": {
    "source_file": "intellij.txt",
    "text": "esult like below:\n\nNow, we can run Jenkins on our local machine using the following command:\n\n mvn -pl war jetty:run\n\nIf it runs successfully, you should be able to view Jenkins console by going to http://localhost:8080/jenkins/\n\nNow, our next goal is to be able to debug Jenkins by using breakpoints in IntelliJ. Close the previous running instance by (Ctr+c).\n\nIn the toolbar, go to Run -> Edit Con"
  },
  "2058": {
    "source_file": "intellij.txt",
    "text": "s to be able to debug Jenkins by using breakpoints in IntelliJ. Close the previous running instance by (Ctr+c).\n\nIn the toolbar, go to Run -> Edit Configurations\u2026\n\nClick on the \u2018+\u2019 icon so we can add a new configuration.\n\nClick on \u2018Maven\u2019.\n\nEnsure that this configuration is the same as above. Click on Apply and OK.\n\nNow, you can choose either Run \u2018Maven Run\u2019 or Debug \u2018Maven Run\u2019 based on what you "
  },
  "2059": {
    "source_file": "intellij.txt",
    "text": "at this configuration is the same as above. Click on Apply and OK.\n\nNow, you can choose either Run \u2018Maven Run\u2019 or Debug \u2018Maven Run\u2019 based on what you would like to do. Breakpoints can easily be applied alongside the code in the IDE.\n\nMoreover, Groovy/Jelly views are re-compiled every time a browser requests a page so that the changes can be observed with just a simple browser refresh. This is also"
  },
  "2060": {
    "source_file": "intellij.txt",
    "text": "/Jelly views are re-compiled every time a browser requests a page so that the changes can be observed with just a simple browser refresh. This is also true for help files.\n\nAlso, you can run \u2018Build\u2019 in IntelliJ to hot-swap code, which means that some changes like method bodies and annotations changes will take effect without having to restart Jenkins."
  },
  "2061": {
    "source_file": "intellij.txt",
    "text": " changes like method bodies and annotations changes will take effect without having to restart Jenkins."
  },
  "2062": {
    "source_file": "internationalization-and-localization.txt",
    "text": "title: Internationalization and Localization\nlayout: developersection\n\n\nDevelopers must do the following to localize a plugin or other module:\n\n(Optional)\n\n shows the detailed internationalization steps.\nThe  documentation provides guidance for more sophisticated internationalization, like date formatting, time formatting, and number formatting.\n\nThe Jenkins project always welcomes contributions t"
  },
  "2063": {
    "source_file": "internationalization-and-localization.txt",
    "text": "sophisticated internationalization, like date formatting, time formatting, and number formatting.\n\nThe Jenkins project always welcomes contributions to translations.\nIf you are interested in helping us, just file a pull request on GitHub.\nIn the remainder of this section, we discuss what needs to be translated and how.\n\n[cols=\"\",]\n|===\n|Remember that properties files must be encoded in .\nThis shou"
  },
  "2064": {
    "source_file": "internationalization-and-localization.txt",
    "text": "inder of this section, we discuss what needs to be translated and how.\n\n[cols=\"\",]\n|===\n|Remember that properties files must be encoded in .\nThis should be the default anyway.\n|===\n\n*  : Command line tool to help translators to generate files, add missing keys, and more.\n*  : Adds a dialog box in Jenkins to translate and send missing keys.\n\nDevelopers place messages that require localization in `+"
  },
  "2065": {
    "source_file": "internationalization-and-localization.txt",
    "text": "ssing keys, and more.\n*  : Adds a dialog box in Jenkins to translate and send missing keys.\n\nDevelopers place messages that require localization in `+Messages.properties+`.\nThose need to be translated in the usual manner.\nSee `+Messages_ja.properties+` in the core as an example if you are new to this process.\n\nIf looking at `+Messages.properties+` alone does not give you enough contextual informat"
  },
  "2066": {
    "source_file": "internationalization-and-localization.txt",
    "text": "+` in the core as an example if you are new to this process.\n\nIf looking at `+Messages.properties+` alone does not give you enough contextual information about where the messages are used.\nYou can access messages with the type-safe `+Messages+` class generated by\nTo find out where messages are actually used, use your IDE to find all the usages of the message format method.\n\nStand-alone HTML files "
  },
  "2067": {
    "source_file": "internationalization-and-localization.txt",
    "text": " generated by\nTo find out where messages are actually used, use your IDE to find all the usages of the message format method.\n\nStand-alone HTML files are often used in Jenkins for things like inline help messages.\nTo translate these resources, add the locale code between the file name and the extension.\nFor example, the Japanese version of `+abc.html+` would be `+abc_ja.html+`, and the British ver"
  },
  "2068": {
    "source_file": "internationalization-and-localization.txt",
    "text": "e locale code between the file name and the extension.\nFor example, the Japanese version of `+abc.html+` would be `+abc_ja.html+`, and the British version of it could be `+abc_en_GB.html+`.\nThese files must be encoded in UTF-8.\n\nAfter successfully testing the changes interactively, submit a pull request to propose the changes.\nInstructions for localization pull requests to Jenkins core are availab"
  },
  "2069": {
    "source_file": "internationalization-and-localization.txt",
    "text": "sting the changes interactively, submit a pull request to propose the changes.\nInstructions for localization pull requests to Jenkins core are available in the .\nPlugins that use Crowdin for translation can follow the .\nPlugins that do not use Crowdin for translation should submit a pull request according to the contributing guide for the specific plugin.\n\nWhen starting a translation, try to check"
  },
  "2070": {
    "source_file": "internationalization-and-localization.txt",
    "text": "n for translation should submit a pull request according to the contributing guide for the specific plugin.\n\nWhen starting a translation, try to check if anyone else is working on the same locale.\nYou can find out who they are by finding existing localization and looking at its history.\nTry to get in touch with them to avoid a surprise.\n\nRefactoring the existing code to handle i18n correctly is te"
  },
  "2071": {
    "source_file": "internationalization-and-localization.txt",
    "text": "alization and looking at its history.\nTry to get in touch with them to avoid a surprise.\n\nRefactoring the existing code to handle i18n correctly is tedious.\nSo  is developed to simplify this.\n\n// == Stapler plugin for NetBeans\n//\n// See\n// https://github.com/stapler/netbeans-stapler-plugin[NetBeans\n// plugin for Stapler] for details."
  },
  "2072": {
    "source_file": "internationalization-and-localization.txt",
    "text": "thub.com/stapler/netbeans-stapler-plugin[NetBeans\n// plugin for Stapler] for details."
  },
  "2073": {
    "source_file": "java.txt",
    "text": "layout: redirect\nredirect_url: /doc/book/platform-information/support-policy-java/"
  },
  "2074": {
    "source_file": "jelly-form-controls.txt",
    "text": "title: Jelly form controls\nlayout: developersection\nreferences:\n- url: https://github.com/jenkinsci/design-library-plugin\n  title: design-library-plugin\n\n\nMost of the jelly files in the Jenkins source have embedded documentation. See  for details on how to get this setup so you can click through to it in your IDE.\n\nFor example you can see the embedded documentation of .\n\nYou can also have a look a"
  },
  "2075": {
    "source_file": "jelly-form-controls.txt",
    "text": "how to get this setup so you can click through to it in your IDE.\n\nFor example you can see the embedded documentation of .\n\nYou can also have a look at the referenced **design-library-plugin**, this repository contains executable examples of user interface elements, including forms. You can also check the live version in\n\n* jelly definition\n\nThis tag creates a right-aligned button for performing s"
  },
  "2076": {
    "source_file": "jelly-form-controls.txt",
    "text": "erface elements, including forms. You can also check the live version in\n\n* jelly definition\n\nThis tag creates a right-aligned button for performing server-side validation. It is suitable for situations where the validation depends on the values of multiple input fields, such as credential check that uses both username and password.\n\n<f:entry title=\"${%Access Key ID}\">\n  <f:textbox field=\"accessId"
  },
  "2077": {
    "source_file": "jelly-form-controls.txt",
    "text": "ultiple input fields, such as credential check that uses both username and password.\n\n<f:entry title=\"${%Access Key ID}\">\n  <f:textbox field=\"accessId\" />\n</f:entry>\n<f:entry title=\"${%Secret Access Key}\">\n  <f:password field=\"secretKey\" />\n</f:entry>\n<f:validateButton\n   title=\"${%Test Connection}\" progress=\"${%Testing...}\"\n   method=\"testConnection\" with=\"secretKey,accessId\" />\n\nThe `title` attr"
  },
  "2078": {
    "source_file": "jelly-form-controls.txt",
    "text": ">\n<f:validateButton\n   title=\"${%Test Connection}\" progress=\"${%Testing...}\"\n   method=\"testConnection\" with=\"secretKey,accessId\" />\n\nThe `title` attribute is used to determine the text written on the button. The `progress` attribute determines the message displayed while the server-side validation is in progress. The `method` attribute specifies the server-side method invoked by this button; this"
  },
  "2079": {
    "source_file": "jelly-form-controls.txt",
    "text": "essage displayed while the server-side validation is in progress. The `method` attribute specifies the server-side method invoked by this button; this follows the stapler name mangling convention, so for example `method=\"testConnection\"` will invoke the `doTestConnection` method. This method needs to be on the Descriptor class that owns this form fragment.\n\nThe `with` attribute specifies the input"
  },
  "2080": {
    "source_file": "jelly-form-controls.txt",
    "text": "the `doTestConnection` method. This method needs to be on the Descriptor class that owns this form fragment.\n\nThe `with` attribute specifies the input fields sent to the server for the validation. They are matched against the `field` attribute or the `name` attribute of other input controls. The values of the nearest input fields above the `<f:validateButton/>` are sent to the server, so this mean"
  },
  "2081": {
    "source_file": "jelly-form-controls.txt",
    "text": " `name` attribute of other input controls. The values of the nearest input fields above the `<f:validateButton/>` are sent to the server, so this means the button has to come after the input fields. Multiple fields can be specified by using ','.\n\nOn the server side, this tag invokes the standard \"do\"-style method like this:\n\n@POST\npublic FormValidation doTestConnection(@QueryParameter(\"accessId\") "
  },
  "2082": {
    "source_file": "jelly-form-controls.txt",
    "text": "the server side, this tag invokes the standard \"do\"-style method like this:\n\n@POST\npublic FormValidation doTestConnection(@QueryParameter(\"accessId\") final String accessId,\n        @QueryParameter(\"secretKey\") final String secretKey,\n        @AncestorInPath Job job) throws IOException, ServletException {\n    try {\n         if (job == null) {\n             Jenkins.get().checkPermission(Jenkins.ADMIN"
  },
  "2083": {
    "source_file": "jelly-form-controls.txt",
    "text": "rInPath Job job) throws IOException, ServletException {\n    try {\n         if (job == null) {\n             Jenkins.get().checkPermission(Jenkins.ADMINISTER);\n         } else {\n             job.checkPermission(Item.CONFIGURE);\n         }\n        ... do some tests ...\n        return FormValidation.ok(\"Success\");\n    } catch (EC2Exception e) {\n        return FormValidation.error(\"Client error : \"+e.g"
  },
  "2084": {
    "source_file": "jelly-form-controls.txt",
    "text": "o some tests ...\n        return FormValidation.ok(\"Success\");\n    } catch (EC2Exception e) {\n        return FormValidation.error(\"Client error : \"+e.getMessage());\n    }\n}\n\nThe `doTestConnection` method contains the validation logic. In the end, this method has to call either `FormValidation.ok`, `.warning`, or `.error` method. Depending on which method you use, the appropriate HTML will be render"
  },
  "2085": {
    "source_file": "jelly-form-controls.txt",
    "text": " method has to call either `FormValidation.ok`, `.warning`, or `.error` method. Depending on which method you use, the appropriate HTML will be rendered on the client side to indicate the status to the user.\n\n* jelly definition\n\nExpandable section that shows \"advanced...\" button by default. Upon clicking it, a section unfolds.\n\n<f:section title=\"Advanced Project Options\">\n  <f:advanced>\n    <st:in"
  },
  "2086": {
    "source_file": "jelly-form-controls.txt",
    "text": "at shows \"advanced...\" button by default. Upon clicking it, a section unfolds.\n\n<f:section title=\"Advanced Project Options\">\n  <f:advanced>\n    <st:include page=\"configure-advanced.jelly\" />\n  </f:advanced>\n</f:section>\n\n* jelly definition\n\nFoldable block expanded when the menu item is checked.\n\n<f:block>\n  <table>\n    <f:optionalBlock name=\"dynamic\" title=\"Use existing dynamic view\">\n      <f:ent"
  },
  "2087": {
    "source_file": "jelly-form-controls.txt",
    "text": "block expanded when the menu item is checked.\n\n<f:block>\n  <table>\n    <f:optionalBlock name=\"dynamic\" title=\"Use existing dynamic view\">\n      <f:entry title=\"View drive\">\n        <f:textbox name=\"drive\" value=\"${it.drive}\"/>\n      </f:entry>\n    </f:optionalBlock>\n  </table>\n</f:block>\n\nUnchecked the text box will not be displayed\nChecked the text box is displayed\n\nUse an  tag to enclose the nor"
  },
  "2088": {
    "source_file": "jelly-form-controls.txt",
    "text": "f:optionalBlock>\n  </table>\n</f:block>\n\nUnchecked the text box will not be displayed\nChecked the text box is displayed\n\nUse an  tag to enclose the normal select tag.\n\n<f:entry name=\"goalType\" title=\"Choose Goal Type\" field=\"goalType\">\n    <select name=\"goalType\">\n        <option value=\"buildGoal\">Build Goal</option>\n        <option value=\"spotBugsGoal\">SpotBugs goal</option>\n    </select>\n</f:entr"
  },
  "2089": {
    "source_file": "jelly-form-controls.txt",
    "text": "e=\"goalType\">\n        <option value=\"buildGoal\">Build Goal</option>\n        <option value=\"spotBugsGoal\">SpotBugs goal</option>\n    </select>\n</f:entry>\n\nBasically the same as above. You need to define the following method in the descriptor of your Describable instance:\n\npublic ListBoxModel doFillGoalTypeItems() {\n    ListBoxModel items = new ListBoxModel();\n\n    items.add(\"Build Goal\", \"buildGoal"
  },
  "2090": {
    "source_file": "jelly-form-controls.txt",
    "text": "escribable instance:\n\npublic ListBoxModel doFillGoalTypeItems() {\n    ListBoxModel items = new ListBoxModel();\n\n    items.add(\"Build Goal\", \"buildGoal\");\n    items.add(\"SpotBugs goal\", \"spotBugsGoal\");\n\n    return items;\n}\n\nThen, use an `<f:entry>` tag to enclose the normal select tag.\n\n<f:entry field=\"goalType\" title=\"Choose Goal Type\">\n   <f:select />\n</f:entry>\n\n* jelly definition\n\nMost form el"
  },
  "2091": {
    "source_file": "jelly-form-controls.txt",
    "text": "ag to enclose the normal select tag.\n\n<f:entry field=\"goalType\" title=\"Choose Goal Type\">\n   <f:select />\n</f:entry>\n\n* jelly definition\n\nMost form elements allow you to have inline help generated by adding a small HTML file and following some conventions.\n\nFor example the `<f:entry>` tag uses the `field` attribute.\n\nGiven a file in src/main/resources/myForm.jelly with this content:\n\n<f:entry titl"
  },
  "2092": {
    "source_file": "jelly-form-controls.txt",
    "text": "tions.\n\nFor example the `<f:entry>` tag uses the `field` attribute.\n\nGiven a file in src/main/resources/myForm.jelly with this content:\n\n<f:entry title=\"Name\" field=\"name\">\n    <f:textbox />\n</f:entry>\n\nAdding a src/main/resources/help-name.html:\n\n<div>\nThis is my content to help the end user understanding how to use this field.\n</div>\n\nWill automatically display the help button with the `<div>..."
  },
  "2093": {
    "source_file": "jelly-form-controls.txt",
    "text": "iv>\nThis is my content to help the end user understanding how to use this field.\n</div>\n\nWill automatically display the help button with the `<div>...</div>` content.\n\n* Most controls support `help.html` as overall help for the `Describable`.\n\n* The help message can be overridden in jelly with the `help` attribute, but please use the convention `help-fieldName.html` as much as possible.\n\n* It is a"
  },
  "2094": {
    "source_file": "jelly-form-controls.txt",
    "text": "help message can be overridden in jelly with the `help` attribute, but please use the convention `help-fieldName.html` as much as possible.\n\n* It is also possible to use localized help files, with the language specific suffix, so `help-fieldName.html` gets `help-fieldName_de.html` for the german version.\n\n<f:entry title=\"This is a nice Title\"  help=\"/plugin/my-plugin/help/custom-file.html\">"
  },
  "2095": {
    "source_file": "jelly-form-controls.txt",
    "text": "` gets `help-fieldName_de.html` for the german version.\n\n<f:entry title=\"This is a nice Title\"  help=\"/plugin/my-plugin/help/custom-file.html\">"
  },
  "2096": {
    "source_file": "jenkins-on-java-11.txt",
    "text": "layout: redirect\nredirect_url: /doc/book/installing/"
  },
  "2097": {
    "source_file": "jenkins-on-java-17.txt",
    "text": "layout: redirect\nredirect_url: /doc/book/installing/"
  },
  "2098": {
    "source_file": "jenkinsfile.txt",
    "text": "layout: section\ntitle: Using a Jenkinsfile\n\n\nThis section builds on the information covered in  and introduces more useful steps, common patterns, and demonstrates some non-trivial `Jenkinsfile` examples.\n\nCreating a `Jenkinsfile`, which is checked into source control footnote:scm[https://en.wikipedia.org/wiki/Source_control_management], provides a number of immediate benefits:\n\n* Code review/iter"
  },
  "2099": {
    "source_file": "jenkinsfile.txt",
    "text": "nto source control footnote:scm[https://en.wikipedia.org/wiki/Source_control_management], provides a number of immediate benefits:\n\n* Code review/iteration on the Pipeline\n* Audit trail for the Pipeline\n* Single source of truth footnote:[https://en.wikipedia.org/wiki/Single_Source_of_Truth] for the Pipeline, which can be viewed and edited by multiple members of the project.\n\nPipeline supports , De"
  },
  "2100": {
    "source_file": "jenkinsfile.txt",
    "text": "ikipedia.org/wiki/Single_Source_of_Truth] for the Pipeline, which can be viewed and edited by multiple members of the project.\n\nPipeline supports , Declarative (introduced in Pipeline 2.5) and Scripted Pipeline.\nBoth of which support building continuous delivery pipelines.\nBoth may be used to define a Pipeline in either the web UI or with a `Jenkinsfile`, though it's generally considered a best pr"
  },
  "2101": {
    "source_file": "jenkinsfile.txt",
    "text": "ous delivery pipelines.\nBoth may be used to define a Pipeline in either the web UI or with a `Jenkinsfile`, though it's generally considered a best practice to create a `Jenkinsfile` and check the file into the source control repository.\n\nAs discussed in the , a `Jenkinsfile` is a text file that contains the definition of a Jenkins Pipeline and is checked into source control.\nConsider the followin"
  },
  "2102": {
    "source_file": "jenkinsfile.txt",
    "text": "d in the , a `Jenkinsfile` is a text file that contains the definition of a Jenkins Pipeline and is checked into source control.\nConsider the following Pipeline which implements a basic three-stage continuous delivery pipeline.\n\n[pipeline]\n\n// Declarative //\npipeline {\n    agent any\n\n    stages {\n        stage('Build') {\n            steps {\n                echo 'Building..'\n            }\n        }"
  },
  "2103": {
    "source_file": "jenkinsfile.txt",
    "text": "ative //\npipeline {\n    agent any\n\n    stages {\n        stage('Build') {\n            steps {\n                echo 'Building..'\n            }\n        }\n        stage('Test') {\n            steps {\n                echo 'Testing..'\n            }\n        }\n        stage('Deploy') {\n            steps {\n                echo 'Deploying....'\n            }\n        }\n    }\n}\n// Script //\nnode {\n    stage('Bu"
  },
  "2104": {
    "source_file": "jenkinsfile.txt",
    "text": "}\n        stage('Deploy') {\n            steps {\n                echo 'Deploying....'\n            }\n        }\n    }\n}\n// Script //\nnode {\n    stage('Build') {\n        echo 'Building....'\n    }\n    stage('Test') {\n        echo 'Testing....'\n    }\n    stage('Deploy') {\n        echo 'Deploying....'\n    }\n}\n\nNot all Pipelines will have these same three stages, but it is a good starting point to define "
  },
  "2105": {
    "source_file": "jenkinsfile.txt",
    "text": "tage('Deploy') {\n        echo 'Deploying....'\n    }\n}\n\nNot all Pipelines will have these same three stages, but it is a good starting point to define them for most projects.\nThe sections below will demonstrate the creation and execution of a simple Pipeline in a test installation of Jenkins.\n\nIt is assumed that there is already a source control repository set up for the project and a Pipeline has "
  },
  "2106": {
    "source_file": "jenkinsfile.txt",
    "text": "ipeline in a test installation of Jenkins.\n\nIt is assumed that there is already a source control repository set up for the project and a Pipeline has been defined in Jenkins following <<getting-started#defining-a-pipeline-in-scm, these instructions>>.\n\nUsing a text editor, ideally one which supports  syntax highlighting, create a new `Jenkinsfile` in the root directory of the project.\n\nThe Declara"
  },
  "2107": {
    "source_file": "jenkinsfile.txt",
    "text": ".\n\nUsing a text editor, ideally one which supports  syntax highlighting, create a new `Jenkinsfile` in the root directory of the project.\n\nThe Declarative Pipeline example above contains the minimum necessary structure to implement a continuous delivery pipeline.\nThe <<syntax#agent, agent directive>>, which is required, instructs Jenkins to allocate an executor and workspace for the Pipeline.\nWith"
  },
  "2108": {
    "source_file": "jenkinsfile.txt",
    "text": "ery pipeline.\nThe <<syntax#agent, agent directive>>, which is required, instructs Jenkins to allocate an executor and workspace for the Pipeline.\nWithout an `agent` directive, not only is the Declarative Pipeline not valid, it would not be capable of doing any work!\nBy default the `agent` directive ensures that the source repository is checked out and made available for steps in the subsequent sta"
  },
  "2109": {
    "source_file": "jenkinsfile.txt",
    "text": " doing any work!\nBy default the `agent` directive ensures that the source repository is checked out and made available for steps in the subsequent stages.\n\nThe <<syntax#stages, stages directive>> and <<syntax#steps, steps directives>> are also required for a valid Declarative Pipeline as they instruct Jenkins what to execute and in which stage it should be executed.\n\nFor more advanced usage with S"
  },
  "2110": {
    "source_file": "jenkinsfile.txt",
    "text": "ed for a valid Declarative Pipeline as they instruct Jenkins what to execute and in which stage it should be executed.\n\nFor more advanced usage with Scripted Pipeline, the example above `node` is a crucial first step as it allocates an executor and workspace for the Pipeline.\nIn essence, without `node`, a Pipeline cannot do any work! From within `node`, the first order of business will be to check"
  },
  "2111": {
    "source_file": "jenkinsfile.txt",
    "text": "orkspace for the Pipeline.\nIn essence, without `node`, a Pipeline cannot do any work! From within `node`, the first order of business will be to checkout the source code for this project.\nSince the `Jenkinsfile` is being pulled directly from source control, Pipeline provides a quick and easy way to access the right revision of the source code.\n\n[role=scripted-pipeline]\n[pipeline]\n\n// Script //\nnod"
  },
  "2112": {
    "source_file": "jenkinsfile.txt",
    "text": "ontrol, Pipeline provides a quick and easy way to access the right revision of the source code.\n\n[role=scripted-pipeline]\n[pipeline]\n\n// Script //\nnode {\n    checkout scm // <1> /* .. snip .. */\n}\n// Declarative not yet implemented //\n\n<1> The `checkout` step will checkout code from source control; `scm` is a special variable which instructs the `checkout` step to clone the specific revision which"
  },
  "2113": {
    "source_file": "jenkinsfile.txt",
    "text": "out` step will checkout code from source control; `scm` is a special variable which instructs the `checkout` step to clone the specific revision which triggered this Pipeline run.\n\nFor many projects the beginning of \"work\" in the Pipeline would be the \"build\" stage.\nTypically this stage of the Pipeline will be where source code is assembled, compiled, or packaged.\nThe `Jenkinsfile` is *not* a repl"
  },
  "2114": {
    "source_file": "jenkinsfile.txt",
    "text": "e \"build\" stage.\nTypically this stage of the Pipeline will be where source code is assembled, compiled, or packaged.\nThe `Jenkinsfile` is *not* a replacement for an existing build tool such as GNU/Make, Maven, Gradle, or others, but rather can be viewed as a glue layer to bind the multiple phases of a project's development lifecycle (build, test, deploy) together.\n\nJenkins has a number of plugins "
  },
  "2115": {
    "source_file": "jenkinsfile.txt",
    "text": "wed as a glue layer to bind the multiple phases of a project's development lifecycle (build, test, deploy) together.\n\nJenkins has a number of plugins for invoking practically any build tool in general use, but this example will simply invoke `make` from a shell step (`sh`).\nThe `sh` step assumes the system is Unix/Linux-based, for Windows-based systems the `bat` could be used instead.\n\n[pipeline]\n"
  },
  "2116": {
    "source_file": "jenkinsfile.txt",
    "text": "rom a shell step (`sh`).\nThe `sh` step assumes the system is Unix/Linux-based, for Windows-based systems the `bat` could be used instead.\n\n[pipeline]\n\n// Declarative //\npipeline {\n    agent any\n\n    stages {\n        stage('Build') {\n            steps {\n                sh 'make' // <1> archiveArtifacts artifacts: '**/target/*.jar', fingerprint: true // <2> }\n        }\n    }\n}\n// Script //\nnode {\n  "
  },
  "2117": {
    "source_file": "jenkinsfile.txt",
    "text": " {\n                sh 'make' // <1> archiveArtifacts artifacts: '**/target/*.jar', fingerprint: true // <2> }\n        }\n    }\n}\n// Script //\nnode {\n    stage('Build') {\n        sh 'make' // <1> archiveArtifacts artifacts: '**/target/*.jar', fingerprint: true // <2> }\n}\n\n<1> The `sh` step invokes the `make` command and will only continue if a zero exit code is returned by the command.\nAny non-zero "
  },
  "2118": {
    "source_file": "jenkinsfile.txt",
    "text": "nt: true // <2> }\n}\n\n<1> The `sh` step invokes the `make` command and will only continue if a zero exit code is returned by the command.\nAny non-zero exit code will fail the Pipeline.\n<2> `archiveArtifacts` captures the files built matching the include pattern (`+**/target/*.jar+`) and saves them to the Jenkins controller for later retrieval.\n\n[TIP]\n\nArchiving artifacts is not a substitute for usi"
  },
  "2119": {
    "source_file": "jenkinsfile.txt",
    "text": "de pattern (`+**/target/*.jar+`) and saves them to the Jenkins controller for later retrieval.\n\n[TIP]\n\nArchiving artifacts is not a substitute for using external artifact repositories such as Artifactory or Nexus and should be considered only for basic reporting and file archival.\n\nRunning automated tests is a crucial component of any successful continuous delivery process.\nAs such, Jenkins has a "
  },
  "2120": {
    "source_file": "jenkinsfile.txt",
    "text": "ic reporting and file archival.\n\nRunning automated tests is a crucial component of any successful continuous delivery process.\nAs such, Jenkins has a number of test recording, reporting, and visualization facilities provided by a .\nAt a fundamental level, when there are test failures, it is useful to have Jenkins record the failures for reporting and visualization in the web UI.\nThe example below "
  },
  "2121": {
    "source_file": "jenkinsfile.txt",
    "text": "evel, when there are test failures, it is useful to have Jenkins record the failures for reporting and visualization in the web UI.\nThe example below uses the `junit` step, provided by the plugin:junit[JUnit plugin].\n\nIn the example below, if tests fail, the Pipeline is marked \"unstable\", as denoted by a yellow ball in the web UI.\nBased on the recorded test reports, Jenkins can also provide histor"
  },
  "2122": {
    "source_file": "jenkinsfile.txt",
    "text": "ail, the Pipeline is marked \"unstable\", as denoted by a yellow ball in the web UI.\nBased on the recorded test reports, Jenkins can also provide historical trend analysis and visualization.\n\n[pipeline]\n\n// Declarative //\npipeline {\n    agent any\n\n    stages {\n        stage('Test') {\n            steps {\n                /* `make check` returns non-zero on test failures,\n                * using `true`"
  },
  "2123": {
    "source_file": "jenkinsfile.txt",
    "text": "stages {\n        stage('Test') {\n            steps {\n                /* `make check` returns non-zero on test failures,\n                * using `true` to allow the Pipeline to continue nonetheless\n                */\n                sh 'make check || true' // <1> junit '**/target/*.xml' // <2> }\n        }\n    }\n}\n// Script //\nnode {\n    /* .. snip .. */\n    stage('Test') {\n        /* `make check` r"
  },
  "2124": {
    "source_file": "jenkinsfile.txt",
    "text": "true' // <1> junit '**/target/*.xml' // <2> }\n        }\n    }\n}\n// Script //\nnode {\n    /* .. snip .. */\n    stage('Test') {\n        /* `make check` returns non-zero on test failures,\n         * using `true` to allow the Pipeline to continue nonetheless\n         */\n        sh 'make check || true' // <1> junit '**/target/*.xml' // <2> }\n    /* .. snip .. */\n}\n\n<1> Using an inline shell conditional "
  },
  "2125": {
    "source_file": "jenkinsfile.txt",
    "text": "ess\n         */\n        sh 'make check || true' // <1> junit '**/target/*.xml' // <2> }\n    /* .. snip .. */\n}\n\n<1> Using an inline shell conditional (`sh 'make check || true'`) ensures that the `sh` step always sees a zero exit code, giving the `junit` step the opportunity to capture and process the test reports.\nAlternative approaches to this are covered in more detail in the <<handling-failure>"
  },
  "2126": {
    "source_file": "jenkinsfile.txt",
    "text": "it` step the opportunity to capture and process the test reports.\nAlternative approaches to this are covered in more detail in the <<handling-failure>> section below.\n<2> `junit` captures and associates the JUnit XML files matching the inclusion pattern (`+**/target/*.xml+`).\n\nDeployment can imply a variety of steps, depending on the project or organization requirements, and may be anything from p"
  },
  "2127": {
    "source_file": "jenkinsfile.txt",
    "text": "ern (`+**/target/*.xml+`).\n\nDeployment can imply a variety of steps, depending on the project or organization requirements, and may be anything from publishing built artifacts to an Artifactory server, to pushing code to a production system.\n\nAt this stage of the example Pipeline, both the \"Build\" and \"Test\" stages have successfully executed.\nIn essence, the \"Deploy\" stage will only execute assumi"
  },
  "2128": {
    "source_file": "jenkinsfile.txt",
    "text": " stage of the example Pipeline, both the \"Build\" and \"Test\" stages have successfully executed.\nIn essence, the \"Deploy\" stage will only execute assuming previous stages completed successfully, otherwise the Pipeline would have exited early.\n\n[pipeline]\n\n// Declarative //\npipeline {\n    agent any\n\n    stages {\n        stage('Deploy') {\n            when {\n              expression {\n                c"
  },
  "2129": {
    "source_file": "jenkinsfile.txt",
    "text": "e]\n\n// Declarative //\npipeline {\n    agent any\n\n    stages {\n        stage('Deploy') {\n            when {\n              expression {\n                currentBuild.result == null || currentBuild.result == 'SUCCESS' // <1> }\n            }\n            steps {\n                sh 'make publish'\n            }\n        }\n    }\n}\n// Script //\nnode {\n    /* .. snip .. */\n    stage('Deploy') {\n        if (cur"
  },
  "2130": {
    "source_file": "jenkinsfile.txt",
    "text": "eps {\n                sh 'make publish'\n            }\n        }\n    }\n}\n// Script //\nnode {\n    /* .. snip .. */\n    stage('Deploy') {\n        if (currentBuild.result == null || currentBuild.result == 'SUCCESS') { // <1> sh 'make publish'\n        }\n    }\n    /* .. snip .. */\n}\n\n<1> Accessing the `currentBuild.result` variable allows the Pipeline to determine if there were any test failures.\nIn whi"
  },
  "2131": {
    "source_file": "jenkinsfile.txt",
    "text": "   }\n    /* .. snip .. */\n}\n\n<1> Accessing the `currentBuild.result` variable allows the Pipeline to determine if there were any test failures.\nIn which case, the value would be `UNSTABLE`.\n\nAssuming everything has executed successfully in the example Jenkins Pipeline, each successful Pipeline run will have associated build artifacts archived, test results reported upon and the full console output"
  },
  "2132": {
    "source_file": "jenkinsfile.txt",
    "text": "e Jenkins Pipeline, each successful Pipeline run will have associated build artifacts archived, test results reported upon and the full console output all in Jenkins.\n\nA Scripted Pipeline can include conditional tests (shown above), loops, try/catch/finally blocks, and even functions.\nThe next section will cover this advanced Scripted Pipeline syntax in more detail.\n\nThe following sections provide"
  },
  "2133": {
    "source_file": "jenkinsfile.txt",
    "text": "finally blocks, and even functions.\nThe next section will cover this advanced Scripted Pipeline syntax in more detail.\n\nThe following sections provide details about handling:\n\n* specific Pipeline syntax in your `Jenkinsfile` and\n* features and functionality of Pipeline syntax which are essential in building your application or Pipeline project.\n\n[[using-environment-variables]]\n\nJenkins Pipeline ex"
  },
  "2134": {
    "source_file": "jenkinsfile.txt",
    "text": "onality of Pipeline syntax which are essential in building your application or Pipeline project.\n\n[[using-environment-variables]]\n\nJenkins Pipeline exposes environment variables via the global variable `env`, which is available from anywhere within a `Jenkinsfile`.\nThe full list of environment variables accessible from within Jenkins Pipeline is documented at $\\{YOUR_JENKINS_URL}/pipeline-syntax/g"
  },
  "2135": {
    "source_file": "jenkinsfile.txt",
    "text": " `Jenkinsfile`.\nThe full list of environment variables accessible from within Jenkins Pipeline is documented at $\\{YOUR_JENKINS_URL}/pipeline-syntax/globals#env and includes:\n\nBUILD_ID:: The current build ID, identical to BUILD_NUMBER for builds created in Jenkins versions 1.597+.\nBUILD_NUMBER:: The current build number, such as \"153\".\nBUILD_TAG:: String of jenkins-$\\{JOB_NAME}-$\\{BUILD_NUMBER}. C"
  },
  "2136": {
    "source_file": "jenkinsfile.txt",
    "text": "ted in Jenkins versions 1.597+.\nBUILD_NUMBER:: The current build number, such as \"153\".\nBUILD_TAG:: String of jenkins-$\\{JOB_NAME}-$\\{BUILD_NUMBER}. Convenient to put into a resource file, a jar file, etc for easier identification.\nBUILD_URL:: The URL where the results of this build can be found (for example, http://buildserver/jenkins/job/MyJobName/17/).\nEXECUTOR_NUMBER:: The unique number that i"
  },
  "2137": {
    "source_file": "jenkinsfile.txt",
    "text": "L where the results of this build can be found (for example, http://buildserver/jenkins/job/MyJobName/17/).\nEXECUTOR_NUMBER:: The unique number that identifies the current executor (among executors of the same machine) performing this build. This is the number you see in the \"build executor status\", except that the number starts from 0, not 1.\nJAVA_HOME:: If your job is configured to use a specifi"
  },
  "2138": {
    "source_file": "jenkinsfile.txt",
    "text": "the number you see in the \"build executor status\", except that the number starts from 0, not 1.\nJAVA_HOME:: If your job is configured to use a specific JDK, this variable is set to the JAVA_HOME of the specified JDK. When this variable is set, PATH is also updated to include the bin subdirectory of JAVA_HOME.\nJENKINS_URL:: Full URL of Jenkins, such as https://example.com:port/jenkins/ (NOTE: only "
  },
  "2139": {
    "source_file": "jenkinsfile.txt",
    "text": "s also updated to include the bin subdirectory of JAVA_HOME.\nJENKINS_URL:: Full URL of Jenkins, such as https://example.com:port/jenkins/ (NOTE: only available if Jenkins URL set in \"System Configuration\").\nJOB_NAME:: Name of the project of this build, such as \"foo\" or \"foo/bar\".\nNODE_NAME:: The name of the node the current build is running on. Set to 'master' for the Jenkins controller.\nWORKSPACE"
  },
  "2140": {
    "source_file": "jenkinsfile.txt",
    "text": "d, such as \"foo\" or \"foo/bar\".\nNODE_NAME:: The name of the node the current build is running on. Set to 'master' for the Jenkins controller.\nWORKSPACE:: The absolute path of the workspace.\n\nReferencing or using these environment variables can be accomplished like accessing any key in a Groovy , for example:\n\n[pipeline]\n\n// Declarative //\npipeline {\n    agent any\n    stages {\n        stage('Example"
  },
  "2141": {
    "source_file": "jenkinsfile.txt",
    "text": "mplished like accessing any key in a Groovy , for example:\n\n[pipeline]\n\n// Declarative //\npipeline {\n    agent any\n    stages {\n        stage('Example') {\n            steps {\n                echo \"Running ${env.BUILD_ID} on ${env.JENKINS_URL}\"\n            }\n        }\n    }\n}\n// Script //\nnode {\n    echo \"Running ${env.BUILD_ID} on ${env.JENKINS_URL}\"\n}\n\nSetting an environment variable within a Jen"
  },
  "2142": {
    "source_file": "jenkinsfile.txt",
    "text": "      }\n        }\n    }\n}\n// Script //\nnode {\n    echo \"Running ${env.BUILD_ID} on ${env.JENKINS_URL}\"\n}\n\nSetting an environment variable within a Jenkins Pipeline is accomplished differently depending on whether Declarative or Scripted Pipeline is used.\n\nDeclarative Pipeline supports an <<syntax#environment, environment>> directive, whereas users of Scripted Pipeline must use the `withEnv` step.\n"
  },
  "2143": {
    "source_file": "jenkinsfile.txt",
    "text": "sed.\n\nDeclarative Pipeline supports an <<syntax#environment, environment>> directive, whereas users of Scripted Pipeline must use the `withEnv` step.\n\n[pipeline]\n\n// Declarative //\npipeline {\n    agent any\n    environment { // <1> CC = 'clang'\n    }\n    stages {\n        stage('Example') {\n            environment { // <2> DEBUG_FLAGS = '-g'\n            }\n            steps {\n                sh 'prin"
  },
  "2144": {
    "source_file": "jenkinsfile.txt",
    "text": "    stages {\n        stage('Example') {\n            environment { // <2> DEBUG_FLAGS = '-g'\n            }\n            steps {\n                sh 'printenv'\n            }\n        }\n    }\n}\n// Script //\nnode {\n    /* .. snip .. */\n    withEnv([\"PATH+MAVEN=${tool 'M3'}/bin\"]) {\n        sh 'mvn -B verify'\n    }\n}\n\n<1> An `environment` directive used in the top-level `pipeline` block will apply to all "
  },
  "2145": {
    "source_file": "jenkinsfile.txt",
    "text": "VEN=${tool 'M3'}/bin\"]) {\n        sh 'mvn -B verify'\n    }\n}\n\n<1> An `environment` directive used in the top-level `pipeline` block will apply to all steps within the Pipeline.\n<2> An `environment` directive defined within a `stage` will only apply the given environment variables to steps within the `stage`.\n\nEnvironment variables can be set at run time and can be used by shell scripts (`sh`), Win"
  },
  "2146": {
    "source_file": "jenkinsfile.txt",
    "text": "he given environment variables to steps within the `stage`.\n\nEnvironment variables can be set at run time and can be used by shell scripts (`sh`), Windows batch scripts (`bat`) and PowerShell scripts (`powershell`).\nEach script can either `returnStatus` or `returnStdout`.\nBelow is an example in a declarative pipeline using `sh` (shell) with both `returnStatus` and `returnStdout`.\n\n[pipeline]\n\n// D"
  },
  "2147": {
    "source_file": "jenkinsfile.txt",
    "text": "us` or `returnStdout`.\nBelow is an example in a declarative pipeline using `sh` (shell) with both `returnStatus` and `returnStdout`.\n\n[pipeline]\n\n// Declarative //\npipeline {\n    agent any // <1> environment {\n        // Using returnStdout\n        CC = \"\"\"${sh(\n                returnStdout: true,\n                script: 'echo \"clang\"'\n            )}\"\"\" // <2> // Using returnStatus\n        EXIT_STA"
  },
  "2148": {
    "source_file": "jenkinsfile.txt",
    "text": " = \"\"\"${sh(\n                returnStdout: true,\n                script: 'echo \"clang\"'\n            )}\"\"\" // <2> // Using returnStatus\n        EXIT_STATUS = \"\"\"${sh(\n                returnStatus: true,\n                script: 'exit 1'\n            )}\"\"\"\n    }\n    stages {\n        stage('Example') {\n            environment {\n                DEBUG_FLAGS = '-g'\n            }\n            steps {\n       "
  },
  "2149": {
    "source_file": "jenkinsfile.txt",
    "text": "\"\n    }\n    stages {\n        stage('Example') {\n            environment {\n                DEBUG_FLAGS = '-g'\n            }\n            steps {\n                sh 'printenv'\n            }\n        }\n    }\n}\n// Script //\n\n<1> An `agent` must be set at the top level of the pipeline.\nThis will fail if agent is set as `agent none`.\n<2> When using `returnStdout` a trailing whitespace will be appended to "
  },
  "2150": {
    "source_file": "jenkinsfile.txt",
    "text": "he top level of the pipeline.\nThis will fail if agent is set as `agent none`.\n<2> When using `returnStdout` a trailing whitespace will be appended to the returned string.\nUse `.trim()` to remove this.\n\nCredentials\n can be handled in Pipelines for immediate use.\nRead more about using credentials in Jenkins on the  page.\n\n.The correct way to handle credentials in Jenkins\nvideo::yfjtMIDgmfs[youtube,w"
  },
  "2151": {
    "source_file": "jenkinsfile.txt",
    "text": "ediate use.\nRead more about using credentials in Jenkins on the  page.\n\n.The correct way to handle credentials in Jenkins\nvideo::yfjtMIDgmfs[youtube,width=800,height=420]\n\nJenkins' declarative Pipeline syntax has the `credentials()` helper method (used within the <<syntax#environment,`environment`>> directive) which supports <<#secret-text,secret text>>, <<#usernames-and-passwords,username and pas"
  },
  "2152": {
    "source_file": "jenkinsfile.txt",
    "text": "ed within the <<syntax#environment,`environment`>> directive) which supports <<#secret-text,secret text>>, <<#usernames-and-passwords,username and password>>, as well as <<#secret-files,secret file>> credentials.\nIf you want to handle other types of credentials, refer to the <<#for-other-credential-types, For other credential types>> section.\n\nThe following Pipeline code shows an example of how to"
  },
  "2153": {
    "source_file": "jenkinsfile.txt",
    "text": "credentials, refer to the <<#for-other-credential-types, For other credential types>> section.\n\nThe following Pipeline code shows an example of how to create a Pipeline using environment variables for secret text credentials.\n\nIn this example, two secret text credentials are assigned to separate environment variables to access Amazon Web Services (AWS).\nThese credentials would have been configured"
  },
  "2154": {
    "source_file": "jenkinsfile.txt",
    "text": "cret text credentials are assigned to separate environment variables to access Amazon Web Services (AWS).\nThese credentials would have been configured in Jenkins with their respective credential IDs `jenkins-aws-secret-key-id` and `jenkins-aws-secret-access-key`.\n\n[pipeline]\n\n// Declarative //\npipeline {\n    agent {\n        // Define agent details here\n    }\n    environment {\n        AWS_ACCESS_KE"
  },
  "2155": {
    "source_file": "jenkinsfile.txt",
    "text": "-access-key`.\n\n[pipeline]\n\n// Declarative //\npipeline {\n    agent {\n        // Define agent details here\n    }\n    environment {\n        AWS_ACCESS_KEY_ID     = credentials('jenkins-aws-secret-key-id')\n        AWS_SECRET_ACCESS_KEY = credentials('jenkins-aws-secret-access-key')\n    }\n    stages {\n        stage('Example stage 1') {\n            steps {\n                // // <1> }\n        }\n        s"
  },
  "2156": {
    "source_file": "jenkinsfile.txt",
    "text": "kins-aws-secret-access-key')\n    }\n    stages {\n        stage('Example stage 1') {\n            steps {\n                // // <1> }\n        }\n        stage('Example stage 2') {\n            steps {\n                // // <2> }\n        }\n    }\n}\n// Script //\n\n<1> You can reference the two credential environment variables (defined in this Pipeline's <<syntax#environment,`environment`>> directive), with"
  },
  "2157": {
    "source_file": "jenkinsfile.txt",
    "text": "t //\n\n<1> You can reference the two credential environment variables (defined in this Pipeline's <<syntax#environment,`environment`>> directive), within this stage's steps using the syntax `$AWS_ACCESS_KEY_ID` and `$AWS_SECRET_ACCESS_KEY`.\nFor example, here you can authenticate to AWS using the secret text credentials assigned to these credential variables.\nTo maintain the security and anonymity o"
  },
  "2158": {
    "source_file": "jenkinsfile.txt",
    "text": "e, here you can authenticate to AWS using the secret text credentials assigned to these credential variables.\nTo maintain the security and anonymity of these credentials, if the job displays the value of these credential variables from within the Pipeline (such as `echo $AWS_SECRET_ACCESS_KEY`), Jenkins only returns the value \"`+****+`\" to reduce the risk of secret information being disclosed to t"
  },
  "2159": {
    "source_file": "jenkinsfile.txt",
    "text": "eline (such as `echo $AWS_SECRET_ACCESS_KEY`), Jenkins only returns the value \"`+****+`\" to reduce the risk of secret information being disclosed to the console output and any logs.\nAny sensitive information in credential IDs themselves (such as usernames) are also returned as \"`+****+`\" in the Pipeline run's output.\nThis only reduces the risk of **accidental exposure**.\nIt does not prevent a mali"
  },
  "2160": {
    "source_file": "jenkinsfile.txt",
    "text": "names) are also returned as \"`+****+`\" in the Pipeline run's output.\nThis only reduces the risk of **accidental exposure**.\nIt does not prevent a malicious user from capturing the credential value by other means.\nA Pipeline that uses credentials can also disclose those credentials.\nDon't allow untrusted Pipeline jobs to use trusted credentials.\n<2> In this Pipeline example, the credentials assigne"
  },
  "2161": {
    "source_file": "jenkinsfile.txt",
    "text": "also disclose those credentials.\nDon't allow untrusted Pipeline jobs to use trusted credentials.\n<2> In this Pipeline example, the credentials assigned to the two `AWS_...` environment variables are scoped globally for the entire Pipeline, so these credential variables could also be used in this stage's steps.\nIf, however, the `environment` directive in this Pipeline were moved to a specific stage"
  },
  "2162": {
    "source_file": "jenkinsfile.txt",
    "text": "redential variables could also be used in this stage's steps.\nIf, however, the `environment` directive in this Pipeline were moved to a specific stage (as is the case in the <<#usernames-and-passwords,Usernames and passwords>> Pipeline example below), then these `AWS_...` environment variables would only be scoped to the steps in that stage.\n\nTIP: Storing static AWS keys in Jenkins credentials is "
  },
  "2163": {
    "source_file": "jenkinsfile.txt",
    "text": ", then these `AWS_...` environment variables would only be scoped to the steps in that stage.\n\nTIP: Storing static AWS keys in Jenkins credentials is not very secure.\nIf you can run Jenkins itself in AWS (at least the agent), it is preferable to use IAM roles for a  or .\nIt is also possible to use .\n\nThe following Pipeline code snippets show an example of how to create a Pipeline using environment"
  },
  "2164": {
    "source_file": "jenkinsfile.txt",
    "text": "IAM roles for a  or .\nIt is also possible to use .\n\nThe following Pipeline code snippets show an example of how to create a Pipeline using environment variables for username and password credentials.\n\nIn this example, username and password credentials are assigned to environment variables to access a Bitbucket repository in a common account or team for your organization; these credentials would ha"
  },
  "2165": {
    "source_file": "jenkinsfile.txt",
    "text": "s are assigned to environment variables to access a Bitbucket repository in a common account or team for your organization; these credentials would have been configured in Jenkins with the credential ID `jenkins-bitbucket-common-creds`.\n\nWhen setting the credential environment variable in the <<syntax#environment, `environment`>> directive:\n\nenvironment {\n    BITBUCKET_COMMON_CREDS = credentials('"
  },
  "2166": {
    "source_file": "jenkinsfile.txt",
    "text": " the credential environment variable in the <<syntax#environment, `environment`>> directive:\n\nenvironment {\n    BITBUCKET_COMMON_CREDS = credentials('jenkins-bitbucket-common-creds')\n}\n\nthis actually sets the following three environment variables:\n\n* `BITBUCKET_COMMON_CREDS` - contains a username and a password separated by a colon in the format `username:password`.\n* `BITBUCKET_COMMON_CREDS_USR` "
  },
  "2167": {
    "source_file": "jenkinsfile.txt",
    "text": " `BITBUCKET_COMMON_CREDS` - contains a username and a password separated by a colon in the format `username:password`.\n* `BITBUCKET_COMMON_CREDS_USR` - an additional variable containing the username component only.\n* `BITBUCKET_COMMON_CREDS_PSW` - an additional variable containing the password component only.\n\nBy convention, variable names for environment variables are typically specified in capit"
  },
  "2168": {
    "source_file": "jenkinsfile.txt",
    "text": " additional variable containing the password component only.\n\nBy convention, variable names for environment variables are typically specified in capital case, with individual words separated by underscores\nYou can, however, specify any legitimate variable name using lower case characters.\nBear in mind that the additional environment variables created by the `credentials()` method (above) will alwa"
  },
  "2169": {
    "source_file": "jenkinsfile.txt",
    "text": "iable name using lower case characters.\nBear in mind that the additional environment variables created by the `credentials()` method (above) will always be appended with `_USR` and `_PSW` (i.e. in the format of an underscore followed by three capital letters).\n\nThe following code snippet shows the example Pipeline in its entirety:\n\n[pipeline]\n\n// Declarative //\npipeline {\n    agent {\n        // De"
  },
  "2170": {
    "source_file": "jenkinsfile.txt",
    "text": " letters).\n\nThe following code snippet shows the example Pipeline in its entirety:\n\n[pipeline]\n\n// Declarative //\npipeline {\n    agent {\n        // Define agent details here\n    }\n    stages {\n        stage('Example stage 1') {\n            environment {\n                BITBUCKET_COMMON_CREDS = credentials('jenkins-bitbucket-common-creds')\n            }\n            steps {\n                // // <1>"
  },
  "2171": {
    "source_file": "jenkinsfile.txt",
    "text": "t {\n                BITBUCKET_COMMON_CREDS = credentials('jenkins-bitbucket-common-creds')\n            }\n            steps {\n                // // <1> }\n        }\n        stage('Example stage 2') {\n            steps {\n                // // <2> }\n        }\n    }\n}\n// Script //\n\n<1> The following credential environment variables (defined in this Pipeline's <<syntax#environment,`environment`>> direct"
  },
  "2172": {
    "source_file": "jenkinsfile.txt",
    "text": "    }\n    }\n}\n// Script //\n\n<1> The following credential environment variables (defined in this Pipeline's <<syntax#environment,`environment`>> directive) are available within this stage's steps and can be referenced using the syntax:\n* `$BITBUCKET_COMMON_CREDS`\n* `$BITBUCKET_COMMON_CREDS_USR`\n* `$BITBUCKET_COMMON_CREDS_PSW`\n\nFor example, here you can authenticate to Bitbucket with the username an"
  },
  "2173": {
    "source_file": "jenkinsfile.txt",
    "text": "OMMON_CREDS`\n* `$BITBUCKET_COMMON_CREDS_USR`\n* `$BITBUCKET_COMMON_CREDS_PSW`\n\nFor example, here you can authenticate to Bitbucket with the username and password assigned to these credential variables.\nTo maintain the security and anonymity of these credentials, if the job displays the value of these credential variables from within the Pipeline the same behavior described in the <<#secret-text,Sec"
  },
  "2174": {
    "source_file": "jenkinsfile.txt",
    "text": "redentials, if the job displays the value of these credential variables from within the Pipeline the same behavior described in the <<#secret-text,Secret text>> example above applies to these username and password credential variable types too.\nThis only reduces the risk of **accidental exposure**.\nIt does not prevent a malicious user from capturing the credential value by other means.\nA Pipeline "
  },
  "2175": {
    "source_file": "jenkinsfile.txt",
    "text": "only reduces the risk of **accidental exposure**.\nIt does not prevent a malicious user from capturing the credential value by other means.\nA Pipeline that uses credentials can also disclose those credentials.\nDon't allow untrusted Pipeline jobs to use trusted credentials.\n<2> In this Pipeline example, the credentials assigned to the three `BITBUCKET_COMMON_CREDS...` environment variables are scope"
  },
  "2176": {
    "source_file": "jenkinsfile.txt",
    "text": "e trusted credentials.\n<2> In this Pipeline example, the credentials assigned to the three `BITBUCKET_COMMON_CREDS...` environment variables are scoped only to `Example stage 1`, so these credential variables are not available for use in this `Example stage 2` stage's steps.\nIf, however, the `environment` directive in this Pipeline were moved immediately within the <<syntax#declarative-pipeline,`p"
  },
  "2177": {
    "source_file": "jenkinsfile.txt",
    "text": "e stage 2` stage's steps.\nIf, however, the `environment` directive in this Pipeline were moved immediately within the <<syntax#declarative-pipeline,`pipeline`>> block (as is the case in the <<#secret-text,Secret text>> Pipeline example above), then these `BITBUCKET_COMMON_CREDS...` environment variables would be scoped globally and could be used in any stage's steps.\n\nA secret file is a credential"
  },
  "2178": {
    "source_file": "jenkinsfile.txt",
    "text": "hese `BITBUCKET_COMMON_CREDS...` environment variables would be scoped globally and could be used in any stage's steps.\n\nA secret file is a credential which is stored in a file and uploaded to Jenkins.\nSecret files are used for credentials that are:\n\n* too unwieldy to enter directly into Jenkins, and/or\n* in binary format, such as a GPG file.\n\nIn this example, we use a Kubernetes config file that "
  },
  "2179": {
    "source_file": "jenkinsfile.txt",
    "text": "\n* too unwieldy to enter directly into Jenkins, and/or\n* in binary format, such as a GPG file.\n\nIn this example, we use a Kubernetes config file that has been configured as a secret file credential named `my-kubeconfig`.\n\n[pipeline]\n\n// Declarative //\npipeline {\n    agent {\n        // Define agent details here\n    }\n    environment {\n        // The MY_KUBECONFIG environment variable will be assign"
  },
  "2180": {
    "source_file": "jenkinsfile.txt",
    "text": "/\npipeline {\n    agent {\n        // Define agent details here\n    }\n    environment {\n        // The MY_KUBECONFIG environment variable will be assigned the value of a temporary file.\n        // For example:\n        //   /home/user/.jenkins/workspace/cred_test@tmp/secretFiles/546a5cf3-9b56-4165-a0fd-19e2afe6b31f/kubeconfig.txt\n        MY_KUBECONFIG = credentials('my-kubeconfig')\n    }\n    stages {"
  },
  "2181": {
    "source_file": "jenkinsfile.txt",
    "text": "/cred_test@tmp/secretFiles/546a5cf3-9b56-4165-a0fd-19e2afe6b31f/kubeconfig.txt\n        MY_KUBECONFIG = credentials('my-kubeconfig')\n    }\n    stages {\n        stage('Example stage 1') {\n            steps {\n                sh(\"kubectl --kubeconfig $MY_KUBECONFIG get pods\")\n            }\n        }\n    }\n}\n// Script //\n\nIf you need to set credentials in a Pipeline for anything other than secret text,"
  },
  "2182": {
    "source_file": "jenkinsfile.txt",
    "text": "_KUBECONFIG get pods\")\n            }\n        }\n    }\n}\n// Script //\n\nIf you need to set credentials in a Pipeline for anything other than secret text, usernames and passwords, or <<#for-secret-text-usernames-and-passwords-and-secret-files,secret files>> like SSH keys or certificates, use Jenkins' *Snippet Generator* feature, which you can access through Jenkins' classic UI.\n\nTo access the *Snippet"
  },
  "2183": {
    "source_file": "jenkinsfile.txt",
    "text": "s>> like SSH keys or certificates, use Jenkins' *Snippet Generator* feature, which you can access through Jenkins' classic UI.\n\nTo access the *Snippet Generator* for your Pipeline project/item:\n\nFrom the Jenkins Dashboard, select the name of your Pipeline project/item.\nIn the left navigation pane, select *Pipeline Syntax* and ensure that the *Snippet Generator* option is available at the top of th"
  },
  "2184": {
    "source_file": "jenkinsfile.txt",
    "text": "eline project/item.\nIn the left navigation pane, select *Pipeline Syntax* and ensure that the *Snippet Generator* option is available at the top of the navigation pane.\nFrom the *Sample Step* field, choose *withCredentials: Bind credentials to variables*.\nUnder *Bindings*, click *Add* and choose from the dropdown:\n  * *SSH User Private Key* - to handle , from which you can specify:\n    ** *Key Fil"
  },
  "2185": {
    "source_file": "jenkinsfile.txt",
    "text": "les*.\nUnder *Bindings*, click *Add* and choose from the dropdown:\n  * *SSH User Private Key* - to handle , from which you can specify:\n    ** *Key File Variable* - the name of the environment variable that will be bound to these credentials.\n       Jenkins actually assigns this temporary variable to the secure location of the private key file required in the SSH public/private key pair authenticat"
  },
  "2186": {
    "source_file": "jenkinsfile.txt",
    "text": "enkins actually assigns this temporary variable to the secure location of the private key file required in the SSH public/private key pair authentication process.\n    ** *Passphrase Variable* ( _Optional_ ) - the name of the environment variable that will be bound to the  associated with the SSH public/private key pair.\n    ** *Username Variable* ( _Optional_ ) - the name of the environment variab"
  },
  "2187": {
    "source_file": "jenkinsfile.txt",
    "text": " will be bound to the  associated with the SSH public/private key pair.\n    ** *Username Variable* ( _Optional_ ) - the name of the environment variable that will be bound to username associated with the SSH public/private key pair.\n    ** *Credentials* - choose the SSH public/private key credentials stored in Jenkins.\n       The value of this field is the credential ID, which Jenkins writes out t"
  },
  "2188": {
    "source_file": "jenkinsfile.txt",
    "text": "ls* - choose the SSH public/private key credentials stored in Jenkins.\n       The value of this field is the credential ID, which Jenkins writes out to the generated snippet.\n  * *Certificate* - to handle , from which you can specify:\n    ** *Keystore Variable* - the name of the environment variable that will be bound to these credentials.\n       Jenkins actually assigns this temporary variable to"
  },
  "2189": {
    "source_file": "jenkinsfile.txt",
    "text": "e Variable* - the name of the environment variable that will be bound to these credentials.\n       Jenkins actually assigns this temporary variable to the secure location of the certificate's keystore required in the certificate authentication process.\n    ** *Password Variable* ( _Optional_ ) - the name of the environment variable that will be bound to the password associated with the certificate"
  },
  "2190": {
    "source_file": "jenkinsfile.txt",
    "text": "s.\n    ** *Password Variable* ( _Optional_ ) - the name of the environment variable that will be bound to the password associated with the certificate.\n    ** *Alias Variable* ( _Optional_ ) - the name of the environment variable that will be bound to the unique alias associated with the certificate.\n    ** *Credentials* - choose the certificate credentials stored in Jenkins.\n       The value of t"
  },
  "2191": {
    "source_file": "jenkinsfile.txt",
    "text": "o the unique alias associated with the certificate.\n    ** *Credentials* - choose the certificate credentials stored in Jenkins.\n       The value of this field is the credential ID, which Jenkins writes out to the generated snippet.\n  * *Docker client certificate* - to handle Docker Host Certificate Authentication.\nClick *Generate Pipeline Script* and Jenkins generates a `withCredentials(...) { .."
  },
  "2192": {
    "source_file": "jenkinsfile.txt",
    "text": "t certificate* - to handle Docker Host Certificate Authentication.\nClick *Generate Pipeline Script* and Jenkins generates a `withCredentials(...) { ... }` Pipeline step snippet for the credentials you specified, which you can then copy and paste into your Declarative or Scripted Pipeline code. +\n  *Notes:*\n  * The *Credentials* fields (above) show the names of credentials configured in Jenkins.\n  "
  },
  "2193": {
    "source_file": "jenkinsfile.txt",
    "text": " your Declarative or Scripted Pipeline code. +\n  *Notes:*\n  * The *Credentials* fields (above) show the names of credentials configured in Jenkins.\n    However, these values are converted to credential IDs after clicking *Generate Pipeline Script*. [[withcredentials-script-examples]]\n  * To combine more than one credential in a single `withCredentials(...) { ... }` Pipeline step, see <<#combining-"
  },
  "2194": {
    "source_file": "jenkinsfile.txt",
    "text": "[withcredentials-script-examples]]\n  * To combine more than one credential in a single `withCredentials(...) { ... }` Pipeline step, see <<#combining-credentials-in-one-step,Combining credentials in one step>> (below) for details.\n\n*SSH User Private Key example*\n\nwithCredentials(bindings: [sshUserPrivateKey(credentialsId: 'jenkins-ssh-key-for-abc', \\\n                                             ke"
  },
  "2195": {
    "source_file": "jenkinsfile.txt",
    "text": "Key example*\n\nwithCredentials(bindings: [sshUserPrivateKey(credentialsId: 'jenkins-ssh-key-for-abc', \\\n                                             keyFileVariable: 'SSH_KEY_FOR_ABC', \\\n                                             passphraseVariable: '', \\\n                                             usernameVariable: '')]) {\n  // some block\n}\n\nThe optional `passphraseVariable` and `usernameVariab"
  },
  "2196": {
    "source_file": "jenkinsfile.txt",
    "text": " '', \\\n                                             usernameVariable: '')]) {\n  // some block\n}\n\nThe optional `passphraseVariable` and `usernameVariable` definitions can be deleted in your final Pipeline code.\n\n*Certificate example*\n\nwithCredentials(bindings: [certificate(aliasVariable: '', \\\n                                       credentialsId: 'jenkins-certificate-for-xyz', \\\n                   "
  },
  "2197": {
    "source_file": "jenkinsfile.txt",
    "text": "bindings: [certificate(aliasVariable: '', \\\n                                       credentialsId: 'jenkins-certificate-for-xyz', \\\n                                       keystoreVariable: 'CERTIFICATE_FOR_XYZ', \\\n                                       passwordVariable: 'XYZ-CERTIFICATE-PASSWORD')]) {\n  // some block\n}\n\nThe optional `aliasVariable` and `passwordVariable` variable definitions can be"
  },
  "2198": {
    "source_file": "jenkinsfile.txt",
    "text": "  passwordVariable: 'XYZ-CERTIFICATE-PASSWORD')]) {\n  // some block\n}\n\nThe optional `aliasVariable` and `passwordVariable` variable definitions can be deleted in your final Pipeline code.\n\nThe following code snippet shows an example Pipeline in its entirety, which implements the *SSH User Private Key* and *Certificate* snippets above:\n\n[pipeline]\n\n// Declarative //\npipeline {\n    agent {\n        /"
  },
  "2199": {
    "source_file": "jenkinsfile.txt",
    "text": "ntirety, which implements the *SSH User Private Key* and *Certificate* snippets above:\n\n[pipeline]\n\n// Declarative //\npipeline {\n    agent {\n        // define agent details\n    }\n    stages {\n        stage('Example stage 1') {\n            steps {\n                withCredentials(bindings: [sshUserPrivateKey(credentialsId: 'jenkins-ssh-key-for-abc', \\\n                                                "
  },
  "2200": {
    "source_file": "jenkinsfile.txt",
    "text": "             withCredentials(bindings: [sshUserPrivateKey(credentialsId: 'jenkins-ssh-key-for-abc', \\\n                                                             keyFileVariable: 'SSH_KEY_FOR_ABC')]) {\n                  // // <1> }\n                withCredentials(bindings: [certificate(credentialsId: 'jenkins-certificate-for-xyz', \\\n                                                       keystoreV"
  },
  "2201": {
    "source_file": "jenkinsfile.txt",
    "text": "ithCredentials(bindings: [certificate(credentialsId: 'jenkins-certificate-for-xyz', \\\n                                                       keystoreVariable: 'CERTIFICATE_FOR_XYZ', \\\n                                                       passwordVariable: 'XYZ-CERTIFICATE-PASSWORD')]) {\n                  // // <2> }\n            }\n        }\n        stage('Example stage 2') {\n            steps {\n  "
  },
  "2202": {
    "source_file": "jenkinsfile.txt",
    "text": "iable: 'XYZ-CERTIFICATE-PASSWORD')]) {\n                  // // <2> }\n            }\n        }\n        stage('Example stage 2') {\n            steps {\n                // // <3> }\n        }\n    }\n}\n// Script //\n\n<1> Within this step, you can reference the credential environment variable with the syntax `$SSH_KEY_FOR_ABC`.\nFor example, here you can authenticate to the ABC application with its configure"
  },
  "2203": {
    "source_file": "jenkinsfile.txt",
    "text": "e credential environment variable with the syntax `$SSH_KEY_FOR_ABC`.\nFor example, here you can authenticate to the ABC application with its configured SSH public/private key pair credentials, whose *SSH User Private Key* file is assigned to `$SSH_KEY_FOR_ABC`.\n<2> Within this step, you can reference the credential environment variable with the syntax `$CERTIFICATE_FOR_XYZ` and `$XYZ-CERTIFICATE-P"
  },
  "2204": {
    "source_file": "jenkinsfile.txt",
    "text": "Y_FOR_ABC`.\n<2> Within this step, you can reference the credential environment variable with the syntax `$CERTIFICATE_FOR_XYZ` and `$XYZ-CERTIFICATE-PASSWORD`.\nFor example, here you can authenticate to the XYZ application with its configured certificate credentials, whose *Certificate*'s keystore file and password are assigned to the variables `$CERTIFICATE_FOR_XYZ` and `$XYZ-CERTIFICATE-PASSWORD`"
  },
  "2205": {
    "source_file": "jenkinsfile.txt",
    "text": "ate credentials, whose *Certificate*'s keystore file and password are assigned to the variables `$CERTIFICATE_FOR_XYZ` and `$XYZ-CERTIFICATE-PASSWORD`, respectively.\n<3> In this Pipeline example, the credentials assigned to the `$SSH_KEY_FOR_ABC`, `$CERTIFICATE_FOR_XYZ` and `$XYZ-CERTIFICATE-PASSWORD` environment variables are scoped only within their respective `withCredentials( ... ) { ... }` st"
  },
  "2206": {
    "source_file": "jenkinsfile.txt",
    "text": "CERTIFICATE_FOR_XYZ` and `$XYZ-CERTIFICATE-PASSWORD` environment variables are scoped only within their respective `withCredentials( ... ) { ... }` steps, so these credential variables are not available for use in this `Example stage 2` stage's steps.\n\nTo maintain the security and anonymity of these credentials, if you attempt to retrieve the value of these credential variables from within these `"
  },
  "2207": {
    "source_file": "jenkinsfile.txt",
    "text": ".\n\nTo maintain the security and anonymity of these credentials, if you attempt to retrieve the value of these credential variables from within these `withCredentials( ... ) { ... }` steps, the same behavior described in the <<#secret-text,Secret text>> example (above) applies to these SSH public/private key pair credential and certificate variable types too.\nThis only reduces the risk of **acciden"
  },
  "2208": {
    "source_file": "jenkinsfile.txt",
    "text": ">> example (above) applies to these SSH public/private key pair credential and certificate variable types too.\nThis only reduces the risk of **accidental exposure**.\nIt does not prevent a malicious user from capturing the credential value by other means.\nA Pipeline that uses credentials can also disclose those credentials.\nDon't allow untrusted Pipeline jobs to use trusted credentials.\n\n* When usi"
  },
  "2209": {
    "source_file": "jenkinsfile.txt",
    "text": "ans.\nA Pipeline that uses credentials can also disclose those credentials.\nDon't allow untrusted Pipeline jobs to use trusted credentials.\n\n* When using the *Sample Step* field's *withCredentials: Bind credentials to variables* option in the *Snippet Generator*, only credentials which your current Pipeline project/item has access to can be selected from any *Credentials* field's list.\nWhile you ca"
  },
  "2210": {
    "source_file": "jenkinsfile.txt",
    "text": " Generator*, only credentials which your current Pipeline project/item has access to can be selected from any *Credentials* field's list.\nWhile you can manually write a `withCredentials( ... ) { ... }` step for your Pipeline (like the examples <<#withcredentials-script-examples,above>>), using the *Snippet Generator* is recommended to avoid specifying credentials that are out of scope for this Pip"
  },
  "2211": {
    "source_file": "jenkinsfile.txt",
    "text": "hcredentials-script-examples,above>>), using the *Snippet Generator* is recommended to avoid specifying credentials that are out of scope for this Pipeline project/item, which when run, will make the step fail.\n* You can also use the *Snippet Generator* to generate `withCredentials( ... ) { ... }` steps to handle secret text, usernames and passwords and secret files.\nHowever, if you only need to h"
  },
  "2212": {
    "source_file": "jenkinsfile.txt",
    "text": "or* to generate `withCredentials( ... ) { ... }` steps to handle secret text, usernames and passwords and secret files.\nHowever, if you only need to handle these types of credentials, it is recommended you use the relevant procedure described in the section <<#for-secret-text-usernames-and-passwords-and-secret-files,above>> for improved Pipeline code readability.\n* The use of **single-quotes** ins"
  },
  "2213": {
    "source_file": "jenkinsfile.txt",
    "text": "section <<#for-secret-text-usernames-and-passwords-and-secret-files,above>> for improved Pipeline code readability.\n* The use of **single-quotes** instead of **double-quotes** to define the `script` (the implicit parameter to `sh`) in Groovy above.\nThe single-quotes will cause the secret to be expanded by the shell as an environment variable.\nThe double-quotes are potentially less secure as the se"
  },
  "2214": {
    "source_file": "jenkinsfile.txt",
    "text": "he single-quotes will cause the secret to be expanded by the shell as an environment variable.\nThe double-quotes are potentially less secure as the secret is interpolated by Groovy, and so typical operating system process listings will accidentally disclose it :\n```\nnode {\n  withCredentials([string(credentialsId: 'mytoken', variable: 'TOKEN')]) {\n    sh /* WRONG! */ \"\"\"\n      set +x\n      curl -H "
  },
  "2215": {
    "source_file": "jenkinsfile.txt",
    "text": "isclose it :\n```\nnode {\n  withCredentials([string(credentialsId: 'mytoken', variable: 'TOKEN')]) {\n    sh /* WRONG! */ \"\"\"\n      set +x\n      curl -H 'Token: $TOKEN' https://some.api/\n    \"\"\"\n    sh /* CORRECT */ '''\n      set +x\n      curl -H 'Token: $TOKEN' https://some.api/\n    '''\n  }\n}\n```\n\nUsing the *Snippet Generator*, you can make multiple credentials available within a single `withCredent"
  },
  "2216": {
    "source_file": "jenkinsfile.txt",
    "text": ": $TOKEN' https://some.api/\n    '''\n  }\n}\n```\n\nUsing the *Snippet Generator*, you can make multiple credentials available within a single `withCredentials( ... ) { ... }` step by doing the following:\n\nFrom the Jenkins Dashboard, select the name of your Pipeline project/item.\nIn the left navigation pane, select *Pipeline Syntax* and ensure that the *Snippet Generator* option is available at the top"
  },
  "2217": {
    "source_file": "jenkinsfile.txt",
    "text": "ur Pipeline project/item.\nIn the left navigation pane, select *Pipeline Syntax* and ensure that the *Snippet Generator* option is available at the top of the navigation pane.\nFrom the *Sample Step* field, choose *withCredentials: Bind credentials to variables*.\nClick *Add* under *Bindings*.\nChoose the credential type to add to the `withCredentials( ... ) { ... }` step from the dropdown list.\nSpeci"
  },
  "2218": {
    "source_file": "jenkinsfile.txt",
    "text": "variables*.\nClick *Add* under *Bindings*.\nChoose the credential type to add to the `withCredentials( ... ) { ... }` step from the dropdown list.\nSpecify the credential *Bindings* details.\n  Read more above these in the procedure under <<#for-other-credential-types,For other credential types>> (above).\nRepeat from \"Click *Add* ...\" (above) for each (set of) credential/s to add to the `withCredentia"
  },
  "2219": {
    "source_file": "jenkinsfile.txt",
    "text": "edential-types,For other credential types>> (above).\nRepeat from \"Click *Add* ...\" (above) for each (set of) credential/s to add to the `withCredentials( ... ) { ... }` step.\nSelect *Generate Pipeline Script* to generate the final `withCredentials( ... ) { ... }` step snippet.\n\nJenkins Pipeline uses rules identical to  for string interpolation.\nGroovy's String interpolation support can be confusin"
  },
  "2220": {
    "source_file": "jenkinsfile.txt",
    "text": ".. ) { ... }` step snippet.\n\nJenkins Pipeline uses rules identical to  for string interpolation.\nGroovy's String interpolation support can be confusing to many newcomers to the language.\nWhile Groovy supports declaring a string with either single quotes, or double quotes, for example:\n\ndef singlyQuoted = 'Hello'\ndef doublyQuoted = \"World\"\n\nOnly the latter string will support the dollar-sign (`$`) "
  },
  "2221": {
    "source_file": "jenkinsfile.txt",
    "text": "tes, or double quotes, for example:\n\ndef singlyQuoted = 'Hello'\ndef doublyQuoted = \"World\"\n\nOnly the latter string will support the dollar-sign (`$`) based string\ninterpolation, for example:\n\ndef username = 'Jenkins'\necho 'Hello Mr. ${username}'\necho \"I said, Hello Mr. ${username}\"\n\nWould result in:\n\nHello Mr. ${username}\nI said, Hello Mr. Jenkins\n\nUnderstanding how to use string interpolation is "
  },
  "2222": {
    "source_file": "jenkinsfile.txt",
    "text": " \"I said, Hello Mr. ${username}\"\n\nWould result in:\n\nHello Mr. ${username}\nI said, Hello Mr. Jenkins\n\nUnderstanding how to use string interpolation is vital for using some of\nPipeline's more advanced features.\n\n[WARNING]\n======\nGroovy string interpolation should [red]*never* be used with credentials.\n======\n\nGroovy string interpolation can leak sensitive environment variables (i.e. credentials, see"
  },
  "2223": {
    "source_file": "jenkinsfile.txt",
    "text": "tion should [red]*never* be used with credentials.\n======\n\nGroovy string interpolation can leak sensitive environment variables (i.e. credentials, see: <<Handling credentials>>).\nThis is because the sensitive environment variable will be interpolated during Groovy evaluation, and the environment variable's value could be made available earlier than intended, resulting in sensitive data leaking in "
  },
  "2224": {
    "source_file": "jenkinsfile.txt",
    "text": " during Groovy evaluation, and the environment variable's value could be made available earlier than intended, resulting in sensitive data leaking in various contexts.\n\nFor example, consider a sensitive environment variable passed to the `sh` step.\n\n[pipeline]\n\n// Declarative //\npipeline {\n    agent any\n    environment {\n        EXAMPLE_CREDS = credentials('example-credentials-id')\n    }\n    stage"
  },
  "2225": {
    "source_file": "jenkinsfile.txt",
    "text": "[pipeline]\n\n// Declarative //\npipeline {\n    agent any\n    environment {\n        EXAMPLE_CREDS = credentials('example-credentials-id')\n    }\n    stages {\n        stage('Example') {\n            steps {\n                /* WRONG! */\n                sh(\"curl -u ${EXAMPLE_CREDS_USR}:${EXAMPLE_CREDS_PSW} https://example.com/\")\n            }\n        }\n    }\n}\n// Script //\n\nShould Groovy perform the inter"
  },
  "2226": {
    "source_file": "jenkinsfile.txt",
    "text": "curl -u ${EXAMPLE_CREDS_USR}:${EXAMPLE_CREDS_PSW} https://example.com/\")\n            }\n        }\n    }\n}\n// Script //\n\nShould Groovy perform the interpolation, the sensitive value will be injected directly into the arguments of the `sh` step, which among other issues, means that the literal value will be visible as an argument to the `sh` process on the agent in OS process listings.\nUsing single-q"
  },
  "2227": {
    "source_file": "jenkinsfile.txt",
    "text": "mong other issues, means that the literal value will be visible as an argument to the `sh` process on the agent in OS process listings.\nUsing single-quotes instead of double-quotes when referencing these sensitive environment variables prevents this type of leaking.\n\n[pipeline]\n\n// Declarative //\npipeline {\n    agent any\n    environment {\n        EXAMPLE_CREDS = credentials('example-credentials-id"
  },
  "2228": {
    "source_file": "jenkinsfile.txt",
    "text": "type of leaking.\n\n[pipeline]\n\n// Declarative //\npipeline {\n    agent any\n    environment {\n        EXAMPLE_CREDS = credentials('example-credentials-id')\n    }\n    stages {\n        stage('Example') {\n            steps {\n                /* CORRECT */\n                sh('curl -u $EXAMPLE_CREDS_USR:$EXAMPLE_CREDS_PSW https://example.com/')\n            }\n        }\n    }\n}\n// Script //\n\n[WARNING]\n======"
  },
  "2229": {
    "source_file": "jenkinsfile.txt",
    "text": "               sh('curl -u $EXAMPLE_CREDS_USR:$EXAMPLE_CREDS_PSW https://example.com/')\n            }\n        }\n    }\n}\n// Script //\n\n[WARNING]\n======\nGroovy string interpolation can inject rogue commands into command interpreters via special characters.\n======\n\nAnother note of caution.\nUsing Groovy string interpolation for user-controlled variables with steps that pass their arguments to command "
  },
  "2230": {
    "source_file": "jenkinsfile.txt",
    "text": "ers.\n======\n\nAnother note of caution.\nUsing Groovy string interpolation for user-controlled variables with steps that pass their arguments to command interpreters such as the `sh`, `bat`, `powershell`, or `pwsh` steps can result in problems analogous to SQL injection.\nThis occurs when a user-controlled variable (generally an environment variable, usually a parameter passed to the build) that conta"
  },
  "2231": {
    "source_file": "jenkinsfile.txt",
    "text": " to SQL injection.\nThis occurs when a user-controlled variable (generally an environment variable, usually a parameter passed to the build) that contains special characters (e.g. `/ \\ $ & % ^ > < | ;`) is passed to the `sh`, `bat`, `powershell`, or `pwsh` steps using Groovy interpolation.\nFor a simple example:\n\n[pipeline]\n\n// Declarative //\npipeline {\n  agent any\n  parameters {\n    string(name: 'S"
  },
  "2232": {
    "source_file": "jenkinsfile.txt",
    "text": "pwsh` steps using Groovy interpolation.\nFor a simple example:\n\n[pipeline]\n\n// Declarative //\npipeline {\n  agent any\n  parameters {\n    string(name: 'STATEMENT', defaultValue: 'hello; ls /', description: 'What should I say?')\n  }\n  stages {\n    stage('Example') {\n      steps {\n        /* WRONG! */\n        sh(\"echo ${STATEMENT}\")\n      }\n    }\n  }\n}\n// Script //\n\nIn this example, the argument to the"
  },
  "2233": {
    "source_file": "jenkinsfile.txt",
    "text": "'Example') {\n      steps {\n        /* WRONG! */\n        sh(\"echo ${STATEMENT}\")\n      }\n    }\n  }\n}\n// Script //\n\nIn this example, the argument to the `sh` step is evaluated by Groovy, and `STATEMENT` is interpolated directly into the argument as if `sh('echo hello; ls /')` has been written in the Pipeline.\nWhen this is processed on the agent, rather than echoing the value `hello; ls /`, it will e"
  },
  "2234": {
    "source_file": "jenkinsfile.txt",
    "text": "`sh('echo hello; ls /')` has been written in the Pipeline.\nWhen this is processed on the agent, rather than echoing the value `hello; ls /`, it will echo `hello` then proceed to list the entire root directory of the agent.\nAny user able to control a variable interpolated by such a step would be able to make the `sh` step run arbitrary code on the agent.\nTo avoid this problem, make sure arguments t"
  },
  "2235": {
    "source_file": "jenkinsfile.txt",
    "text": "variable interpolated by such a step would be able to make the `sh` step run arbitrary code on the agent.\nTo avoid this problem, make sure arguments to steps such as `sh` or `bat` that reference parameters or other user-controlled environment variables use single quotes to avoid Groovy interpolation.\n\n[pipeline]\n\n// Declarative //\npipeline {\n  agent any\n  parameters {\n    string(name: 'STATEMENT',"
  },
  "2236": {
    "source_file": "jenkinsfile.txt",
    "text": "es use single quotes to avoid Groovy interpolation.\n\n[pipeline]\n\n// Declarative //\npipeline {\n  agent any\n  parameters {\n    string(name: 'STATEMENT', defaultValue: 'hello; ls /', description: 'What should I say?')\n  }\n  stages {\n    stage('Example') {\n      steps {\n        /* CORRECT */\n        sh('echo ${STATEMENT}')\n      }\n    }\n  }\n}\n// Script //\n\nCredential mangling is another issue that can"
  },
  "2237": {
    "source_file": "jenkinsfile.txt",
    "text": " {\n      steps {\n        /* CORRECT */\n        sh('echo ${STATEMENT}')\n      }\n    }\n  }\n}\n// Script //\n\nCredential mangling is another issue that can occur when credentials that contain special characters are passed to a step using Groovy interpolation.\nWhen the credential value is mangled, it is no longer valid and will no longer be masked in the console log.\n\n[pipeline]\n\n// Declarative //\npipel"
  },
  "2238": {
    "source_file": "jenkinsfile.txt",
    "text": "ion.\nWhen the credential value is mangled, it is no longer valid and will no longer be masked in the console log.\n\n[pipeline]\n\n// Declarative //\npipeline {\n  agent any\n  environment {\n    EXAMPLE_KEY = credentials('example-credentials-id') // Secret value is 'sec%ret'\n  }\n  stages {\n    stage('Example') {\n      steps {\n          /* WRONG! */\n          bat \"echo ${EXAMPLE_KEY}\"\n      }\n    }\n  }\n}\n"
  },
  "2239": {
    "source_file": "jenkinsfile.txt",
    "text": "value is 'sec%ret'\n  }\n  stages {\n    stage('Example') {\n      steps {\n          /* WRONG! */\n          bat \"echo ${EXAMPLE_KEY}\"\n      }\n    }\n  }\n}\n// Script //\n\nHere, the `bat` step receives `echo sec%ret` and the Windows batch shell will simply drop the `%` and print out the value `secret`.\nBecause there is a single character difference, the value `secret` will not be masked.\nThough the value "
  },
  "2240": {
    "source_file": "jenkinsfile.txt",
    "text": "rop the `%` and print out the value `secret`.\nBecause there is a single character difference, the value `secret` will not be masked.\nThough the value is not the same as the actual credential, this is still a significant exposure of sensitive information.\nAgain, single-quotes avoids this issue.\n\n[pipeline]\n\n// Declarative //\npipeline {\n  agent any\n  environment {\n    EXAMPLE_KEY = credentials('exam"
  },
  "2241": {
    "source_file": "jenkinsfile.txt",
    "text": "ion.\nAgain, single-quotes avoids this issue.\n\n[pipeline]\n\n// Declarative //\npipeline {\n  agent any\n  environment {\n    EXAMPLE_KEY = credentials('example-credentials-id') // Secret value is 'sec%ret'\n  }\n  stages {\n    stage('Example') {\n      steps {\n          /* CORRECT */\n          bat 'echo %EXAMPLE_KEY%'\n      }\n    }\n  }\n}\n// Script //\n\nDeclarative Pipeline supports parameters out-of-the-box"
  },
  "2242": {
    "source_file": "jenkinsfile.txt",
    "text": "{\n          /* CORRECT */\n          bat 'echo %EXAMPLE_KEY%'\n      }\n    }\n  }\n}\n// Script //\n\nDeclarative Pipeline supports parameters out-of-the-box, allowing the Pipeline to accept user-specified parameters at runtime via the <<syntax#parameters, parameters directive>>.\nConfiguring parameters with Scripted Pipeline is done with the `properties` step, which can be found in the Snippet Generator."
  },
  "2243": {
    "source_file": "jenkinsfile.txt",
    "text": "parameters directive>>.\nConfiguring parameters with Scripted Pipeline is done with the `properties` step, which can be found in the Snippet Generator.\n\nIf you configured your pipeline to accept parameters using the *Build with Parameters* option, those parameters are accessible as members of the `params` variable.\n\nAssuming that a String parameter named \"Greeting\" has been configured in the `Jenki"
  },
  "2244": {
    "source_file": "jenkinsfile.txt",
    "text": "se parameters are accessible as members of the `params` variable.\n\nAssuming that a String parameter named \"Greeting\" has been configured in the `Jenkinsfile`, it can access that parameter via `${params.Greeting}`:\n\n[pipeline]\n\n// Declarative //\npipeline {\n    agent any\n    parameters {\n        string(name: 'Greeting', defaultValue: 'Hello', description: 'How should I greet the world?')\n    }\n    s"
  },
  "2245": {
    "source_file": "jenkinsfile.txt",
    "text": "ine {\n    agent any\n    parameters {\n        string(name: 'Greeting', defaultValue: 'Hello', description: 'How should I greet the world?')\n    }\n    stages {\n        stage('Example') {\n            steps {\n                echo \"${params.Greeting} World!\"\n            }\n        }\n    }\n}\n// Script //\nproperties([parameters([string(defaultValue: 'Hello', description: 'How should I greet the world?', n"
  },
  "2246": {
    "source_file": "jenkinsfile.txt",
    "text": "d!\"\n            }\n        }\n    }\n}\n// Script //\nproperties([parameters([string(defaultValue: 'Hello', description: 'How should I greet the world?', name: 'Greeting')])])\n\nnode {\n    echo \"${params.Greeting} World!\"\n}\n\nDeclarative Pipeline supports robust failure handling by default via its <<syntax#post, post section>> which allows declaring a number of different \"post conditions\" such as: `alway"
  },
  "2247": {
    "source_file": "jenkinsfile.txt",
    "text": "obust failure handling by default via its <<syntax#post, post section>> which allows declaring a number of different \"post conditions\" such as: `always`, `unstable`, `success`, `failure`, and `changed`.\nThe <<syntax#post, Pipeline Syntax>> section provides more detail on how to use the various post conditions.\n\n[pipeline]\n\n// Declarative //\npipeline {\n    agent any\n    stages {\n        stage('Test"
  },
  "2248": {
    "source_file": "jenkinsfile.txt",
    "text": "ovides more detail on how to use the various post conditions.\n\n[pipeline]\n\n// Declarative //\npipeline {\n    agent any\n    stages {\n        stage('Test') {\n            steps {\n                sh 'make check'\n            }\n        }\n    }\n    post {\n        always {\n            junit '**/target/*.xml'\n        }\n        failure {\n            mail to: team@example.com, subject: 'The Pipeline failed :("
  },
  "2249": {
    "source_file": "jenkinsfile.txt",
    "text": "      always {\n            junit '**/target/*.xml'\n        }\n        failure {\n            mail to: team@example.com, subject: 'The Pipeline failed :('\n        }\n    }\n}\n// Script //\nnode {\n    /* .. snip .. */\n    stage('Test') {\n        try {\n            sh 'make check'\n        }\n        finally {\n            junit '**/target/*.xml'\n        }\n    }\n    /* .. snip .. */\n}\n\nScripted Pipeline howev"
  },
  "2250": {
    "source_file": "jenkinsfile.txt",
    "text": "       sh 'make check'\n        }\n        finally {\n            junit '**/target/*.xml'\n        }\n    }\n    /* .. snip .. */\n}\n\nScripted Pipeline however relies on Groovy's built-in `try`/`catch`/`finally` semantics for handling failures during execution of the Pipeline.\n\nIn the <<test>> example above, the `sh` step was modified to never return a non-zero exit code (`sh 'make check || true'`).\nThis"
  },
  "2251": {
    "source_file": "jenkinsfile.txt",
    "text": "ion of the Pipeline.\n\nIn the <<test>> example above, the `sh` step was modified to never return a non-zero exit code (`sh 'make check || true'`).\nThis approach, while valid, means the following stages need to check `currentBuild.result` to know if there has been a test failure or not.\n\nAn alternative way of handling this, which preserves the early-exit behavior of failures in Pipeline, while still"
  },
  "2252": {
    "source_file": "jenkinsfile.txt",
    "text": "ere has been a test failure or not.\n\nAn alternative way of handling this, which preserves the early-exit behavior of failures in Pipeline, while still giving `junit` the chance to capture test reports, is to use a series of `try`/`finally` blocks:\n\nJenkins Pipelines provide dedicated steps for flexible error handling, allowing you to control how your Pipeline responds to errors and warnings.\nThese"
  },
  "2253": {
    "source_file": "jenkinsfile.txt",
    "text": "enkins Pipelines provide dedicated steps for flexible error handling, allowing you to control how your Pipeline responds to errors and warnings.\nThese steps help you surface errors and warnings clearly in Jenkins, giving you control over whether the Pipeline fails, continues, or simply reports a warning.\nFor more information, refer to:\n\n*\n*\n*\n*\n\nIn all the previous examples, only a single agent ha"
  },
  "2254": {
    "source_file": "jenkinsfile.txt",
    "text": "Pipeline fails, continues, or simply reports a warning.\nFor more information, refer to:\n\n*\n*\n*\n*\n\nIn all the previous examples, only a single agent has been used.\nThis means Jenkins will allocate an executor wherever one is available, regardless of how it is labeled or configured.\nNot only can this behavior be overridden, but Pipeline allows utilizing multiple agents in the Jenkins environment fro"
  },
  "2255": {
    "source_file": "jenkinsfile.txt",
    "text": "ow it is labeled or configured.\nNot only can this behavior be overridden, but Pipeline allows utilizing multiple agents in the Jenkins environment from within the _same_ `Jenkinsfile`, which can be helpful for more advanced use-cases such as executing builds/tests across multiple platforms.\n\nIn the example below, the \"Build\" stage will be performed on one agent and the built results will be reused"
  },
  "2256": {
    "source_file": "jenkinsfile.txt",
    "text": "g builds/tests across multiple platforms.\n\nIn the example below, the \"Build\" stage will be performed on one agent and the built results will be reused on two subsequent agents, labelled \"linux\" and \"windows\" respectively, during the \"Test\" stage.\n\n[pipeline]\n\n// Declarative //\npipeline {\n    agent none\n    stages {\n        stage('Build') {\n            agent any\n            steps {\n                "
  },
  "2257": {
    "source_file": "jenkinsfile.txt",
    "text": "ipeline]\n\n// Declarative //\npipeline {\n    agent none\n    stages {\n        stage('Build') {\n            agent any\n            steps {\n                checkout scm\n                sh 'make'\n                stash includes: '**/target/*.jar', name: 'app' // <1> }\n        }\n        stage('Test on Linux') {\n            agent { // <2> label 'linux'\n            }\n            steps {\n                unsta"
  },
  "2258": {
    "source_file": "jenkinsfile.txt",
    "text": "' // <1> }\n        }\n        stage('Test on Linux') {\n            agent { // <2> label 'linux'\n            }\n            steps {\n                unstash 'app' // <3> sh 'make check'\n            }\n            post {\n                always {\n                    junit '**/target/*.xml'\n                }\n            }\n        }\n        stage('Test on Windows') {\n            agent {\n                lab"
  },
  "2259": {
    "source_file": "jenkinsfile.txt",
    "text": "          junit '**/target/*.xml'\n                }\n            }\n        }\n        stage('Test on Windows') {\n            agent {\n                label 'windows'\n            }\n            steps {\n                unstash 'app'\n                bat 'make check' // <4> }\n            post {\n                always {\n                    junit '**/target/*.xml'\n                }\n            }\n        }\n "
  },
  "2260": {
    "source_file": "jenkinsfile.txt",
    "text": "ke check' // <4> }\n            post {\n                always {\n                    junit '**/target/*.xml'\n                }\n            }\n        }\n    }\n}\n// Script //\nstage('Build') {\n    node {\n        checkout scm\n        sh 'make'\n        stash includes: '**/target/*.jar', name: 'app' // <1> }\n}\n\nstage('Test') {\n    node('linux') { // <2> checkout scm\n        try {\n            unstash 'app' "
  },
  "2261": {
    "source_file": "jenkinsfile.txt",
    "text": " includes: '**/target/*.jar', name: 'app' // <1> }\n}\n\nstage('Test') {\n    node('linux') { // <2> checkout scm\n        try {\n            unstash 'app' // <3> sh 'make check'\n        }\n        finally {\n            junit '**/target/*.xml'\n        }\n    }\n    node('windows') {\n        checkout scm\n        try {\n            unstash 'app'\n            bat 'make check' // <4> }\n        finally {\n        "
  },
  "2262": {
    "source_file": "jenkinsfile.txt",
    "text": " }\n    node('windows') {\n        checkout scm\n        try {\n            unstash 'app'\n            bat 'make check' // <4> }\n        finally {\n            junit '**/target/*.xml'\n        }\n    }\n}\n\n<1> The `stash` step allows capturing files matching an inclusion pattern (`+**/target/*.jar+`) for reuse within the _same_ Pipeline.\nOnce the Pipeline has completed its execution, stashed files are dele"
  },
  "2263": {
    "source_file": "jenkinsfile.txt",
    "text": "an inclusion pattern (`+**/target/*.jar+`) for reuse within the _same_ Pipeline.\nOnce the Pipeline has completed its execution, stashed files are deleted from the Jenkins controller.\n<2> The parameter in `agent`/`node` allows for any valid Jenkins label expression.\nConsult the <<syntax#, Pipeline Syntax>> section for more details.\n<3> `unstash` will retrieve the named \"stash\" from the Jenkins cont"
  },
  "2264": {
    "source_file": "jenkinsfile.txt",
    "text": "bel expression.\nConsult the <<syntax#, Pipeline Syntax>> section for more details.\n<3> `unstash` will retrieve the named \"stash\" from the Jenkins controller into the Pipeline's current workspace.\n<4> The `bat` script allows for executing batch scripts on Windows-based platforms.\n\nPipeline follows the Groovy language convention of allowing parentheses to be omitted around method arguments.\n\nMany Pi"
  },
  "2265": {
    "source_file": "jenkinsfile.txt",
    "text": "s on Windows-based platforms.\n\nPipeline follows the Groovy language convention of allowing parentheses to be omitted around method arguments.\n\nMany Pipeline steps also use the named-parameter syntax as a shorthand for creating a Map in Groovy, which uses the syntax `[key1: value1, key2: value2]`.\nMaking statements like the following functionally equivalent:\n\ngit url: 'git://example.com/amazing-pro"
  },
  "2266": {
    "source_file": "jenkinsfile.txt",
    "text": "uses the syntax `[key1: value1, key2: value2]`.\nMaking statements like the following functionally equivalent:\n\ngit url: 'git://example.com/amazing-project.git', branch: 'master'\ngit([url: 'git://example.com/amazing-project.git', branch: 'master'])\n\nFor convenience, when calling steps taking only one parameter (or only one mandatory parameter), the parameter name may be omitted, for example:\n\nsh 'e"
  },
  "2267": {
    "source_file": "jenkinsfile.txt",
    "text": "or convenience, when calling steps taking only one parameter (or only one mandatory parameter), the parameter name may be omitted, for example:\n\nsh 'echo hello' /* short form  */\nsh([script: 'echo hello'])  /* long form */\n\nScripted Pipeline is a domain-specific language footnote:dsl[https://en.wikipedia.org/wiki/Domain-specific_language] based on Groovy, most  can be used in Scripted Pipeline wit"
  },
  "2268": {
    "source_file": "jenkinsfile.txt",
    "text": "ain-specific language footnote:dsl[https://en.wikipedia.org/wiki/Domain-specific_language] based on Groovy, most  can be used in Scripted Pipeline without modification.\n\nThe example in the <<using-multiple-agents,section above>> runs tests across two different platforms in a linear series.\nIn practice, if the `make check` execution takes 30 minutes to complete, the \"Test\" stage would now take 60 m"
  },
  "2269": {
    "source_file": "jenkinsfile.txt",
    "text": " different platforms in a linear series.\nIn practice, if the `make check` execution takes 30 minutes to complete, the \"Test\" stage would now take 60 minutes to complete!\n\nFortunately, Pipeline has built-in functionality for executing portions of Scripted Pipeline in parallel, implemented in the aptly named `parallel` step.\n\nRefactoring the example above to use the `parallel` step:\n\n[pipeline]\n\n// "
  },
  "2270": {
    "source_file": "jenkinsfile.txt",
    "text": "pted Pipeline in parallel, implemented in the aptly named `parallel` step.\n\nRefactoring the example above to use the `parallel` step:\n\n[pipeline]\n\n// Script //\nstage('Build') {\n    /* .. snip .. */\n}\n\nstage('Test') {\n    parallel linux: {\n        node('linux') {\n            checkout scm\n            try {\n                unstash 'app'\n                sh 'make check'\n            }\n            finall"
  },
  "2271": {
    "source_file": "jenkinsfile.txt",
    "text": "e('linux') {\n            checkout scm\n            try {\n                unstash 'app'\n                sh 'make check'\n            }\n            finally {\n                junit '**/target/*.xml'\n            }\n        }\n    },\n    windows: {\n        node('windows') {\n            /* .. snip .. */\n        }\n    }\n}\n// Declarative not yet implemented //\n\nInstead of executing the tests on the \"linux\" an"
  },
  "2272": {
    "source_file": "jenkinsfile.txt",
    "text": "de('windows') {\n            /* .. snip .. */\n        }\n    }\n}\n// Declarative not yet implemented //\n\nInstead of executing the tests on the \"linux\" and \"windows\" labelled nodes in series, they will now execute in parallel assuming the requisite capacity exists in the Jenkins environment."
  },
  "2273": {
    "source_file": "jenkinsfile.txt",
    "text": "ity exists in the Jenkins environment."
  },
  "2274": {
    "source_file": "jep-235.txt",
    "text": "title: Agent &rarr; Controller Security Changes in 2.326\n# TODO Mention the first LTS release with this change as well\nlayout: documentation\n\n\nJenkins 2.326 removes the ability to disable or customize the agent-to-controller security system.\nThis change is specified in https://github.com/jenkinsci/jep/tree/master/jep/235[JEP-235].\n\nSeveral plugins are known to be affected by this change.\nFor the f"
  },
  "2275": {
    "source_file": "jep-235.txt",
    "text": "nge is specified in https://github.com/jenkinsci/jep/tree/master/jep/235[JEP-235].\n\nSeveral plugins are known to be affected by this change.\nFor the following plugins, updates are available as of December 29, 2021:\n// DATE SENSITIVE\n\n* https://plugins.jenkins.io/cobertura/[Cobertura Plugin Plugin] needs to be updated to 1.17 or newer.\n* https://plugins.jenkins.io/code-coverage-api/[Code Coverage A"
  },
  "2276": {
    "source_file": "jep-235.txt",
    "text": "s.jenkins.io/cobertura/[Cobertura Plugin Plugin] needs to be updated to 1.17 or newer.\n* https://plugins.jenkins.io/code-coverage-api/[Code Coverage API Plugin] needs to be updated to 2.0.4 or newer\n* https://plugins.jenkins.io/log-parser/[Log Parser Plugin] needs to be updated to 2.2 or newer\n* https://plugins.jenkins.io/maven-plugin/[Maven Integration Plugin] needs to be updated to 3.15.1 or new"
  },
  "2277": {
    "source_file": "jep-235.txt",
    "text": " Plugin] needs to be updated to 2.2 or newer\n* https://plugins.jenkins.io/maven-plugin/[Maven Integration Plugin] needs to be updated to 3.15.1 or newer\n* https://plugins.jenkins.io/warnings-ng/[Warnings Next Generation Plugin] needs to be updated to 5.2.0 or newer\n* https://plugins.jenkins.io/xunit/[XUnit Plugin] needs to be updated to 2.0.3 or newer\n// XUnit is speculative, see JEP\n\nOther plugin"
  },
  "2278": {
    "source_file": "jep-235.txt",
    "text": " 5.2.0 or newer\n* https://plugins.jenkins.io/xunit/[XUnit Plugin] needs to be updated to 2.0.3 or newer\n// XUnit is speculative, see JEP\n\nOther plugins have not yet been adapted.\nTheir compatibility fixes are tracked in the Jira epic https://issues.jenkins.io/browse/JENKINS-67173[JENKINS-67173].\n\nAs part of the change in 2.326, almost all code related to the agent-to-controller security system's c"
  },
  "2279": {
    "source_file": "jep-235.txt",
    "text": "enkins.io/browse/JENKINS-67173[JENKINS-67173].\n\nAs part of the change in 2.326, almost all code related to the agent-to-controller security system's configuration has been removed.\n\nA notable exception is `jenkins.security.s2m.AdminWhitelistRule` as that is used by https://plugins.jenkins.io/configuration-as-code/[Configuration as Code Plugin] and is also expected to be in frequent use in .\nIt is "
  },
  "2280": {
    "source_file": "jep-235.txt",
    "text": "that is used by https://plugins.jenkins.io/configuration-as-code/[Configuration as Code Plugin] and is also expected to be in frequent use in .\nIt is now a stub retaining the basic API -- `#getMasterKillSwitch` and `#setMasterKillSwitch(boolean)`, but both methods only generate log messages informing users about their obsolescence.\nInvocations of these methods can be safely removed when running Je"
  },
  "2281": {
    "source_file": "jep-235.txt",
    "text": "t both methods only generate log messages informing users about their obsolescence.\nInvocations of these methods can be safely removed when running Jenkins 2.326 or newer.\nUsers of Configuration as Code may remove the `remotingSecurity` section from\n\njenkins:\n  remotingSecurity:\n    enabled: true\n\n// TODO Also mention first LTS here."
  },
  "2282": {
    "source_file": "jep-235.txt",
    "text": "\njenkins:\n  remotingSecurity:\n    enabled: true\n\n// TODO Also mention first LTS here."
  },
  "2283": {
    "source_file": "json.txt",
    "text": "title: Expose HTTP API with JSON content with Jenkins\nsummary: How to write GET and POST HTTP API with Jenkins, and how to test it.\nlayout: developersection\nreferences:\n- url: https://github.com/stapler/stapler/blob/master/docs/reference.adoc\n  title: Stapler URL Binding Reference\n- url: ../routing\n  title: How requests in Jenkins are routed\n- url: ../../testing\n  title: Testing Jenkins\n\n\nThis pag"
  },
  "2284": {
    "source_file": "json.txt",
    "text": ": Stapler URL Binding Reference\n- url: ../routing\n  title: How requests in Jenkins are routed\n- url: ../../testing\n  title: Testing Jenkins\n\n\nThis page explains how to expose Json objects over HTTP API in your Jenkins plugins, using `GET` and `POST` verbs.\nThis page also shows how to test it with JenkinsRules from .\n\nThis object represents the structured data that is exchanged between the HTTP ser"
  },
  "2285": {
    "source_file": "json.txt",
    "text": "verbs.\nThis page also shows how to test it with JenkinsRules from .\n\nThis object represents the structured data that is exchanged between the HTTP server (Jenkins) and the client (curl for example).\nWe are using a very simple java Object for example purpose, but in production code you will have more complex objects to manipulate.\n\nNote that if you use Stapler (`JSONObject`) for marshalling and unm"
  },
  "2286": {
    "source_file": "json.txt",
    "text": "purpose, but in production code you will have more complex objects to manipulate.\n\nNote that if you use Stapler (`JSONObject`) for marshalling and unmarshalling JSON, you need an empty constructor.\n\npublic static class MyJsonObject {\n    private String message;\n\n    //empty constructor required for JSON parsing.\n    public MyJsonObject() {}\n\n    public MyJsonObject(String message) {\n        this.m"
  },
  "2287": {
    "source_file": "json.txt",
    "text": "ng message;\n\n    //empty constructor required for JSON parsing.\n    public MyJsonObject() {}\n\n    public MyJsonObject(String message) {\n        this.message = message;\n    }\n\n    public void setMessage(String message) {\n        this.message = message;\n    }\n\n    public String getMessage() {\n        return message;\n    }\n}\n\nThis part shows how to expose an HTTP GET that return a structured JSON res"
  },
  "2288": {
    "source_file": "json.txt",
    "text": ";\n    }\n\n    public String getMessage() {\n        return message;\n    }\n}\n\nThis part shows how to expose an HTTP GET that return a structured JSON response.\n\n/* (1) */\nimport static java.util.Objects.requireNonNull;\n\nimport edu.umd.cs.findbugs.annotations.CheckForNull;\nimport hudson.Extension;\nimport hudson.model.RootAction;\nimport net.sf.json.JSONObject;\nimport org.kohsuke.stapler.HttpResponse;\ni"
  },
  "2289": {
    "source_file": "json.txt",
    "text": "tions.CheckForNull;\nimport hudson.Extension;\nimport hudson.model.RootAction;\nimport net.sf.json.JSONObject;\nimport org.kohsuke.stapler.HttpResponse;\nimport org.kohsuke.stapler.QueryParameter;\nimport org.kohsuke.stapler.WebMethod;\nimport org.kohsuke.stapler.json.JsonBody;\nimport org.kohsuke.stapler.json.JsonHttpResponse;\nimport org.kohsuke.stapler.verb.GET;\nimport org.kohsuke.stapler.verb.POST;\n\n@E"
  },
  "2290": {
    "source_file": "json.txt",
    "text": "tapler.json.JsonBody;\nimport org.kohsuke.stapler.json.JsonHttpResponse;\nimport org.kohsuke.stapler.verb.GET;\nimport org.kohsuke.stapler.verb.POST;\n\n@Extension /* (2) */\npublic class JsonAPI implements RootAction /* (3) */ {\n\n    @CheckForNull\n    @Override\n    public String getIconFileName() {\n        return null; /* (4) */\n    }\n\n    @CheckForNull\n    @Override\n    public String getDisplayName() "
  },
  "2291": {
    "source_file": "json.txt",
    "text": "erride\n    public String getIconFileName() {\n        return null; /* (4) */\n    }\n\n    @CheckForNull\n    @Override\n    public String getDisplayName() {\n        return null; /* (5) */\n    }\n\n    @Override\n    public String getUrlName() {\n        return \"custom-api\"; /* (6) */\n    }\n\n    @GET\n    @WebMethod(name = \"get-example\")/* (7) */\n    public /* (8) */ JsonHttpResponse getExample() {\n        J"
  },
  "2292": {
    "source_file": "json.txt",
    "text": "n \"custom-api\"; /* (6) */\n    }\n\n    @GET\n    @WebMethod(name = \"get-example\")/* (7) */\n    public /* (8) */ JsonHttpResponse getExample() {\n        JSONObject response = JSONObject.fromObject(new MyJsonObject(\"I am Jenkins\"));\n        return new JsonHttpResponse(response, 200); /* (9) */\n    }\n\n    @GET\n    @WebMethod(name = \"get-example-param\")\n    public JsonHttpResponse getWithParameters(\n    "
  },
  "2293": {
    "source_file": "json.txt",
    "text": "nHttpResponse(response, 200); /* (9) */\n    }\n\n    @GET\n    @WebMethod(name = \"get-example-param\")\n    public JsonHttpResponse getWithParameters(\n        @QueryParameter(required = true) String paramValue /* (10) */) {\n\n        requireNonNull(paramValue);\n        MyJsonObject myJsonObject = new MyJsonObject(\"I am Jenkins \" + paramValue);\n        JSONObject response = JSONObject.fromObject(myJsonOb"
  },
  "2294": {
    "source_file": "json.txt",
    "text": "lue);\n        MyJsonObject myJsonObject = new MyJsonObject(\"I am Jenkins \" + paramValue);\n        JSONObject response = JSONObject.fromObject(myJsonObject);\n        return new JsonHttpResponse(response, 200);\n    }\n\n    @GET\n    @WebMethod(name = \"get-error500\")\n    public JsonHttpResponse getError500() { /* (11) */\n        MyJsonObject myJsonObject = new MyJsonObject(\"You got an error 500\");\n    "
  },
  "2295": {
    "source_file": "json.txt",
    "text": "t-error500\")\n    public JsonHttpResponse getError500() { /* (11) */\n        MyJsonObject myJsonObject = new MyJsonObject(\"You got an error 500\");\n        JSONObject jsonResponse = JSONObject.fromObject(myJsonObject);\n        JsonHttpResponse error500 = new JsonHttpResponse(jsonResponse, 500);\n        throw error500;\n    }\n}\n\n1. Non-exhaustive list of imports to use.\n2. Must be an extension to be d"
  },
  "2296": {
    "source_file": "json.txt",
    "text": " = new JsonHttpResponse(jsonResponse, 500);\n        throw error500;\n    }\n}\n\n1. Non-exhaustive list of imports to use.\n2. Must be an extension to be discovered as a service by Jenkins.\n3. This class is an extension of RootAction.  It is a way to expose HTTP paths that is more frequently used to expose the Web UI, but it can also be used without HTML rendering.\n4. Since there is no HTML/Jelly rende"
  },
  "2297": {
    "source_file": "json.txt",
    "text": "se HTTP paths that is more frequently used to expose the Web UI, but it can also be used without HTML rendering.\n4. Since there is no HTML/Jelly rendering, no icons are needed.\n5. Since there is no HTML/Jelly rendering, no display name is needed.\n6. `getUrlName()` is the root of the JSON API.  Each WebMethod in the class is prefixed by this.\n7. `@GET` indicates the HTTP method that is expected, an"
  },
  "2298": {
    "source_file": "json.txt",
    "text": "`getUrlName()` is the root of the JSON API.  Each WebMethod in the class is prefixed by this.\n7. `@GET` indicates the HTTP method that is expected, and `@WebMethod` indicates that it is accepting an HTTP request. By default, the JAVA name of the WebMethod is used, but a different name can be specified by using `name =`\n8. `JsonHttpResponse` is a subclass of `HttpResponse` that indicates that the r"
  },
  "2299": {
    "source_file": "json.txt",
    "text": "ethod is used, but a different name can be specified by using `name =`\n8. `JsonHttpResponse` is a subclass of `HttpResponse` that indicates that the response content will be JSON\n9. An HTTP status can be set in the response.\n10. `@QueryParameter` indicates that this parameter is injected from HTTP query parameter. By default, the JAVA parameter name is used (in this case `paramValue`), but a diffe"
  },
  "2300": {
    "source_file": "json.txt",
    "text": "icates that this parameter is injected from HTTP query parameter. By default, the JAVA parameter name is used (in this case `paramValue`), but a different name can be specified by using `value =` annotation attribute.\n11. The method `getError500` is added in the example to show how to set an error response as JSON.\n\nA `mvn hpi:run` in the plugin should be enough to run it locally.  Assuming that J"
  },
  "2301": {
    "source_file": "json.txt",
    "text": "added in the example to show how to set an error response as JSON.\n\nA `mvn hpi:run` in the plugin should be enough to run it locally.  Assuming that Jenkins is up at http://localhost:8080/jenkins/ , you should have at this point:\n\ncurl -XGET \\\n    -w \"\\n STATUS:%{http_code}\"  \\\n    http://localhost:8080/jenkins/custom-api/get-example-param?paramValue=hello\n\n{\"message\":\"I am Jenkins hello\"}\n STATUS"
  },
  "2302": {
    "source_file": "json.txt",
    "text": " \"\\n STATUS:%{http_code}\"  \\\n    http://localhost:8080/jenkins/custom-api/get-example-param?paramValue=hello\n\n{\"message\":\"I am Jenkins hello\"}\n STATUS:200\n\nimport static org.hamcrest.MatcherAssert.assertThat;\n\nimport jenkins.model.Jenkins;\nimport org.hamcrest.Matchers;\nimport org.junit.jupiter.api.Test;\nimport org.jvnet.hudson.test.JenkinsRule;\nimport org.jvnet.hudson.test.JenkinsRule.JSONWebRespo"
  },
  "2303": {
    "source_file": "json.txt",
    "text": ".hamcrest.Matchers;\nimport org.junit.jupiter.api.Test;\nimport org.jvnet.hudson.test.JenkinsRule;\nimport org.jvnet.hudson.test.JenkinsRule.JSONWebResponse;\nimport org.jvnet.hudson.test.MockAuthorizationStrategy;\nimport org.jvnet.hudson.test.junit.jupiter.WithJenkins;\n\n@WithJenkins\nclass JsonAPITest {\n\n    private static final String GET_API_URL = \"custom-api/get-example-param?paramValue=hello\";\n\n  "
  },
  "2304": {
    "source_file": "json.txt",
    "text": "ter.WithJenkins;\n\n@WithJenkins\nclass JsonAPITest {\n\n    private static final String GET_API_URL = \"custom-api/get-example-param?paramValue=hello\";\n\n    @Test\n    void testGetJSON(JenkinsRule j) throws Exception {\n        JenkinsRule.WebClient webClient = j.createWebClient();\n\n        JSONWebResponse response = webClient.getJSON(GET_API_URL);\n        assertThat(response.getContentAsString(), Matche"
  },
  "2305": {
    "source_file": "json.txt",
    "text": "nt = j.createWebClient();\n\n        JSONWebResponse response = webClient.getJSON(GET_API_URL);\n        assertThat(response.getContentAsString(), Matchers.containsString(\"I am Jenkins hello\"));\n        assertThat(response.getStatusCode(), Matchers.equalTo(200));\n    }\n\n    @Test\n    void testAdvancedGetJSON(JenkinsRule j) throws Exception {\n        //Given a Jenkins setup with a user \"admin\"\n       "
  },
  "2306": {
    "source_file": "json.txt",
    "text": "lTo(200));\n    }\n\n    @Test\n    void testAdvancedGetJSON(JenkinsRule j) throws Exception {\n        //Given a Jenkins setup with a user \"admin\"\n        MockAuthorizationStrategy auth = new MockAuthorizationStrategy()\n            .grant(Jenkins.ADMINISTER).everywhere().to(\"admin\");\n\n        j.jenkins.setSecurityRealm(j.createDummySecurityRealm());\n        j.jenkins.setAuthorizationStrategy(auth);\n\n "
  },
  "2307": {
    "source_file": "json.txt",
    "text": "TER).everywhere().to(\"admin\");\n\n        j.jenkins.setSecurityRealm(j.createDummySecurityRealm());\n        j.jenkins.setAuthorizationStrategy(auth);\n\n        //We need to setup the WebClient, we use it to call the HTTP API\n        JenkinsRule.WebClient webClient = j.createWebClient();\n\n        //By default if the status code is not ok, WebClient throw an exception\n        //Since we want to assert "
  },
  "2308": {
    "source_file": "json.txt",
    "text": "t webClient = j.createWebClient();\n\n        //By default if the status code is not ok, WebClient throw an exception\n        //Since we want to assert the error status code, we need to set to false.\n        webClient.setThrowExceptionOnFailingStatusCode(false);\n\n        // - simple call without authentication should be forbidden\n        JSONWebResponse response = webClient.getJSON(GET_API_URL);\n   "
  },
  "2309": {
    "source_file": "json.txt",
    "text": "de(false);\n\n        // - simple call without authentication should be forbidden\n        JSONWebResponse response = webClient.getJSON(GET_API_URL);\n        assertThat(response.getStatusCode(), Matchers.equalTo(403));\n\n        // - same call but authenticated using withBasicApiToken() should be fine\n        response = webClient.withBasicApiToken(\"admin\").getJSON(GET_API_URL);\n        assertThat(resp"
  },
  "2310": {
    "source_file": "json.txt",
    "text": "ticated using withBasicApiToken() should be fine\n        response = webClient.withBasicApiToken(\"admin\").getJSON(GET_API_URL);\n        assertThat(response.getStatusCode(), Matchers.equalTo(200));\n    }\n}\n\nThis section shows how to expose an HTTP endpoint that takes a structured JSON Object as input, and does a response with a JSON structured Object.\nFor this example the same Object is used as inpu"
  },
  "2311": {
    "source_file": "json.txt",
    "text": "oint that takes a structured JSON Object as input, and does a response with a JSON structured Object.\nFor this example the same Object is used as input and output, but you can also use different JSON structure for the response.\n\nStarting from the class `JsonAPI` provided for GET example, add:\n\n@POST\n@WebMethod(name = \"create\")\npublic JsonHttpResponse create(@JsonBody MyJsonObject body) {\n    //Do "
  },
  "2312": {
    "source_file": "json.txt",
    "text": "ss `JsonAPI` provided for GET example, add:\n\n@POST\n@WebMethod(name = \"create\")\npublic JsonHttpResponse create(@JsonBody MyJsonObject body) {\n    //Do any logic required for creation\n    //For the example purpose we just uppercase the message parsed from the request.\n    JSONObject response = new JSONObject();\n    response.put(\"message\", body.message.toUpperCase());\n    return new JsonHttpResponse("
  },
  "2313": {
    "source_file": "json.txt",
    "text": "rom the request.\n    JSONObject response = new JSONObject();\n    response.put(\"message\", body.message.toUpperCase());\n    return new JsonHttpResponse(response, 200);\n}\n\nA `mvn hpi:run` in the plugin should be enough to run it locally.\nAssuming that Jenkins is up at http://localhost:8080/jenkins/ , you should have at this point:\n\nWrite a file `my.json` containing the JSON body:\n\n{\"message\":\"A nice "
  },
  "2314": {
    "source_file": "json.txt",
    "text": "enkins is up at http://localhost:8080/jenkins/ , you should have at this point:\n\nWrite a file `my.json` containing the JSON body:\n\n{\"message\":\"A nice message to send\"}\n\nThen, if you need a user and a token:\n\n* go on Jenkins UI\n* login as a user, for example 'myuser'\n* on the top right click on user name\n* go on configure (for this user)\n* in the section \"API Token\" create a new token.\n\nFor additio"
  },
  "2315": {
    "source_file": "json.txt",
    "text": "example 'myuser'\n* on the top right click on user name\n* go on configure (for this user)\n* in the section \"API Token\" create a new token.\n\nFor additional documentation on the token, please visit:\n\n*\n*\n\nAnd then send the POST request:\n\ncurl -XPOST \\\n    -H \"Content-Type: application/json\" \\\n    --user myuser:xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx \\\n    http://localhost:8080/jenkins/custom-api/create \\\n"
  },
  "2316": {
    "source_file": "json.txt",
    "text": "   -H \"Content-Type: application/json\" \\\n    --user myuser:xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx \\\n    http://localhost:8080/jenkins/custom-api/create \\\n    --data \"@my.json\"\n\n{\"message\":\"A NICE MESSAGE TO SEND\"}\n STATUS:200\n\nStarting from the class `JsonAPITest` provided for the GET example, add:\n\n@Test\nvoid testPostJSON(JenkinsRule j) throws Exception {\n\n    //Given a Jenkins setup with a user \"adm"
  },
  "2317": {
    "source_file": "json.txt",
    "text": "onAPITest` provided for the GET example, add:\n\n@Test\nvoid testPostJSON(JenkinsRule j) throws Exception {\n\n    //Given a Jenkins setup with a user \"admin\"\n    MockAuthorizationStrategy auth = new MockAuthorizationStrategy()\n        .grant(Jenkins.ADMINISTER).everywhere().to(\"admin\");\n\n    j.jenkins.setSecurityRealm(j.createDummySecurityRealm());\n    j.jenkins.setAuthorizationStrategy(auth);\n\n    //"
  },
  "2318": {
    "source_file": "json.txt",
    "text": "NISTER).everywhere().to(\"admin\");\n\n    j.jenkins.setSecurityRealm(j.createDummySecurityRealm());\n    j.jenkins.setAuthorizationStrategy(auth);\n\n    //We need to setup the WebClient, we use it to call the HTTP API\n    JenkinsRule.WebClient webClient = j.createWebClient();\n\n    // Testing an authenticated POST that should answer 200 OK and return same json\n    MyJsonObject objectToSend = new MyJsonO"
  },
  "2319": {
    "source_file": "json.txt",
    "text": " j.createWebClient();\n\n    // Testing an authenticated POST that should answer 200 OK and return same json\n    MyJsonObject objectToSend = new MyJsonObject(\"Jenkins is the way !\");\n    JenkinsRule.JSONWebResponse response = webClient\n        .withBasicApiToken(\"admin\")\n        .postJSON(\"custom-api/create\", JSONObject.fromObject(objectToSend));\n\n    //because API is returning the same object, we a"
  },
  "2320": {
    "source_file": "json.txt",
    "text": "icApiToken(\"admin\")\n        .postJSON(\"custom-api/create\", JSONObject.fromObject(objectToSend));\n\n    //because API is returning the same object, we assert the input message.\n    assertThat(response.getContentAsString(), Matchers.containsString(\"JENKINS IS THE WAY !\"));\n    assertThat(response.getStatusCode(), Matchers.equalTo(200));\n}\n\nFor people that are familiar with REST/JSON concept you may w"
  },
  "2321": {
    "source_file": "json.txt",
    "text": "INS IS THE WAY !\"));\n    assertThat(response.getStatusCode(), Matchers.equalTo(200));\n}\n\nFor people that are familiar with REST/JSON concept you may want to use other HTTP verbs. It should work, but since generally in Jenkins only `GET` and `POST` are used, this page only shows example for this 2 verbs.\n\nYou may also want to use several HTTP status code, following HTTP convention like `201` for cr"
  },
  "2322": {
    "source_file": "json.txt",
    "text": "e used, this page only shows example for this 2 verbs.\n\nYou may also want to use several HTTP status code, following HTTP convention like `201` for created. It will also work, and the examples above are returning explicit `200` status to show how to manage the HTTP status that is return.\nSome statuses are managed by Jenkins Core and may be returned automatically, like `403` when the user in the re"
  },
  "2323": {
    "source_file": "json.txt",
    "text": "manage the HTTP status that is return.\nSome statuses are managed by Jenkins Core and may be returned automatically, like `403` when the user in the request does not have the required permission or is anonymous, or `404` when the HTTP API is not found.\n\nIf you are not familiar with Jenkins architecture, you can have a look to  and at\n\nFor more advanced reading on the HTTP layer of Jenkins, it's man"
  },
  "2324": {
    "source_file": "json.txt",
    "text": ".\n\nIf you are not familiar with Jenkins architecture, you can have a look to  and at\n\nFor more advanced reading on the HTTP layer of Jenkins, it's managed by ."
  },
  "2325": {
    "source_file": "kubernetes.txt",
    "text": "layout: section\ntitle: Kubernetes\n\n\nifdef::env-github[:imagesdir: ../resources]\nifndef::env-github[:imagesdir: ../../resources]\n\nKubernetes (K8s) is an open-source system for automating deployment, scaling,\nand management of containerized applications.\n\nA Kubernetes cluster adds a new automation layer to Jenkins.\nKubernetes makes sure that resources are used effectively and that your servers\nand u"
  },
  "2326": {
    "source_file": "kubernetes.txt",
    "text": "s.\n\nA Kubernetes cluster adds a new automation layer to Jenkins.\nKubernetes makes sure that resources are used effectively and that your servers\nand underlying infrastructure are not overloaded.\nKubernetes' ability to orchestrate container deployment ensures that Jenkins always\nhas the right amount of resources available.\n\nHosting Jenkins on a Kubernetes Cluster is beneficial for Kubernetes-based\n"
  },
  "2327": {
    "source_file": "kubernetes.txt",
    "text": " ensures that Jenkins always\nhas the right amount of resources available.\n\nHosting Jenkins on a Kubernetes Cluster is beneficial for Kubernetes-based\ndeployments and dynamic container-based scalable Jenkins agents.\n\nSeveral strategies for such setup and maintenance are explored below, including:\n\n* Direct use of `kubectl` and YAML files to configure certain aspects of\n  the deployment.\n* Use of th"
  },
  "2328": {
    "source_file": "kubernetes.txt",
    "text": "and maintenance are explored below, including:\n\n* Direct use of `kubectl` and YAML files to configure certain aspects of\n  the deployment.\n* Use of the `helm` tool and Helm Chart files to manage a whole ecosystem.\n  For example, both the controller AND a population of agents where actual work\n  happens.\n* Further use of the Jenkins Operator to manage operations for Jenkins\n  on Kubernetes in the c"
  },
  "2329": {
    "source_file": "kubernetes.txt",
    "text": "ND a population of agents where actual work\n  happens.\n* Further use of the Jenkins Operator to manage operations for Jenkins\n  on Kubernetes in the cluster.\n\n'''\n\nHere, we see a step-by-step process for setting up Jenkins on a Kubernetes Cluster.\n\nFor setting up a Jenkins Cluster on Kubernetes, we will do the following:\n\n[arabic]\n<<create-a-namespace,Create a Namespace>>\n<<create-a-service-accoun"
  },
  "2330": {
    "source_file": "kubernetes.txt",
    "text": "or setting up a Jenkins Cluster on Kubernetes, we will do the following:\n\n[arabic]\n<<create-a-namespace,Create a Namespace>>\n<<create-a-service-account,Create a service account>> with Kubernetes admin permissions.\n<<create-a-volume,Create local persistent volume>> for persistent Jenkins data on Pod restarts.\n<<create-a-deployment,Create a deployment YAML>> and deploy it.\n<<create-a-service,Create "
  },
  "2331": {
    "source_file": "kubernetes.txt",
    "text": "stent volume>> for persistent Jenkins data on Pod restarts.\n<<create-a-deployment,Create a deployment YAML>> and deploy it.\n<<create-a-service,Create a service YAML>> and deploy it.\n\nNOTE: This guide doesn\u2019t use local persistent volume as this is a generic guide.\nFor using persistent volume for your Jenkins data, you need to create volumes of relevant cloud or on-prem data center and configure it."
  },
  "2332": {
    "source_file": "kubernetes.txt",
    "text": "eneric guide.\nFor using persistent volume for your Jenkins data, you need to create volumes of relevant cloud or on-prem data center and configure it.\n\nAll the Jenkins Kubernetes manifest files used here are hosted on GitHub.\nPlease clone the repository if you have trouble copying the manifest from the document.\n\ngit clone https://github.com/scriptcamp/kubernetes-jenkins\n\nUse the GitHub files for "
  },
  "2333": {
    "source_file": "kubernetes.txt",
    "text": "ory if you have trouble copying the manifest from the document.\n\ngit clone https://github.com/scriptcamp/kubernetes-jenkins\n\nUse the GitHub files for reference and follow the steps in the next sections.\n\nLet\u2019s get started with deploying Jenkins on Kubernetes.\n\n[#create-a-namespace]\n*Step 1*: Create a Namespace for Jenkins.\nIt is good to categorize all the DevOps tools as a separate namespace from "
  },
  "2334": {
    "source_file": "kubernetes.txt",
    "text": "bernetes.\n\n[#create-a-namespace]\n*Step 1*: Create a Namespace for Jenkins.\nIt is good to categorize all the DevOps tools as a separate namespace from other applications.\n\nkubectl create namespace devops-tools\n\n[#create-a-service-account]\n*Step 2:* Create a 'jenkins-01-serviceAccount.yaml' file and copy the following admin service account manifest.\n\n\napiVersion: rbac.authorization.k8s.io/v1\nkind: C"
  },
  "2335": {
    "source_file": "kubernetes.txt",
    "text": "eate a 'jenkins-01-serviceAccount.yaml' file and copy the following admin service account manifest.\n\n\napiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRole\nmetadata:\n  name: jenkins-admin\nrules:\n  - apiGroups: [\"\"]\n    resources: [\"*\"]\n    verbs: [\"*\"]\n\napiVersion: v1\nkind: ServiceAccount\nmetadata:\n  name: jenkins-admin\n  namespace: devops-tools\n\napiVersion: rbac.authorization.k8s.io/v1\nkind:"
  },
  "2336": {
    "source_file": "kubernetes.txt",
    "text": ": [\"*\"]\n\napiVersion: v1\nkind: ServiceAccount\nmetadata:\n  name: jenkins-admin\n  namespace: devops-tools\n\napiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRoleBinding\nmetadata:\n  name: jenkins-admin\nroleRef:\n  apiGroup: rbac.authorization.k8s.io\n  kind: ClusterRole\n  name: jenkins-admin\nsubjects:\n- kind: ServiceAccount\n  name: jenkins-admin\n  namespace: devops-tools\n\nThe 'jenkins-01-serviceAcco"
  },
  "2337": {
    "source_file": "kubernetes.txt",
    "text": " kind: ClusterRole\n  name: jenkins-admin\nsubjects:\n- kind: ServiceAccount\n  name: jenkins-admin\n  namespace: devops-tools\n\nThe 'jenkins-01-serviceAccount.yaml' creates a 'jenkins-admin' clusterRole, 'jenkins-admin' ServiceAccount and binds the 'clusterRole' to the service account.\n\nThe 'jenkins-admin' cluster role has all the permissions to manage the cluster components.\nYou can also restrict acce"
  },
  "2338": {
    "source_file": "kubernetes.txt",
    "text": "erRole' to the service account.\n\nThe 'jenkins-admin' cluster role has all the permissions to manage the cluster components.\nYou can also restrict access by specifying individual resource actions.\n\nNow create the service account using kubectl.\n\nkubectl apply -f jenkins-01-serviceAccount.yaml\n\n[#create-a-volume]\n**Step 3: **Create 'jenkins-02-volume.yaml' and copy the following persistent volume man"
  },
  "2339": {
    "source_file": "kubernetes.txt",
    "text": "l apply -f jenkins-01-serviceAccount.yaml\n\n[#create-a-volume]\n**Step 3: **Create 'jenkins-02-volume.yaml' and copy the following persistent volume manifest.\n\nkind: StorageClass\napiVersion: storage.k8s.io/v1\nmetadata:\n  name: local-storage\nprovisioner: kubernetes.io/no-provisioner\nvolumeBindingMode: WaitForFirstConsumer\n\napiVersion: v1\nkind: PersistentVolume\nmetadata:\n  name: jenkins-pv-volume\n  la"
  },
  "2340": {
    "source_file": "kubernetes.txt",
    "text": ": kubernetes.io/no-provisioner\nvolumeBindingMode: WaitForFirstConsumer\n\napiVersion: v1\nkind: PersistentVolume\nmetadata:\n  name: jenkins-pv-volume\n  labels:\n    type: local\nspec:\n  storageClassName: local-storage\n  claimRef:\n    name: jenkins-pv-claim\n    namespace: devops-tools\n  capacity:\n    storage: 10Gi\n  accessModes:\n    - ReadWriteOnce\n  local:\n    path: /mnt\n  nodeAffinity:\n    required:\n  "
  },
  "2341": {
    "source_file": "kubernetes.txt",
    "text": "\n    namespace: devops-tools\n  capacity:\n    storage: 10Gi\n  accessModes:\n    - ReadWriteOnce\n  local:\n    path: /mnt\n  nodeAffinity:\n    required:\n      nodeSelectorTerms:\n      - matchExpressions:\n        - key: kubernetes.io/hostname\n          operator: In\n          values:\n          - worker-node01\n\napiVersion: v1\nkind: PersistentVolumeClaim\nmetadata:\n  name: jenkins-pv-claim\n  namespace: devo"
  },
  "2342": {
    "source_file": "kubernetes.txt",
    "text": "rator: In\n          values:\n          - worker-node01\n\napiVersion: v1\nkind: PersistentVolumeClaim\nmetadata:\n  name: jenkins-pv-claim\n  namespace: devops-tools\nspec:\n  storageClassName: local-storage\n  accessModes:\n    - ReadWriteOnce\n  resources:\n    requests:\n      storage: 3Gi\n\n*Important Note:* Replace 'worker-node01' with any one of your cluster worker nodes hostname.\n\nYou can get the worker n"
  },
  "2343": {
    "source_file": "kubernetes.txt",
    "text": " requests:\n      storage: 3Gi\n\n*Important Note:* Replace 'worker-node01' with any one of your cluster worker nodes hostname.\n\nYou can get the worker node hostname using the kubectl.\n\nkubectl get nodes\n\nFor volume, we are using the 'local' storage class for the purpose of demonstration.\nMeaning, it creates a 'PersistentVolume' volume in a specific node under the '/mnt' location.\n\nAs the 'local' sto"
  },
  "2344": {
    "source_file": "kubernetes.txt",
    "text": "ss for the purpose of demonstration.\nMeaning, it creates a 'PersistentVolume' volume in a specific node under the '/mnt' location.\n\nAs the 'local' storage class requires the node selector, you need to specify the worker node name correctly for the Jenkins pod to get scheduled in the specific node.\n\nIf the pod gets deleted or restarted, the data will get persisted in the node volume.\nHowever, if th"
  },
  "2345": {
    "source_file": "kubernetes.txt",
    "text": "nkins pod to get scheduled in the specific node.\n\nIf the pod gets deleted or restarted, the data will get persisted in the node volume.\nHowever, if the node gets deleted, you will lose all the data.\n\nIdeally, you should use a persistent volume using the available storage class with the cloud provider, or the one provided by the cluster administrator to persist data on node failures.\n\nLet\u2019s create "
  },
  "2346": {
    "source_file": "kubernetes.txt",
    "text": "the available storage class with the cloud provider, or the one provided by the cluster administrator to persist data on node failures.\n\nLet\u2019s create the volume using kubectl\n\nkubectl create -f jenkins-02-volume.yaml\n\n[#create-a-deployment]\n*Step 4:* Create a Deployment file named 'jenkins-03-deployment.yaml' and copy the following deployment manifest.\n\napiVersion: apps/v1\nkind: Deployment\nmetadat"
  },
  "2347": {
    "source_file": "kubernetes.txt",
    "text": " Create a Deployment file named 'jenkins-03-deployment.yaml' and copy the following deployment manifest.\n\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: jenkins\n  namespace: devops-tools\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: jenkins-server\n  strategy:\n    type: Recreate\n  template:\n    metadata:\n      labels:\n        app: jenkins-server\n    spec:\n      securityContext"
  },
  "2348": {
    "source_file": "kubernetes.txt",
    "text": "app: jenkins-server\n  strategy:\n    type: Recreate\n  template:\n    metadata:\n      labels:\n        app: jenkins-server\n    spec:\n      securityContext:\n            # Note: fsGroup may be customized for a bit of better\n            # filesystem security on the shared host\n            fsGroup: 1000\n            runAsUser: 1000\n            ### runAsGroup: 1000\n      serviceAccountName: jenkins-admin\n  "
  },
  "2349": {
    "source_file": "kubernetes.txt",
    "text": "y on the shared host\n            fsGroup: 1000\n            runAsUser: 1000\n            ### runAsGroup: 1000\n      serviceAccountName: jenkins-admin\n      containers:\n        - name: jenkins\n          image: jenkins/jenkins:lts\n          # OPTIONAL: check for new floating-tag LTS releases whenever the pod is restarted:\n          imagePullPolicy: Always\n          resources:\n            limits:\n     "
  },
  "2350": {
    "source_file": "kubernetes.txt",
    "text": "heck for new floating-tag LTS releases whenever the pod is restarted:\n          imagePullPolicy: Always\n          resources:\n            limits:\n              memory: \"2Gi\"\n              cpu: \"1000m\"\n            requests:\n              memory: \"500Mi\"\n              cpu: \"500m\"\n          ports:\n            - name: httpport\n              containerPort: 8080\n            - name: jnlpport\n             "
  },
  "2351": {
    "source_file": "kubernetes.txt",
    "text": "\"\n              cpu: \"500m\"\n          ports:\n            - name: httpport\n              containerPort: 8080\n            - name: jnlpport\n              containerPort: 50000\n          livenessProbe:\n            httpGet:\n              path: \"/login\"\n              port: 8080\n            initialDelaySeconds: 90\n            periodSeconds: 10\n            timeoutSeconds: 5\n            failureThreshold: 5\n"
  },
  "2352": {
    "source_file": "kubernetes.txt",
    "text": "           port: 8080\n            initialDelaySeconds: 90\n            periodSeconds: 10\n            timeoutSeconds: 5\n            failureThreshold: 5\n          readinessProbe:\n            httpGet:\n              path: \"/login\"\n              port: 8080\n            initialDelaySeconds: 60\n            periodSeconds: 10\n            timeoutSeconds: 5\n            failureThreshold: 3\n          volumeMount"
  },
  "2353": {
    "source_file": "kubernetes.txt",
    "text": "\n            initialDelaySeconds: 60\n            periodSeconds: 10\n            timeoutSeconds: 5\n            failureThreshold: 3\n          volumeMounts:\n            - name: jenkins-data\n              mountPath: /var/jenkins_home\n      volumes:\n        - name: jenkins-data\n          persistentVolumeClaim:\n              claimName: jenkins-pv-claim\n\nIn this Jenkins Kubernetes deployment we have used "
  },
  "2354": {
    "source_file": "kubernetes.txt",
    "text": "  - name: jenkins-data\n          persistentVolumeClaim:\n              claimName: jenkins-pv-claim\n\nIn this Jenkins Kubernetes deployment we have used the following:\n\n[arabic]\nThe Jenkins container version is referenced in the example YAML above by a floating tag `lts`, so the optional `imagePullPolicy: Always` line is added to pull and deploy a new LTS image release (if it exists) *whenever* the p"
  },
  "2355": {
    "source_file": "kubernetes.txt",
    "text": "floating tag `lts`, so the optional `imagePullPolicy: Always` line is added to pull and deploy a new LTS image release (if it exists) *whenever* the pod is restarted. Otherwise, the currently deployed version is used after restart (and there's no other way to tell Kubernetes to pull a newer image, short of locating and deleting the old one from the node's cache).\n  * Note that \"whenever the pod is"
  },
  "2356": {
    "source_file": "kubernetes.txt",
    "text": "er way to tell Kubernetes to pull a newer image, short of locating and deleting the old one from the node's cache).\n  * Note that \"whenever the pod is restarted\" includes events such as a server reboot or the restart requested in Web-UI to apply downloaded plugin updates.\n  * Kubernetes automatically uses this policy by default if the `:latest` image tag is specified, or none is specified at all ("
  },
  "2357": {
    "source_file": "kubernetes.txt",
    "text": "loaded plugin updates.\n  * Kubernetes automatically uses this policy by default if the `:latest` image tag is specified, or none is specified at all (then the `:latest` image tag is automatically defaulted).\n  * For predictable and deterministic updates, use the version-based image tags instead. Search https://hub.docker.com/r/jenkins/jenkins/tags for the ones currently served.\n  * Consider an ima"
  },
  "2358": {
    "source_file": "kubernetes.txt",
    "text": "tes, use the version-based image tags instead. Search https://hub.docker.com/r/jenkins/jenkins/tags for the ones currently served.\n  * Consider an image tag like `lts-jdk21` to avoid surprises when the Jenkins core switches to using a newer JDK (usually they are backwards compatible, but...) or stay with `lts` for indefinite hands-off maintenance approach.\nThe `spec:/strategy:/type: Recreate` requ"
  },
  "2359": {
    "source_file": "kubernetes.txt",
    "text": "lly they are backwards compatible, but...) or stay with `lts` for indefinite hands-off maintenance approach.\nThe `spec:/strategy:/type: Recreate` requires that Kubernetes first stops the old container instance, then starts a new one a few seconds later, whenever a restart is requested such as pulling in a new Jenkins version.\n'securityContext' for Jenkins pod to be able to write to the local persi"
  },
  "2360": {
    "source_file": "kubernetes.txt",
    "text": "er, whenever a restart is requested such as pulling in a new Jenkins version.\n'securityContext' for Jenkins pod to be able to write to the local persistent volume.\n  * Note that `fsGroup` specifies the group ID used for mounted filesystem access,\n    while `runAsUser` and `runAsGroup` specify the account IDs all process runs as\n    (as seen by both the host OS and the container guest operating env"
  },
  "2361": {
    "source_file": "kubernetes.txt",
    "text": " while `runAsUser` and `runAsGroup` specify the account IDs all process runs as\n    (as seen by both the host OS and the container guest operating environment).\n    There is no `fsUser` equivalent.\n  * One caveat is that the Jenkins container has ID 1000 defined in its `/etc/passwd`\n    and `/etc/group` files, and e.g. `git` program requires that the identifier of\n    the user it runs as is resolv"
  },
  "2362": {
    "source_file": "kubernetes.txt",
    "text": "1000 defined in its `/etc/passwd`\n    and `/etc/group` files, and e.g. `git` program requires that the identifier of\n    the user it runs as is resolvable.  While it is trivial to define desired accounts\n    in a derived container (made `FROM jenkins:lts` for example) and run as accounts\n    according to your site preferences, it is clumsy out of the box.\nLiveness and readiness probe to monitor th"
  },
  "2363": {
    "source_file": "kubernetes.txt",
    "text": ":lts` for example) and run as accounts\n    according to your site preferences, it is clumsy out of the box.\nLiveness and readiness probe to monitor the health of the Jenkins pod.\nLocal persistent volume based on local storage class that holds the Jenkins data\n  path '/var/jenkins_home'. You may have to prepare it with:\nrunAsUser=1000\nfsGroup=1000   # Or custom ID, per above\nmkdir -p /var/jenkins_h"
  },
  "2364": {
    "source_file": "kubernetes.txt",
    "text": "kins data\n  path '/var/jenkins_home'. You may have to prepare it with:\nrunAsUser=1000\nfsGroup=1000   # Or custom ID, per above\nmkdir -p /var/jenkins_home\nchown -R $runAsUser:$fsGroup /var/jenkins_home\nchmod -R g+rwX /var/jenkins_home\n\nNOTE: The deployment file uses local storage class persistent volume for Jenkins data.\nFor production use cases, you should add a cloud-specific storage class persis"
  },
  "2365": {
    "source_file": "kubernetes.txt",
    "text": "yment file uses local storage class persistent volume for Jenkins data.\nFor production use cases, you should add a cloud-specific storage class persistent volume for your Jenkins data.\n\nIf you don\u2019t want the local storage persistent volume, you can replace the volume definition in the deployment with the host directory as shown below.\n\nvolumes:\n- name: jenkins-data\n  emptyDir: \\{}\n\nCreate the depl"
  },
  "2366": {
    "source_file": "kubernetes.txt",
    "text": "eplace the volume definition in the deployment with the host directory as shown below.\n\nvolumes:\n- name: jenkins-data\n  emptyDir: \\{}\n\nCreate the deployment using kubectl.\n\nkubectl apply -f jenkins-03-deployment.yaml\n\nCheck the deployment status.\n\nkubectl get deployments -n devops-tools\n\nNow, you can get the deployment details using the following command.\n\nkubectl describe deployments --namespace="
  },
  "2367": {
    "source_file": "kubernetes.txt",
    "text": "bectl get deployments -n devops-tools\n\nNow, you can get the deployment details using the following command.\n\nkubectl describe deployments --namespace=devops-tools\n\n[#create-a-service]\n\nWe have now created a deployment.\nHowever, it is not accessible to the outside world.\nFor accessing the Jenkins deployment from the outside world, we need to create a service and map it to the deployment.\n\nCreate 'j"
  },
  "2368": {
    "source_file": "kubernetes.txt",
    "text": "o the outside world.\nFor accessing the Jenkins deployment from the outside world, we need to create a service and map it to the deployment.\n\nCreate 'jenkins-04-service.yaml' and copy the following service manifest:\n\napiVersion: v1\nkind: Service\nmetadata:\n  name: jenkins-service\n  namespace: devops-tools\n  annotations:\n      prometheus.io/scrape: 'true'\n      prometheus.io/path:   /\n      prometheu"
  },
  "2369": {
    "source_file": "kubernetes.txt",
    "text": "ata:\n  name: jenkins-service\n  namespace: devops-tools\n  annotations:\n      prometheus.io/scrape: 'true'\n      prometheus.io/path:   /\n      prometheus.io/port:   '8080'\nspec:\n  selector:\n    app: jenkins-server\n  type: NodePort\n  ports:\n    - port: 8080\n      targetPort: 8080\n      nodePort: 32000\n\nNOTE: Here, we are using the type as 'NodePort' which will expose Jenkins on all kubernetes node IP"
  },
  "2370": {
    "source_file": "kubernetes.txt",
    "text": "8080\n      targetPort: 8080\n      nodePort: 32000\n\nNOTE: Here, we are using the type as 'NodePort' which will expose Jenkins on all kubernetes node IPs on port 32000.\nIf you have an ingress setup, you can create an ingress rule to access Jenkins.\nAlso, you can expose the Jenkins service as a Loadbalancer if you are running the cluster on AWS, Google, or Azure cloud.\n\nCreate the Jenkins service usi"
  },
  "2371": {
    "source_file": "kubernetes.txt",
    "text": "o, you can expose the Jenkins service as a Loadbalancer if you are running the cluster on AWS, Google, or Azure cloud.\n\nCreate the Jenkins service using kubectl.\n\nkubectl apply -f jenkins-04-service.yaml\n\nNow, when browsing to any one of the Node IPs on port 32000, you will be able to access the Jenkins dashboard.\n\nhttp://<node-ip>:32000\n\nJenkins will ask for the initial Admin password when you ac"
  },
  "2372": {
    "source_file": "kubernetes.txt",
    "text": " on port 32000, you will be able to access the Jenkins dashboard.\n\nhttp://<node-ip>:32000\n\nJenkins will ask for the initial Admin password when you access the dashboard for the first time.\n\nYou can get that from the pod logs either from the Kubernetes dashboard or CLI.\nYou can get the pod details using the following CLI command.\n\nkubectl get pods --namespace=devops-tools\n\nWith the pod name, you ca"
  },
  "2373": {
    "source_file": "kubernetes.txt",
    "text": "s dashboard or CLI.\nYou can get the pod details using the following CLI command.\n\nkubectl get pods --namespace=devops-tools\n\nWith the pod name, you can get the logs as shown below.\nReplace the pod name with your pod name.\n\nkubectl logs jenkins-deployment-2539456353-j00w5 --namespace=devops-tools\n\nThe password can be found at the end of the log.\n\n==\nYou can watch the Jenkins server logs (posted to "
  },
  "2374": {
    "source_file": "kubernetes.txt",
    "text": "ment-2539456353-j00w5 --namespace=devops-tools\n\nThe password can be found at the end of the log.\n\n==\nYou can watch the Jenkins server logs (posted to `stdout` or `stderr` of the JVM and collected by Kubernetes) with the following loop to handle Jenkins restarts as well:\n\nwhile sleep 0.1 ; do kubectl logs -f -l app=jenkins-server -n devops-tools ; done &\n\n(The label `jenkins-server` is defined in `"
  },
  "2375": {
    "source_file": "kubernetes.txt",
    "text": "ns restarts as well:\n\nwhile sleep 0.1 ; do kubectl logs -f -l app=jenkins-server -n devops-tools ; done &\n\n(The label `jenkins-server` is defined in `jenkins-03-deployment.yaml`)\n\nAlternatively,  tool can be used to watch multiple pods' logs.\n======\n\nAlternatively, you can run the exec command to get the password directly from the location as shown below.\n\n* Using the first (normally only) instanc"
  },
  "2376": {
    "source_file": "kubernetes.txt",
    "text": "\nAlternatively, you can run the exec command to get the password directly from the location as shown below.\n\n* Using the first (normally only) instance of the application pod:\nkubectl exec -it \"deployment.apps/jenkins\" cat /var/jenkins_home/secrets/initialAdminPassword -n devops-tools\n\n* ...or, using a specific container instance:\nkubectl exec -it jenkins-559d8cd85c-cfcgk cat /var/jenkins_home/sec"
  },
  "2377": {
    "source_file": "kubernetes.txt",
    "text": "nitialAdminPassword -n devops-tools\n\n* ...or, using a specific container instance:\nkubectl exec -it jenkins-559d8cd85c-cfcgk cat /var/jenkins_home/secrets/initialAdminPassword -n devops-tools\n\nOnce you enter the password, proceed to install the suggested plugins and create an admin user.\nAll of these steps are self-explanatory from the Jenkins dashboard.\n\n'''\n\nBelow we will explore further deploym"
  },
  "2378": {
    "source_file": "kubernetes.txt",
    "text": "sted plugins and create an admin user.\nAll of these steps are self-explanatory from the Jenkins dashboard.\n\n'''\n\nBelow we will explore further deployment strategies.\n\nWhen you host Jenkins on Kubernetes for production workloads, you need to consider setting up a highly available persistent volume, to avoid data loss during pod or node deletion.\n\nA pod or node deletion could happen anytime in Kuber"
  },
  "2379": {
    "source_file": "kubernetes.txt",
    "text": "setting up a highly available persistent volume, to avoid data loss during pod or node deletion.\n\nA pod or node deletion could happen anytime in Kubernetes environments.\nIt could be a patching activity or a downscaling activity.\n\nHopefully, this step-by-step guide helps you learn and understand the components involved in setting up a Jenkins server on a Kubernetes cluster."
  },
  "2380": {
    "source_file": "kubernetes.txt",
    "text": "-by-step guide helps you learn and understand the components involved in setting up a Jenkins server on a Kubernetes cluster."
  },
  "2381": {
    "source_file": "linux.txt",
    "text": "layout: section\ntitle: Linux\n\n\nifdef::env-github[:imagesdir: ../resources]\nifndef::env-github[:imagesdir: ../../resources]\n\nJenkins installers are available for several Linux distributions.\n\n* <<Debian/Ubuntu>>\n* <<Fedora>>\n* <<red-hat-centos,Red Hat Enterprise Linux and derivatives>>\n\nOn Debian and Debian-based distributions like Ubuntu you can install Jenkins through `apt`.\n\n// Using Ubuntu 24.0"
  },
  "2382": {
    "source_file": "linux.txt",
    "text": " Enterprise Linux and derivatives>>\n\nOn Debian and Debian-based distributions like Ubuntu you can install Jenkins through `apt`.\n\n// Using Ubuntu 24.04 because the Jenkins project infrastructure uses Ubuntu\n.How To Install Jenkins on Ubuntu 24.04\nvideo::8fVOdFdzlKc[youtube, width=640, height=360]\n\n// Debian 12 and Ubuntu 24.04 installation processes are similar\n// .How To Install Jenkins on Debian"
  },
  "2383": {
    "source_file": "linux.txt",
    "text": "eo::8fVOdFdzlKc[youtube, width=640, height=360]\n\n// Debian 12 and Ubuntu 24.04 installation processes are similar\n// .How To Install Jenkins on Debian 12\n// video::0EevQXwBV2A[youtube, width=640, height=360]\n\nYou need to choose either the Jenkins Long Term Support release or the Jenkins weekly release.\n\n[#debian-java]\n\nJenkins requires Java to run, yet not all Linux distributions include Java by d"
  },
  "2384": {
    "source_file": "linux.txt",
    "text": "g Term Support release or the Jenkins weekly release.\n\n[#debian-java]\n\nJenkins requires Java to run, yet not all Linux distributions include Java by default.\nAdditionally,  with Jenkins.\n\nThere are multiple Java implementations which you can use.\n is the most popular one at the moment, we will use it in this guide.\n\nUpdate the Debian apt repositories, install OpenJDK 21, and check the installation"
  },
  "2385": {
    "source_file": "linux.txt",
    "text": " the most popular one at the moment, we will use it in this guide.\n\nUpdate the Debian apt repositories, install OpenJDK 21, and check the installation with the commands:\n\nsudo apt update\nsudo apt install fontconfig openjdk-21-jre\njava -version\n\nIf the installation was successful, you should see an output similar to the following:\n\nopenjdk 21.0.8 2025-07-15\nOpenJDK Runtime Environment (build 21.0.8"
  },
  "2386": {
    "source_file": "linux.txt",
    "text": "e installation was successful, you should see an output similar to the following:\n\nopenjdk 21.0.8 2025-07-15\nOpenJDK Runtime Environment (build 21.0.8+9-Debian-1)\nOpenJDK 64-Bit Server VM (build 21.0.8+9-Debian-1, mixed mode, sharing)\n\nOn Debian/Ubuntu, it is strongly recommended to install Java *before* Jenkins.\nIf Jenkins is installed first and Java is added later, the Jenkins service may fail t"
  },
  "2387": {
    "source_file": "linux.txt",
    "text": "tu, it is strongly recommended to install Java *before* Jenkins.\nIf Jenkins is installed first and Java is added later, the Jenkins service may fail to start with:\n\njenkins: failed to find a valid Java installation\n\nInstalling Java first ensures the environment is fully initialized and avoids this issue.\nAfter completing the Java installation, continue with the Jenkins installation steps below.\n\n["
  },
  "2388": {
    "source_file": "linux.txt",
    "text": "environment is fully initialized and avoids this issue.\nAfter completing the Java installation, continue with the Jenkins installation steps below.\n\n[#debian-stable]\n\n[#long-term-support-release]\nA  is chosen every 12 weeks from the stream of regular releases as the stable release for that time period.\nIt can be installed from the .\n\nsudo wget -O /etc/apt/keyrings/jenkins-keyring.asc \\\n  https://p"
  },
  "2389": {
    "source_file": "linux.txt",
    "text": " releases as the stable release for that time period.\nIt can be installed from the .\n\nsudo wget -O /etc/apt/keyrings/jenkins-keyring.asc \\\n  https://pkg.jenkins.io/debian-stable/jenkins.io-2023.key\necho \"deb [signed-by=/etc/apt/keyrings/jenkins-keyring.asc]\" \\\n  https://pkg.jenkins.io/debian-stable binary/ | sudo tee \\\n  /etc/apt/sources.list.d/jenkins.list > /dev/null\nsudo apt update\nsudo apt ins"
  },
  "2390": {
    "source_file": "linux.txt",
    "text": "ng.asc]\" \\\n  https://pkg.jenkins.io/debian-stable binary/ | sudo tee \\\n  /etc/apt/sources.list.d/jenkins.list > /dev/null\nsudo apt update\nsudo apt install jenkins\n\n[#debian-weekly]\n\n[#weekly-release]\nA new release is produced weekly to deliver bug fixes and features to users and plugin developers.\nIt can be installed from the .\n\nsudo wget -O /etc/apt/keyrings/jenkins-keyring.asc \\\n  https://pkg.je"
  },
  "2391": {
    "source_file": "linux.txt",
    "text": "xes and features to users and plugin developers.\nIt can be installed from the .\n\nsudo wget -O /etc/apt/keyrings/jenkins-keyring.asc \\\n  https://pkg.jenkins.io/debian/jenkins.io-2023.key\necho \"deb [signed-by=/etc/apt/keyrings/jenkins-keyring.asc]\" \\\n  https://pkg.jenkins.io/debian binary/ | sudo tee \\\n  /etc/apt/sources.list.d/jenkins.list > /dev/null\nsudo apt update\nsudo apt install jenkins\n\nBegin"
  },
  "2392": {
    "source_file": "linux.txt",
    "text": " https://pkg.jenkins.io/debian binary/ | sudo tee \\\n  /etc/apt/sources.list.d/jenkins.list > /dev/null\nsudo apt update\nsudo apt install jenkins\n\nBeginning with Jenkins 2.335 and Jenkins 2.332.1, the package is configured with `systemd` rather than the older System V `init`.\nMore information is available in .\n\nThe package installation will:\n\n* Setup Jenkins as a daemon launched on start. Run `syste"
  },
  "2393": {
    "source_file": "linux.txt",
    "text": "e older System V `init`.\nMore information is available in .\n\nThe package installation will:\n\n* Setup Jenkins as a daemon launched on start. Run `systemctl cat jenkins` for more details.\n* Create a '`jenkins`' user to run this service.\n* Direct console log output to `systemd-journald`. Run `journalctl -u jenkins.service` if you are troubleshooting Jenkins.\n* Populate `/lib/systemd/system/jenkins.se"
  },
  "2394": {
    "source_file": "linux.txt",
    "text": "e log output to `systemd-journald`. Run `journalctl -u jenkins.service` if you are troubleshooting Jenkins.\n* Populate `/lib/systemd/system/jenkins.service` with configuration parameters for the launch, e.g `JENKINS_HOME`\n* Set Jenkins to listen on port 8080. Access this port with your browser to start configuration.\n\nIf Jenkins fails to start because a port is in use,\nrun `systemctl edit jenkins`"
  },
  "2395": {
    "source_file": "linux.txt",
    "text": "ort 8080. Access this port with your browser to start configuration.\n\nIf Jenkins fails to start because a port is in use,\nrun `systemctl edit jenkins` and add the following:\n\n[Service]\nEnvironment=\"JENKINS_PORT=8081\"\n\nHere, \"8081\" was chosen but you can put another port available.\n\n[TIP]\n\nWhy use `apt` and not `apt-get` or another command?\nThe apt command has been available since 2014.\nIt has a co"
  },
  "2396": {
    "source_file": "linux.txt",
    "text": "can put another port available.\n\n[TIP]\n\nWhy use `apt` and not `apt-get` or another command?\nThe apt command has been available since 2014.\nIt has a command structure that is similar to `apt-get` but was created to be a more pleasant experience for typical users.\nSimple software management tasks like install, search and remove are easier with `apt`.\n\nYou can install Jenkins through `dnf`. You need "
  },
  "2397": {
    "source_file": "linux.txt",
    "text": "pical users.\nSimple software management tasks like install, search and remove are easier with `apt`.\n\nYou can install Jenkins through `dnf`. You need to add the Jenkins repository from the Jenkins website to the package manager first.\n\n[#fedora-stable]\n\n[#long-term-support-release-2]\nA  is chosen every 12 weeks from the stream of regular releases as the stable release for that time period.\nIt can "
  },
  "2398": {
    "source_file": "linux.txt",
    "text": "e]\n\n[#long-term-support-release-2]\nA  is chosen every 12 weeks from the stream of regular releases as the stable release for that time period.\nIt can be installed from the  yum repository.\n\nsudo wget -O /etc/yum.repos.d/jenkins.repo \\\n    https://pkg.jenkins.io/redhat-stable/jenkins.repo\nsudo rpm --import https://pkg.jenkins.io/redhat-stable/jenkins.io-2023.key\nsudo dnf upgrade\n# Add required depe"
  },
  "2399": {
    "source_file": "linux.txt",
    "text": ".jenkins.io/redhat-stable/jenkins.repo\nsudo rpm --import https://pkg.jenkins.io/redhat-stable/jenkins.io-2023.key\nsudo dnf upgrade\n# Add required dependencies for the jenkins package\nsudo dnf install fontconfig java-21-openjdk\nsudo dnf install jenkins\nsudo systemctl daemon-reload\n\n[#fedora-weekly]\n\n[#weekly-release-2]\nA new release is produced weekly to deliver bug fixes and features to users and "
  },
  "2400": {
    "source_file": "linux.txt",
    "text": "s\nsudo systemctl daemon-reload\n\n[#fedora-weekly]\n\n[#weekly-release-2]\nA new release is produced weekly to deliver bug fixes and features to users and plugin developers.\nIt can be installed from the  yum repository.\n\nsudo wget -O /etc/yum.repos.d/jenkins.repo \\\n    https://pkg.jenkins.io/redhat/jenkins.repo\nsudo rpm --import https://pkg.jenkins.io/redhat/jenkins.io-2023.key\nsudo dnf upgrade\n# Add r"
  },
  "2401": {
    "source_file": "linux.txt",
    "text": "ins.repo \\\n    https://pkg.jenkins.io/redhat/jenkins.repo\nsudo rpm --import https://pkg.jenkins.io/redhat/jenkins.io-2023.key\nsudo dnf upgrade\n# Add required dependencies for the jenkins package\nsudo dnf install fontconfig java-21-openjdk\nsudo dnf install jenkins\n\nYou can enable the Jenkins service to start at boot with the command:\n\nsudo systemctl enable jenkins\n\nYou can start the Jenkins service"
  },
  "2402": {
    "source_file": "linux.txt",
    "text": "stall jenkins\n\nYou can enable the Jenkins service to start at boot with the command:\n\nsudo systemctl enable jenkins\n\nYou can start the Jenkins service with the command:\n\nsudo systemctl start jenkins\n\nYou can check the status of the Jenkins service using the command:\n\nsudo systemctl status jenkins\n\nIf everything has been set up correctly, you should see an output like this:\n\nLoaded: loaded (/lib/sy"
  },
  "2403": {
    "source_file": "linux.txt",
    "text": "ing the command:\n\nsudo systemctl status jenkins\n\nIf everything has been set up correctly, you should see an output like this:\n\nLoaded: loaded (/lib/systemd/system/jenkins.service; enabled; vendor preset: enabled)\nActive: active (running) since Tue 2018-11-13 16:19:01 +03; 4min 57s ago\n\nIf you have a firewall installed, you must add Jenkins as an exception.\nYou must change `YOURPORT` in the script "
  },
  "2404": {
    "source_file": "linux.txt",
    "text": "18-11-13 16:19:01 +03; 4min 57s ago\n\nIf you have a firewall installed, you must add Jenkins as an exception.\nYou must change `YOURPORT` in the script below to the port you want to use.\nPort `8080` is the most common.\n\nYOURPORT=8080\nPERM=\"--permanent\"\nSERV=\"$PERM --service=jenkins\"\n\nfirewall-cmd $PERM --new-service=jenkins\nfirewall-cmd $SERV --set-short=\"Jenkins ports\"\nfirewall-cmd $SERV --set-desc"
  },
  "2405": {
    "source_file": "linux.txt",
    "text": "\nSERV=\"$PERM --service=jenkins\"\n\nfirewall-cmd $PERM --new-service=jenkins\nfirewall-cmd $SERV --set-short=\"Jenkins ports\"\nfirewall-cmd $SERV --set-description=\"Jenkins port exceptions\"\nfirewall-cmd $SERV --add-port=$YOURPORT/tcp\nfirewall-cmd $PERM --add-service=jenkins\nfirewall-cmd --zone=public --add-service=http --permanent\nfirewall-cmd --reload\n\n[#red-hat-centos]\n\nYou can install Jenkins through"
  },
  "2406": {
    "source_file": "linux.txt",
    "text": "dd-service=jenkins\nfirewall-cmd --zone=public --add-service=http --permanent\nfirewall-cmd --reload\n\n[#red-hat-centos]\n\nYou can install Jenkins through `yum` on Red Hat Enterprise Linux, AlmaLinux, Rocky Linux, Oracle Linux, CentOS, and other Red Hat based distributions.\n\n.How To Install Jenkins on Rocky Linux 9\nvideo::2-L0WohfsqY[youtube, width=640, height=360]\n\nYou need to choose either the Jenki"
  },
  "2407": {
    "source_file": "linux.txt",
    "text": "based distributions.\n\n.How To Install Jenkins on Rocky Linux 9\nvideo::2-L0WohfsqY[youtube, width=640, height=360]\n\nYou need to choose either the Jenkins Long Term Support release or the Jenkins weekly release.\n\n[#red-hat-stable]\n\n[#long-term-support-release-3]\nA  is chosen every 12 weeks from the stream of regular releases as the stable release for that time period.\nIt can be installed from the  y"
  },
  "2408": {
    "source_file": "linux.txt",
    "text": "release-3]\nA  is chosen every 12 weeks from the stream of regular releases as the stable release for that time period.\nIt can be installed from the  yum repository.\n\nsudo wget -O /etc/yum.repos.d/jenkins.repo \\\n    https://pkg.jenkins.io/redhat-stable/jenkins.repo\nsudo rpm --import https://pkg.jenkins.io/redhat-stable/jenkins.io-2023.key\nsudo yum upgrade\n# Add required dependencies for the jenkins"
  },
  "2409": {
    "source_file": "linux.txt",
    "text": "e/jenkins.repo\nsudo rpm --import https://pkg.jenkins.io/redhat-stable/jenkins.io-2023.key\nsudo yum upgrade\n# Add required dependencies for the jenkins package\nsudo yum install fontconfig java-21-openjdk\nsudo yum install jenkins\nsudo systemctl daemon-reload\n\n[#red-hat-weekly]\n\n[#weekly-release-3]\nA new release is produced weekly to deliver bug fixes and features to users and plugin developers.\nIt c"
  },
  "2410": {
    "source_file": "linux.txt",
    "text": "reload\n\n[#red-hat-weekly]\n\n[#weekly-release-3]\nA new release is produced weekly to deliver bug fixes and features to users and plugin developers.\nIt can be installed from the  yum repository.\n\nsudo wget -O /etc/yum.repos.d/jenkins.repo \\\n    https://pkg.jenkins.io/redhat/jenkins.repo\nsudo rpm --import https://pkg.jenkins.io/redhat/jenkins.io-2023.key\nsudo yum upgrade\n# Add required dependencies fo"
  },
  "2411": {
    "source_file": "linux.txt",
    "text": "pkg.jenkins.io/redhat/jenkins.repo\nsudo rpm --import https://pkg.jenkins.io/redhat/jenkins.io-2023.key\nsudo yum upgrade\n# Add required dependencies for the jenkins package\nsudo yum install fontconfig java-21-openjdk\nsudo yum install jenkins\n\nYou can enable the Jenkins service to start at boot with the command:\n\nsudo systemctl enable jenkins\n\nYou can start the Jenkins service with the command:\n\nsud"
  },
  "2412": {
    "source_file": "linux.txt",
    "text": "enable the Jenkins service to start at boot with the command:\n\nsudo systemctl enable jenkins\n\nYou can start the Jenkins service with the command:\n\nsudo systemctl start jenkins\n\nYou can check the status of the Jenkins service using the command:\n\nsudo systemctl status jenkins\n\nIf everything has been set up correctly, you should see an output like this:\n\nLoaded: loaded (/lib/systemd/system/jenkins.se"
  },
  "2413": {
    "source_file": "linux.txt",
    "text": "systemctl status jenkins\n\nIf everything has been set up correctly, you should see an output like this:\n\nLoaded: loaded (/lib/systemd/system/jenkins.service; enabled; vendor preset: enabled)\nActive: active (running) since Tue 2023-06-22 16:19:01 +03; 4min 57s ago\n...\n\nIf you have a firewall installed, you must add Jenkins as an exception.\nYou must change `YOURPORT` in the script below to the port y"
  },
  "2414": {
    "source_file": "linux.txt",
    "text": "4min 57s ago\n...\n\nIf you have a firewall installed, you must add Jenkins as an exception.\nYou must change `YOURPORT` in the script below to the port you want to use.\nPort `8080` is the most common.\n\nYOURPORT=8080\nPERM=\"--permanent\"\nSERV=\"$PERM --service=jenkins\"\n\nfirewall-cmd $PERM --new-service=jenkins\nfirewall-cmd $SERV --set-short=\"Jenkins ports\"\nfirewall-cmd $SERV --set-description=\"Jenkins po"
  },
  "2415": {
    "source_file": "linux.txt",
    "text": "ice=jenkins\"\n\nfirewall-cmd $PERM --new-service=jenkins\nfirewall-cmd $SERV --set-short=\"Jenkins ports\"\nfirewall-cmd $SERV --set-description=\"Jenkins port exceptions\"\nfirewall-cmd $SERV --add-port=$YOURPORT/tcp\nfirewall-cmd $PERM --add-service=jenkins\nfirewall-cmd --zone=public --add-service=http --permanent\nfirewall-cmd --reload"
  },
  "2416": {
    "source_file": "linux.txt",
    "text": "firewall-cmd --zone=public --add-service=http --permanent\nfirewall-cmd --reload"
  },
  "2417": {
    "source_file": "macos.txt",
    "text": "layout: section\ntitle: macOS\n\n\nifdef::env-github[:imagesdir: ../resources]\nifndef::env-github[:imagesdir: ../../resources]\n\nThe macOS installer for Jenkins is maintained outside the Jenkins project.\nRefer to documentation based on the version of Jenkins to be run.\n\n*\n*"
  },
  "2418": {
    "source_file": "macos.txt",
    "text": "ins to be run.\n\n*\n*"
  },
  "2419": {
    "source_file": "managing-permissions.txt",
    "text": "layout: developersection\ntitle: Managing plugin permissions\nreferences:\n- url: https://github.com/jenkins-infra/repository-permissions-updater\n  title: Repository Permissions Updater\n- url: ../adopt-a-plugin\n  title: Adopting a plugin\n\n\nThis page documents managing permissions for plugin maintainers.\nThere are 2 main permissions available to plugin contributors:\n\n* **GitHub permissions**.\n  It inc"
  },
  "2420": {
    "source_file": "managing-permissions.txt",
    "text": "uments managing permissions for plugin maintainers.\nThere are 2 main permissions available to plugin contributors:\n\n* **GitHub permissions**.\n  It includes merging pull requests, push to the repositories, managing GitHub applications, etc.\n  The effective list of permissions depends on the , see below.\n* **Release Permissions** which are needed to deploy releases to the .\n  Snapshots can be deploy"
  },
  "2421": {
    "source_file": "managing-permissions.txt",
    "text": "ctive list of permissions depends on the , see below.\n* **Release Permissions** which are needed to deploy releases to the .\n  Snapshots can be deployed by contributors without this permission.\n\nNOTE: If you want to adopt a plugin, please see  instead.\n\nGitHub permissions in Jenkins are managed by GitHub teams.\nAlmost every plugin has a `<pluginId> Developers` team created specifically for this pl"
  },
  "2422": {
    "source_file": "managing-permissions.txt",
    "text": "d.\n\nGitHub permissions in Jenkins are managed by GitHub teams.\nAlmost every plugin has a `<pluginId> Developers` team created specifically for this plugin.\nThis team may have a different  depending on time of creation.\nFor all new repositories we tend to grant `Admin` permissions at the moment, and other plugin teams can get permissions elevated upon a request.\n\nAny active maintainer is eligible t"
  },
  "2423": {
    "source_file": "managing-permissions.txt",
    "text": "d to grant `Admin` permissions at the moment, and other plugin teams can get permissions elevated upon a request.\n\nAny active maintainer is eligible to add more contributors to the GitHub repository.\nThere are multiple ways to do that:\n\nVia GitHub Web Interface, if you have admin permissions in the `<pluginId> Developers` team\n** It is possible to also add collaborators to repositories\nVia a reque"
  },
  "2424": {
    "source_file": "managing-permissions.txt",
    "text": "b Interface, if you have admin permissions in the `<pluginId> Developers` team\n** It is possible to also add collaborators to repositories\nVia a request in the\nVia a request in the\nVia the ChatOps command in the `#jenkins` IRC channel, if you have voice permissions there (see the )\n\nYou will need to send a permission transfer request and to specify the permission recipient's GitHub account and Jen"
  },
  "2425": {
    "source_file": "managing-permissions.txt",
    "text": "ice permissions there (see the )\n\nYou will need to send a permission transfer request and to specify the permission recipient's GitHub account and Jenkins LDAP (aka Jenkins Jira) account there.\nAn explicit approval by an active maintainer will be required before the permission transfer happens.\nIf there no response from a maintainer, a  might be used to request ownership of the plugin.\n\nThere are "
  },
  "2426": {
    "source_file": "managing-permissions.txt",
    "text": "uired before the permission transfer happens.\nIf there no response from a maintainer, a  might be used to request ownership of the plugin.\n\nThere are two following ways to do that:\n\nVia ChatOps command in the `#jenkins` IRC channel, if you have voice permissions there (see the )\nVia a request in the .\n\nThe following approvals are generally recognized as valid:\n\n* Confirmation in a Jenkins Jira tic"
  },
  "2427": {
    "source_file": "managing-permissions.txt",
    "text": " permissions there (see the )\nVia a request in the .\n\nThe following approvals are generally recognized as valid:\n\n* Confirmation in a Jenkins Jira ticket (permission request or other ticket)\n* Explicit approval in a GitHub pull request or issue\n** The reply should be sent from a GitHub account associated with a maintainer's Jenkins LDAP account\n* Confirmation in the .\n** The reply should be sent f"
  },
  "2428": {
    "source_file": "managing-permissions.txt",
    "text": "e reply should be sent from a GitHub account associated with a maintainer's Jenkins LDAP account\n* Confirmation in the .\n** The reply should be sent from the email listed in the Jenkins LDAP account\n\nOther types of approval (emails from different addresses, email forwards by requesters, etc.) will be reviewed and verified by `jenkinsci` GitHub administrators.\n\nRelease Permissions are needed to dep"
  },
  "2429": {
    "source_file": "managing-permissions.txt",
    "text": "resses, email forwards by requesters, etc.) will be reviewed and verified by `jenkinsci` GitHub administrators.\n\nRelease Permissions are needed to deploy releases to the .\nPermissions to upload plugin releases are independent of GitHub push access and maintained in the  repository.\n\nTo request upload permissions for a new maintainer:\n\nIf you have never done it before,\n  you log in at least in once"
  },
  "2430": {
    "source_file": "managing-permissions.txt",
    "text": "d maintained in the  repository.\n\nTo request upload permissions for a new maintainer:\n\nIf you have never done it before,\n  you log in at least in once with your Jenkins account into the .\n  Any modification to the permission files will be ineffective until then.\nFile a PR in the  for the specific plugin repository which needs the permission change.\n  Refer to the  for more detailed instructions.\n "
  },
  "2431": {
    "source_file": "managing-permissions.txt",
    "text": " until then.\nFile a PR in the  for the specific plugin repository which needs the permission change.\n  Refer to the  for more detailed instructions.\n  Once the permissions are updated, you'll be able to release your plugin.\n\n//TODO(oleg-nenashev): Add CoC violations and so on?\n\nPermission removal can be requested in the same way, e.g. during .\nSuch requests are subject for explicit approval by con"
  },
  "2432": {
    "source_file": "managing-permissions.txt",
    "text": "d CoC violations and so on?\n\nPermission removal can be requested in the same way, e.g. during .\nSuch requests are subject for explicit approval by contributors being removed or by `jenkinsci` GitHub administrators."
  },
  "2433": {
    "source_file": "managing-security.txt",
    "text": "layout: section\n\n\nifdef::env-github[:imagesdir: ../resources]\nifndef::env-github[:imagesdir: ../../resources]\n\nJenkins is used everywhere from workstations on corporate intranets, to\nhigh-powered servers connected to the public internet. To safely support this\nwide spread of security and threat profiles, Jenkins offers many configuration\noptions for enabling, editing, or disabling various security"
  },
  "2434": {
    "source_file": "managing-security.txt",
    "text": "pport this\nwide spread of security and threat profiles, Jenkins offers many configuration\noptions for enabling, editing, or disabling various security features.\n\nAs of Jenkins 2.0, many of the security options were enabled by default to\nensure that Jenkins environments remained secure unless an administrator\nexplicitly disabled certain protections.\n\nThis section will introduce the various security"
  },
  "2435": {
    "source_file": "managing-security.txt",
    "text": "enkins environments remained secure unless an administrator\nexplicitly disabled certain protections.\n\nThis section will introduce the various security options available to a Jenkins\nadministrator, explaining the protections offered, and trade-offs to disabling\nsome of them.\n\nBeginning with Jenkins 2.214 and Jenkins LTS 2.222.1, the \"Enable Security\" checkbox has been removed.\nJenkins own user data"
  },
  "2436": {
    "source_file": "managing-security.txt",
    "text": " disabling\nsome of them.\n\nBeginning with Jenkins 2.214 and Jenkins LTS 2.222.1, the \"Enable Security\" checkbox has been removed.\nJenkins own user database is used as the default security realm.\n\nIn versions before Jenkins 2.214 and Jenkins LTS 2.222.1, when the *Enable Security* checkbox is checked,\nusers can log in with a username and password in order to\nperform operations not available to anony"
  },
  "2437": {
    "source_file": "managing-security.txt",
    "text": "1, when the *Enable Security* checkbox is checked,\nusers can log in with a username and password in order to\nperform operations not available to anonymous users. Which operations require\nusers to log in depends on the chosen authorization strategy and its configuration;\nby default anonymous users have no permissions, and logged in users have full\ncontrol. The \"Enable Security\" checkbox should *alw"
  },
  "2438": {
    "source_file": "managing-security.txt",
    "text": "d its configuration;\nby default anonymous users have no permissions, and logged in users have full\ncontrol. The \"Enable Security\" checkbox should *always* be enabled for any non-local (test) Jenkins\nenvironment.\n\nThe \"Security\" section of the web UI allows a Jenkins administrator to\nenable, configure, or disable key security features which apply to the entire\nJenkins environment.\n\nJenkins can use "
  },
  "2439": {
    "source_file": "managing-security.txt",
    "text": "allows a Jenkins administrator to\nenable, configure, or disable key security features which apply to the entire\nJenkins environment.\n\nJenkins can use a TCP port to communicate with inbound (formerly known as \u201cJNLP\u201d) agents,\nsuch as Windows-based agents.\nAs of Jenkins 2.0, by default this port is disabled.\n\nFor administrators wishing to use inbound TCP agents, the two port options are:\n\n*Random*: T"
  },
  "2440": {
    "source_file": "managing-security.txt",
    "text": "ts.\nAs of Jenkins 2.0, by default this port is disabled.\n\nFor administrators wishing to use inbound TCP agents, the two port options are:\n\n*Random*: The TCP port is chosen at random to avoid collisions on the Jenkins <<../glossary#controller,controller>>.\n  The downside to randomized ports is that they are chosen during the boot of the Jenkins controller,\n  making it difficult to manage firewall r"
  },
  "2441": {
    "source_file": "managing-security.txt",
    "text": "er>>.\n  The downside to randomized ports is that they are chosen during the boot of the Jenkins controller,\n  making it difficult to manage firewall rules allowing TCP traffic.\n*Fixed*: The port is chosen by the Jenkins administrator and is consistent across reboots of the Jenkins controller.\n  This makes it easier to manage firewall rules allowing TCP-based agents to connect to the controller.\n\nA"
  },
  "2442": {
    "source_file": "managing-security.txt",
    "text": "t across reboots of the Jenkins controller.\n  This makes it easier to manage firewall rules allowing TCP-based agents to connect to the controller.\n\nAs of Jenkins 2.217, inbound agents may instead be configured to use WebSocket transport to connect to Jenkins.\nIn this case no extra TCP port need be enabled and no special security configuration is needed.\n\nAccess Control is the primary mechanism fo"
  },
  "2443": {
    "source_file": "managing-security.txt",
    "text": "o Jenkins.\nIn this case no extra TCP port need be enabled and no special security configuration is needed.\n\nAccess Control is the primary mechanism for securing a Jenkins environment\nagainst unauthorized usage. Two facets of configuration are necessary for\nconfiguring Access Control in Jenkins:\n\nA *Security Realm* which informs the Jenkins environment how and where to\n  pull user (or identity) inf"
  },
  "2444": {
    "source_file": "managing-security.txt",
    "text": "ry for\nconfiguring Access Control in Jenkins:\n\nA *Security Realm* which informs the Jenkins environment how and where to\n  pull user (or identity) information from. Also commonly known as \"authentication.\"\n*Authorization* configuration which informs the Jenkins environment as to\n  which users and/or groups can access which aspects of Jenkins, and to what\n  extent.\n\nUsing both the Security Realm an"
  },
  "2445": {
    "source_file": "managing-security.txt",
    "text": "the Jenkins environment as to\n  which users and/or groups can access which aspects of Jenkins, and to what\n  extent.\n\nUsing both the Security Realm and Authorization configurations it is possible\nto configure very relaxed or very rigid authentication and authorization\nschemes in Jenkins.\n\nAdditionally, some plugins such as the\nplugin:role-strategy[Role-based Authorization Strategy]\nplugin can exte"
  },
  "2446": {
    "source_file": "managing-security.txt",
    "text": " and authorization\nschemes in Jenkins.\n\nAdditionally, some plugins such as the\nplugin:role-strategy[Role-based Authorization Strategy]\nplugin can extend the Access Control capabilities of Jenkins to support even\nmore nuanced authentication and authorization schemes.\n\nBy default Jenkins includes support for a few different Security Realms:\n\nDelegate to servlet container:: For delegating authenticat"
  },
  "2447": {
    "source_file": "managing-security.txt",
    "text": "ization schemes.\n\nBy default Jenkins includes support for a few different Security Realms:\n\nDelegate to servlet container:: For delegating authentication a servlet\ncontainer running the Jenkins controller, such as\nIf using this option, please consult\nthe servlet container's authentication documentation.\nJenkins\u2019 own user database:: Use Jenkins's own built-in user data store for\nauthentication inst"
  },
  "2448": {
    "source_file": "managing-security.txt",
    "text": "\nthe servlet container's authentication documentation.\nJenkins\u2019 own user database:: Use Jenkins's own built-in user data store for\nauthentication instead of delegating to an external system. This is enabled by\ndefault with new Jenkins 2.0 or later installations and is suitable for smaller\nenvironments.\nLDAP:: Delegate all authentication to a configured LDAP server, including both\nusers and groups."
  },
  "2449": {
    "source_file": "managing-security.txt",
    "text": "stallations and is suitable for smaller\nenvironments.\nLDAP:: Delegate all authentication to a configured LDAP server, including both\nusers and groups. This option is more common for larger installations in\norganizations which already have configured an external identity provider such\nas LDAP. This also supports Active Directory installations.\n\nThis feature is provided by the plugin:ldap[LDAP plugi"
  },
  "2450": {
    "source_file": "managing-security.txt",
    "text": "an external identity provider such\nas LDAP. This also supports Active Directory installations.\n\nThis feature is provided by the plugin:ldap[LDAP plugin]\nthat may not be installed on your instance.\n\nUnix user/group database:: Delegates the authentication to the underlying Unix\nOS-level user database on the Jenkins controller. This mode will also allow re-use\nof Unix groups for authorization. For ex"
  },
  "2451": {
    "source_file": "managing-security.txt",
    "text": "ion to the underlying Unix\nOS-level user database on the Jenkins controller. This mode will also allow re-use\nof Unix groups for authorization. For example, Jenkins can be configured such\nthat \"Everyone in the `developers` group has administrator access.\" To support this feature, Jenkins relies on\n\nwhich may need to be configured external to the Jenkins environment.\n\n[CAUTION]\n\nUnix allows an user"
  },
  "2452": {
    "source_file": "managing-security.txt",
    "text": "ess.\" To support this feature, Jenkins relies on\n\nwhich may need to be configured external to the Jenkins environment.\n\n[CAUTION]\n\nUnix allows an user and a group to have the same name. In order to\ndisambiguate, use the `@` prefix to force the name to be interpreted as\na group. For example, `@dev` would mean the `dev` group and not the `dev` user.\n\n\n\nPlugins can provide additional security realms "
  },
  "2453": {
    "source_file": "managing-security.txt",
    "text": "o be interpreted as\na group. For example, `@dev` would mean the `dev` group and not the `dev` user.\n\n\n\nPlugins can provide additional security realms which may be useful for\nincorporating Jenkins into existing identity systems, such as:\n\n* plugin:active-directory[Active Directory]\n* plugin:github-oauth[GitHub Authentication]\n\nThe Security Realm, or authentication, indicates _who_ can access the Je"
  },
  "2454": {
    "source_file": "managing-security.txt",
    "text": "ive-directory[Active Directory]\n* plugin:github-oauth[GitHub Authentication]\n\nThe Security Realm, or authentication, indicates _who_ can access the Jenkins\nenvironment. The other piece of the puzzle is *Authorization*, which indicates\n_what_ they can access in the Jenkins environment. By default Jenkins supports\na few different Authorization options:\n\nAnyone can do anything:: Everyone gets full co"
  },
  "2455": {
    "source_file": "managing-security.txt",
    "text": " access in the Jenkins environment. By default Jenkins supports\na few different Authorization options:\n\nAnyone can do anything:: Everyone gets full control of Jenkins, including\nanonymous users who haven't logged in. *Do not use this setting* for anything\nother than local test Jenkins controllers.\nLegacy mode:: Behaves exactly the same as Jenkins <1.164. Namely, if a user has\nthe \"admin\" role, the"
  },
  "2456": {
    "source_file": "managing-security.txt",
    "text": "thing\nother than local test Jenkins controllers.\nLegacy mode:: Behaves exactly the same as Jenkins <1.164. Namely, if a user has\nthe \"admin\" role, they will be granted full control over the system, and otherwise\n(including anonymous users) will only have the read access. *Do not use this\nsetting* for anything other than local test Jenkins controllers.\nLogged in users can do anything:: In this mode"
  },
  "2457": {
    "source_file": "managing-security.txt",
    "text": "have the read access. *Do not use this\nsetting* for anything other than local test Jenkins controllers.\nLogged in users can do anything:: In this mode, every logged-in user gets full\ncontrol of Jenkins. Depending on an advanced option, anonymous users get read\naccess to Jenkins, or no access at all. This mode is useful to force users to\nlog in before taking actions, so that there is an audit trail"
  },
  "2458": {
    "source_file": "managing-security.txt",
    "text": "s get read\naccess to Jenkins, or no access at all. This mode is useful to force users to\nlog in before taking actions, so that there is an audit trail of users' actions.\nMatrix-based security:: This authorization scheme allows for granular control\nover which users and groups are able to perform which actions in the Jenkins\nenvironment (see the screenshot below).\nProject-based Matrix Authorization "
  },
  "2459": {
    "source_file": "managing-security.txt",
    "text": "er which users and groups are able to perform which actions in the Jenkins\nenvironment (see the screenshot below).\nProject-based Matrix Authorization Strategy:: This authorization scheme is an\nextension to Matrix-based security which allows additional access control lists\n(ACLs) to be defined for *each project* separately in the Project configuration\nscreen. This allows granting specific users or "
  },
  "2460": {
    "source_file": "managing-security.txt",
    "text": "l access control lists\n(ACLs) to be defined for *each project* separately in the Project configuration\nscreen. This allows granting specific users or groups access only to specified\nprojects, instead of all projects in the Jenkins environment. The ACLs defined\nwith Project-based Matrix Authorization are additive such that access grants\ndefined in the Security screen will be combined with\nproject-s"
  },
  "2461": {
    "source_file": "managing-security.txt",
    "text": "Ls defined\nwith Project-based Matrix Authorization are additive such that access grants\ndefined in the Security screen will be combined with\nproject-specific ACLs.\n\nMatrix-based security and Project-based Matrix Authorization Strategy are provided\nby the plugin:matrix-auth[Matrix Authorization Strategy Plugin]\nand may not be installed on your Jenkins.\n\nFor most Jenkins environments, Matrix-based s"
  },
  "2462": {
    "source_file": "managing-security.txt",
    "text": " the plugin:matrix-auth[Matrix Authorization Strategy Plugin]\nand may not be installed on your Jenkins.\n\nFor most Jenkins environments, Matrix-based security provides the most security\nand flexibility so it is recommended as a starting point for \"production\"\nenvironments.\n\n.Matrix-based security\n\nThe table shown above can get quite wide as each column represents a permission\nprovided by Jenkins co"
  },
  "2463": {
    "source_file": "managing-security.txt",
    "text": "duction\"\nenvironments.\n\n.Matrix-based security\n\nThe table shown above can get quite wide as each column represents a permission\nprovided by Jenkins core or a plugin. Hovering the mouse over a permission will\ndisplay more information about the permission.\n\nEach row in the table represents a user or group (also known as a \"role\"). This\nincludes special entries named \"anonymous\" and \"authenticated.\" "
  },
  "2464": {
    "source_file": "managing-security.txt",
    "text": "ion.\n\nEach row in the table represents a user or group (also known as a \"role\"). This\nincludes special entries named \"anonymous\" and \"authenticated.\" The \"anonymous\"\nentry represents permissions granted to all unauthenticated users accessing the\nJenkins environment. Whereas \"authenticated' can be used to grant permissions\nto all authenticated users accessing the environment.\n\nThe permissions grant"
  },
  "2465": {
    "source_file": "managing-security.txt",
    "text": "ins environment. Whereas \"authenticated' can be used to grant permissions\nto all authenticated users accessing the environment.\n\nThe permissions granted in the matrix are additive. For example, if a user\n\"kohsuke\" is in the groups \"developers\" and \"administrators\", then the\npermissions granted to \"kohsuke\" will be a union of all those permissions\ngranted to \"kohsuke\", \"developers\", \"administrators"
  },
  "2466": {
    "source_file": "managing-security.txt",
    "text": "dministrators\", then the\npermissions granted to \"kohsuke\" will be a union of all those permissions\ngranted to \"kohsuke\", \"developers\", \"administrators\", \"authenticated\", and\n\"anonymous.\"\n\nSee .\n\nSee .\n\nSee ."
  },
  "2467": {
    "source_file": "mark-a-plugin-incompatible.txt",
    "text": "layout: developer\ntitle: Mark a new plugin version as incompatible with older versions\n\n\nThe need for this should be rare.\nJenkins has an automatic data format upgrade capability, which should be used whenever possible for the best user experience.\n\nAt times, changes will be made to a plugin which result in the new version of the plugin no longer being compatible with the configuration used for ol"
  },
  "2468": {
    "source_file": "mark-a-plugin-incompatible.txt",
    "text": "At times, changes will be made to a plugin which result in the new version of the plugin no longer being compatible with the configuration used for older versions.\nWhen this is the case, you will probably want to be sure that your plugin's users are aware of this incompatibility.\nThere is support for marking the oldest version which is compatible with the configuration of your plugin's current ver"
  },
  "2469": {
    "source_file": "mark-a-plugin-incompatible.txt",
    "text": "aware of this incompatibility.\nThere is support for marking the oldest version which is compatible with the configuration of your plugin's current version.\n\n## Recording Oldest Compatible Version\nStarting from Plugin POM 3.33, it is possible to set a `hpi.compatibleSinceVersion` property to define the oldest compatible version.\n\n<properties>\n    <jenkins.version>2.289.3</jenkins.version>\n    <hpi."
  },
  "2470": {
    "source_file": "mark-a-plugin-incompatible.txt",
    "text": " `hpi.compatibleSinceVersion` property to define the oldest compatible version.\n\n<properties>\n    <jenkins.version>2.289.3</jenkins.version>\n    <hpi.compatibleSinceVersion>1.0</hpi.compatibleSinceVersion>\n</properties>\n\n`compatibleSinceVersion` should be the oldest version which is compatible with the configuration for the new version of your plugin -\nif your new version is not configuration-comp"
  },
  "2471": {
    "source_file": "mark-a-plugin-incompatible.txt",
    "text": "ld be the oldest version which is compatible with the configuration for the new version of your plugin -\nif your new version is not configuration-compatible with any previous versions, `compatibleSinceVersion` should use the next release's version number.\n\nYou can use the same system with .\n\n## Modification to Display of Updatable Plugin List\n\nWhen a new plugin version is available as an update, a"
  },
  "2472": {
    "source_file": "mark-a-plugin-incompatible.txt",
    "text": "mber.\n\nYou can use the same system with .\n\n## Modification to Display of Updatable Plugin List\n\nWhen a new plugin version is available as an update, and that new plugin version has a `compatibleSinceVersion` defined, the Update Center will check to see whether the installed version of the plugin is compatible with the new plugin.\nIf the installed version is not configuration-compatible, the plugin"
  },
  "2473": {
    "source_file": "mark-a-plugin-incompatible.txt",
    "text": "ee whether the installed version of the plugin is compatible with the new plugin.\nIf the installed version is not configuration-compatible, the plugin will show up in the available updates list with a note, in red, that jobs may need to be reconfigured.\n\nSee below:"
  },
  "2474": {
    "source_file": "mark-a-plugin-incompatible.txt",
    "text": "ed.\n\nSee below:"
  },
  "2475": {
    "source_file": "markup-formatter.txt",
    "text": "title: Markup Formatters\nlayout: section\n\n\nJenkins allows users with the appropriate permissions to enter descriptions of various objects, like views, jobs, builds, etc.\nThese descriptions are filtered by _markup formatters_.\nThey serve two purposes:\n\n1. Allow users to use rich formatting for these descriptions\n2. Protect other users from https://en.wikipedia.org/wiki/Cross-site_scripting[Cross-Si"
  },
  "2476": {
    "source_file": "markup-formatter.txt",
    "text": "\n\n1. Allow users to use rich formatting for these descriptions\n2. Protect other users from https://en.wikipedia.org/wiki/Cross-site_scripting[Cross-Site Scripting] (XSS) attacks\n\nThe markup formatter can be configured in _Manage Jenkins \u00bb Security \u00bb Markup Formatter_.\n\nThe default markup formatter _Plain text_ renders all descriptions as entered:\nUnsafe HTML metacharacters like `<` and `&` are esc"
  },
  "2477": {
    "source_file": "markup-formatter.txt",
    "text": "Markup Formatter_.\n\nThe default markup formatter _Plain text_ renders all descriptions as entered:\nUnsafe HTML metacharacters like `<` and `&` are escaped, and line breaks are rendered as `<br/>` HTML tags.\n\nAnother commonly installed markup formatter is _Safe HTML_, provided by the plugin:antisamy-markup-formatter[OWASP Markup Formatter Plugin].\nIt allows the use of a basic, safe subset of HTML.\n"
  },
  "2478": {
    "source_file": "markup-formatter.txt",
    "text": "r is _Safe HTML_, provided by the plugin:antisamy-markup-formatter[OWASP Markup Formatter Plugin].\nIt allows the use of a basic, safe subset of HTML.\n\nEvery user with an account and Overall/Read permission can edit their own user profile.\nThis includes a description that is rendered using the configured markup formatter.\n\nTherefore it can be unsafe to configure a markup formatter allowing arbitrar"
  },
  "2479": {
    "source_file": "markup-formatter.txt",
    "text": "es a description that is rendered using the configured markup formatter.\n\nTherefore it can be unsafe to configure a markup formatter allowing arbitrary HTML even when restricting permissions like _Job/Configure_ and _Build/Update_ to fully trusted users:\nAnyone with an account will be able to edit their own description and any other user accessing their profile may become victim of an XSS attack.\n"
  },
  "2480": {
    "source_file": "markup-formatter.txt",
    "text": "ers:\nAnyone with an account will be able to edit their own description and any other user accessing their profile may become victim of an XSS attack.\n\nThis is particularly risky on publicly accessible Jenkins instances when the security realm is implemented using a service like GitHub, GitLab, or Google accounts, resulting in potentially anyone being able to log in to Jenkins and edit their own pr"
  },
  "2481": {
    "source_file": "markup-formatter.txt",
    "text": "emented using a service like GitHub, GitLab, or Google accounts, resulting in potentially anyone being able to log in to Jenkins and edit their own profile.\n\n// TODO: Discuss HTML fallback features in formatters with other markup languages"
  },
  "2482": {
    "source_file": "migrate-documentation-to-github.txt",
    "text": "layout: developersection\ntitle: Migrate docs to GitHub\n\n\nJenkins plugin documentation was originally maintained on a wiki.\nThe wiki was deprecated in 2019 due to spam and was shut down in 2021.\nPlugin documentation is migrating to GitHub.\nInstructions are available on the  site.\n\n// Create the branch\n\nFollow the .\n\nAdditional information is available from:\n\n*  for plugin docs as markdown\n*  for en"
  },
  "2483": {
    "source_file": "migrate-documentation-to-github.txt",
    "text": "s are available on the  site.\n\n// Create the branch\n\nFollow the .\n\nAdditional information is available from:\n\n*  for plugin docs as markdown\n*  for entire wiki site as HTML\n*\n\n// Create a pull request"
  },
  "2484": {
    "source_file": "misc.txt",
    "text": "title: Miscellaneous API Usage Recommendations\nlayout: developer\n\n\n`Callable` is essentially an API of Jenkins through the controller/agent communication channel.\nThis lets Jenkins plugins execute complex computations on the other end of such a channel.\n\nCare needs to be taken to prevent users able to control agent processes from exploiting this and sending a malicious `Callable` to the controller"
  },
  "2485": {
    "source_file": "misc.txt",
    "text": "el.\n\nCare needs to be taken to prevent users able to control agent processes from exploiting this and sending a malicious `Callable` to the controller for execution.\n\nFollow the instructions in the  to implement `Callable` safely.\n\n`CrumbExclusion` is an extension point that allows excluding certain URLs from https://en.wikipedia.org/wiki/Cross-site_request_forgery[CSRF] protection.\n\nWherever poss"
  },
  "2486": {
    "source_file": "misc.txt",
    "text": "s an extension point that allows excluding certain URLs from https://en.wikipedia.org/wiki/Cross-site_request_forgery[CSRF] protection.\n\nWherever possible, do not use it to allow bypassing CSRF protection.\n\nSince Jenkins 2.96, requests using Basic authentication providing an API token do not need to provide a CSRF token (crumb).\nMost of the time, only unauthenticated requests (through `Unprotected"
  },
  "2487": {
    "source_file": "misc.txt",
    "text": "thentication providing an API token do not need to provide a CSRF token (crumb).\nMost of the time, only unauthenticated requests (through `UnprotectedRootAction`) when integrating with external systems will need to bypass CSRF protection.\n\nImplementations of jenkinsdoc:CrumbExclusion[`CrumbExclusion`] need to only allow bypassing CSRF protection for the _specific URLs_ that do not need it.\n\n[IMPOR"
  },
  "2488": {
    "source_file": "misc.txt",
    "text": "tions of jenkinsdoc:CrumbExclusion[`CrumbExclusion`] need to only allow bypassing CSRF protection for the _specific URLs_ that do not need it.\n\n[IMPORTANT]\n\nMake sure that the `HttpServletRequest#getPathInfo()` _equals_ the specific allowed URL, or _starts with_ a known safe prefix.\nMost URLs handling `POST` requests in Jenkins (web methods annotated using `@POST` or `@RequirePOST`) can receive ar"
  },
  "2489": {
    "source_file": "misc.txt",
    "text": "starts with_ a known safe prefix.\nMost URLs handling `POST` requests in Jenkins (web methods annotated using `@POST` or `@RequirePOST`) can receive arbitrary suffixes without impacting processing of the request, so checking for URLs _containing_ a specific string will allow attackers to easily bypass all CSRF protection in Jenkins.\n\nWhen disabling CSRF protection for an endpoint receiving `POST` r"
  },
  "2490": {
    "source_file": "misc.txt",
    "text": "ecific string will allow attackers to easily bypass all CSRF protection in Jenkins.\n\nWhen disabling CSRF protection for an endpoint receiving `POST` requests, be sure to only allow performing safe actions, like informing Jenkins about events that are verified again afterwards anyway before actions are being taken.\nIf the URLs without CSRF protection are provided by an `UnprotectedRootAction`, be s"
  },
  "2491": {
    "source_file": "misc.txt",
    "text": " verified again afterwards anyway before actions are being taken.\nIf the URLs without CSRF protection are provided by an `UnprotectedRootAction`, be sure to distinguish between authenticated and unauthenticated (anonymous) requests:\nDo not allow additional access or act on objects only because the current user has permission to access them.\n// This is kind of weird, should CrumbExclusion and Unpro"
  },
  "2492": {
    "source_file": "misc.txt",
    "text": "tional access or act on objects only because the current user has permission to access them.\n// This is kind of weird, should CrumbExclusion and UnprotectedRootAction just be merged into one section?\n\nAn `UnprotectedRootAction` is a `RootAction` that is available even to users without Overall/Read.\nTypes implementing `UnprotectedRootAction` should be kept minimal to reduce the surface that is publ"
  },
  "2493": {
    "source_file": "misc.txt",
    "text": " is available even to users without Overall/Read.\nTypes implementing `UnprotectedRootAction` should be kept minimal to reduce the surface that is publicly exposed.\nBe careful to not open up access to otherwise protected objects to users lacking otherwise necessary permissions to access them by having public fields or getters.\nWhile many types check for permissions in `StaplerProxy#getTarget`, many"
  },
  "2494": {
    "source_file": "misc.txt",
    "text": "wise necessary permissions to access them by having public fields or getters.\nWhile many types check for permissions in `StaplerProxy#getTarget`, many others do not, and permission checks are expected to be implemented in the getters granting access to navigate to these objects.\n\nSee https://github.com/stapler/stapler/blob/master/docs/reference.adoc[the Stapler reference documentation] for how req"
  },
  "2495": {
    "source_file": "misc.txt",
    "text": "to navigate to these objects.\n\nSee https://github.com/stapler/stapler/blob/master/docs/reference.adoc[the Stapler reference documentation] for how requests are handled in Jenkins.\n\nWhen exposing objects using the Jenkins remote API, be sure to check necessary permissions in `@Exported` getters and only expose objects the current user has permission to know about and access.\nDo not rely on permissi"
  },
  "2496": {
    "source_file": "misc.txt",
    "text": "necessary permissions in `@Exported` getters and only expose objects the current user has permission to know about and access.\nDo not rely on permission checks in internal APIs to exist.\n\nNOTE: Permission checks done in `StaplerProxy#getTarget` to control Stapler routing have no effect on `Api` / `@Exported`.\nFor `@ExportedBean` annotated types, it may therefore be necessary to implement permissio"
  },
  "2497": {
    "source_file": "misc.txt",
    "text": "ntrol Stapler routing have no effect on `Api` / `@Exported`.\nFor `@ExportedBean` annotated types, it may therefore be necessary to implement permission checks both in `StaplerProxy`, as well as on getters returning this type.\n\nPlugins distributed by the Jenkins project must adhere to these rules:\n\n* They must not provide additional certificates that apply to the default update sites provided by th"
  },
  "2498": {
    "source_file": "misc.txt",
    "text": "the Jenkins project must adhere to these rules:\n\n* They must not provide additional certificates that apply to the default update sites provided by the Jenkins project.\n* They must not disable signature checks for downloads.\n\nPlugins intending to make other plugins available to Jenkins administrators through the plugin manager are advised to define their own custom update sites, with custom certif"
  },
  "2499": {
    "source_file": "misc.txt",
    "text": "e other plugins available to Jenkins administrators through the plugin manager are advised to define their own custom update sites, with custom certificates.\nThis addition to the Jenkins configuration must be documented in the plugin documentation, in particular if there is any overlap with plugins provided through Jenkins project update sites.\n\nOther programs should generally be invoked using a j"
  },
  "2500": {
    "source_file": "misc.txt",
    "text": "n particular if there is any overlap with plugins provided through Jenkins project update sites.\n\nOther programs should generally be invoked using a jenkinsdoc:hudson.Launcher[`Launcher`] instance bound to the appropriate agent through its channel.\nDirectly using `Runtime#exec` and similar Java APIs is usually a bug and can in some cases constitute a security vulnerability:\nWhile users with the pe"
  },
  "2501": {
    "source_file": "misc.txt",
    "text": "irectly using `Runtime#exec` and similar Java APIs is usually a bug and can in some cases constitute a security vulnerability:\nWhile users with the permissions to configure and run jobs may be able to invoke arbitrary tools on those agents, they should not be able to run programs on the Jenkins controller.\n\nNOTE: Most Jenkins controllers archive artifacts on the Jenkins controller file system, so "
  },
  "2502": {
    "source_file": "misc.txt",
    "text": "ld not be able to run programs on the Jenkins controller.\n\nNOTE: Most Jenkins controllers archive artifacts on the Jenkins controller file system, so even possible constraints, such as for the command to exist on the controller's file system, or not taking any arguments, is trivially bypassed.\n\nPlugins that integrate with external services may encounter problems establishing connections via HTTPS "
  },
  "2503": {
    "source_file": "misc.txt",
    "text": "taking any arguments, is trivially bypassed.\n\nPlugins that integrate with external services may encounter problems establishing connections via HTTPS due to various SSL/TLS issues.\nAn easy way to prevent issues due to misconfigurations is to override the hostname verifier (to not perform hostname validation) and/or trust manager (to accept all certificates).\n\nThis is a very unsafe behavior and mus"
  },
  "2504": {
    "source_file": "misc.txt",
    "text": " the hostname verifier (to not perform hostname validation) and/or trust manager (to accept all certificates).\n\nThis is a very unsafe behavior and must never be the default in plugins distributed by the Jenkins project.\nIgnoring SSL/TLS errors is only permitted if the following constraints are both followed:\n\n1. Ignoring SSL/TLS errors is limited to the specific connections opened by the plugin.\n "
  },
  "2505": {
    "source_file": "misc.txt",
    "text": "y permitted if the following constraints are both followed:\n\n1. Ignoring SSL/TLS errors is limited to the specific connections opened by the plugin.\n   Plugins should never cause SSL/TLS errors to be ignored for the entire Jenkins controller.\n   As a consequence, APIs like `HttpsURLConnection#setDefaultHostnameVerifier` or `HttpsURLConnection#setDefaultSSLSocketFactory` must not be called by plugi"
  },
  "2506": {
    "source_file": "misc.txt",
    "text": " consequence, APIs like `HttpsURLConnection#setDefaultHostnameVerifier` or `HttpsURLConnection#setDefaultSSLSocketFactory` must not be called by plugins.\n   The only exceptions to this rule are dedicated plugins with only this purpose, like plugin:skip-certificate-check[skip-certificate-check].\n2. Ignoring SSL/TLS problems for specific connections (e.g. `HttpsURLConnection#setHostnameVerifier` or "
  },
  "2507": {
    "source_file": "misc.txt",
    "text": "ip-certificate-check[skip-certificate-check].\n2. Ignoring SSL/TLS problems for specific connections (e.g. `HttpsURLConnection#setHostnameVerifier` or `HttpsURLConnection#setSSLSocketFactory`) is allowed, but users need to opt in to this behavior.\n   By default, SSL/TLS problems must not be ignored.\n\nIdeally, users have fine-grained control over which connections should ignore errors.\nFor example, "
  },
  "2508": {
    "source_file": "misc.txt",
    "text": "By default, SSL/TLS problems must not be ignored.\n\nIdeally, users have fine-grained control over which connections should ignore errors.\nFor example, if a plugin allows integrating with a set of several different remote services, ignoring SSL/TLS errors should be a per-service option, rather than a single global option.\n\nPlugin developers need to be careful when working with user-provided content."
  },
  "2509": {
    "source_file": "misc.txt",
    "text": "ors should be a per-service option, rather than a single global option.\n\nPlugin developers need to be careful when working with user-provided content.\nThis can take many forms, but common data formats are XML, JSON, and YAML, and are provided through potentially untrusted sources.\n\nIf you're implementing form validation for a build step whose configuration is provided as XML, or a post-build step "
  },
  "2510": {
    "source_file": "misc.txt",
    "text": " potentially untrusted sources.\n\nIf you're implementing form validation for a build step whose configuration is provided as XML, or a post-build step that processes a file in the workspace, be sure to treat the contents as not fully trusted.\n\nDeserializing untrusted content can easily result in a remote code execution (RCE) vulnerability.\n\nTo prevent this, use https://javadoc.jenkins.io/component/"
  },
  "2511": {
    "source_file": "misc.txt",
    "text": "lizing untrusted content can easily result in a remote code execution (RCE) vulnerability.\n\nTo prevent this, use https://javadoc.jenkins.io/component/remoting/hudson/remoting/ObjectInputStreamEx.html[`ObjectInputStreamEx`] and pass `hudson.remoting.ClassFilter.DEFAULT`.\nThis will integrate your deserialization mechanism with https://github.com/jenkinsci/jep/tree/master/jep/200[JEP-200].\n\nNote that"
  },
  "2512": {
    "source_file": "misc.txt",
    "text": "lassFilter.DEFAULT`.\nThis will integrate your deserialization mechanism with https://github.com/jenkinsci/jep/tree/master/jep/200[JEP-200].\n\nNote that this may require adding a `hudson.remoting.ClassFilter` to your plugin that allows deserializing further safe types.\nMake sure to review these types for potentially unsafe `readResolve` and `readObject` implementations.\nIf at all possible, prefer se"
  },
  "2513": {
    "source_file": "misc.txt",
    "text": "rther safe types.\nMake sure to review these types for potentially unsafe `readResolve` and `readObject` implementations.\nIf at all possible, prefer serializing object graphs using types already approved.\n\nBe sure to review the https://cheatsheetseries.owasp.org/cheatsheets/XML_External_Entity_Prevention_Cheat_Sheet.html[OWASP Cheat Sheet for XML External Entity prevention] and the https://semgrep."
  },
  "2514": {
    "source_file": "misc.txt",
    "text": "s.owasp.org/cheatsheets/XML_External_Entity_Prevention_Cheat_Sheet.html[OWASP Cheat Sheet for XML External Entity prevention] and the https://semgrep.dev/docs/cheat-sheets/java-xxe[Semgrep cheat sheet on XXE].\nAll content should be treated as untrusted except in very specific circumstances.\n`jenkinsdoc:XMLUtils[]` provides functionality to perform common XML operations safely.\n\nWhen using jackson-"
  },
  "2515": {
    "source_file": "misc.txt",
    "text": "ed except in very specific circumstances.\n`jenkinsdoc:XMLUtils[]` provides functionality to perform common XML operations safely.\n\nWhen using jackson-databind, make sure to depend on 2.10.x or newer, and only use the \"safe\" replacement APIs to prevent deserialization vulnerabilities: Use `activateDefaultTyping` instead of `enableDefaultTyping`.\nSee https://github.com/FasterXML/jackson-docs/wiki/Ja"
  },
  "2516": {
    "source_file": "misc.txt",
    "text": "t deserialization vulnerabilities: Use `activateDefaultTyping` instead of `enableDefaultTyping`.\nSee https://github.com/FasterXML/jackson-docs/wiki/JacksonPolymorphicDeserialization[the documentation on polymorphic deserialization].\n\nX-Stream is bundled with Jenkins.\nJenkins plugins generally should not use it directly, but only through jenkinsdoc:hudson.util.XStream2[`XStream2`].\n\nWhen processing"
  },
  "2517": {
    "source_file": "misc.txt",
    "text": "led with Jenkins.\nJenkins plugins generally should not use it directly, but only through jenkinsdoc:hudson.util.XStream2[`XStream2`].\n\nWhen processing YAML, be sure to look into the parser library's security documentation.\nIt needs to be configured to prevent the instantiation of arbitrary types.\n\nWhen using SnakeYAML, make sure to never use the parameterless `new Yaml()` constructor, but to pass "
  },
  "2518": {
    "source_file": "misc.txt",
    "text": "o prevent the instantiation of arbitrary types.\n\nWhen using SnakeYAML, make sure to never use the parameterless `new Yaml()` constructor, but to pass a `SafeConstructor` as argument (or otherwise restrict what can be deserialized).\nAdditionally, use at least version 1.26 to get denial-of-service protection (\"billion laughs\").\nConsider depending on the plugin:snakeyaml-api[SnakeYAML API Plugin] ins"
  },
  "2519": {
    "source_file": "misc.txt",
    "text": "at least version 1.26 to get denial-of-service protection (\"billion laughs\").\nConsider depending on the plugin:snakeyaml-api[SnakeYAML API Plugin] instead of bundling SnakeYAML with your plugin.\n\nMany Jenkins plugins allow the use of Groovy to extend their capabilities.\nFor example, the plugin:email-ext[Email Extension Plugin] allows executing a script to determine whether an email should be sent."
  },
  "2520": {
    "source_file": "misc.txt",
    "text": " their capabilities.\nFor example, the plugin:email-ext[Email Extension Plugin] allows executing a script to determine whether an email should be sent.\n\nAll such functionality, if available to users without Overall/Administer, must integrate with plugin:script-security[Script Security Plugin].\n\nPlugins such as plugin:script-security[Script Security] and plugin:workflow-cps[Pipeline:Groovy] allow no"
  },
  "2521": {
    "source_file": "misc.txt",
    "text": "in:script-security[Script Security Plugin].\n\nPlugins such as plugin:script-security[Script Security] and plugin:workflow-cps[Pipeline:Groovy] allow non-admin users of Jenkins to run scripts in a sandbox.\nAs of late 2024, a blocklist prevents use of known unsafe AST transformations that previously caused security issues.\n\nPlugin-contributed Groovy AST transformations, in particular those applying g"
  },
  "2522": {
    "source_file": "misc.txt",
    "text": "nown unsafe AST transformations that previously caused security issues.\n\nPlugin-contributed Groovy AST transformations, in particular those applying globally through `META-INF/services`, need to be written with this in mind.\nSubstantial functionality that allows users to circumvent Script Security sandbox protections must not be provided by other plugins.\n\nWhen there is a necessity to log secrets,"
  },
  "2523": {
    "source_file": "misc.txt",
    "text": " that allows users to circumvent Script Security sandbox protections must not be provided by other plugins.\n\nWhen there is a necessity to log secrets, care must be taken to avoid accidental exposure.\nThey must be logged at a level that is not visible by default in the system log.\nThis implies setting the logging level to a level more verbose than INFO (i.e., CONFIG, FINE, FINER, or FINEST)."
  },
  "2524": {
    "source_file": "misc.txt",
    "text": " by default in the system log.\nThis implies setting the logging level to a level more verbose than INFO (i.e., CONFIG, FINE, FINER, or FINEST)."
  },
  "2525": {
    "source_file": "model.txt",
    "text": "title: Model\nlayout: developer\n\n\n- This view is Jenkins itself\n- Many plugins add technical layers like additional storage.\n- Plugins are adding features so by definition the content of the business layer is infinite :)\n\n   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n   \u2502    Automation, machine to machine       \u2502   \u2502 End users/Browsers  \u2502   \u2502    Agents  "
  },
  "2526": {
    "source_file": "model.txt",
    "text": "\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n   \u2502    Automation, machine to machine       \u2502   \u2502 End users/Browsers  \u2502   \u2502    Agents   \u2502\n   \u2502    command line prompt (curl, wget..)   \u2502   \u2502                     \u2502   \u2502             \u2502\n   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25b2\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25b2\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25b2\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25b2\u2500\u2500\u2500\u2500\u2500\u2518\n             \u2502                     \u2502                         \u2502   "
  },
  "2527": {
    "source_file": "model.txt",
    "text": "\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25b2\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25b2\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25b2\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25b2\u2500\u2500\u2500\u2500\u2500\u2518\n             \u2502                     \u2502                         \u2502                     \u2502\n             \u2502                     \u2502                         \u2502                     \u2502\n             \u2502                     \u2502                         \u2502                     \u2502\n \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500"
  },
  "2528": {
    "source_file": "model.txt",
    "text": "   \u2502\n             \u2502                     \u2502                         \u2502                     \u2502\n \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n \u2502   Command line CLI    \u2502   HTTP Endpoints    \u2502  Web user interface     \u2502    Remoting    \u2502\n \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2502                     \u2502                         \u2502                \u2502\n \u2502  SSH  \u2502   websocket   \u2502        "
  },
  "2529": {
    "source_file": "model.txt",
    "text": "     \u2502    Remoting    \u2502\n \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2502                     \u2502                         \u2502                \u2502\n \u2502  SSH  \u2502   websocket   \u2502                     \u2502  (Jelly /Groovy views)  \u2502                \u2502\n \u2502       \u2502   or HTTP     \u2502                     \u2502                         \u2502                \u2502\n \u2502       \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524                \u2502\n \u2502      "
  },
  "2530": {
    "source_file": "model.txt",
    "text": "     \u2502                         \u2502                \u2502\n \u2502       \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524                \u2502\n \u2502       \u2502                                                               \u2502                \u2502\n \u2502       \u2502       Stapler: security, routing, requests processing         \u2502                \u2502\n \u2502       \u2502                                                               \u2502"
  },
  "2531": {
    "source_file": "model.txt",
    "text": " Stapler: security, routing, requests processing         \u2502                \u2502\n \u2502       \u2502                                                               \u2502                \u2502\n \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n \u2502                                                                                        \u2502\n \u2502                       Business layer: models,"
  },
  "2532": {
    "source_file": "model.txt",
    "text": "\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n \u2502                                                                                        \u2502\n \u2502                       Business layer: models, processing, scheduling                   \u2502\n \u2502                                                                                        \u2502\n \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n \u2502                    "
  },
  "2533": {
    "source_file": "model.txt",
    "text": "                                  \u2502\n \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n \u2502                                                                                        \u2502\n \u2502                      Storage layer: XML files on JENKINS_HOME                          \u2502\n \u2502                                                                                      "
  },
  "2534": {
    "source_file": "model.txt",
    "text": "e layer: XML files on JENKINS_HOME                          \u2502\n \u2502                                                                                        \u2502\n \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\nSome references to dive deeper:\n\n - https://github.com/jenkinsci/remoting/blob/master/README.md[Remoting]\n -\n -\n -\n -"
  },
  "2535": {
    "source_file": "model.txt",
    "text": "e references to dive deeper:\n\n - https://github.com/jenkinsci/remoting/blob/master/README.md[Remoting]\n -\n -\n -\n -"
  },
  "2536": {
    "source_file": "monitoring.txt",
    "text": "layout: section\n\n\nifndef::env-github[:imagesdir: ../../resources/managing]\n\nNOTE: This page is under development, there will be more content added soon.\nSee the jira:WEBSITE-738[] EPIC for tasks related to this page, contributions are welcome!\n\n- plugin:datadog[Datadog plugin for Jenkins]\n- plugin:metrics-datadog[Metrics-Datadog plugin for Jenkins]\n- https://www.datadoghq.com/blog/monitor-jenkins-"
  },
  "2537": {
    "source_file": "monitoring.txt",
    "text": "gin:datadog[Datadog plugin for Jenkins]\n- plugin:metrics-datadog[Metrics-Datadog plugin for Jenkins]\n- https://www.datadoghq.com/blog/monitor-jenkins-datadog[Jenkins on Datadog]\n\n- https://opensource.newrelic.com/projects/newrelic/nr-jenkins-plugin[Jenkins on Newrelic]\n- https://newrelic.com/blog/best-practices/how-use-jenkins-integration-tests[Developing a Jenkins Integration Pipeline for the New"
  },
  "2538": {
    "source_file": "monitoring.txt",
    "text": "enkins on Newrelic]\n- https://newrelic.com/blog/best-practices/how-use-jenkins-integration-tests[Developing a Jenkins Integration Pipeline for the New Relic Infrastructure On-Host Integrations]\n\n- plugin:prometheus[Prometheus plugin for Jenkins]\n- https://medium.com/@eng.mohamed.m.saeed/monitoring-jenkins-with-grafana-and-prometheus-a7e037cbb376[How-To blog on Medium]\n\n- plugin:monitoring[Monitori"
  },
  "2539": {
    "source_file": "monitoring.txt",
    "text": "tps://medium.com/@eng.mohamed.m.saeed/monitoring-jenkins-with-grafana-and-prometheus-a7e037cbb376[How-To blog on Medium]\n\n- plugin:monitoring[Monitoring plugin for Jenkins]\n\n- plugin:versioncolumn[Versions Node Monitors]\n- plugin:systemloadaverage-monitor[Agents Monitoring for unix nodes]\n- plugin:jqs-monitoring[Job/Queue/Slaves Monitoring]\n\nJenkins installs \"ping thread\" on every remoting connect"
  },
  "2540": {
    "source_file": "monitoring.txt",
    "text": "nitor[Agents Monitoring for unix nodes]\n- plugin:jqs-monitoring[Job/Queue/Slaves Monitoring]\n\nJenkins installs \"ping thread\" on every remoting connection, such as controller/agent connections, regardless of its\ntransport mechanism (such as SSH, JNLP, etc.). The lower level of the Jenkins remoting protocol is a message oriented\nprotocol, and a ping thread periodically sends a ping message that the "
  },
  "2541": {
    "source_file": "monitoring.txt",
    "text": " etc.). The lower level of the Jenkins remoting protocol is a message oriented\nprotocol, and a ping thread periodically sends a ping message that the receiving end will reply. The ping thread\nmeasures the time it takes for the reply to arrive, and if it's taking excessive time (currently\nhttps://github.com/jenkinsci/remoting/blob/master/src/main/java/hudson/remoting/Launcher.java[4 minutes] and\nco"
  },
  "2542": {
    "source_file": "monitoring.txt",
    "text": " it's taking excessive time (currently\nhttps://github.com/jenkinsci/remoting/blob/master/src/main/java/hudson/remoting/Launcher.java[4 minutes] and\nconfigurable), then it assumes that the connection was lost and initiates the formal close down.\n\nThis is to avoid an infinite hang, as some of the failure modes in network cannot be detected otherwise. The timeout is\nalso set to a long enough value so"
  },
  "2543": {
    "source_file": "monitoring.txt",
    "text": " is to avoid an infinite hang, as some of the failure modes in network cannot be detected otherwise. The timeout is\nalso set to a long enough value so that a temporary surge in the load or a long garbage collection pause will not trip\noff the close down.\n\nPing thread is installed on both controller & agent; each side pings the other and tries to detect the problem from\ntheir own sides.\n\nThe ping t"
  },
  "2544": {
    "source_file": "monitoring.txt",
    "text": "own.\n\nPing thread is installed on both controller & agent; each side pings the other and tries to detect the problem from\ntheir own sides.\n\nThe ping thread time out is reported through `+java.util.logging+`. In addition, the controller will also report this\nexception in the agent launch log. Note that some agent launchers, most notably SSH agents, writes all stdout/stderr\noutputs from the agent JV"
  },
  "2545": {
    "source_file": "monitoring.txt",
    "text": "rt this\nexception in the agent launch log. Note that some agent launchers, most notably SSH agents, writes all stdout/stderr\noutputs from the agent JVM into this same log file, so you need to be careful. See\nhttps://issues.jenkins.io/browse/JENKINS-25695[JENKINS-25695].\n\n[[PingThread-Disablingpingthread]]\n\nSometimes, for example https://wiki.jenkins.io/display/JENKINS/Remoting+issue[to diagnose th"
  },
  "2546": {
    "source_file": "monitoring.txt",
    "text": "5695[JENKINS-25695].\n\n[[PingThread-Disablingpingthread]]\n\nSometimes, for example https://wiki.jenkins.io/display/JENKINS/Remoting+issue[to diagnose the agent connection loss\nproblem], you may want to disable the ping thread.  This needs to be done in two places.\n\nDisable the controller from pinging agents by setting `+hudson.slaves.ChannelPinger.pingIntervalSeconds+` on the controller JVM to -1.\n\n"
  },
  "2547": {
    "source_file": "monitoring.txt",
    "text": " two places.\n\nDisable the controller from pinging agents by setting `+hudson.slaves.ChannelPinger.pingIntervalSeconds+` on the controller JVM to -1.\n\nYou can also change the value in memory for a running Jenkins, if you don't want to restart Jenkins.\n\nSet `pingIntervalSeconds` and `pingTimeoutSeconds on the controller` JVM to -1:\n\nJenkins.instance.injector.getInstance(hudson.slaves.ChannelPinger.c"
  },
  "2548": {
    "source_file": "monitoring.txt",
    "text": "\n\nSet `pingIntervalSeconds` and `pingTimeoutSeconds on the controller` JVM to -1:\n\nJenkins.instance.injector.getInstance(hudson.slaves.ChannelPinger.class).@pingIntervalSeconds = -1\nJenkins.instance.injector.getInstance(hudson.slaves.ChannelPinger.class).@pingTimeoutSeconds = -1\n\nThe above will only affect newly connected agents. Existing connected agents will continue running pings.\n\nTo disable a"
  },
  "2549": {
    "source_file": "monitoring.txt",
    "text": "ass).@pingTimeoutSeconds = -1\n\nThe above will only affect newly connected agents. Existing connected agents will continue running pings.\n\nTo disable agents from pinging the controller, the system property\n\n-Dhudson.remoting.Launcher.pingIntervalSec=-1\n\nneeds to be set to agents.\nHow to do this depends on the launcher."
  },
  "2550": {
    "source_file": "monitoring.txt",
    "text": "1\n\nneeds to be set to agents.\nHow to do this depends on the launcher."
  },
  "2551": {
    "source_file": "move-description-to-index.txt",
    "text": "layout: developersection\ntitle: Move description\n\n\nTo help administrators decide if a plugin is relevant for them, each plugin should provide a short description which is then shown in plugin manager and on the plugin site.\nThe preferred location for the plugin description is in the file `src/main/resources/index.jelly`.\nIn the past it was also possible to provide it using the `description` tag in"
  },
  "2552": {
    "source_file": "move-description-to-index.txt",
    "text": " the plugin description is in the file `src/main/resources/index.jelly`.\nIn the past it was also possible to provide it using the `description` tag in plugin POM, but\nrecent versions of the parent POM require the preferred location and will fail to compile if the plugin description is not available from `index.jelly` in the expected directory.\n\nCopy the contents of the `description` tag from the P"
  },
  "2553": {
    "source_file": "move-description-to-index.txt",
    "text": "ompile if the plugin description is not available from `index.jelly` in the expected directory.\n\nCopy the contents of the `description` tag from the POM file to `src/main/resources/index.jelly`.\n\nNOTE: Some plugins do not currently provide description at all or use description copied from the `hello-world` sample plugin. For such plugins you have to write the description yourself. Such plugins are"
  },
  "2554": {
    "source_file": "move-description-to-index.txt",
    "text": "n at all or use description copied from the `hello-world` sample plugin. For such plugins you have to write the description yourself. Such plugins are listed in jira:JENKINS-68300[].\n\nWhen such a conversion is needed, the Maven build process will frequently output a message like:\n\n[ERROR] Failed to execute goal maven-hpi-plugin:hpi (default-hpi) on\nproject your-plugin: Missing target/classes/index"
  },
  "2555": {
    "source_file": "move-description-to-index.txt",
    "text": "quently output a message like:\n\n[ERROR] Failed to execute goal maven-hpi-plugin:hpi (default-hpi) on\nproject your-plugin: Missing target/classes/index.jelly. Delete any\n<description> from pom.xml and create src/main/resources/index.jelly:\n\n// Create the branch\n\n// Compile the plugin\n\nConfirm that the description transition warning message is displayed:\n\n[ERROR] Failed to execute goal maven-hpi-plu"
  },
  "2556": {
    "source_file": "move-description-to-index.txt",
    "text": "the branch\n\n// Compile the plugin\n\nConfirm that the description transition warning message is displayed:\n\n[ERROR] Failed to execute goal maven-hpi-plugin:hpi (default-hpi) on\nproject your-plugin: Missing target/classes/index.jelly. Delete any\n<description> from pom.xml and create src/main/resources/index.jelly:\n\nIf the warning message is not displayed and the plugin is using the most recent parent"
  },
  "2557": {
    "source_file": "move-description-to-index.txt",
    "text": "ption> from pom.xml and create src/main/resources/index.jelly:\n\nIf the warning message is not displayed and the plugin is using the most recent parent pom, then no transition is necessary.\n\nRemove the `<description>` tag and its value from the POM.\nCreate the `src/main/resources/index.jelly` file and insert the description as follows:\n\n<?jelly escape-by-default='true'?>\n<div>\nInsert your plugin de"
  },
  "2558": {
    "source_file": "move-description-to-index.txt",
    "text": "reate the `src/main/resources/index.jelly` file and insert the description as follows:\n\n<?jelly escape-by-default='true'?>\n<div>\nInsert your plugin description here\n</div>\n\nReview the change with the command:\n\ngit diff\ndiff --git a/src/main/resources/index.jelly b/src/main/resources/index.jelly\nnew file mode 100644\nindex 0000000..9434d10\n--- /dev/null\n++ b/src/main/resources/index.jelly\n@@ -0,0 +1"
  },
  "2559": {
    "source_file": "move-description-to-index.txt",
    "text": "/index.jelly b/src/main/resources/index.jelly\nnew file mode 100644\nindex 0000000..9434d10\n--- /dev/null\n++ b/src/main/resources/index.jelly\n@@ -0,0 +1,4 @@\n<?jelly escape-by-default='true'?>\n<div>\nInsert your plugin description here\n</div>\n\n// Compile the plugin\n\nConfirm that the description transition warning message is no longer displayed.\n\n// Create a pull request"
  },
  "2560": {
    "source_file": "move-description-to-index.txt",
    "text": "e the plugin\n\nConfirm that the description transition warning message is no longer displayed.\n\n// Create a pull request"
  },
  "2561": {
    "source_file": "multibranch.txt",
    "text": "layout: section\ntitle: Branches and Pull Requests\n\n\nifdef::env-github[:imagesdir: ../resources]\nifndef::env-github[:imagesdir: ../../resources]\n\nIn the <<jenkinsfile#, previous section>> a `Jenkinsfile` which could be\nchecked into source control was implemented. This section covers the concept of\n*Multibranch* Pipelines which build on the `Jenkinsfile` foundation to provide\nmore dynamic and automa"
  },
  "2562": {
    "source_file": "multibranch.txt",
    "text": "implemented. This section covers the concept of\n*Multibranch* Pipelines which build on the `Jenkinsfile` foundation to provide\nmore dynamic and automatic functionality in Jenkins.\n\n.Creating a Multibranch Pipeline in Jenkins\nvideo::B_2FXWI6CWg[youtube,width=800,height=420]\n\nThe *Multibranch Pipeline* project type enables you to implement different\nJenkinsfiles for different branches of the same pr"
  },
  "2563": {
    "source_file": "multibranch.txt",
    "text": "e,width=800,height=420]\n\nThe *Multibranch Pipeline* project type enables you to implement different\nJenkinsfiles for different branches of the same project.\nIn a Multibranch Pipeline project, Jenkins automatically discovers, manages and\nexecutes Pipelines for branches which contain a `Jenkinsfile` in source control.\n\nThis eliminates the need for manual Pipeline creation and management.\n\nTo create "
  },
  "2564": {
    "source_file": "multibranch.txt",
    "text": "lines for branches which contain a `Jenkinsfile` in source control.\n\nThis eliminates the need for manual Pipeline creation and management.\n\nTo create a Multibranch Pipeline:\n\n* Click *New Item* on Jenkins home page.\n\n* Enter a name for your Pipeline, select *Multibranch Pipeline* and click *OK*.\n\n[CAUTION]\n\nJenkins uses the name of the Pipeline to create directories on disk. Pipeline\nnames which i"
  },
  "2565": {
    "source_file": "multibranch.txt",
    "text": " select *Multibranch Pipeline* and click *OK*.\n\n[CAUTION]\n\nJenkins uses the name of the Pipeline to create directories on disk. Pipeline\nnames which include spaces may uncover bugs in scripts which do not expect\npaths to contain spaces.\n\n* Add a *Branch Source* (for example, Git).\n\n* Enter the location of the Git Repository.\n\n* *Save* the Multibranch Pipeline project.\n\nUpon *Save*, Jenkins automat"
  },
  "2566": {
    "source_file": "multibranch.txt",
    "text": "nch Source* (for example, Git).\n\n* Enter the location of the Git Repository.\n\n* *Save* the Multibranch Pipeline project.\n\nUpon *Save*, Jenkins automatically scans the designated repository and creates\nappropriate items for each branch in the repository which contains a\n`Jenkinsfile`.\n\nBy default, Jenkins will not automatically re-index the repository for branch\nadditions or deletions (unless using"
  },
  "2567": {
    "source_file": "multibranch.txt",
    "text": "ry which contains a\n`Jenkinsfile`.\n\nBy default, Jenkins will not automatically re-index the repository for branch\nadditions or deletions (unless using an <<organization-folders,Organization Folder>>),\nso it is often useful to configure a Multibranch Pipeline to periodically\nre-index in the configuration:\n\nMultibranch Pipelines expose additional information about the branch being\nbuilt through the "
  },
  "2568": {
    "source_file": "multibranch.txt",
    "text": "Pipeline to periodically\nre-index in the configuration:\n\nMultibranch Pipelines expose additional information about the branch being\nbuilt through the `env` global variable, such as:\n\nBRANCH_NAME:: Name of the branch for which this Pipeline is executing, for\nexample `master`.\n\nCHANGE_ID:: An identifier corresponding to some kind of change request, such as a pull request number\n\nAdditional environme"
  },
  "2569": {
    "source_file": "multibranch.txt",
    "text": "ng, for\nexample `master`.\n\nCHANGE_ID:: An identifier corresponding to some kind of change request, such as a pull request number\n\nAdditional environment variables are listed in the\n<<getting-started#global-variable-reference,Global Variable Reference>>.\n\nMultibranch Pipelines can be used for validating pull/change requests with the appropriate plugin.\nThis functionality is provided by the followin"
  },
  "2570": {
    "source_file": "multibranch.txt",
    "text": ">>.\n\nMultibranch Pipelines can be used for validating pull/change requests with the appropriate plugin.\nThis functionality is provided by the following plugins:\n\n* plugin:github-branch-source[GitHub Branch Source]\n* plugin:cloudbees-bitbucket-branch-source[Bitbucket Branch Source]\n* plugin:gitlab-branch-source[GitLab Branch Source]\n* plugin:gitea[Gitea]\n* plugin:tuleap-git-branch-source[Tuleap Git"
  },
  "2571": {
    "source_file": "multibranch.txt",
    "text": "source[Bitbucket Branch Source]\n* plugin:gitlab-branch-source[GitLab Branch Source]\n* plugin:gitea[Gitea]\n* plugin:tuleap-git-branch-source[Tuleap Git Branch Source]\n* plugin:aws-codecommit-jobs[AWS CodeCommit Jobs]\n* plugin:dagshub-branch-source[DAGsHub Branch Source]\n\nPlease consult their documentation for further information on how to\nuse those plugins.\n\n[[organization-folders]]\n\nOrganization F"
  },
  "2572": {
    "source_file": "multibranch.txt",
    "text": "sHub Branch Source]\n\nPlease consult their documentation for further information on how to\nuse those plugins.\n\n[[organization-folders]]\n\nOrganization Folders enable Jenkins to monitor an entire GitHub\nOrganization, Bitbucket Team/Project, GitLab organization, or Gitea organization and automatically create new\nMultibranch Pipelines for repositories which contain branches and pull requests\ncontaining"
  },
  "2573": {
    "source_file": "multibranch.txt",
    "text": "ization, or Gitea organization and automatically create new\nMultibranch Pipelines for repositories which contain branches and pull requests\ncontaining a `Jenkinsfile`.\n\nOrganization folders are implemented for:\n\n* GitHub in the plugin:github-branch-source[GitHub Branch Source] plugin\n* Bitbucket in the plugin:cloudbees-bitbucket-branch-source[Bitbucket Branch Source] plugin\n* GitLab in the plugin:"
  },
  "2574": {
    "source_file": "multibranch.txt",
    "text": "ource[GitHub Branch Source] plugin\n* Bitbucket in the plugin:cloudbees-bitbucket-branch-source[Bitbucket Branch Source] plugin\n* GitLab in the plugin:gitlab-branch-source[GitLab Branch Source] plugin\n* Gitea in the plugin:gitea[Gitea] plugin\n\n// Hints of possible implementations mentioned in\n// AWS Code Commit Jobs Plugin - not really an organization folder, but discovers repositories in AWS CodeC"
  },
  "2575": {
    "source_file": "multibranch.txt",
    "text": "s of possible implementations mentioned in\n// AWS Code Commit Jobs Plugin - not really an organization folder, but discovers repositories in AWS CodeCommit\n// Tuleap Git Branch Source Plugin - not mentioned as an organization folder"
  },
  "2576": {
    "source_file": "new-plugin.txt",
    "text": "title: Creating a new plugin\nsummary: How to start with a new plugin\nlayout: developer\n\n\n[NOTE]\nPlease read  before you start if you intend to release your plugin publicly using the Jenkins project infrastructure.\n\nWe publish project archetypes, including an \"empty plugin\" one, that allow you to easily set up a minimal plugin project with recommended defaults.\nJust run the following command on the"
  },
  "2577": {
    "source_file": "new-plugin.txt",
    "text": "uding an \"empty plugin\" one, that allow you to easily set up a minimal plugin project with recommended defaults.\nJust run the following command on the command line (with Maven and JDK installed, see ), and follow the interactive instructions:\n\nmvn archetype:generate -Dfilter=io.jenkins.archetypes:empty-plugin"
  },
  "2578": {
    "source_file": "new-plugin.txt",
    "text": "chetype:generate -Dfilter=io.jenkins.archetypes:empty-plugin"
  },
  "2579": {
    "source_file": "nodes.txt",
    "text": "layout: section\n\n\nBuilds in a  use nodes, agents, and executors, which are distinct from the Jenkins controller itself.\nUnderstanding what each of these components are is useful when managing nodes:\n\nJenkins controller::\n\nThe Jenkins controller is the Jenkins service itself and where Jenkins is installed.\nIt is also a web server that also acts as a \"brain\" for deciding how, when, and where to run "
  },
  "2580": {
    "source_file": "nodes.txt",
    "text": "e Jenkins service itself and where Jenkins is installed.\nIt is also a web server that also acts as a \"brain\" for deciding how, when, and where to run tasks.\nManagement tasks such as configuration, authorization, and authentication are executed on the controller, which serves HTTP requests.\nFiles written when a Pipeline executes are written to the filesystem on the controller, unless they are off-l"
  },
  "2581": {
    "source_file": "nodes.txt",
    "text": " controller, which serves HTTP requests.\nFiles written when a Pipeline executes are written to the filesystem on the controller, unless they are off-loaded to an artifact repository such as Nexus or Artifactory.\n\nNodes::\n\nNodes are the \"machines\" on which build agents run.\nJenkins monitors each attached node for disk space, free temp space, free swap, clock time/sync, and response time.\nA node is "
  },
  "2582": {
    "source_file": "nodes.txt",
    "text": "which build agents run.\nJenkins monitors each attached node for disk space, free temp space, free swap, clock time/sync, and response time.\nA node is taken offline if any of these values go outside the configured threshold.\nJenkins supports two types of nodes:\n* *agents* (described below)\n* *built-in node*\n** The built-in node is a node that exists within the controller process.\nIt is possible to "
  },
  "2583": {
    "source_file": "nodes.txt",
    "text": " of nodes:\n* *agents* (described below)\n* *built-in node*\n** The built-in node is a node that exists within the controller process.\nIt is possible to use agents and the build-in node to run tasks.\nHowever, running tasks on the built-in node is discouraged for security, performance, and scalability reasons.\nThe number of executors configured for the node determines the node's ability to run tasks.\n"
  },
  "2584": {
    "source_file": "nodes.txt",
    "text": "raged for security, performance, and scalability reasons.\nThe number of executors configured for the node determines the node's ability to run tasks.\nSet the number of executors to 0 to disable running tasks on the built-in node.\n\nAgents::\n\nAgents manage the task execution on behalf of the Jenkins controller by using executors.\nAn agent is a small (170KB single jar) Java client process that connec"
  },
  "2585": {
    "source_file": "nodes.txt",
    "text": "nage the task execution on behalf of the Jenkins controller by using executors.\nAn agent is a small (170KB single jar) Java client process that connects to a Jenkins controller and is assumed to be unreliable.\nAn agent can use any operating system that supports Java.\nAny tools required for building and testing get installed on the node where the agent runs.\nBecause these tools are a part of the no"
  },
  "2586": {
    "source_file": "nodes.txt",
    "text": "at supports Java.\nAny tools required for building and testing get installed on the node where the agent runs.\nBecause these tools are a part of the node, they can be installed directly or in a container, such as Docker or Kubernetes.\nEach agent is effectively a process with its own Process Identifier (PID) on the host machine.\nIn practice, nodes and agents are essentially the same but it is good t"
  },
  "2587": {
    "source_file": "nodes.txt",
    "text": "fectively a process with its own Process Identifier (PID) on the host machine.\nIn practice, nodes and agents are essentially the same but it is good to remember that they are conceptually distinct.\n\nExecutors::\n\nAn executor is a slot for the execution of tasks.\nEffectively, it is a thread in the agent.\nThe number of executors on a node defines the number of concurrent tasks that can run.\nIn other "
  },
  "2588": {
    "source_file": "nodes.txt",
    "text": "n of tasks.\nEffectively, it is a thread in the agent.\nThe number of executors on a node defines the number of concurrent tasks that can run.\nIn other words, this determines the number of concurrent Pipeline `stages` that can execute at the same time.\nDetermine the correct number of executors per build node must be determined based on the resources available on the node and the resources required f"
  },
  "2589": {
    "source_file": "nodes.txt",
    "text": "\nDetermine the correct number of executors per build node must be determined based on the resources available on the node and the resources required for the workload.\nWhen determining how many executors to run on a node, consider CPU and memory requirements, as well as the amount of I/O and network activity:\n* One executor per node is the safest configuration.\n* One executor per CPU core can work "
  },
  "2590": {
    "source_file": "nodes.txt",
    "text": "rements, as well as the amount of I/O and network activity:\n* One executor per node is the safest configuration.\n* One executor per CPU core can work well, if the tasks running are small.\n* Monitor I/O performance, CPU load, memory usage, and I/O throughput carefully when running multiple executors on a node.\n\nJenkins agents are the \"workers\" that perform operations requested by the Jenkins contro"
  },
  "2591": {
    "source_file": "nodes.txt",
    "text": "oughput carefully when running multiple executors on a node.\n\nJenkins agents are the \"workers\" that perform operations requested by the Jenkins controller.\nThe Jenkins controller administers the agents and can manage the tooling on the agents.\nJenkins agents may be statically allocated or they can be dynamically allocated through systems like Kubernetes, OpenShift, Amazon EC2, Azure, Google Cloud,"
  },
  "2592": {
    "source_file": "nodes.txt",
    "text": "s agents may be statically allocated or they can be dynamically allocated through systems like Kubernetes, OpenShift, Amazon EC2, Azure, Google Cloud, IBM Cloud, Oracle Cloud, and other cloud providers.\n\nThis 30 minute tutorial from Darin Pope creates a Jenkins agent and connects it to a controller.\n\n.How to create an agent node in Jenkins\nvideo::99DddJiH7lM[youtube, width=640, height=360]\n\nIf you"
  },
  "2593": {
    "source_file": "nodes.txt",
    "text": "s a Jenkins agent and connects it to a controller.\n\n.How to create an agent node in Jenkins\nvideo::99DddJiH7lM[youtube, width=640, height=360]\n\nIf you are having trouble getting the inbound agent installed as a Windows service (i.e., you followed https://wiki.jenkins.io/display/JENKINS/Installing+Jenkins+as+a+Windows+service[the instructions on installing the agent as a service here] but it didn't"
  },
  "2594": {
    "source_file": "nodes.txt",
    "text": "ps://wiki.jenkins.io/display/JENKINS/Installing+Jenkins+as+a+Windows+service[the instructions on installing the agent as a service here] but it didn't work), an alternative method of starting the service automatically when Windows starts is to use the Windows Scheduler.\u00a0\n\nWe take advantage of the Windows Scheduler's ability to run command at system startup\n\nConfigure your node to use the \"Launch a"
  },
  "2595": {
    "source_file": "nodes.txt",
    "text": "e Windows Scheduler.\u00a0\n\nWe take advantage of the Windows Scheduler's ability to run command at system startup\n\nConfigure your node to use the \"Launch agents by connecting it to the master\" launch method\n* Click Save\nNote the command required to launch the agent\n* On the new agent node's Jenkins page, note the agent command line shown.\u00a0\n** It will be like:\n\njava \\\n    -jar agent.jar \\\n    -url <Jenk"
  },
  "2596": {
    "source_file": "nodes.txt",
    "text": " the agent\n* On the new agent node's Jenkins page, note the agent command line shown.\u00a0\n** It will be like:\n\njava \\\n    -jar agent.jar \\\n    -url <Jenkins URL> \\\n    -secret <secret key> \\\n    -name <agent name>\n\nObtain the agent.jar file and copy it to your new Windows agent node\n* In the command line noted in the last step, the \"agent.jar\" is a hyperlink. Click it to download the agent.jar file.\n"
  },
  "2597": {
    "source_file": "nodes.txt",
    "text": "to your new Windows agent node\n* In the command line noted in the last step, the \"agent.jar\" is a hyperlink. Click it to download the agent.jar file.\n* Copy the agent.jar file to a permanent location on your agent machine\nEnsure that you have a java version available on your agent machine\n* If not, obtain and install a  of Java\nRun the command manually from a CMD window on your agent to confirm th"
  },
  "2598": {
    "source_file": "nodes.txt",
    "text": "version available on your agent machine\n* If not, obtain and install a  of Java\nRun the command manually from a CMD window on your agent to confirm that it works\n* Open the CMD window\n* Run the command the one like\n\njava \\\n    -jar agent.jar \\\n    -url <Jenkins URL> \\\n    -secret <secret key> \\\n    -name <agent name>\n\n* Go back to the node's web page in Jenkins.\u00a0 If everything works then page shou"
  },
  "2599": {
    "source_file": "nodes.txt",
    "text": "rl <Jenkins URL> \\\n    -secret <secret key> \\\n    -name <agent name>\n\n* Go back to the node's web page in Jenkins.\u00a0 If everything works then page should say \"Agent is connected\"\n* Stop the command (control-c)\nRegister a new scheduled job to run the same command\n* Open \"Task Scheduler\" on your windows machine\n** Start -> Run: task Scheduler\n* Create a basic task (Menu: Action -> Create Basic Task)\n"
  },
  "2600": {
    "source_file": "nodes.txt",
    "text": "ame command\n* Open \"Task Scheduler\" on your windows machine\n** Start -> Run: task Scheduler\n* Create a basic task (Menu: Action -> Create Basic Task)\n** First page of the wizard:\n*** Name: Jenkins Agent\n*** Description (optional)\n*** Click Next\n** Next page of the wizard\n*** When do you want the task to start: select \"When the computer starts\"\n*** Click Next\n** Next page of the wizard\n*** What act"
  },
  "2601": {
    "source_file": "nodes.txt",
    "text": "xt page of the wizard\n*** When do you want the task to start: select \"When the computer starts\"\n*** Click Next\n** Next page of the wizard\n*** What action do you want the task to perform: select \"Start a program\"\n*** Click Next\n** Next page of the wizard\n*** Program/Script: enter \"java.exe\" (or the full path to your java.exe)\n*** Add arguments: enter the rest of the command, like\n\njava\n    -jar age"
  },
  "2602": {
    "source_file": "nodes.txt",
    "text": "ard\n*** Program/Script: enter \"java.exe\" (or the full path to your java.exe)\n*** Add arguments: enter the rest of the command, like\n\njava\n    -jar agent.jar \\\n    -url <Jenkins URL> \\\n    -secret <secret key> \\\n    -name <agent name>\n\n*** eg:\n\njava \\\n    -jar D:\\Scripts\\jenkins\\agent.jar \\\n    -url http://jenkinshost.example.com \\\n    -secret d6a84df1fc4f45ddc9c6ab34b08f13391983ffffffffffb3488b7d5"
  },
  "2603": {
    "source_file": "nodes.txt",
    "text": "\n    -jar D:\\Scripts\\jenkins\\agent.jar \\\n    -url http://jenkinshost.example.com \\\n    -secret d6a84df1fc4f45ddc9c6ab34b08f13391983ffffffffffb3488b7d5ac77fbc7 \\\n    -name buildNode1\n\n*** Click Next\n** Next page of the wizard\n*** Click the check box \"Open the Properties dialog for this task when I click Finish\n*** Click Finish\n* Update the task's properties\n** On the General tab\n*** Select the user"
  },
  "2604": {
    "source_file": "nodes.txt",
    "text": "Open the Properties dialog for this task when I click Finish\n*** Click Finish\n* Update the task's properties\n** On the General tab\n*** Select the user to run the task as\n*** Select \"Run whether user is logged on or not\"\n** On the settings tab\n*** Uncheck \"Stop the task if it runs longer than\"\n*** Check \"Run the task as soon as possible after a scheduled start is missed\"\n*** Check \"If the task fail"
  },
  "2605": {
    "source_file": "nodes.txt",
    "text": "heck \"Stop the task if it runs longer than\"\n*** Check \"Run the task as soon as possible after a scheduled start is missed\"\n*** Check \"If the task failed, restart every: 10 minutes\", and \"Attempt to restart up to: 3 times\"\n** Click OK\nStart the scheduled task and again check that the agent is connected\n* Go back to the node's web page in Jenkins.\u00a0 If everything works then page should say \"Agent is "
  },
  "2606": {
    "source_file": "nodes.txt",
    "text": "led task and again check that the agent is connected\n* Go back to the node's web page in Jenkins.\u00a0 If everything works then page should say \"Agent is connected\"\n\nYou can install a Jenkins agent on Windows using the command line.\nIn this video, Darin reviews setting up and installing the Jenkins agent, including how to create any necessary files.\n\n.How to install a Jenkins agent on Windows\nvideo::N"
  },
  "2607": {
    "source_file": "nodes.txt",
    "text": "reviews setting up and installing the Jenkins agent, including how to create any necessary files.\n\n.How to install a Jenkins agent on Windows\nvideo::N8AQTlHoBKc[youtube,width=800,height=420]\n\nThis video reviews the process of creating a macOS agent for Jenkins using Java 11.\n\nvideo::DteE1Zf8CIw[youtube,width=800,height=420]"
  },
  "2608": {
    "source_file": "nodes.txt",
    "text": "or Jenkins using Java 11.\n\nvideo::DteE1Zf8CIw[youtube,width=800,height=420]"
  },
  "2609": {
    "source_file": "obtaining-a-thread-dump.txt",
    "text": "layout: section\n\n\nifdef::env-github[:imagesdir: ../resources]\nifndef::env-github[:imagesdir: ../../resources]\n\nDuring the troubleshooting of Jenkins, others may request that you obtain\nthread dumps of relevant Java VMs.\nThread dumps concisely capture what every thread in a VM is doing at a given point in time.\nThey are useful to diagnose hang problems, deadlocks, and performance issues.\nThis page "
  },
  "2610": {
    "source_file": "obtaining-a-thread-dump.txt",
    "text": " what every thread in a VM is doing at a given point in time.\nThey are useful to diagnose hang problems, deadlocks, and performance issues.\nThis page explains how you can obtain a thread dump.\n\n[[Obtainingathreaddump-FromJenkinsWebUI]]\n\nThis is the simplest way of obtaining thread dumps.\n\nIf Jenkins or its build agents are operating normally, you can obtain a\nthread dump remotely by going to\n`+htt"
  },
  "2611": {
    "source_file": "obtaining-a-thread-dump.txt",
    "text": "implest way of obtaining thread dumps.\n\nIf Jenkins or its build agents are operating normally, you can obtain a\nthread dump remotely by going to\n`+http://your.jenkins.server/threadDump+`.\nFor an agent named 'xyz', go to `+http://your.jenkins.server/computer/xyz/systemInfo+`.\nYou need to have the administrator permission on the system.\n\n[[Obtainingathreaddump-Byusingjstack]]\n\nIf Jenkins is not resp"
  },
  "2612": {
    "source_file": "obtaining-a-thread-dump.txt",
    "text": "omputer/xyz/systemInfo+`.\nYou need to have the administrator permission on the system.\n\n[[Obtainingathreaddump-Byusingjstack]]\n\nIf Jenkins is not responding to web UI, try\nhttps://docs.oracle.com/javase/8/docs/technotes/guides/troubleshoot/tooldescr016.html[jstack]\nto obtain the thread dump.\nYou might have to add -F to get the dump.\nIf that was the case, please mention that in the report as well.\n"
  },
  "2613": {
    "source_file": "obtaining-a-thread-dump.txt",
    "text": "16.html[jstack]\nto obtain the thread dump.\nYou might have to add -F to get the dump.\nIf that was the case, please mention that in the report as well.\n\nMake sure to run jstack as the same user that's running Jenkins itself\ninstead of using the root user.\n\n[[Obtainingathreaddump-Bysendingsignal]]\n\nIf the above two approaches do not work, you can still have the JVM\nprint the thread dump to its stdout"
  },
  "2614": {
    "source_file": "obtaining-a-thread-dump.txt",
    "text": "er.\n\n[[Obtainingathreaddump-Bysendingsignal]]\n\nIf the above two approaches do not work, you can still have the JVM\nprint the thread dump to its stdout by sending it a signal.\n\nIf you have a terminal or command prompt that's running the JVM, you can\nhit Ctrl+ + (Unix) or Ctrl+Break (Windows) to do this.\nIf the JVM is running in background, you do this by `+kill -3 PID+` (Unix) or use\nhttps://docs.o"
  },
  "2615": {
    "source_file": "obtaining-a-thread-dump.txt",
    "text": "it Ctrl+ + (Unix) or Ctrl+Break (Windows) to do this.\nIf the JVM is running in background, you do this by `+kill -3 PID+` (Unix) or use\nhttps://docs.oracle.com/javacomponents/jmc-5-5/jmc-user-guide/toc.htm/[a tool like this] to send a signal (Windows).\n\nYou need to be on the same machine as the Jenkins controller when\nyou run this command.\nIn a situation like this, the standard output of JVM is no"
  },
  "2616": {
    "source_file": "obtaining-a-thread-dump.txt",
    "text": ").\n\nYou need to be on the same machine as the Jenkins controller when\nyou run this command.\nIn a situation like this, the standard output of JVM is normally redirected to a log file,\nso you need to hunt down where it is written to and pick up the dump from there.\nOn Unix, you can look at `+/proc/PID/fd/1+` to figure out which file the stdout is being\nwritten to.\nIf you are running as a Windows ser"
  },
  "2617": {
    "source_file": "obtaining-a-thread-dump.txt",
    "text": "p from there.\nOn Unix, you can look at `+/proc/PID/fd/1+` to figure out which file the stdout is being\nwritten to.\nIf you are running as a Windows service, see the  for the log file location.\n\nThis approach is platform specific, but it tends to be more reliable\neven when JVM is in a dire state."
  },
  "2618": {
    "source_file": "obtaining-a-thread-dump.txt",
    "text": "re reliable\neven when JVM is in a dire state."
  },
  "2619": {
    "source_file": "offline.txt",
    "text": "layout: section\ntitle: Offline Installations\n\n\nifdef::env-github[:imagesdir: ../resources]\nifndef::env-github[:imagesdir: ../../resources]\n\nThis section describes how to install Jenkins on a machine\nthat does not have an internet connection.\n\nTo install Jenkins itself, download the appropriate war file and\ntransfer it to your machine.\n\nOffline plugin installations require additional effort due to "
  },
  "2620": {
    "source_file": "offline.txt",
    "text": "all Jenkins itself, download the appropriate war file and\ntransfer it to your machine.\n\nOffline plugin installations require additional effort due to dependency requirements.\n\nThe  is the recommended tool for offline plugin installation.\nIt downloads user specified plugins and all dependencies of the user specified plugins.\nThe  also reports available plugin updates and plugin security warnings.\nI"
  },
  "2621": {
    "source_file": "offline.txt",
    "text": " user specified plugins and all dependencies of the user specified plugins.\nThe  also reports available plugin updates and plugin security warnings.\nIt is included in the official .\nIt is also used to install plugins as part of the .\nRefer to the  for questions and answers\n\nIf you want to transfer the individual plugins, you'll need to retrieve\nall dependencies as well. There are several dependenc"
  },
  "2622": {
    "source_file": "offline.txt",
    "text": "r questions and answers\n\nIf you want to transfer the individual plugins, you'll need to retrieve\nall dependencies as well. There are several dependency retrieval scripts and tools\non Github. For example:\n\n*  - Java command line utility to install Jenkins plugins and their dependencies.\n*  - Java is\nrequired; packages Jenkins and plugins into an immutable package\ninstaller.  Supported formats inclu"
  },
  "2623": {
    "source_file": "offline.txt",
    "text": "kins plugins and their dependencies.\n*  - Java is\nrequired; packages Jenkins and plugins into an immutable package\ninstaller.  Supported formats include: RPM, DEB, Docker. Can proxy\nJenkins and plugins through Nexus or Artifactory since Gradle is used to\nassemble plugins."
  },
  "2624": {
    "source_file": "offline.txt",
    "text": "d to\nassemble plugins."
  },
  "2625": {
    "source_file": "optional-dependencies.txt",
    "text": "layout: developersection\ntitle: Optional dependencies\n\n\nBy default, dependencies are mandatory \u2014 if any of the dependencies are unavailable then the plugin will be disabled and can not be used.\n\nHowever, this is just the default. It is possible to declare dependencies to other plugins as optional.\nIn this way, even if some of the optional dependencies are unavailable, the plugin will continue to b"
  },
  "2626": {
    "source_file": "optional-dependencies.txt",
    "text": "clare dependencies to other plugins as optional.\nIn this way, even if some of the optional dependencies are unavailable, the plugin will continue to be loaded and executed.\n\nTo declare an optional dependency, add the `<optional/>` tag to the declared dependency in the plugin `pom.xml`.\n\n<dependencies>\n  <dependency>\n    <groupId>org.jvnet.hudson.plugins</groupId>\n    <artifactId>javanet-uploader</"
  },
  "2627": {
    "source_file": "optional-dependencies.txt",
    "text": " dependency in the plugin `pom.xml`.\n\n<dependencies>\n  <dependency>\n    <groupId>org.jvnet.hudson.plugins</groupId>\n    <artifactId>javanet-uploader</artifactId>\n    <version>1.5</version>\n    <optional>true</optional>\n  </dependency>\n</dependencies>\n\nIf any of the classes in the unavailable optional dependencies are used in the plugin a `NoClassDefFoundError` will be thrown.\nIt is still your resp"
  },
  "2628": {
    "source_file": "optional-dependencies.txt",
    "text": "\n\nIf any of the classes in the unavailable optional dependencies are used in the plugin a `NoClassDefFoundError` will be thrown.\nIt is still your responsibility to cope with these errors (although Jenkins itself does some of this handling.\nIf your particular extension fails to load with `LinkageError` because of a missing dependency, it will gracefully disable just that extension and move on to tr"
  },
  "2629": {
    "source_file": "optional-dependencies.txt",
    "text": "rticular extension fails to load with `LinkageError` because of a missing dependency, it will gracefully disable just that extension and move on to try instantiating other extensions.\n\nYou can mark your extension as an optional extension by changing the `@Extension` annotation to `@Extension(optional = true)` and Jenkins doesn't log any class loading errors when reading it.\n\n@Extension(optional = "
  },
  "2630": {
    "source_file": "optional-dependencies.txt",
    "text": "the `@Extension` annotation to `@Extension(optional = true)` and Jenkins doesn't log any class loading errors when reading it.\n\n@Extension(optional = true)\npublic static class YourDescriptor extends Descriptor<YourDescribable> {\n    @Override\n    public String getDisplayName() {\n        return \"YourDisplayName\";\n    }\n}\n\nTo determine if an optional dependency is installed, the Jenkins.getPlugin(St"
  },
  "2631": {
    "source_file": "optional-dependencies.txt",
    "text": "lic String getDisplayName() {\n        return \"YourDisplayName\";\n    }\n}\n\nTo determine if an optional dependency is installed, the Jenkins.getPlugin(String) method can be used.\n\nif (Jenkins.get().getPlugin(\"javanet-uploader\") != null) {\n    // use classes in the \"javanet-uploader\" plugin\n}\n\n## Plugin statuses and behaviors\n\n|===\n| Status | getPlugin(\"dependee\") != null | getPlugin(\"dependee\") .getW"
  },
  "2632": {
    "source_file": "optional-dependencies.txt",
    "text": "sses in the \"javanet-uploader\" plugin\n}\n\n## Plugin statuses and behaviors\n\n|===\n| Status | getPlugin(\"dependee\") != null | getPlugin(\"dependee\") .getWrapper().isEnabled() | Load class from your plugin\n\n| Not installed | false | NPE | Fail\n| Installed without restart | true | true | Succeed\n| Installed without restart before your plugin | true | true | Succeed\n| Installed | true | true | Succeed\n| "
  },
  "2633": {
    "source_file": "optional-dependencies.txt",
    "text": " without restart | true | true | Succeed\n| Installed without restart before your plugin | true | true | Succeed\n| Installed | true | true | Succeed\n| Uninstalled - not restarted | true | true | Succeed\n| Disabled - not restarted | true | false | Succeed\n| Disabled | false | NPE | Fail\n\n|===\n\n## Code causes class loading\n\nWhen your plugin optionally depends on another plugin, you have to access cla"
  },
  "2634": {
    "source_file": "optional-dependencies.txt",
    "text": "eed\n| Disabled | false | NPE | Fail\n\n|===\n\n## Code causes class loading\n\nWhen your plugin optionally depends on another plugin, you have to access classes in the other plugin only when you have checked the plugin is installed.\n\nIn most cases, you can do that by testing the plugin is installed before executing code that accesses optionally loaded plugin classes.\n\nHowever,there are cases when your c"
  },
  "2635": {
    "source_file": "optional-dependencies.txt",
    "text": " do that by testing the plugin is installed before executing code that accesses optionally loaded plugin classes.\n\nHowever,there are cases when your class causes loading of other classes at class instantiation or through reflection calls.\nFor example, `Descriptor#<init>` calls `Class#getMethod(\"getDescriptor\")` and often causes those cases.\n\n### Example case\n\n* dependee-plugin and depender-plugin "
  },
  "2636": {
    "source_file": "optional-dependencies.txt",
    "text": ", `Descriptor#<init>` calls `Class#getMethod(\"getDescriptor\")` and often causes those cases.\n\n### Example case\n\n* dependee-plugin and depender-plugin both depend on base-plugin.\n* depender-plugin optionally depends on dependee-plugin.\n* class Derived in dependee-plugin extends class Base in base-plugin.\n\n## Contained in public method declarations\n\n* Classes in public method declarations will be lo"
  },
  "2637": {
    "source_file": "optional-dependencies.txt",
    "text": " in dependee-plugin extends class Base in base-plugin.\n\n## Contained in public method declarations\n\n* Classes in public method declarations will be loaded.\n* Any of following public method declarations cause Derived to be loaded when SomeClass is instantiated, or someone calls `SomeClass#getMethod` and so on.\nIf dependee-plugin is not installed, it causes `NoClassDefFoundError` even though `doSome"
  },
  "2638": {
    "source_file": "optional-dependencies.txt",
    "text": "tantiated, or someone calls `SomeClass#getMethod` and so on.\nIf dependee-plugin is not installed, it causes `NoClassDefFoundError` even though `doSomething1()` and `doSomething2` are never executed.\n\npublic class SomeClass {\n  // They cause loading Derived even without execution.\n\n  public Derived doSomething1() {\n    // dosomething...\n  }\n\n  public void doSomething2(Derived arg0) {\n    // dosomet"
  },
  "2639": {
    "source_file": "optional-dependencies.txt",
    "text": "erived even without execution.\n\n  public Derived doSomething1() {\n    // dosomething...\n  }\n\n  public void doSomething2(Derived arg0) {\n    // dosomething...\n  }\n}\n\n* It is best to not use classes from optional plugins in method declarations.\n** There might be cases even non-public (protected or private) method declarations cause class loading.\n\n## Upcasting\n\n* If there are codes upcasting to the "
  },
  "2640": {
    "source_file": "optional-dependencies.txt",
    "text": "e might be cases even non-public (protected or private) method declarations cause class loading.\n\n## Upcasting\n\n* If there are codes upcasting to the base class, the derived class will be loaded.\n* Following code cause Derived loaded when `SomeClass` is instantiated, or someone calls `SomeClass#getMethod` and so on. If dependee-plugin is not installed, it causes `NoClassDefFoundError` even though "
  },
  "2641": {
    "source_file": "optional-dependencies.txt",
    "text": " is instantiated, or someone calls `SomeClass#getMethod` and so on. If dependee-plugin is not installed, it causes `NoClassDefFoundError` even though `doSomething()` are never executed.\n\npublic class SomeClass {\n  public void doSomething() {\n    Derived d = getDrived();\n    Base b = (Base)d; // This causes loading Derived even without execution.\n    ...\n  }\n}\n\n* Following code also cause loading `"
  },
  "2642": {
    "source_file": "optional-dependencies.txt",
    "text": "ved d = getDrived();\n    Base b = (Base)d; // This causes loading Derived even without execution.\n    ...\n  }\n}\n\n* Following code also cause loading `Derived`.\n\npublic class SomeClass {\n  public void doSomething() {\n    Derived d = getDrived();\n    doSomethingImpl(d); // This causes loading Derived even without execution.\n    ...\n  }\n\n  private void doSomethingImpl(Base b) {\n    // do something\n  "
  },
  "2643": {
    "source_file": "optional-dependencies.txt",
    "text": "oSomethingImpl(d); // This causes loading Derived even without execution.\n    ...\n  }\n\n  private void doSomethingImpl(Base b) {\n    // do something\n  }\n}\n\n## Upcasting not causing class loading\n\n* Upcasting to `Object` does not cause class loading. Following code does not cause loading `Derived`.\n\npublic class SomeClass {\n  public void doSomething() {\n    Derived d = getDrived();\n    Object b = (O"
  },
  "2644": {
    "source_file": "optional-dependencies.txt",
    "text": "ollowing code does not cause loading `Derived`.\n\npublic class SomeClass {\n  public void doSomething() {\n    Derived d = getDrived();\n    Object b = (Object)d; // This causes loading Derived even without execution.\n    ...\n  }\n}\n\n* Generic types are considered only when compiling, and ignored when execution. Following code does not cause loading `Derived`.\n\npublic class SomeClass {\n  public void do"
  },
  "2645": {
    "source_file": "optional-dependencies.txt",
    "text": "onsidered only when compiling, and ignored when execution. Following code does not cause loading `Derived`.\n\npublic class SomeClass {\n  public void doSomething() {\n    Collection<Derived> dList = getDerivedList();\n    Base b = (Base)dList.get(0);\n  }\n}"
  },
  "2646": {
    "source_file": "optional-dependencies.txt",
    "text": "\n}"
  },
  "2647": {
    "source_file": "other.txt",
    "text": "layout: section\ntitle: Other Systems\n\n\nifdef::env-github[:imagesdir: ../resources]\nifndef::env-github[:imagesdir: ../../resources]\n\n[[other-systems]]\n[[other-operating-systems]]\n\nJenkins can be installed on FreeBSD using the standard FreeBSD package manager, `pkg`.\n\nA  is chosen every 12 weeks from the stream of regular releases as the stable release for that time period.\nIt can be installed from "
  },
  "2648": {
    "source_file": "other.txt",
    "text": "manager, `pkg`.\n\nA  is chosen every 12 weeks from the stream of regular releases as the stable release for that time period.\nIt can be installed from the FreeBSD `pkg` package manager.\n\n# pkg install jenkins-lts\n\n[IMPORTANT]\n\nDisclaimer: The  maintains the Jenkins packaging for FreeBSD.\nThe Jenkins package for FreeBSD is NOT officially supported by the Jenkins project,\nbut it is actively used by t"
  },
  "2649": {
    "source_file": "other.txt",
    "text": "ns the Jenkins packaging for FreeBSD.\nThe Jenkins package for FreeBSD is NOT officially supported by the Jenkins project,\nbut it is actively used by the  at https://ci.freebsd.org/ .\n\nA new release is produced weekly to deliver bug fixes and features to users and plugin developers.\nIt can be installed from the FreeBSD `pkg` package manager.\n\n# pkg install jenkins\n\nThe long term support package `je"
  },
  "2650": {
    "source_file": "other.txt",
    "text": " to users and plugin developers.\nIt can be installed from the FreeBSD `pkg` package manager.\n\n# pkg install jenkins\n\nThe long term support package `jenkins-lts` and the weekly package installation `jenkins` will:\n\n* Configure Jenkins as a daemon which may optionally be launched on start. See `/etc/rc.conf` for more details\n* Create a '`jenkins`' user to run the service\n* Direct console log output "
  },
  "2651": {
    "source_file": "other.txt",
    "text": "h may optionally be launched on start. See `/etc/rc.conf` for more details\n* Create a '`jenkins`' user to run the service\n* Direct console log output to the file `/var/log/jenkins.log`. Check this file when troubleshooting Jenkins\n* Set Jenkins to listen on port 8180 from the path `/jenkins`.  Open http://localhost:8180/jenkins to login to Jenkins\n\nYou can start the Jenkins service with the comman"
  },
  "2652": {
    "source_file": "other.txt",
    "text": "sten on port 8180 from the path `/jenkins`.  Open http://localhost:8180/jenkins to login to Jenkins\n\nYou can start the Jenkins service with the command:\n\n# service jenkins onestart\n\nYou can check the status of the Jenkins service using the command:\n\n# service jenkins status\n\nYou can stop the Jenkins service with the command:\n\n# service jenkins stop\n\nAdd the following to `/etc/rc.conf` to start Jen"
  },
  "2653": {
    "source_file": "other.txt",
    "text": "# service jenkins status\n\nYou can stop the Jenkins service with the command:\n\n# service jenkins stop\n\nAdd the following to `/etc/rc.conf` to start Jenkins automatically on system boot:\n\njenkins_enable=\"YES\"\n\nOnce Jenkins is enabled, it can be started with:\n\n# service jenkins start\n\nOther configuration values that can be set in `/etc/rc.conf` or in `/etc/rc.conf.d/jenkins` are described in `/usr/lo"
  },
  "2654": {
    "source_file": "other.txt",
    "text": " with:\n\n# service jenkins start\n\nOther configuration values that can be set in `/etc/rc.conf` or in `/etc/rc.conf.d/jenkins` are described in `/usr/local/etc/rc.d/jenkins`.\nRefer to the  on the  for more information specific to Jenkins on FreeBSD.\n\nOn a system running\nJenkins can be installed in either the local or global zone using the\n (IPS).\n\n[IMPORTANT]\n\nDisclaimer: This platform is NOT offici"
  },
  "2655": {
    "source_file": "other.txt",
    "text": "n a system running\nJenkins can be installed in either the local or global zone using the\n (IPS).\n\n[IMPORTANT]\n\nDisclaimer: This platform is NOT officially supported by the Jenkins team,\nuse it at your own risk. Packaging and integration described in this section\nis maintained by the OpenIndiana Hipster team, bundling the generic `jenkins.war`\nto work in that operating environment.\n\nFor the common "
  },
  "2656": {
    "source_file": "other.txt",
    "text": "this section\nis maintained by the OpenIndiana Hipster team, bundling the generic `jenkins.war`\nto work in that operating environment.\n\nFor the common case of running the newest packaged weekly build as a standalone (Jetty) server, simply execute:\n\npkg install jenkins\nsvcadm enable jenkins\n\nThe common packaging integration for a standalone service will:\n\n* Create a `jenkins` user to run the service"
  },
  "2657": {
    "source_file": "other.txt",
    "text": "g install jenkins\nsvcadm enable jenkins\n\nThe common packaging integration for a standalone service will:\n\n* Create a `jenkins` user to run the service and to own the directory structures under `/var/lib/jenkins`.\n* Pull the Java package and other packages required to execute Jenkins, including\n  the `jenkins-core-weekly` package with the latest `jenkins.war`.\n* Set up Jenkins as an SMF service ins"
  },
  "2658": {
    "source_file": "other.txt",
    "text": "kages required to execute Jenkins, including\n  the `jenkins-core-weekly` package with the latest `jenkins.war`.\n* Set up Jenkins as an SMF service instance (`svc:/network/http:jenkins`) which\n  can then be enabled with the `svcadm` command demonstrated above.\n* Set up Jenkins to listen on port 8080.\n* Configure the log output to be managed by SMF at `/var/svc/log/network-http:jenkins.log`.\n\nOnce J"
  },
  "2659": {
    "source_file": "other.txt",
    "text": "ed above.\n* Set up Jenkins to listen on port 8080.\n* Configure the log output to be managed by SMF at `/var/svc/log/network-http:jenkins.log`.\n\nOnce Jenkins is running, consult the log\n(`/var/svc/log/network-http:jenkins.log`) to retrieve the generated\nadministrator password for the initial set up of Jenkins, usually it will be\nfound at `/var/lib/jenkins/home/secrets/initialAdminPassword`. Then na"
  },
  "2660": {
    "source_file": "other.txt",
    "text": "ed\nadministrator password for the initial set up of Jenkins, usually it will be\nfound at `/var/lib/jenkins/home/secrets/initialAdminPassword`. Then navigate to\n to <<setup-wizard, complete configuration of the\nJenkins controller>>.\n\nTo change attributes of the service, such as environment variables like `JENKINS_HOME`\nor the port number used for the Jetty web server, use the `svccfg` utility:\n\nsvc"
  },
  "2661": {
    "source_file": "other.txt",
    "text": "tes of the service, such as environment variables like `JENKINS_HOME`\nor the port number used for the Jetty web server, use the `svccfg` utility:\n\nsvccfg -s svc:/network/http:jenkins editprop\nsvcadm refresh svc:/network/http:jenkins\n\nYou can also refer to `/lib/svc/manifest/network/jenkins-standalone.xml` for more\ndetails and comments about currently supported tunables of the SMF service.\nNote tha"
  },
  "2662": {
    "source_file": "other.txt",
    "text": "er to `/lib/svc/manifest/network/jenkins-standalone.xml` for more\ndetails and comments about currently supported tunables of the SMF service.\nNote that the `jenkins` user account created by the packaging is specially privileged\nto allow binding to port numbers under 1024.\n\nThe current status of Jenkins-related packages available for the given release\nof OpenIndiana can be queried with:\n\npkg info -"
  },
  "2663": {
    "source_file": "other.txt",
    "text": "rt numbers under 1024.\n\nThe current status of Jenkins-related packages available for the given release\nof OpenIndiana can be queried with:\n\npkg info -r '*jenkins*'\n\nUpgrades to the package can be performed by updating the entire operating\nenvironment with `pkg update`, or specifically for Jenkins core software with:\n\npkg update jenkins-core-weekly\n\n[CAUTION]\n\nProcedure for updating the package wil"
  },
  "2664": {
    "source_file": "other.txt",
    "text": " with `pkg update`, or specifically for Jenkins core software with:\n\npkg update jenkins-core-weekly\n\n[CAUTION]\n\nProcedure for updating the package will restart the currently running Jenkins\nprocess. Make sure to prepare it for shutdown and finish all running jobs\nbefore updating, if needed.\n\nGenerally it should suffice to install a ,  the\n`jenkins.war`, and run it as a standalone process.\n\nSome ca"
  },
  "2665": {
    "source_file": "other.txt",
    "text": " running jobs\nbefore updating, if needed.\n\nGenerally it should suffice to install a ,  the\n`jenkins.war`, and run it as a standalone process.\n\nSome caveats apply:\n\n* Headless JVM and fonts: For OpenJDK builds on minimalized-footprint systems,\n  there may be\n  , because Jenkins needs some fonts to render certain\n  pages."
  },
  "2666": {
    "source_file": "other.txt",
    "text": " may be\n  , because Jenkins needs some fonts to render certain\n  pages."
  },
  "2667": {
    "source_file": "overview.txt",
    "text": "layout: redirect\nredirect_url: '/doc/book/pipeline/getting-started'"
  },
  "2668": {
    "source_file": "permissions.txt",
    "text": "title: Permissions\nlayout: documentation\n\n\nThe following sections describe the access granted to users with (or without) the specified permissions.\n\nThese permissions are granted globally, rather than on individual objects.\n\nWhile Overall/Read is a prerequisite for more extensive access to Jenkins, some features are available without it.\n\n// ALWAYS_READABLE_PATHS in https://github.com/jenkinsci/je"
  },
  "2669": {
    "source_file": "permissions.txt",
    "text": "rerequisite for more extensive access to Jenkins, some features are available without it.\n\n// ALWAYS_READABLE_PATHS in https://github.com/jenkinsci/jenkins/blob/master/core/src/main/java/jenkins/model/Jenkins.java\n\n* Very basic UI, like the login form, the account signup form (if using the Jenkins user database as security realm), and some error pages (\"Oops!\").\n* Access to URLs provided by the se"
  },
  "2670": {
    "source_file": "permissions.txt",
    "text": "m, the account signup form (if using the Jenkins user database as security realm), and some error pages (\"Oops!\").\n* Access to URLs provided by the security realm (to implement user signup or handle SSO authentication) (`/securityRealm/`).\n* `agent.jar`, `remoting.jar`, and `jenkins-cli.jar` files (plus deprecated aliases) to easily download client packages matching the running version of Jenkins "
  },
  "2671": {
    "source_file": "permissions.txt",
    "text": "ar`, `remoting.jar`, and `jenkins-cli.jar` files (plus deprecated aliases) to easily download client packages matching the running version of Jenkins (`/jnlpJars/`).\n* Agent JNLP files (`/computer/.../jenkins-agent.jnlp?encrypted=true` plus deprecated alias) to connect inbound agents to Jenkins.\n* Access to the TCP agent listener endpoint used by agents connecting to Jenkins via the agent TCP port"
  },
  "2672": {
    "source_file": "permissions.txt",
    "text": "d alias) to connect inbound agents to Jenkins.\n* Access to the TCP agent listener endpoint used by agents connecting to Jenkins via the agent TCP port (`/tcpSlaveAgentListener/`).\n* Access to some static resources (JS, CSS, and image files) bundled with Jenkins and Jenkins plugins (`/adjuncts/`).\n\nAdditionally, both Jenkins and any plugin may implement an extension point to make URLs available wit"
  },
  "2673": {
    "source_file": "permissions.txt",
    "text": "ith Jenkins and Jenkins plugins (`/adjuncts/`).\n\nAdditionally, both Jenkins and any plugin may implement an extension point to make URLs available without authentication.\nSCM plugins commonly do this to let SCM features like post-commit hooks inform Jenkins about new commits, causing jobs to poll for changes.\n\n// https://github.com/jenkinsci/jenkins/blob/master/core/src/main/java/hudson/model/Unpr"
  },
  "2674": {
    "source_file": "permissions.txt",
    "text": "Jenkins about new commits, causing jobs to poll for changes.\n\n// https://github.com/jenkinsci/jenkins/blob/master/core/src/main/java/hudson/model/UnprotectedRootAction.java\n\nAs of Jenkins 2.290, the following extensions are provided as part of Jenkins (core):\n\n* `/assets/` provides access to further static resources.\n* `/cli/` handles CLI connections.\n  CLI documentation is also available here, bu"
  },
  "2675": {
    "source_file": "permissions.txt",
    "text": "s (core):\n\n* `/assets/` provides access to further static resources.\n* `/cli/` handles CLI connections.\n  CLI documentation is also available here, but those pages are individually protected.\n* The `/whoAmI/` URL allows determining who the current user is.\n  It is available to users without permissions to troubleshoot permissions issues.\n* `/wsagents/` handles agent connections using web sockets.\n"
  },
  "2676": {
    "source_file": "permissions.txt",
    "text": "er is.\n  It is available to users without permissions to troubleshoot permissions issues.\n* `/wsagents/` handles agent connections using web sockets.\n* `/instance-identity/` provides a public key that allows identifying the Jenkins instance and setting up secure communication with it.\n  See https://github.com/jenkinsci/instance-identity-plugin[the component documentation] for details.\n* `/static-f"
  },
  "2677": {
    "source_file": "permissions.txt",
    "text": "ng up secure communication with it.\n  See https://github.com/jenkinsci/instance-identity-plugin[the component documentation] for details.\n* `/static-files/` is used to implement the Resource Root URL feature serving user-provided contents from another domain.\n  See .\n// TODO: This link isn't quite correct yet, because this feature is barely covered, will be fixed in the future.\n\nA list of all thes"
  },
  "2678": {
    "source_file": "permissions.txt",
    "text": "r domain.\n  See .\n// TODO: This link isn't quite correct yet, because this feature is barely covered, will be fixed in the future.\n\nA list of all these extensions is provided on the UI when selecting (but not saving) the _Delegate to Servlet container_ security realm, or can be obtained via the  using:\n\nExtensionList.lookup(UnprotectedRootAction).each {\n  println String.format(\"URL: '%s/' provided"
  },
  "2679": {
    "source_file": "permissions.txt",
    "text": "r_ security realm, or can be obtained via the  using:\n\nExtensionList.lookup(UnprotectedRootAction).each {\n  println String.format(\"URL: '%s/' provided by '%s' in '%s'\", it.urlName, Jenkins.get().pluginManager.whichPlugin(it.class)?.shortName?:\"Jenkins Core\", it.class.name)\n}\nreturn\n\nWhile these extensions opt out of the built-in _Overall/Read_ permission requirements, they are expected to implemen"
  },
  "2680": {
    "source_file": "permissions.txt",
    "text": "s Core\", it.class.name)\n}\nreturn\n\nWhile these extensions opt out of the built-in _Overall/Read_ permission requirements, they are expected to implement permission checks themselves whenever performing actions typically requiring permissions, or to check for the presence of a previously set up token in place of regular authentication.\n\nNOTE: In your HTTP access logs, you may see accesses to URLs st"
  },
  "2681": {
    "source_file": "permissions.txt",
    "text": "eck for the presence of a previously set up token in place of regular authentication.\n\nNOTE: In your HTTP access logs, you may see accesses to URLs starting with `/static/`, followed by a random looking string of letters and numbers.\nThis is part of a caching feature in Jenkins: Requests to these URLs expect cacheable responses, so HTTP response headers with a long expiration time are set.\nThe str"
  },
  "2682": {
    "source_file": "permissions.txt",
    "text": "a caching feature in Jenkins: Requests to these URLs expect cacheable responses, so HTTP response headers with a long expiration time are set.\nThe string following `/static/` is randomly generated once on startup, ensuring that it changes when the Jenkins version (and therefore the contents of cacheable files) changes.\nAny path starting with `/static/.../` can be treated for logging purposes as if"
  },
  "2683": {
    "source_file": "permissions.txt",
    "text": "nkins version (and therefore the contents of cacheable files) changes.\nAny path starting with `/static/.../` can be treated for logging purposes as if this prefix wasn't present.\n\n[#overall-read]\n\nUsers with Overall/Read access are expected to be legitimate users of Jenkins.\n\nIn addition to the above, a user granted _Overall/Read_ can do all of the following:\n\n* Access the basic Jenkins API and th"
  },
  "2684": {
    "source_file": "permissions.txt",
    "text": "itimate users of Jenkins.\n\nIn addition to the above, a user granted _Overall/Read_ can do all of the following:\n\n* Access the basic Jenkins API and the API of any object they have access to.\n* Access the People directory listing user accounts and known committer identities of anyone involved in visible projects (Jenkins 2.451 and earlier).\n* List and view all agents configured in Jenkins and acces"
  },
  "2685": {
    "source_file": "permissions.txt",
    "text": "wn committer identities of anyone involved in visible projects (Jenkins 2.451 and earlier).\n* List and view all agents configured in Jenkins and access their summary pages.\n* Use search to find and access all agents and user accounts, and any other objects the user has been granted access to.\n\nTo support various features available to legitimate users of Jenkins, the following not as obvious URLs a"
  },
  "2686": {
    "source_file": "permissions.txt",
    "text": "bjects the user has been granted access to.\n\nTo support various features available to legitimate users of Jenkins, the following not as obvious URLs are accessible as well:\n\n* Further path prefixes (in addition to `adjuncts/`, `assets/`, and core webapp resources) providing static assets, both by Jenkins core and by plugins.\n  See .\n* Path prefixes providing access to all URLs implemented in exten"
  },
  "2687": {
    "source_file": "permissions.txt",
    "text": "app resources) providing static assets, both by Jenkins core and by plugins.\n  See .\n* Path prefixes providing access to all URLs implemented in extension lists of all extension points implemented in Jenkins.\n  These URLs are typically used to support form validation and form autocompletion, and the way they're organized means that some basic access is granted to any user with _Overall/Read_ acces"
  },
  "2688": {
    "source_file": "permissions.txt",
    "text": "t form validation and form autocompletion, and the way they're organized means that some basic access is granted to any user with _Overall/Read_ access.\n\nWhile the vast majority of URLs in Jenkins are by default protected by an _Overall/Read_ permission check, a lack of individual permission checks in endpoints for form validation and similar actions taken through the UI can result in users with o"
  },
  "2689": {
    "source_file": "permissions.txt",
    "text": "ion check, a lack of individual permission checks in endpoints for form validation and similar actions taken through the UI can result in users with only _Overall/Read_ access to be able to access these actions.\nLack of necessary permission checks constitutes a security vulnerability.\nWhile these are expected to be resolved in a timely manner, this may be worth considering when deciding who to gra"
  },
  "2690": {
    "source_file": "permissions.txt",
    "text": "nstitutes a security vulnerability.\nWhile these are expected to be resolved in a timely manner, this may be worth considering when deciding who to grant _Overall/Read_ permission to.\n\n[#administer]\n\nIn short: **Everything.**\n\nAdministrators can do all of the following:\n\n* Install and upload plugins that can run arbitrary code.\n* Use the Script Console both on the Jenkins controller and on individu"
  },
  "2691": {
    "source_file": "permissions.txt",
    "text": "l of the following:\n\n* Install and upload plugins that can run arbitrary code.\n* Use the Script Console both on the Jenkins controller and on individual agents, running arbitrary code in the Jenkins controller and agent processes.\n* Use the Script Console (or configure jobs) to run arbitrary shell scripts on the Jenkins controller or any connected agent.\n\nThere are no limits to what users with _Ov"
  },
  "2692": {
    "source_file": "permissions.txt",
    "text": "nsole (or configure jobs) to run arbitrary shell scripts on the Jenkins controller or any connected agent.\n\nThere are no limits to what users with _Overall/Administer_ permission can do in Jenkins.\nAnything they cannot accomplish through the existing UI they can do through the Script Console or by installing a plugin that does it.\n\nAn instance on which an untrusted user gained _Overall/Administer_"
  },
  "2693": {
    "source_file": "permissions.txt",
    "text": " UI they can do through the Script Console or by installing a plugin that does it.\n\nAn instance on which an untrusted user gained _Overall/Administer_ permission should be considered fully compromised and should be replaced.\nAll secrets (credentials, etc.) stored on that instance should be rotated or revoked and all artifacts created from that point on should be verified.\n\nAgent/Build::\nThis permi"
  },
  "2694": {
    "source_file": "permissions.txt",
    "text": " etc.) stored on that instance should be rotated or revoked and all artifacts created from that point on should be verified.\n\nAgent/Build::\nThis permission allows users to run jobs as them on agents.\nIn default setup where all builds run under SYSTEM user this permission is not relevant,\nbut if  is active this permission defines which users may run jobs on agents.\n\nAgent/Configure::\nThis permissio"
  },
  "2695": {
    "source_file": "permissions.txt",
    "text": " user this permission is not relevant,\nbut if  is active this permission defines which users may run jobs on agents.\n\nAgent/Configure::\nThis permission allows users to configure agents.\nUsers with this permission can make all jobs run on a computer where they have root access,\ngaining access to all information used by the build (content of files, environment variables including credentials).\n\nAgen"
  },
  "2696": {
    "source_file": "permissions.txt",
    "text": "here they have root access,\ngaining access to all information used by the build (content of files, environment variables including credentials).\n\nAgent/Connect::\nThis permission allows users to connect agents or mark agents as online.\nThis permission is implied by _Agent/Disconnect_.\n\nAgent/Create::\nThis permission allows users to create agents. Security implications are the same as for _Agent/Con"
  },
  "2697": {
    "source_file": "permissions.txt",
    "text": " is implied by _Agent/Disconnect_.\n\nAgent/Create::\nThis permission allows users to create agents. Security implications are the same as for _Agent/Configure_.\n\nAgent/Delete::\nThis permission allows users to delete existing agents.\n\nAgent/Disconnect::\nThis permission allows users to disconnect agents or mark agents as temporarily offline.\n\nThough these permissions use the word \"Job\" in their name,\n"
  },
  "2698": {
    "source_file": "permissions.txt",
    "text": "\nThis permission allows users to disconnect agents or mark agents as temporarily offline.\n\nThough these permissions use the word \"Job\" in their name,\nthey refer to any items you can create using the _New Item_ menu option (freestyle jobs, folders, pipelines, ...)\n\nJob/Build::\nThis permission grants the ability to start a new build.\n\nJob/Cancel::\nThis permission grants the ability to cancel a sched"
  },
  "2699": {
    "source_file": "permissions.txt",
    "text": "pelines, ...)\n\nJob/Build::\nThis permission grants the ability to start a new build.\n\nJob/Cancel::\nThis permission grants the ability to cancel a scheduled, or abort a running, build.\n\nJob/Configure::\nChange the configuration of a job.\n\nJob/Create::\nCreate a new job.\n\nJob/Delete::\nDelete a job.\n\nJob/Discover::\nThis permission grants discover access to jobs.\nLower than read permissions, it allows yo"
  },
  "2700": {
    "source_file": "permissions.txt",
    "text": "reate a new job.\n\nJob/Delete::\nDelete a job.\n\nJob/Discover::\nThis permission grants discover access to jobs.\nLower than read permissions, it allows you to redirect anonymous users to the login page when they try to access a job url.\nWithout it they would get a 404 error and wouldn't be able to discover project names.\nThis permission is only useful if anonymous users have _Overall/Read_ permission,"
  },
  "2701": {
    "source_file": "permissions.txt",
    "text": "ould get a 404 error and wouldn't be able to discover project names.\nThis permission is only useful if anonymous users have _Overall/Read_ permission, but not _Job/Read_.\nIt is implied by _Job/Read_.\n\nJob/Move::\nRequired to move a job from one folder (or Jenkins root) to another.\n\nJob/Read::\nSee a job. (You may deny this permission but allow Discover to force an anonymous user to log in to see the"
  },
  "2702": {
    "source_file": "permissions.txt",
    "text": " (or Jenkins root) to another.\n\nJob/Read::\nSee a job. (You may deny this permission but allow Discover to force an anonymous user to log in to see the job.)\n\nJob/Workspace::\nThis permission grants the ability to retrieve the contents of a workspace Jenkins checked out for performing builds.\nIf you don\u2019t want a user to access files in the workspace (e.g. source code checked out from SCM or intermed"
  },
  "2703": {
    "source_file": "permissions.txt",
    "text": "enkins checked out for performing builds.\nIf you don\u2019t want a user to access files in the workspace (e.g. source code checked out from SCM or intermediate build results) through the workspace browser, you can revoke this permission.\n\nRun/Delete::\nThis permission allows users to manually delete specific builds from the build history.\n\nRun/Update::\nThis permission allows users to update description "
  },
  "2704": {
    "source_file": "permissions.txt",
    "text": "s permission allows users to manually delete specific builds from the build history.\n\nRun/Update::\nThis permission allows users to update description and other properties of a build, for example to leave notes about the cause of a build failure.\n\nView/Configure::\nThis permission allows users to change the configuration of views.\n\nView/Create::\nThis permission allows users to create new views.\n\nVie"
  },
  "2705": {
    "source_file": "permissions.txt",
    "text": "w/Configure::\nThis permission allows users to change the configuration of views.\n\nView/Create::\nThis permission allows users to create new views.\n\nView/Delete::\nThis permission allows users to delete existing views.\n\nView/Read::\nThis permission allows users to see views (implied by generic read access).\n\nFollowing permissions are only enabled if the plugin:credentials[Credentials Plugin] is instal"
  },
  "2706": {
    "source_file": "permissions.txt",
    "text": "s users to see views (implied by generic read access).\n\nFollowing permissions are only enabled if the plugin:credentials[Credentials Plugin] is installed\n\nCredentials/Create::\nThe create permission is necessary to add credentials to a credentials provider.\n\nCredentials/Delete::\nThe delete permission is necessary to remove credentials stored in a credentials provider.\n\nCredentials/ManageDomains::\nT"
  },
  "2707": {
    "source_file": "permissions.txt",
    "text": "vider.\n\nCredentials/Delete::\nThe delete permission is necessary to remove credentials stored in a credentials provider.\n\nCredentials/ManageDomains::\nThe manage domains permission is necessary to add/remove/configure the credential domains of a credentials provider (where the credentials provider supports multiple credential domains).\n\nCredentials/Update::\nThe update permission is necessary to modi"
  },
  "2708": {
    "source_file": "permissions.txt",
    "text": "tials provider (where the credentials provider supports multiple credential domains).\n\nCredentials/Update::\nThe update permission is necessary to modify credentials in a credentials provider.\n\nCredentials/View::\nThe view permission is necessary to view the credentials stored in a credentials provider.\n\nRun/Replay::\nAbility to perform a new Pipeline build with an edited script. This permission is i"
  },
  "2709": {
    "source_file": "permissions.txt",
    "text": "ew the credentials stored in a credentials provider.\n\nRun/Replay::\nAbility to perform a new Pipeline build with an edited script. This permission is implied by Job/Configure.\nThis permission is enabled by plugin:workflow-cps[Pipeline: Groovy].\n\nThese permissions are not enabled by default.\n\nThis permission grants read-only access to the Jenkins global configuration.\nIts primarily intended to be us"
  },
  "2710": {
    "source_file": "permissions.txt",
    "text": " permissions are not enabled by default.\n\nThis permission grants read-only access to the Jenkins global configuration.\nIts primarily intended to be used when the Jenkins configuration is managed externally, e.g. using the plugin:configuration-as-code/[Configuration as Code] plugin.\nIt works best when combined with the _ExtendedRead_ permission that allows read-only access to agents and items.\n\nThi"
  },
  "2711": {
    "source_file": "permissions.txt",
    "text": "/[Configuration as Code] plugin.\nIt works best when combined with the _ExtendedRead_ permission that allows read-only access to agents and items.\n\nThis permission can be enabled by setting  or installing the plugin:extended-read-permission[Extended Read Permission] plugin.\n\nLearn more in jep:224[].\n\nNOTE: This permission was added in Jenkins 2.222.\nSome features, especially those provided by plugi"
  },
  "2712": {
    "source_file": "permissions.txt",
    "text": "ead Permission] plugin.\n\nLearn more in jep:224[].\n\nNOTE: This permission was added in Jenkins 2.222.\nSome features, especially those provided by plugins, may not yet support this permission.\n\n_Overall/Administer_ (described below) is a very high level of permission:\nBetween administrative tools like the script console and the ability to install plugins, there are no limits to what administrators c"
  },
  "2713": {
    "source_file": "permissions.txt",
    "text": "l of permission:\nBetween administrative tools like the script console and the ability to install plugins, there are no limits to what administrators can do.\n\n_Overall/Manage_ grants permission to access and modify a subset of administrative options.\nUsers with this permission are able to perform some administrative tasks.\nOptions generally considered critical to the security of Jenkins are not ava"
  },
  "2714": {
    "source_file": "permissions.txt",
    "text": "Users with this permission are able to perform some administrative tasks.\nOptions generally considered critical to the security of Jenkins are not available to these users.\n\nThis permission can be enabled by setting  or installing the plugin:manage-permission[Overall/Manage permission enabler] plugin.\n\nLearn more in jep:223[].\n\nNOTE: This permission was added in Jenkins 2.222.\nSome features, espec"
  },
  "2715": {
    "source_file": "permissions.txt",
    "text": "ermission[Overall/Manage permission enabler] plugin.\n\nLearn more in jep:223[].\n\nNOTE: This permission was added in Jenkins 2.222.\nSome features, especially those provided by plugins, may not yet support this permission.\n\nThe following three permissions are obsolete since Jenkins 2.222:\n\n* Overall/RunScripts\n* Overall/UploadPlugins\n* Overall/ManageUpdateSites\n\nThese permissions were intended for us"
  },
  "2716": {
    "source_file": "permissions.txt",
    "text": "ns are obsolete since Jenkins 2.222:\n\n* Overall/RunScripts\n* Overall/UploadPlugins\n* Overall/ManageUpdateSites\n\nThese permissions were intended for use in an externally managed, hosted Jenkins environment.\nThey would allow a user to directly (through the script console) or indirectly (through plugin installation) execute code they control.\nBy default, these permissions were _implied_ by the Overal"
  },
  "2717": {
    "source_file": "permissions.txt",
    "text": " the script console) or indirectly (through plugin installation) execute code they control.\nBy default, these permissions were _implied_ by the Overall/Administer permission by default to not impact more common Jenkins environments, while allowing a hosted environment to have administrators with _Overall/Administer_ permission but not these more sensitive permissions.\n\nThis model has been retired."
  },
  "2718": {
    "source_file": "permissions.txt",
    "text": "hosted environment to have administrators with _Overall/Administer_ permission but not these more sensitive permissions.\n\nThis model has been retired.\nWhile these permissions still exist, they're no longer used by Jenkins core and related features have been removed, e.g., uploading plugins or using the script console just requires Overall/Administer permission now.\n\nFor more fine-grained access to"
  },
  "2719": {
    "source_file": "permissions.txt",
    "text": "ve been removed, e.g., uploading plugins or using the script console just requires Overall/Administer permission now.\n\nFor more fine-grained access to the global configuration, the permissions _Overall/Manage_ and _Overall/SystemRead_ can optionally be enabled."
  },
  "2720": {
    "source_file": "permissions.txt",
    "text": "be enabled."
  },
  "2721": {
    "source_file": "pipeline-as-code.txt",
    "text": "layout: documentation\nsection: doc\n\n\n_Pipeline as Code_ describes a set of features that allow Jenkins users to define pipelined job processes with code, stored and versioned in a source repository.\nThese features allow Jenkins to discover, manage, and run jobs for multiple source repositories and branches -- eliminating the need for manual job creation and management.\n\nTo use _Pipeline as Code_, "
  },
  "2722": {
    "source_file": "pipeline-as-code.txt",
    "text": "nd run jobs for multiple source repositories and branches -- eliminating the need for manual job creation and management.\n\nTo use _Pipeline as Code_, projects must contain a file named `Jenkinsfile` in the repository root, which contains a \"Pipeline script.\"\n\nAdditionally, one of the enabling jobs needs to be configured in Jenkins:\n\n* _Multibranch Pipeline_: build multiple branches of a _single_ r"
  },
  "2723": {
    "source_file": "pipeline-as-code.txt",
    "text": "script.\"\n\nAdditionally, one of the enabling jobs needs to be configured in Jenkins:\n\n* _Multibranch Pipeline_: build multiple branches of a _single_ repository automatically\n* _Organization Folders_: scan a *GitHub Organization* or *Bitbucket Team* to discover an organization's repositories, automatically creating managed _Multibranch Pipeline_ jobs for them\n* _Pipeline_: Regular Pipeline jobs hav"
  },
  "2724": {
    "source_file": "pipeline-as-code.txt",
    "text": "o discover an organization's repositories, automatically creating managed _Multibranch Pipeline_ jobs for them\n* _Pipeline_: Regular Pipeline jobs have an option when specifying the pipeline to \"Use SCM\".\n\nFundamentally, an organization's repositories can be viewed as a hierarchy, where each repository may have child elements of branches and pull requests.\n\n.Example Repository Structure\n\n....\n--- "
  },
  "2725": {
    "source_file": "pipeline-as-code.txt",
    "text": "s can be viewed as a hierarchy, where each repository may have child elements of branches and pull requests.\n\n.Example Repository Structure\n\n....\n--- GitHub Organization\n    +--- Project 1\n        +--- master\n        +--- feature-branch-a\n        +--- feature-branch-b\n    +--- Project 2\n        +--- master\n        +--- pull-request-1\n        +--- etc...\n....\n\nPrior to _Multibranch Pipeline_ jobs a"
  },
  "2726": {
    "source_file": "pipeline-as-code.txt",
    "text": "- feature-branch-b\n    +--- Project 2\n        +--- master\n        +--- pull-request-1\n        +--- etc...\n....\n\nPrior to _Multibranch Pipeline_ jobs and _Organization Folders_,\nplugin:cloudbees-folder[Folders]\ncould be used to create this hierarchy in Jenkins by organizing repositories\ninto folders containing jobs for each individual branch.\n\n_Multibranch Pipeline_ and _Organization Folders_ elimi"
  },
  "2727": {
    "source_file": "pipeline-as-code.txt",
    "text": "n Jenkins by organizing repositories\ninto folders containing jobs for each individual branch.\n\n_Multibranch Pipeline_ and _Organization Folders_ eliminate the manual process by detecting branches and repositories, respectively, and creating appropriate folders with jobs in Jenkins automatically.\n\nPresence of the `Jenkinsfile` in the root of a repository makes it eligible for Jenkins to automatical"
  },
  "2728": {
    "source_file": "pipeline-as-code.txt",
    "text": "te folders with jobs in Jenkins automatically.\n\nPresence of the `Jenkinsfile` in the root of a repository makes it eligible for Jenkins to automatically manage and execute jobs based on repository branches.\n\nThe `Jenkinsfile` should contain a Pipeline script, specifying the steps to execute the job.\nThe script has all the power of Pipeline available, from something as simple as invoking a Maven bu"
  },
  "2729": {
    "source_file": "pipeline-as-code.txt",
    "text": "e script, specifying the steps to execute the job.\nThe script has all the power of Pipeline available, from something as simple as invoking a Maven builder, to a series of interdependent steps, which have coordinated parallel execution with deployment and validation phases.\n\nA simple way to get started with Pipeline is to use the _Snippet Generator_ available in the configuration screen for a Jenk"
  },
  "2730": {
    "source_file": "pipeline-as-code.txt",
    "text": "t and validation phases.\n\nA simple way to get started with Pipeline is to use the _Snippet Generator_ available in the configuration screen for a Jenkins _Pipeline_ job.\nUsing the _Snippet Generator_, you can create a Pipeline script as you might through the dropdowns in other Jenkins jobs.\n\n[[folder-computation]]\n\n*Multibranch Pipeline* projects and *GitHub Organization Folders* extend Jenkins' f"
  },
  "2731": {
    "source_file": "pipeline-as-code.txt",
    "text": "ough the dropdowns in other Jenkins jobs.\n\n[[folder-computation]]\n\n*Multibranch Pipeline* projects and *GitHub Organization Folders* extend Jenkins' folder functionality by introducing computed folders, which automatically manage their contents by dynamically creating and updating child items.\nThese features require the plugin:github-branch-source[*GitHub Branch Source*] plugin to be installed, as"
  },
  "2732": {
    "source_file": "pipeline-as-code.txt",
    "text": "namically creating and updating child items.\nThese features require the plugin:github-branch-source[*GitHub Branch Source*] plugin to be installed, as it provides the necessary functionality for managing branches and repositories.\n\n* **Multibranch Pipeline Projects:** The computed folder functionality includes **Scan Multibranch Pipeline Log** and **Scan Multibranch Pipeline Now** options, which d"
  },
  "2733": {
    "source_file": "pipeline-as-code.txt",
    "text": "peline Projects:** The computed folder functionality includes **Scan Multibranch Pipeline Log** and **Scan Multibranch Pipeline Now** options, which dynamically manage pipeline items.\nThese options allow Jenkins to scan repositories, generate child items for eligible branches, and automatically update the pipeline list based on changes.\n\n* **GitHub Organization Projects:** The computed folder func"
  },
  "2734": {
    "source_file": "pipeline-as-code.txt",
    "text": "tems for eligible branches, and automatically update the pipeline list based on changes.\n\n* **GitHub Organization Projects:** The computed folder functionality includes **Scan Organization Log** and **Scan Organization Now** options.\nThis functionality populates repositories as individual Multibranch Pipelines and provides insights into branch and repository scans.\n\nFolder scans can be automatical"
  },
  "2735": {
    "source_file": "pipeline-as-code.txt",
    "text": "ty populates repositories as individual Multibranch Pipelines and provides insights into branch and repository scans.\n\nFolder scans can be automatically triggered through webhook callbacks whenever branches or repositories are created or removed.\nScans can also be configured to run periodically via the **Build Triggers** settings, which default to a re-scan after one day of inactivity.\n\n[role=\"ima"
  },
  "2736": {
    "source_file": "pipeline-as-code.txt",
    "text": "ns can also be configured to run periodically via the **Build Triggers** settings, which default to a re-scan after one day of inactivity.\n\n[role=\"image-border\"]\n\n{empty}\n\nThe log from the last attempt to scan the organization is available in the **Scan Organization Log**.\nIf the scan doesn\u2019t produce the expected set of repositories, the log may contain useful information to help diagnose the issu"
  },
  "2737": {
    "source_file": "pipeline-as-code.txt",
    "text": "can Organization Log**.\nIf the scan doesn\u2019t produce the expected set of repositories, the log may contain useful information to help diagnose the issue.\n\n[role=\"image-border\"]\n\n{empty}\n\nBoth _Multibranch Pipeline_ projects and _Organization Folders_ have configuration options to allow precise selection of repositories.\nThese features also allow selection of two types of credentials to use when con"
  },
  "2738": {
    "source_file": "pipeline-as-code.txt",
    "text": "have configuration options to allow precise selection of repositories.\nThese features also allow selection of two types of credentials to use when connecting to the remote systems:\n\n* _scan_ credentials, which are used for accessing the GitHub or Bitbucket APIs\n* _checkout_ credentials, which are used when the repository is cloned from the remote system; it may be useful to choose an SSH key or _\""
  },
  "2739": {
    "source_file": "pipeline-as-code.txt",
    "text": "bucket APIs\n* _checkout_ credentials, which are used when the repository is cloned from the remote system; it may be useful to choose an SSH key or _\"- anonymous -\"_, which uses the default credentials configured for the OS user\n\nIMPORTANT: If you are using a _GitHub Organization_, you should  to use to avoid storing your password in Jenkins and prevent any issues when using the GitHub API.\nWhen u"
  },
  "2740": {
    "source_file": "pipeline-as-code.txt",
    "text": "e using a _GitHub Organization_, you should  to use to avoid storing your password in Jenkins and prevent any issues when using the GitHub API.\nWhen using a GitHub access token, you must use standard _Username with password_ credentials, where the username is the same as your GitHub username and the password is your access token.\n\n_Multibranch Pipeline_ projects are one of the fundamental enabling"
  },
  "2741": {
    "source_file": "pipeline-as-code.txt",
    "text": "ername is the same as your GitHub username and the password is your access token.\n\n_Multibranch Pipeline_ projects are one of the fundamental enabling features for _Pipeline as Code_.\nChanges to the build or deployment procedure can evolve with project requirements and the job always reflects the current state of the project.\nIt also allows you to configure different jobs for different branches of"
  },
  "2742": {
    "source_file": "pipeline-as-code.txt",
    "text": "ct requirements and the job always reflects the current state of the project.\nIt also allows you to configure different jobs for different branches of the same project, or to forgo a job if appropriate.\nThe `Jenkinsfile` in the root directory of a branch or pull request identifies a multibranch project.\n\nNOTE: _Multibranch Pipeline_ projects expose the name of the branch being built with the `BRAN"
  },
  "2743": {
    "source_file": "pipeline-as-code.txt",
    "text": "anch or pull request identifies a multibranch project.\n\nNOTE: _Multibranch Pipeline_ projects expose the name of the branch being built with the `BRANCH_NAME` environment variable and provide a special `checkout scm` Pipeline command, which is guaranteed to check out the specific commit that the Jenkinsfile originated.\nIf the Jenkinsfile needs to check out the repository for any reason, make sure "
  },
  "2744": {
    "source_file": "pipeline-as-code.txt",
    "text": "teed to check out the specific commit that the Jenkinsfile originated.\nIf the Jenkinsfile needs to check out the repository for any reason, make sure to use `checkout scm`, as it also accounts for alternate origin repositories to handle things like pull requests.\n\nTo create a _Multibranch Pipeline_, go to: _New Item -> Multibranch Pipeline_.\nConfigure the SCM source as appropriate.\nThere are optio"
  },
  "2745": {
    "source_file": "pipeline-as-code.txt",
    "text": "ull requests.\n\nTo create a _Multibranch Pipeline_, go to: _New Item -> Multibranch Pipeline_.\nConfigure the SCM source as appropriate.\nThere are options for many different types of repositories and services including Git, Mercurial, Bitbucket, and GitHub.\nIf using GitHub, for example, click *Add source*, select GitHub and configure the appropriate owner, scan credentials, and repository.\n\nOther op"
  },
  "2746": {
    "source_file": "pipeline-as-code.txt",
    "text": "tHub.\nIf using GitHub, for example, click *Add source*, select GitHub and configure the appropriate owner, scan credentials, and repository.\n\nOther options available to _Multibranch Pipeline_ projects are:\n\n* *API endpoint* - an alternate API endpoint to use a self-hosted GitHub Enterprise\n* *Checkout credentials* - alternate credentials to use when checking out the code (cloning)\n* *Include branc"
  },
  "2747": {
    "source_file": "pipeline-as-code.txt",
    "text": "t to use a self-hosted GitHub Enterprise\n* *Checkout credentials* - alternate credentials to use when checking out the code (cloning)\n* *Include branches* - a regular expression to specify branches to include\n* *Exclude branches* - a regular expression to specify branches to exclude; note that this will take precedence over includes\n* *Property strategy* - if necessary, define custom properties fo"
  },
  "2748": {
    "source_file": "pipeline-as-code.txt",
    "text": "on to specify branches to exclude; note that this will take precedence over includes\n* *Property strategy* - if necessary, define custom properties for each branch\n\nAfter configuring these items and saving the configuration, Jenkins will automatically scan the repository and import appropriate branches.\n\nOrganization Folders offer a convenient way to allow Jenkins to automatically manage which rep"
  },
  "2749": {
    "source_file": "pipeline-as-code.txt",
    "text": "y scan the repository and import appropriate branches.\n\nOrganization Folders offer a convenient way to allow Jenkins to automatically manage which repositories are automatically included in Jenkins.\nParticularly, if your organization utilizes _GitHub Organizations_ or _Bitbucket Teams_, any time a developer creates a new repository\nwith a `Jenkinsfile`, Jenkins will automatically detect it and cre"
  },
  "2750": {
    "source_file": "pipeline-as-code.txt",
    "text": " Organizations_ or _Bitbucket Teams_, any time a developer creates a new repository\nwith a `Jenkinsfile`, Jenkins will automatically detect it and create a _Multibranch Pipeline_ project for it.\nThis alleviates the need for administrators or developers to manually create projects for these new repositories.\n\nTo create an _Organization Folder_ in Jenkins, go to: *New Item -> Organization Folder* or"
  },
  "2751": {
    "source_file": "pipeline-as-code.txt",
    "text": "rs to manually create projects for these new repositories.\n\nTo create an _Organization Folder_ in Jenkins, go to: *New Item -> Organization Folder* or *New Item -> Bitbucket Team* and follow the configuration steps for each item, making sure to specify appropriate _Scan Credentials_ and a specific *owner* for the GitHub Organization or Bitbucket Team name, respectively.\n\nOther options available ar"
  },
  "2752": {
    "source_file": "pipeline-as-code.txt",
    "text": "fy appropriate _Scan Credentials_ and a specific *owner* for the GitHub Organization or Bitbucket Team name, respectively.\n\nOther options available are:\n\n* *Repository name pattern* - a regular expression to specify which repositories are *included*\n* *API endpoint* - an alternate API endpoint to use a self-hosted GitHub Enterprise\n* *Checkout credentials* - alternate credentials to use when check"
  },
  "2753": {
    "source_file": "pipeline-as-code.txt",
    "text": "* *API endpoint* - an alternate API endpoint to use a self-hosted GitHub Enterprise\n* *Checkout credentials* - alternate credentials to use when checking out the code (cloning)\n\nAfter configuring these items and saving the configuration, Jenkins will automatically scan the organization and import appropriate repositories and resulting branches.\n\nComputed folders can remove items immediately or lea"
  },
  "2754": {
    "source_file": "pipeline-as-code.txt",
    "text": " automatically scan the organization and import appropriate repositories and resulting branches.\n\nComputed folders can remove items immediately or leave them based on a desired retention strategy.\nBy default, items will be removed as soon as the folder computation determines they are no longer present.\nIf your organization requires these items remain available for a longer period of time, simply c"
  },
  "2755": {
    "source_file": "pipeline-as-code.txt",
    "text": "er computation determines they are no longer present.\nIf your organization requires these items remain available for a longer period of time, simply configure the Orphaned Item Strategy appropriately.\nIt may be useful to keep items in order to examine build results of a branch after it's been removed, for example.\n\n[role=\"image-border\"]\n\n{empty}\n\nYou can also configure a custom icon for folder dis"
  },
  "2756": {
    "source_file": "pipeline-as-code.txt",
    "text": "e build results of a branch after it's been removed, for example.\n\n[role=\"image-border\"]\n\n{empty}\n\nYou can also configure a custom icon for folder display by installing the plugin:custom-folder-icon[*Custom Folder Icon*] plugin.\nFor example, it might be useful to display an aggregate health of the child builds.\nAlternately, you might reference the same icon you use in your GitHub organization acco"
  },
  "2757": {
    "source_file": "pipeline-as-code.txt",
    "text": " be useful to display an aggregate health of the child builds.\nAlternately, you might reference the same icon you use in your GitHub organization account.\n\n[role=\"image-border\"]\n\n{empty}\n\nTo demonstrate using an Organization Folder to manage repositories, we'll use the fictitious organization: CloudBeers, Inc..\n\nGo to *New Item*.\nEnter 'CloudBeersInc' for the item name.\nSelect *Organization Folder"
  },
  "2758": {
    "source_file": "pipeline-as-code.txt",
    "text": "ries, we'll use the fictitious organization: CloudBeers, Inc..\n\nGo to *New Item*.\nEnter 'CloudBeersInc' for the item name.\nSelect *Organization Folder* and click *OK*.\n\n[role=\"image-border\"]\n\n{empty}\n\nOptionally, enter a better descriptive name for the _Description_, such as 'CloudBeers GitHub'.\nIn the _Repository Sources_ section, complete the section for \"GitHub Organization\".\nMake sure the *own"
  },
  "2759": {
    "source_file": "pipeline-as-code.txt",
    "text": "he _Description_, such as 'CloudBeers GitHub'.\nIn the _Repository Sources_ section, complete the section for \"GitHub Organization\".\nMake sure the *owner* matches the GitHub Organization name exactly, in our case it must be: _CloudBeersInc_.\nThis defaults to the same value that was entered for the item name in the first step.\nNext, select or add new *Credentials* - we'll enter our GitHub username a"
  },
  "2760": {
    "source_file": "pipeline-as-code.txt",
    "text": "ults to the same value that was entered for the item name in the first step.\nNext, select or add new *Credentials* - we'll enter our GitHub username and access token as the password.\n\n[role=\"image-border\"]\n\n{empty}\n\nAfter saving, the \"Folder Computation\" will run to scan for eligible repositories, followed by multibranch builds.\n\n[role=\"image-border\"]\n\n{empty}\n\nRefresh the page after the job runs "
  },
  "2761": {
    "source_file": "pipeline-as-code.txt",
    "text": "ion\" will run to scan for eligible repositories, followed by multibranch builds.\n\n[role=\"image-border\"]\n\n{empty}\n\nRefresh the page after the job runs to ensure the view of repositories has been updated.\n\n[role=\"image-border\"]\n\n{empty}\n\nAt this point, you're finished with basic project configuration and can now explore your imported repositories.\nYou can also investigate the results of the jobs run"
  },
  "2762": {
    "source_file": "pipeline-as-code.txt",
    "text": " you're finished with basic project configuration and can now explore your imported repositories.\nYou can also investigate the results of the jobs run as part of the initial _Folder Computation_.\n\n[role=\"image-border\"]\n\n{empty}\n\nContinuous delivery allows organizations to deliver software with lower risk.\nThe path to continuous delivery starts by modeling the software delivery pipeline used within"
  },
  "2763": {
    "source_file": "pipeline-as-code.txt",
    "text": "llows organizations to deliver software with lower risk.\nThe path to continuous delivery starts by modeling the software delivery pipeline used within the organization and then focusing on the automation of it all.\nEarly, directed feedback, enabled by pipeline automation enables software delivery more quickly over traditional methods of delivery.\n\nJenkins is the Swiss army knife in the software de"
  },
  "2764": {
    "source_file": "pipeline-as-code.txt",
    "text": "y pipeline automation enables software delivery more quickly over traditional methods of delivery.\n\nJenkins is the Swiss army knife in the software delivery toolchain.\nDevelopers and operations (DevOps) personnel have different mindsets and use different tools to get their respective jobs done.\nSince Jenkins integrates with a huge variety of toolsets, it serves as the intersection point between de"
  },
  "2765": {
    "source_file": "pipeline-as-code.txt",
    "text": "rent tools to get their respective jobs done.\nSince Jenkins integrates with a huge variety of toolsets, it serves as the intersection point between development and operations teams.\n\nMany organizations have been orchestrating pipelines with existing Jenkins plugins for several years.\nAs their automation sophistication and their own Jenkins experience increases, organizations inevitably want to mov"
  },
  "2766": {
    "source_file": "pipeline-as-code.txt",
    "text": "Jenkins plugins for several years.\nAs their automation sophistication and their own Jenkins experience increases, organizations inevitably want to move beyond simple pipelines and create complex flows specific to their delivery process.\n\nThese Jenkins users require a feature that treats complex pipelines as a first-class object, and so the plugin:workflow-aggregator[Pipeline plugin] was developed."
  },
  "2767": {
    "source_file": "pipeline-as-code.txt",
    "text": "s users require a feature that treats complex pipelines as a first-class object, and so the plugin:workflow-aggregator[Pipeline plugin] was developed.\n\nContinuous delivery is a process - rather than a tool - and requires a mindset and culture that must percolate from the top-down within an organization.\nOnce the organization has bought into the philosophy, the next and most difficult part is mappi"
  },
  "2768": {
    "source_file": "pipeline-as-code.txt",
    "text": "st percolate from the top-down within an organization.\nOnce the organization has bought into the philosophy, the next and most difficult part is mapping the flow of software as it makes its way from development to production.\n\nThe root of such a pipeline will always be an orchestration tool like a Jenkins, but there are some key requirements that such an integral part of the pipeline must satisfy "
  },
  "2769": {
    "source_file": "pipeline-as-code.txt",
    "text": "line will always be an orchestration tool like a Jenkins, but there are some key requirements that such an integral part of the pipeline must satisfy before it can be tasked with enterprise-critical processes:\n\n* *Zero or low downtime disaster recovery*: A commit, just as a mythical hero, encounters harder and longer challenges as it makes its way down the pipeline.\n  It is not unusual to see pipe"
  },
  "2770": {
    "source_file": "pipeline-as-code.txt",
    "text": "ry*: A commit, just as a mythical hero, encounters harder and longer challenges as it makes its way down the pipeline.\n  It is not unusual to see pipeline executions that last days.\n  A hardware or a Jenkins failure on day six of a seven-day pipeline has serious consequences for on-time delivery of a product.\n* *Audit runs and debug ability*: Build managers like to see the exact execution flow thr"
  },
  "2771": {
    "source_file": "pipeline-as-code.txt",
    "text": " has serious consequences for on-time delivery of a product.\n* *Audit runs and debug ability*: Build managers like to see the exact execution flow through the pipeline, so they can easily debug issues.\n\nTo ensure a tool can scale with an organization and suitably automate existing delivery pipelines without changing them, the tool should also support:\n\n* *Complex pipelines*: Delivery pipelines are"
  },
  "2772": {
    "source_file": "pipeline-as-code.txt",
    "text": " and suitably automate existing delivery pipelines without changing them, the tool should also support:\n\n* *Complex pipelines*: Delivery pipelines are typically more complex than canonical examples (linear process: Dev->Test->Deploy, with a couple of operations at each stage).\n  Build managers want constructs that help parallelize parts of the flow, run loops, perform retries and so forth.\n  State"
  },
  "2773": {
    "source_file": "pipeline-as-code.txt",
    "text": " operations at each stage).\n  Build managers want constructs that help parallelize parts of the flow, run loops, perform retries and so forth.\n  Stated differently, build managers want programming constructs to define pipelines.\n\n* *Manual interventions*: Pipelines cross intra-organizational boundaries necessitating manual handoffs and interventions.\n  Build managers seek capabilities such as bein"
  },
  "2774": {
    "source_file": "pipeline-as-code.txt",
    "text": "ons*: Pipelines cross intra-organizational boundaries necessitating manual handoffs and interventions.\n  Build managers seek capabilities such as being able to pause a pipeline for a human to intervene and make manual decisions.\n\nThe Pipeline plugin allows users to create such a pipeline through a new job type called Pipeline.\nThe flow definition is captured in a Groovy script, thus adding control"
  },
  "2775": {
    "source_file": "pipeline-as-code.txt",
    "text": "allows users to create such a pipeline through a new job type called Pipeline.\nThe flow definition is captured in a Groovy script, thus adding control flow capabilities such as loops, forks and retries.\nPipeline allows for stages with the option to set concurrencies, preventing multiple builds of the same pipeline from trying to access the same resource at the same time.\n\n.Pipeline Job Type\n\nThere"
  },
  "2776": {
    "source_file": "pipeline-as-code.txt",
    "text": "et concurrencies, preventing multiple builds of the same pipeline from trying to access the same resource at the same time.\n\n.Pipeline Job Type\n\nThere is just one job to capture the entire software delivery pipeline in an organization.\nOf course, you can still connect two Pipeline job types together if you want.\nA Pipeline job type uses a Groovy-based DSL for job definitions.\nThe DSL affords the a"
  },
  "2777": {
    "source_file": "pipeline-as-code.txt",
    "text": " can still connect two Pipeline job types together if you want.\nA Pipeline job type uses a Groovy-based DSL for job definitions.\nThe DSL affords the advantage of defining jobs programmatically:\n\nnode('linux'){\n  git url: 'https://github.com/jglick/simple-maven-project-with-tests.git'\n  def mvnHome = tool 'M3'\n  env.PATH = \"${mvnHome}/bin:${env.PATH}\"\n  sh 'mvn -B clean verify'\n}\n\n.Stages\n\nIntra-or"
  },
  "2778": {
    "source_file": "pipeline-as-code.txt",
    "text": "mple-maven-project-with-tests.git'\n  def mvnHome = tool 'M3'\n  env.PATH = \"${mvnHome}/bin:${env.PATH}\"\n  sh 'mvn -B clean verify'\n}\n\n.Stages\n\nIntra-organizational (or conceptual) boundaries are captured through a primitive called \"stages.\"\nA deployment pipeline consists of various stages, where each subsequent stage builds on the previous one.\nThe idea is to spend as few resources as possible earl"
  },
  "2779": {
    "source_file": "pipeline-as-code.txt",
    "text": "nt pipeline consists of various stages, where each subsequent stage builds on the previous one.\nThe idea is to spend as few resources as possible early in the pipeline and find obvious issues, rather than spend a lot of computing resources for something that is ultimately discovered to be broken.\n\n[[throttled-concurrent]]\n.Throttled stage concurrency with Pipeline\n\n{empty}\n\nConsider a simple pipel"
  },
  "2780": {
    "source_file": "pipeline-as-code.txt",
    "text": "ing that is ultimately discovered to be broken.\n\n[[throttled-concurrent]]\n.Throttled stage concurrency with Pipeline\n\n{empty}\n\nConsider a simple pipeline with three stages.\nA naive implementation of this pipeline can sequentially trigger each stage on every commit.\nThus, the deployment step is triggered immediately after the Selenium test steps are complete.\nHowever, this would mean that the deplo"
  },
  "2781": {
    "source_file": "pipeline-as-code.txt",
    "text": "n every commit.\nThus, the deployment step is triggered immediately after the Selenium test steps are complete.\nHowever, this would mean that the deployment from commit two overrides the last deployment in motion from commit one.\nThe right approach is for commits two and three to wait for the deployment from commit one to complete, consolidate all the changes that have happened since commit one and"
  },
  "2782": {
    "source_file": "pipeline-as-code.txt",
    "text": " for commits two and three to wait for the deployment from commit one to complete, consolidate all the changes that have happened since commit one and trigger the deployment.\nIf there is an issue, developers can easily figure out if the issue was introduced in commit two or commit three.\n\nPipeline provides this functionality by enhancing the stage primitive.\nFor example, a stage can have a concurr"
  },
  "2783": {
    "source_file": "pipeline-as-code.txt",
    "text": "roduced in commit two or commit three.\n\nPipeline provides this functionality by enhancing the stage primitive.\nFor example, a stage can have a concurrency level of one defined to indicate that at any point only one thread should be running through the stage.\nThis achieves the desired state of running a deployment as fast as it should run.\n\n stage name: 'Production', concurrency: 1\n node {\n     una"
  },
  "2784": {
    "source_file": "pipeline-as-code.txt",
    "text": "e stage.\nThis achieves the desired state of running a deployment as fast as it should run.\n\n stage name: 'Production', concurrency: 1\n node {\n     unarchive mapping: ['target/x.war' : 'x.war']\n     deploy 'target/x.war', 'production'\n     echo 'Deployed to http://localhost:8888/production/'\n }\n\n.Gates and Approvals\n\nContinuous delivery means having binaries in a release ready state whereas continu"
  },
  "2785": {
    "source_file": "pipeline-as-code.txt",
    "text": "yed to http://localhost:8888/production/'\n }\n\n.Gates and Approvals\n\nContinuous delivery means having binaries in a release ready state whereas continuous deployment means pushing the binaries to production - or automated deployments.\nAlthough continuous deployment is a sexy term and a desired state, in reality organizations still want a human to give the final approval before bits are pushed to pr"
  },
  "2786": {
    "source_file": "pipeline-as-code.txt",
    "text": "ous deployment is a sexy term and a desired state, in reality organizations still want a human to give the final approval before bits are pushed to production.\nThis is captured through the \"input\" primitive in Pipeline.\nThe input step can wait indefinitely for a human to intervene.\n\ninput message: \"Does http://localhost:8888/staging/ look good?\"\n\n.Deployment of Artifacts to Staging/Production\n\nDep"
  },
  "2787": {
    "source_file": "pipeline-as-code.txt",
    "text": "nitely for a human to intervene.\n\ninput message: \"Does http://localhost:8888/staging/ look good?\"\n\n.Deployment of Artifacts to Staging/Production\n\nDeployment of binaries is the last mile in a pipeline.\nThe numerous servers employed within the organization and available in the market make it difficult to employ a uniform deployment step.\nToday, these are solved by third-party deployer products whos"
  },
  "2788": {
    "source_file": "pipeline-as-code.txt",
    "text": "ation and available in the market make it difficult to employ a uniform deployment step.\nToday, these are solved by third-party deployer products whose job it is to focus on deployment of a particular stack to a data center.\nTeams can also write their own extensions to hook into the Pipeline job type and make the deployment easier.\n\nMeanwhile, job creators can write a plain old Groovy function to "
  },
  "2789": {
    "source_file": "pipeline-as-code.txt",
    "text": "r own extensions to hook into the Pipeline job type and make the deployment easier.\n\nMeanwhile, job creators can write a plain old Groovy function to define any custom steps that can deploy (or undeploy) artifacts from production.\n\ndef deploy(war, id) {\n    sh \"cp ${war} /tmp/webapps/${id}.war\"\n}\n\n.Restartable flows\n\nAll Pipelines are resumable, so if Jenkins needs to be restarted while a flow is "
  },
  "2790": {
    "source_file": "pipeline-as-code.txt",
    "text": ") {\n    sh \"cp ${war} /tmp/webapps/${id}.war\"\n}\n\n.Restartable flows\n\nAll Pipelines are resumable, so if Jenkins needs to be restarted while a flow is running, it should resume at the same point in its execution after Jenkins starts back up.\nSimilarly, if a flow is running a lengthy sh or bat step when an agent unexpectedly disconnects, no progress should be lost when connectivity is restored.\n\nThe"
  },
  "2791": {
    "source_file": "pipeline-as-code.txt",
    "text": ", if a flow is running a lengthy sh or bat step when an agent unexpectedly disconnects, no progress should be lost when connectivity is restored.\n\nThere are some cases when a flow build will have done a great deal of work and proceeded to a point where a transient error occurred: one which does not reflect the inputs to this build, such as source code changes.\nFor example, after completing a lengt"
  },
  "2792": {
    "source_file": "pipeline-as-code.txt",
    "text": "re a transient error occurred: one which does not reflect the inputs to this build, such as source code changes.\nFor example, after completing a lengthy build and test of a software component, final deployment to a server might fail because of network problems.\n\n.Pipeline Stage View\n\nWhen you have complex builds pipelines, it is useful to see the progress of each stage and to see where build failu"
  },
  "2793": {
    "source_file": "pipeline-as-code.txt",
    "text": "k problems.\n\n.Pipeline Stage View\n\nWhen you have complex builds pipelines, it is useful to see the progress of each stage and to see where build failures are occurring in the pipeline.\nThis can enable users to debug which tests are failing at which stage or if there are other problems in their pipeline.\nMany organization also want to make their pipelines user-friendly for non-developers without ha"
  },
  "2794": {
    "source_file": "pipeline-as-code.txt",
    "text": "tage or if there are other problems in their pipeline.\nMany organization also want to make their pipelines user-friendly for non-developers without having to develop a homegrown UI, which can prove to be a lengthy and ongoing development effort.\n\nThe Pipeline Stage View feature offers extended visualization of Pipeline build history on the index page of a flow project.\nThis visualization also incl"
  },
  "2795": {
    "source_file": "pipeline-as-code.txt",
    "text": " Pipeline Stage View feature offers extended visualization of Pipeline build history on the index page of a flow project.\nThis visualization also includes helpful metrics like average run time by stage and by build, and a user-friendly interface for interacting with input steps.\n\n.Pipeline Stage View plugin\n\n{empty}\n\nThe only prerequisite for this plugin is a pipeline with defined stages in the fl"
  },
  "2796": {
    "source_file": "pipeline-as-code.txt",
    "text": "interacting with input steps.\n\n.Pipeline Stage View plugin\n\n{empty}\n\nThe only prerequisite for this plugin is a pipeline with defined stages in the flow.\nThere can be as many stages as you desired and they can be in a linear sequence, and the stage names will be displayed as columns in the Stage View interface.\n\nTraceability is important for DevOps teams who need to be able to trace code from comm"
  },
  "2797": {
    "source_file": "pipeline-as-code.txt",
    "text": "ames will be displayed as columns in the Stage View interface.\n\nTraceability is important for DevOps teams who need to be able to trace code from commit to deployment.\nIt enables impact analysis by showing relationships between artifacts and allows for visibility into the full lifecycle of an artifact, from its code repository to where the artifact is eventually deployed in production.\n\nJenkins an"
  },
  "2798": {
    "source_file": "pipeline-as-code.txt",
    "text": "or visibility into the full lifecycle of an artifact, from its code repository to where the artifact is eventually deployed in production.\n\nJenkins and the Pipeline feature support tracking versions of artifacts using file fingerprinting, which allows users to trace which downstream builds are using any given artifact.\nTo fingerprint with Pipeline, simply add a \"fingerprint: true\" argument to any "
  },
  "2799": {
    "source_file": "pipeline-as-code.txt",
    "text": "s users to trace which downstream builds are using any given artifact.\nTo fingerprint with Pipeline, simply add a \"fingerprint: true\" argument to any artifact archiving step. For example:\n\narchiveArtifacts artifacts: '**', fingerprint: true\n\nwill archive any WAR artifacts created in the Pipeline and fingerprint them for traceability.\nThis trace log of this artifact and a list of all fingerprinted "
  },
  "2800": {
    "source_file": "pipeline-as-code.txt",
    "text": "hive any WAR artifacts created in the Pipeline and fingerprint them for traceability.\nThis trace log of this artifact and a list of all fingerprinted artifacts in a build will then be available in the left-hand menu of Jenkins:\n\nTo find where an artifact is used and deployed to, simply follow the \"more details\" link through the artifact's name and view the entries for the artifact in its \"Usage\" l"
  },
  "2801": {
    "source_file": "pipeline-as-code.txt",
    "text": "fact is used and deployed to, simply follow the \"more details\" link through the artifact's name and view the entries for the artifact in its \"Usage\" list.\n\n[[fingerprinting]]\n.Fingerprint of a WAR\n\n{empty}\n\nVisit the  to learn more."
  },
  "2802": {
    "source_file": "pipeline-best-practices.txt",
    "text": "layout: section\ntitle: Pipeline Best Practices\n\n\nifdef::env-github[:imagesdir: ../resources]\nifndef::env-github[:imagesdir: ../../resources]\n\nThis guide provides a small selection of best practices for pipelines and points out the most common mistakes.\n\nThe goal is to point pipeline authors and maintainers towards patterns that result in better Pipeline execution and away from pitfalls they might "
  },
  "2803": {
    "source_file": "pipeline-best-practices.txt",
    "text": "s.\n\nThe goal is to point pipeline authors and maintainers towards patterns that result in better Pipeline execution and away from pitfalls they might otherwise not be aware of.\nThis guide is not meant to be an exhaustive list of all possible Pipeline best practices but instead to provide a number of specific examples useful in tracking down common practices.\nUse it as a \"do this\" generally and not"
  },
  "2804": {
    "source_file": "pipeline-best-practices.txt",
    "text": " best practices but instead to provide a number of specific examples useful in tracking down common practices.\nUse it as a \"do this\" generally and not as an incredibly detailed \"how-to\".\n\nThis guide is arranged by area, guideline, then listing specific examples.\n\nUse Groovy code to connect a set of actions rather than as the main functionality of your Pipeline.\nIn other words, instead of relying o"
  },
  "2805": {
    "source_file": "pipeline-best-practices.txt",
    "text": "ic examples.\n\nUse Groovy code to connect a set of actions rather than as the main functionality of your Pipeline.\nIn other words, instead of relying on Pipeline functionality (Groovy or Pipeline steps) to drive the build process forward, use single steps (such as `sh`) to accomplish multiple parts of the build.\nPipelines, as their complexity increases (the amount of Groovy code, number of steps us"
  },
  "2806": {
    "source_file": "pipeline-best-practices.txt",
    "text": "teps (such as `sh`) to accomplish multiple parts of the build.\nPipelines, as their complexity increases (the amount of Groovy code, number of steps used, etc.), require more resources (CPU, memory, storage) on the controller.\nThink of Pipeline as a tool to accomplish a build rather than the core of a build.\n\nExample: Using a single Maven build step to drive the build through its build/test/deploy "
  },
  "2807": {
    "source_file": "pipeline-best-practices.txt",
    "text": "ool to accomplish a build rather than the core of a build.\n\nExample: Using a single Maven build step to drive the build through its build/test/deploy process.\n\nUsing a shell script within Jenkins Pipeline can help simplify builds by combining multiple steps into a single stage.\nThe shell script also allows users to add or update commands without having to modify each step or stage separately.\n\nThi"
  },
  "2808": {
    "source_file": "pipeline-best-practices.txt",
    "text": "e steps into a single stage.\nThe shell script also allows users to add or update commands without having to modify each step or stage separately.\n\nThis video reviews using a shell script in Jenkins Pipeline and the benefits it provides.\n\nvideo::mbeQWBNaNKQ[youtube,width=800,height=420]\n\nFor a Pipeline, Groovy code *always* executes on controller which means using controller resources(memory and CP"
  },
  "2809": {
    "source_file": "pipeline-best-practices.txt",
    "text": "BNaNKQ[youtube,width=800,height=420]\n\nFor a Pipeline, Groovy code *always* executes on controller which means using controller resources(memory and CPU).\nTherefore, it is critically important to reduce the amount of Groovy code executed by Pipelines (this includes any methods called on classes imported in Pipelines).\nThe following are the most common example Groovy methods to avoid using:\n\n*JsonSl"
  },
  "2810": {
    "source_file": "pipeline-best-practices.txt",
    "text": "(this includes any methods called on classes imported in Pipelines).\nThe following are the most common example Groovy methods to avoid using:\n\n*JsonSlurper:* This function (and some other similar ones like XmlSlurper or readFile) can be used to read from a file on disk, parse the data from that file into a JSON object, and inject that object into a Pipeline using a command like JsonSlurper().parse"
  },
  "2811": {
    "source_file": "pipeline-best-practices.txt",
    "text": "from a file on disk, parse the data from that file into a JSON object, and inject that object into a Pipeline using a command like JsonSlurper().parseText(readFile(\"$LOCAL_FILE\")). This command loads the local file into memory on the controller twice and, if the file is very large or the command is executed frequently, will require a lot of memory.\n.. Solution: Instead of using JsonSlurper, use a "
  },
  "2812": {
    "source_file": "pipeline-best-practices.txt",
    "text": " and, if the file is very large or the command is executed frequently, will require a lot of memory.\n.. Solution: Instead of using JsonSlurper, use a shell step and return the standard out. This shell would look something like this: `def JsonReturn = sh label: '', returnStdout: true, script: 'echo \"$LOCAL_FILE\"| jq \"$PARSING_QUERY\"'`. This will use agent resources to read the file and the $PARSING"
  },
  "2813": {
    "source_file": "pipeline-best-practices.txt",
    "text": " sh label: '', returnStdout: true, script: 'echo \"$LOCAL_FILE\"| jq \"$PARSING_QUERY\"'`. This will use agent resources to read the file and the $PARSING_QUERY will help parse down the file into a smaller size.\n*HttpRequest:* Frequently this command is used to grab data from an external source and store it in a variable. This practice is not ideal because not only is that request coming directly from"
  },
  "2814": {
    "source_file": "pipeline-best-practices.txt",
    "text": "used to grab data from an external source and store it in a variable. This practice is not ideal because not only is that request coming directly from the controller (which could give incorrect results for things like HTTPS requests if the controller does not have certificates loaded), but also the response to that request is stored twice.\n.. Solution: Use a shell step to perform the HTTP request "
  },
  "2815": {
    "source_file": "pipeline-best-practices.txt",
    "text": " does not have certificates loaded), but also the response to that request is stored twice.\n.. Solution: Use a shell step to perform the HTTP request from the agent, for example using a tool like `curl` or `wget`, as appropriate. If the result must be later in the Pipeline, try to filter the result on the agent side as much as possible so that only the minimum required information must be transmit"
  },
  "2816": {
    "source_file": "pipeline-best-practices.txt",
    "text": "e later in the Pipeline, try to filter the result on the agent side as much as possible so that only the minimum required information must be transmitted back to the Jenkins controller.\n\nCombine Pipeline steps into single steps as often as possible to reduce the amount of overhead caused by the Pipeline execution engine itself. For example, if you run three shell steps back-to-back, each of those "
  },
  "2817": {
    "source_file": "pipeline-best-practices.txt",
    "text": "o reduce the amount of overhead caused by the Pipeline execution engine itself. For example, if you run three shell steps back-to-back, each of those steps has to be started and stopped, requiring connections and resources on the agent and controller to be created and cleaned up. However, if you put all of the commands into a single shell step, then only a single step needs to be started and stopp"
  },
  "2818": {
    "source_file": "pipeline-best-practices.txt",
    "text": " to be created and cleaned up. However, if you put all of the commands into a single shell step, then only a single step needs to be started and stopped.\n\nExample:\nInstead of creating a series of  `echo` or `sh` steps, combine them into a single step or script.\n\nUsing Jenkins.instance or its accessor methods in a Pipeline or shared library indicates a code misuse within that Pipeline/shared librar"
  },
  "2819": {
    "source_file": "pipeline-best-practices.txt",
    "text": " or script.\n\nUsing Jenkins.instance or its accessor methods in a Pipeline or shared library indicates a code misuse within that Pipeline/shared library. Using Jenkins APIs from an unsandboxed shared library means that the shared library is both a shared library and a kind of Jenkins plugin. You need to be very careful when interacting with Jenkins APIs from a Pipeline to avoid severe security and "
  },
  "2820": {
    "source_file": "pipeline-best-practices.txt",
    "text": "red library and a kind of Jenkins plugin. You need to be very careful when interacting with Jenkins APIs from a Pipeline to avoid severe security and performance issues. If you must use Jenkins APIs in your build, the recommended approach is to create a minimal plugin in Java that implements a safe wrapper around the Jenkins API you want to access using Pipeline's Step API. Using Jenkins APIs from"
  },
  "2821": {
    "source_file": "pipeline-best-practices.txt",
    "text": "e a minimal plugin in Java that implements a safe wrapper around the Jenkins API you want to access using Pipeline's Step API. Using Jenkins APIs from a sandboxed Jenkinsfile directly means that you have probably had to whitelist methods that allow sandbox protections to be bypassed by anyone who can modify a Pipeline, which is a significant security risk. The whitelisted method is run as the Syst"
  },
  "2822": {
    "source_file": "pipeline-best-practices.txt",
    "text": "andbox protections to be bypassed by anyone who can modify a Pipeline, which is a significant security risk. The whitelisted method is run as the System user, having overall admin permissions, which can lead to developers possessing higher permissions than intended.\n\nSolution: The best solution would be to work around the calls being made, but if they must be done then it would be better to implem"
  },
  "2823": {
    "source_file": "pipeline-best-practices.txt",
    "text": "s than intended.\n\nSolution: The best solution would be to work around the calls being made, but if they must be done then it would be better to implement a Jenkins plugin which is able to gather the data needed.\n\nAs a Jenkins administrator, removing old or unwanted builds keeps the Jenkins controller running efficiently.\nWhen you do not remove older builds, there are less resources for more curren"
  },
  "2824": {
    "source_file": "pipeline-best-practices.txt",
    "text": "old or unwanted builds keeps the Jenkins controller running efficiently.\nWhen you do not remove older builds, there are less resources for more current and relevant builds.\nThis video reviews using the  directive in individual Pipeline jobs.\nThe video also reviews the process to keep specific historical builds.\n\n.How to clean up old Jenkins builds\nvideo::_Z7BlaTTGlo[youtube,width=800,height=420]\n\n"
  },
  "2825": {
    "source_file": "pipeline-best-practices.txt",
    "text": "o also reviews the process to keep specific historical builds.\n\n.How to clean up old Jenkins builds\nvideo::_Z7BlaTTGlo[youtube,width=800,height=420]\n\nWherever possible stay away from customized/overwritten Pipeline steps.\nOverriding built-in Pipeline Steps is the process of using shared libraries to overwrite the standard Pipeline APIs like `sh` or `timeout`.\nThis process is dangerous because the "
  },
  "2826": {
    "source_file": "pipeline-best-practices.txt",
    "text": " Steps is the process of using shared libraries to overwrite the standard Pipeline APIs like `sh` or `timeout`.\nThis process is dangerous because the Pipeline APIs can change at any time causing custom code to break or give different results than expected.\nWhen custom code breaks because of Pipeline API changes, troubleshooting is difficult because even if the custom code has not changed, it may n"
  },
  "2827": {
    "source_file": "pipeline-best-practices.txt",
    "text": "ected.\nWhen custom code breaks because of Pipeline API changes, troubleshooting is difficult because even if the custom code has not changed, it may not work the same after an API update.\nSo even if custom code has not changed, that does not mean after an API update it will keep working the same.\nLastly, because of the ubiquitous use of these steps throughout Pipelines, if something is coded incor"
  },
  "2828": {
    "source_file": "pipeline-best-practices.txt",
    "text": "er an API update it will keep working the same.\nLastly, because of the ubiquitous use of these steps throughout Pipelines, if something is coded incorrectly/inefficiently the results can be catastrophic to Jenkins.\n\nHaving large variable declaration files can require large amounts of memory for little to no benefit, because the file is loaded for every Pipeline whether the variables are needed or "
  },
  "2829": {
    "source_file": "pipeline-best-practices.txt",
    "text": "files can require large amounts of memory for little to no benefit, because the file is loaded for every Pipeline whether the variables are needed or not. Creating small variable files that contain only variables relevant to the current execution is recommended.\n\nUsing large shared libraries in Pipelines requires checking out a very large file before the Pipeline can start and loading the same sha"
  },
  "2830": {
    "source_file": "pipeline-best-practices.txt",
    "text": "recommended.\n\nUsing large shared libraries in Pipelines requires checking out a very large file before the Pipeline can start and loading the same shared library per job that is currently executing, which can lead to increased memory overhead and slower execution time.\n\nTry not to share workspaces across multiple Pipeline executions or multiple distinct Pipelines.\nThis practice can lead to either "
  },
  "2831": {
    "source_file": "pipeline-best-practices.txt",
    "text": "wer execution time.\n\nTry not to share workspaces across multiple Pipeline executions or multiple distinct Pipelines.\nThis practice can lead to either unexpected file modification within each Pipeline or workspace renaming.\n\nIdeally, shared volumes/disks are mounted in a separate place and the files are copied from that place to the current workspace.\nThen when the build is done the files can be co"
  },
  "2832": {
    "source_file": "pipeline-best-practices.txt",
    "text": "sks are mounted in a separate place and the files are copied from that place to the current workspace.\nThen when the build is done the files can be copied back if there were updates done.\n\nBuild in distinct containers which create needed resources from scratch(cloud-type agents work great for this).\nBuilding these containers will ensure that the build process begins at the start every time and is "
  },
  "2833": {
    "source_file": "pipeline-best-practices.txt",
    "text": "om scratch(cloud-type agents work great for this).\nBuilding these containers will ensure that the build process begins at the start every time and is easily repeatable.\nIf building containers will not work, disable concurrency on the Pipeline or use the Lockable Resources Plugin to lock the workspace when it is running so that no other builds can use it while it is locked.\n**WARNING**: Disabling c"
  },
  "2834": {
    "source_file": "pipeline-best-practices.txt",
    "text": "the Lockable Resources Plugin to lock the workspace when it is running so that no other builds can use it while it is locked.\n**WARNING**: Disabling concurrency or locking the workspace when it is running can cause Pipelines to become blocked when waiting on resources if those resources are arbitrarily locked.\n\n**Also, be aware that both of these methods have slower time to results of builds than "
  },
  "2835": {
    "source_file": "pipeline-best-practices.txt",
    "text": "iting on resources if those resources are arbitrarily locked.\n\n**Also, be aware that both of these methods have slower time to results of builds than using unique resources for each job**\n\nPipeline code is CPS-transformed so that Pipelines are able to resume after a Jenkins restart.\nThat is, while the pipeline is running your script, you can shut down Jenkins or lose connectivity to an agent.\nWhen"
  },
  "2836": {
    "source_file": "pipeline-best-practices.txt",
    "text": "o resume after a Jenkins restart.\nThat is, while the pipeline is running your script, you can shut down Jenkins or lose connectivity to an agent.\nWhen it comes back, Jenkins remembers what it was doing and your pipeline script resumes execution as if it were never interrupted.\nA technique known as \"\" execution plays a key role in resuming Pipelines.\nHowever, some Groovy expressions do not work cor"
  },
  "2837": {
    "source_file": "pipeline-best-practices.txt",
    "text": " it were never interrupted.\nA technique known as \"\" execution plays a key role in resuming Pipelines.\nHowever, some Groovy expressions do not work correctly as a result of CPS transformation.\n\nUnder the hood, CPS relies on being able to serialize the pipeline's current state along with the remainder of the pipeline to be executed.\nThis means that using Objects in the pipeline that are not serializ"
  },
  "2838": {
    "source_file": "pipeline-best-practices.txt",
    "text": " pipeline's current state along with the remainder of the pipeline to be executed.\nThis means that using Objects in the pipeline that are not serializable will trigger a `NotSerializableException` to be thrown when the pipeline attempts to persist its state.\n\nSee  for more details and some examples of things that may be problematic.\n\nBelow will cover techniques to ensure the pipeline can function "
  },
  "2839": {
    "source_file": "pipeline-best-practices.txt",
    "text": "s state.\n\nSee  for more details and some examples of things that may be problematic.\n\nBelow will cover techniques to ensure the pipeline can function as expected.\n\nLocal variables are captured as part of the pipeline's state during serialization.\nThis means that storing non-serializable objects in variables during pipeline execution will result in a `NotSerializableException` to be thrown.\n\nOne st"
  },
  "2840": {
    "source_file": "pipeline-best-practices.txt",
    "text": "s means that storing non-serializable objects in variables during pipeline execution will result in a `NotSerializableException` to be thrown.\n\nOne strategy to make use of non-serializable objects to always infer their value \"just-in-time\" instead of calculating their value and storing that value in a variable.\n\n[[using-noncps]]\n\nIf necessary, you can use the `@NonCPS` annotation to disable the CP"
  },
  "2841": {
    "source_file": "pipeline-best-practices.txt",
    "text": " calculating their value and storing that value in a variable.\n\n[[using-noncps]]\n\nIf necessary, you can use the `@NonCPS` annotation to disable the CPS transformation for a specific method whose body would not execute correctly if it were CPS-transformed.\nJust be aware that this also means the Groovy function will have to restart completely since it is not transformed.\n\nAsynchronous Pipeline steps"
  },
  "2842": {
    "source_file": "pipeline-best-practices.txt",
    "text": "rmed.\nJust be aware that this also means the Groovy function will have to restart completely since it is not transformed.\n\nAsynchronous Pipeline steps (such as `sh` and `sleep`) are always CPS-transformed, and may not be used inside of a method annotated with `@NonCPS`.\nIn general, you should avoid using pipeline steps inside of methods annotated with `@NonCPS`\n\nIt is noteworthy that changing the "
  },
  "2843": {
    "source_file": "pipeline-best-practices.txt",
    "text": "ated with `@NonCPS`.\nIn general, you should avoid using pipeline steps inside of methods annotated with `@NonCPS`\n\nIt is noteworthy that changing the pipeline's durability can result in `NotSerializableException` not being thrown where they otherwise would have been.\nThis is because decreasing the pipeline's durability through PERFORMANCE_OPTIMIZED means that the pipeline's current state is persis"
  },
  "2844": {
    "source_file": "pipeline-best-practices.txt",
    "text": " would have been.\nThis is because decreasing the pipeline's durability through PERFORMANCE_OPTIMIZED means that the pipeline's current state is persisted significantly less frequently.\nTherefore, the pipeline never attempts to serialize the non-serializable values and as such, no exception is thrown.\n\n[IMPORTANT]\n\nThis note exists to inform users as to the root cause of this behavior.\nIt is not re"
  },
  "2845": {
    "source_file": "pipeline-best-practices.txt",
    "text": "lizable values and as such, no exception is thrown.\n\n[IMPORTANT]\n\nThis note exists to inform users as to the root cause of this behavior.\nIt is not recommended that the Pipeline's durability setting be set to Performance Optimized purely to avoid serializability issues."
  },
  "2846": {
    "source_file": "pipeline-best-practices.txt",
    "text": "ializability issues."
  },
  "2847": {
    "source_file": "pipeline-editor.txt",
    "text": "layout: section\ntitle: Pipeline Editor\n\n\nifdef::env-github[:imagesdir: ../resources]\nifndef::env-github[:imagesdir: ../../resources]\n\n// Show 2/3 of the Blue ocean admonitions\n// :pipeline-visualization-admonition: true\n\nThe Blue Ocean Pipeline Editor is an easy way for anyone to get started with creating Pipelines in Jenkins.\nIt's also great for existing Jenkins users to start adopting Pipeline.\n"
  },
  "2848": {
    "source_file": "pipeline-editor.txt",
    "text": "r is an easy way for anyone to get started with creating Pipelines in Jenkins.\nIt's also great for existing Jenkins users to start adopting Pipeline.\n\nThe editor allows users to create and edit Declarative Pipelines and perform actions such as adding stages or configuring parallel tasks, depending on their needs.\nWhen the user completes their configuration, the editor saves the Pipeline to a sourc"
  },
  "2849": {
    "source_file": "pipeline-editor.txt",
    "text": " stages or configuring parallel tasks, depending on their needs.\nWhen the user completes their configuration, the editor saves the Pipeline to a source code repository as a `Jenkinsfile`.\nIf the Pipeline requires further modification, Blue Ocean makes it easy to jump back into the visual editor to modify the Pipeline at any time.\n\nvideo::FhDomw6BaHU[youtube, width=640, height=360, align=\"center\"]\n"
  },
  "2850": {
    "source_file": "pipeline-editor.txt",
    "text": "s it easy to jump back into the visual editor to modify the Pipeline at any time.\n\nvideo::FhDomw6BaHU[youtube, width=640, height=360, align=\"center\"]\n\nThe Blue Ocean Pipeline Editor is a great alternative for Jenkins users, but there are some limitations to its functionality:\n\n* The editor utilizes SCM-based Declarative Pipelines only.\n* User credentials must have write permission.\n* The editor do"
  },
  "2851": {
    "source_file": "pipeline-editor.txt",
    "text": "ions to its functionality:\n\n* The editor utilizes SCM-based Declarative Pipelines only.\n* User credentials must have write permission.\n* The editor does not have full parity with Declarative Pipeline.\n* The Pipeline is re-ordered and comments are removed.\n\nTo use the editor, a user must first <<creating-pipelines, create a Pipeline in Blue Ocean>> or have at least one existing Pipeline in Jenkins."
  },
  "2852": {
    "source_file": "pipeline-editor.txt",
    "text": "oved.\n\nTo use the editor, a user must first <<creating-pipelines, create a Pipeline in Blue Ocean>> or have at least one existing Pipeline in Jenkins.\nIf editing an existing Pipeline, the credentials for that Pipeline must allow pushing changes to the target repository.\n\nThe editor can be launched through the:\n\n* *New Pipeline* option from the .\n* *Branches* tab within the .\n* *Edit* (icon:pencil["
  },
  "2853": {
    "source_file": "pipeline-editor.txt",
    "text": "e target repository.\n\nThe editor can be launched through the:\n\n* *New Pipeline* option from the .\n* *Branches* tab within the .\n* *Edit* (icon:pencil[]) in the Pipeline run details view.\n\nThe Pipeline editor includes the <<getting-started#navigation-bar, standard navigation bar>> at the top, with a local navigation bar below it.\nThe local navigation bar includes:\n\n* *Pipeline Name* - This also inc"
  },
  "2854": {
    "source_file": "pipeline-editor.txt",
    "text": "bar, standard navigation bar>> at the top, with a local navigation bar below it.\nThe local navigation bar includes:\n\n* *Pipeline Name* - This also includes the branch name.\n* *Cancel* - Discards changes made to the pipeline.\n* *Save* - Opens the <<#save-pipeline-dialog, save Pipeline dialog>>.\n\nBy default, the pane on the right side of the editor displays the *Pipeline Settings*.\nSelecting an exis"
  },
  "2855": {
    "source_file": "pipeline-editor.txt",
    "text": "ave-pipeline-dialog, save Pipeline dialog>>.\n\nBy default, the pane on the right side of the editor displays the *Pipeline Settings*.\nSelecting an existing stage or adding a stage displays the  pane instead.\nTo navigate back to the *Pipeline Settings* pane, select any empty space in the background of the editor.\nWithin the Pipeline Settings pane, there are two sections that are configurable.\n\nThe *"
  },
  "2856": {
    "source_file": "pipeline-editor.txt",
    "text": " pane, select any empty space in the background of the editor.\nWithin the Pipeline Settings pane, there are two sections that are configurable.\n\nThe *Agent* section controls which agent the Pipeline uses.\nThis performs the same process as the <<../pipeline/syntax#agent, agent directive>>.\nThe *Image* field allows users to configure which container image runs when the Pipeline is active.\n\nThe *Envi"
  },
  "2857": {
    "source_file": "pipeline-editor.txt",
    "text": "peline/syntax#agent, agent directive>>.\nThe *Image* field allows users to configure which container image runs when the Pipeline is active.\n\nThe *Environment* section allows users to configure environment variables for the Pipeline.\nThis is the same process as the <<../pipeline/syntax#environment, environment directive>>.\n\nThe left pane displays the stage editor UI, which allows users to create or"
  },
  "2858": {
    "source_file": "pipeline-editor.txt",
    "text": "process as the <<../pipeline/syntax#environment, environment directive>>.\n\nThe left pane displays the stage editor UI, which allows users to create or add stages of a Pipeline.\n\n* To add a stage to the Pipeline, select the icon:plus[] icon to the right of an existing stage.\nSelecting the icon:plus[] icon below an existing stage adds a parallel stage.\n* To delete unwanted stages, use the <<stage-co"
  },
  "2859": {
    "source_file": "pipeline-editor.txt",
    "text": "ht of an existing stage.\nSelecting the icon:plus[] icon below an existing stage adds a parallel stage.\n* To delete unwanted stages, use the <<stage-configuration, more menu in the stage configuration pane>>.\n\nAfter setting the stage name and saving, the name displays above the stage.\nStages that contain incomplete or invalid information display a icon:warning[].\nPipelines can have validation error"
  },
  "2860": {
    "source_file": "pipeline-editor.txt",
    "text": "the name displays above the stage.\nStages that contain incomplete or invalid information display a icon:warning[].\nPipelines can have validation errors during editing, but saving is blocked until the errors are fixed.\n\nSelecting a stage in the editor displays the *Stage Configuration* pane on the right side of the screen.\nHere, you can modify the name of the stage, delete the stage, and add steps "
  },
  "2861": {
    "source_file": "pipeline-editor.txt",
    "text": " displays the *Stage Configuration* pane on the right side of the screen.\nHere, you can modify the name of the stage, delete the stage, and add steps to a stage.\n\nThe name of the stage can be set at the top of the stage configuration pane.\nThe more menu, represented by three dots to the right of the stage name, allows users to delete the currently selected stage.\nSelecting *Add step* displays the "
  },
  "2862": {
    "source_file": "pipeline-editor.txt",
    "text": "enu, represented by three dots to the right of the stage name, allows users to delete the currently selected stage.\nSelecting *Add step* displays the list of available step types.\nAfter selecting a step type, the page displays the step configuration pane.\n\nThis pane display is based on the step type selected, and contains the necessary fields or controls.\n\nBe sure to provide a strong name for the "
  },
  "2863": {
    "source_file": "pipeline-editor.txt",
    "text": "pane.\n\nThis pane display is based on the step type selected, and contains the necessary fields or controls.\n\nBe sure to provide a strong name for the step, as the name retains its original configuration.\nDeleting the step and recreating it is the only way to provide a different name.\nThe more menu, represented by three dots to the right of the step name, allows users to delete the current step.\nFi"
  },
  "2864": {
    "source_file": "pipeline-editor.txt",
    "text": "y way to provide a different name.\nThe more menu, represented by three dots to the right of the step name, allows users to delete the current step.\nFields that contain incomplete or invalid information display a icon:exclamation[].\nAny validation errors must be addressed before saving.\n\nChanges to a Pipeline must be saved in source control before running.\nThe *Save Pipeline* dialog controls the sa"
  },
  "2865": {
    "source_file": "pipeline-editor.txt",
    "text": "ors must be addressed before saving.\n\nChanges to a Pipeline must be saved in source control before running.\nThe *Save Pipeline* dialog controls the saving of changes to source control.\n\nYou can optionally enter a description of the changes before saving.\nThe dialog also provides options for saving changes to the same branch or creating a new branch to save to.\nSelecting *Save & run* saves any chan"
  },
  "2866": {
    "source_file": "pipeline-editor.txt",
    "text": "ing.\nThe dialog also provides options for saving changes to the same branch or creating a new branch to save to.\nSelecting *Save & run* saves any changes to the Pipeline as a new commit, starts a new Pipeline run based on those changes, and navigates to the <<activity#, Activity view>> for this pipeline."
  },
  "2867": {
    "source_file": "pipeline-editor.txt",
    "text": " to the <<activity#, Activity view>> for this pipeline."
  },
  "2868": {
    "source_file": "pipeline-integration.txt",
    "text": "layout: developer\ntitle: Writing Pipeline-Compatible Plugins\nreferences:\n- url: https://github.com/jenkinsci/workflow-step-api-plugin/blob/master/README.md\n  title: Writing Pipeline steps\n- url: https://github.com/jenkinsci/workflow-basic-steps-plugin/blob/master/CORE-STEPS.md\n  title: Additional info about core Pipeline steps\n- url: https://github.com/jenkinsci/workflow-scm-step-plugin/blob/maste"
  },
  "2869": {
    "source_file": "pipeline-integration.txt",
    "text": "n/blob/master/CORE-STEPS.md\n  title: Additional info about core Pipeline steps\n- url: https://github.com/jenkinsci/workflow-scm-step-plugin/blob/master/README.md\n  title: SCM steps and Pipeline\n\n\nIf you are maintaining (or creating) a plugin and wish its features to work smoothly with Pipeline,\nthere are a number of special considerations.\n\nSeveral common types of plugin features  ``@Extension``s "
  },
  "2870": {
    "source_file": "pipeline-integration.txt",
    "text": " its features to work smoothly with Pipeline,\nthere are a number of special considerations.\n\nSeveral common types of plugin features  ``@Extension``s can be invoked from a Pipeline script without any special\nplugin dependencies so long as you use newer Jenkins core APIs.\nThen there is \u201cmetastep\u201d in Pipeline (`step`, `checkout`, `wrap`) which loads the extension by class name and calls it.\n\nThere a"
  },
  "2871": {
    "source_file": "pipeline-integration.txt",
    "text": "er Jenkins core APIs.\nThen there is \u201cmetastep\u201d in Pipeline (`step`, `checkout`, `wrap`) which loads the extension by class name and calls it.\n\nThere are several considerations common to the various metasteps.\n\nFirst, make sure the baseline Jenkins version in your `pom.xml` is sufficiently new.\n\nSuggested versions for:\n\n- <<Basic update>>\n- <<Build wrappers>>\n\nThis introduces some new API methods, "
  },
  "2872": {
    "source_file": "pipeline-integration.txt",
    "text": "rsion in your `pom.xml` is sufficiently new.\n\nSuggested versions for:\n\n- <<Basic update>>\n- <<Build wrappers>>\n\nThis introduces some new API methods, and deprecates some old ones.\n\nNOTE: If you are nervous about making your plugin depend on a recent Jenkins version,\nremember that you can always create a branch from your previous release (setting the version to `x.y.1-SNAPSHOT`) that\nworks with old"
  },
  "2873": {
    "source_file": "pipeline-integration.txt",
    "text": "Jenkins version,\nremember that you can always create a branch from your previous release (setting the version to `x.y.1-SNAPSHOT`) that\nworks with older versions of Jenkins and `git cherry-pick -x` trunk changes into it as needed;\nor merge from one branch to another if that is easier.\n(`mvn -B release:prepare release:perform` works fine on a branch and knows to increment just the last version comp"
  },
  "2874": {
    "source_file": "pipeline-integration.txt",
    "text": "ranch to another if that is easier.\n(`mvn -B release:prepare release:perform` works fine on a branch and knows to increment just the last version component)\n\n.Api replacement\n|===\n|Original|Replacement\n\n|`AbstractBuild.getProject`|`Run.getParent`\n\n|`BuildListener`| `TaskListener` (in new method overloads)\n\n|`getBuiltOn`| `FilePath.toComputer` (if you need a `Node` where the build is running)\n\n|`Tr"
  },
  "2875": {
    "source_file": "pipeline-integration.txt",
    "text": "BuildListener`| `TaskListener` (in new method overloads)\n\n|`getBuiltOn`| `FilePath.toComputer` (if you need a `Node` where the build is running)\n\n|`TransientProjectActionFactory`|`TransientActionFactory<Job>`\n|===\n\nThere is no equivalent to `AbstractBuild.getBuildVariables()` for `WorkflowRun` (any Groovy local variables are not accessible as such).\nAlso, `WorkflowRun.getEnvironment(TaskListener)`"
  },
  "2876": {
    "source_file": "pipeline-integration.txt",
    "text": "Build.getBuildVariables()` for `WorkflowRun` (any Groovy local variables are not accessible as such).\nAlso, `WorkflowRun.getEnvironment(TaskListener)` _is_ implemented, but only yields the initial build environment, irrespective of `withEnv` blocks and the like.\n\nTIP: To get the _contextual_ environment in a `Step`, you can inject `EnvVars` using `@StepContextParameter`;\n\nWARNING: Pending jira:JEN"
  },
  "2877": {
    "source_file": "pipeline-integration.txt",
    "text": "nd the like.\n\nTIP: To get the _contextual_ environment in a `Step`, you can inject `EnvVars` using `@StepContextParameter`;\n\nWARNING: Pending jira:JENKINS-29144[] there is no equivalent for a `SimpleBuildStep`.\nBut `SimpleBuildWrapper` does have access to an `initialEnvironment` if required.\n\nAnyway code run from Pipeline should take any configuration values as literal strings and make no attempt "
  },
  "2878": {
    "source_file": "pipeline-integration.txt",
    "text": "ss to an `initialEnvironment` if required.\n\nAnyway code run from Pipeline should take any configuration values as literal strings and make no attempt to perform\nvariable substitution (including via the `token-macro` plugin),\nsince the script author would be using Groovy facilities (`+\"like ${this}\"+`) for any desired dynamic behavior.\nTo have a single code fragment support both Pipeline and tradit"
  },
  "2879": {
    "source_file": "pipeline-integration.txt",
    "text": "ould be using Groovy facilities (`+\"like ${this}\"+`) for any desired dynamic behavior.\nTo have a single code fragment support both Pipeline and traditional builds, you can use idioms such as:\n\nprivate final String location;\n\npublic String getLocation() {\n    return location;\n}\n\n@DataBoundSetter\npublic void setLocation(String location) {\n    this.location = location;\n}\n\nprivate String actualLocatio"
  },
  "2880": {
    "source_file": "pipeline-integration.txt",
    "text": "() {\n    return location;\n}\n\n@DataBoundSetter\npublic void setLocation(String location) {\n    this.location = location;\n}\n\nprivate String actualLocation(Run<?,?> build, TaskListener listener) {\n    if (build instanceof AbstractBuild) {\n        EnvVars env = build.getEnvironment(listener);\n        env.overrideAll(((AbstractBuild) build).getBuildVariables());\n        return env.expand(location);\n    "
  },
  "2881": {
    "source_file": "pipeline-integration.txt",
    "text": " env = build.getEnvironment(listener);\n        env.overrideAll(((AbstractBuild) build).getBuildVariables());\n        return env.expand(location);\n    } else {\n        return location;\n    }\n}\n\nNOTE: jira:JENKINS-35671[] would simplify this.\n\nIt is a good idea to replace a lengthy `@DataBoundConstructor` with a short one taking just truly mandatory parameters\n(such as a server location).\nFor all op"
  },
  "2882": {
    "source_file": "pipeline-integration.txt",
    "text": "good idea to replace a lengthy `@DataBoundConstructor` with a short one taking just truly mandatory parameters\n(such as a server location).\nFor all optional parameters, create a public setter marked with `@DataBoundSetter`\n(with any non-null default value set in the constructor or field initializer).\nThis allows most parameters to be left at their default values in a Pipeline script,\nnot to mentio"
  },
  "2883": {
    "source_file": "pipeline-integration.txt",
    "text": "value set in the constructor or field initializer).\nThis allows most parameters to be left at their default values in a Pipeline script,\nnot to mention simplifying ongoing code maintenance because it is much easier to introduce new options this way.\n\nFor Java-level compatibility, leave any previous constructors in place, but mark them `@Deprecated`.\nAlso remove `@DataBoundConstructor` from them (t"
  },
  "2884": {
    "source_file": "pipeline-integration.txt",
    "text": "\nFor Java-level compatibility, leave any previous constructors in place, but mark them `@Deprecated`.\nAlso remove `@DataBoundConstructor` from them (there can be only one).\n\nTo ensure _Snippet Generator_ enumerates only those options the user has actually customized from their form defaults,\nensure that Jelly `default` attributes match the property defaults as seen from the getter.\nFor a cleaner X"
  },
  "2885": {
    "source_file": "pipeline-integration.txt",
    "text": "ually customized from their form defaults,\nensure that Jelly `default` attributes match the property defaults as seen from the getter.\nFor a cleaner XStream serial form in freestyle projects, it is best for the default value to also be represented\nas a null in the Java field.\nSo for example if you want a textual property which can sensibly default to blank, your configuration form would look like\n"
  },
  "2886": {
    "source_file": "pipeline-integration.txt",
    "text": " a null in the Java field.\nSo for example if you want a textual property which can sensibly default to blank, your configuration form would look like\n\n<f:entry field=\"stuff\" title=\"${%Stuff}\">\n    <f:textbox/>\n</f:entry>\n\nand your `Describable` should use\n\n@CheckForNull\nprivate String stuff;\n\n@CheckForNull\npublic String getStuff() {\n    return stuff;\n}\n\n@DataBoundSetter\npublic void setStuff(@Check"
  },
  "2887": {
    "source_file": "pipeline-integration.txt",
    "text": "d use\n\n@CheckForNull\nprivate String stuff;\n\n@CheckForNull\npublic String getStuff() {\n    return stuff;\n}\n\n@DataBoundSetter\npublic void setStuff(@CheckForNull String stuff) {\n    this.stuff = Util.fixEmpty(stuff);\n}\n\nIf you want a nonblank default, it is a little more complicated.\nIf you do not care about XStream hygiene, for example because the `Describable` is a Pipeline `Step` (or is only being "
  },
  "2888": {
    "source_file": "pipeline-integration.txt",
    "text": " is a little more complicated.\nIf you do not care about XStream hygiene, for example because the `Describable` is a Pipeline `Step` (or is only being used as part of one):\n\n<f:entry field=\"stuff\" title=\"${%Stuff}\">\n    <f:textbox default=\"${descriptor.defaultStuff}\"/>\n</f:entry>\n\n@NonNull\nprivate String stuff = DescriptorImpl.defaultStuff;\n\n@NonNull\npublic String getStuff() {\n    return stuff;\n}\n\n"
  },
  "2889": {
    "source_file": "pipeline-integration.txt",
    "text": "r.defaultStuff}\"/>\n</f:entry>\n\n@NonNull\nprivate String stuff = DescriptorImpl.defaultStuff;\n\n@NonNull\npublic String getStuff() {\n    return stuff;\n}\n\n@DataBoundSetter\npublic void setStuff(@NonNull String stuff) {\n    this.stuff = stuff;\n}\n\n@Extension\npublic static class DescriptorImpl extends Descriptor<Whatever> {\n    public static final String defaultStuff = \"junk\";\n    // \u2026\n}\n\nTIP: The `Descrip"
  },
  "2890": {
    "source_file": "pipeline-integration.txt",
    "text": "\npublic static class DescriptorImpl extends Descriptor<Whatever> {\n    public static final String defaultStuff = \"junk\";\n    // \u2026\n}\n\nTIP: The `Descriptor` is the most convenient place to put a constant for use from a Jelly view: `descriptor` is always\ndefined even if `instance` is null, and Jelly/JEXL allows a `static` field to be loaded using instance-field notation.\nFrom a Groovy view you could "
  },
  "2891": {
    "source_file": "pipeline-integration.txt",
    "text": "s\ndefined even if `instance` is null, and Jelly/JEXL allows a `static` field to be loaded using instance-field notation.\nFrom a Groovy view you could use any syntax supported by Java to refer to a constant, but Jelly in Jenkins is weaker:\n`getStatic` will not work on classes defined in plugins.\n\nTo make sure the field is omitted from the XStream form when unmodified, you can use the same `Descript"
  },
  "2892": {
    "source_file": "pipeline-integration.txt",
    "text": " will not work on classes defined in plugins.\n\nTo make sure the field is omitted from the XStream form when unmodified, you can use the same `Descriptor`\nand configuration form but _null_ out the default:\n\n@CheckForNull\nprivate String stuff;\n\n@NonNull\npublic String getStuff() {\n    return stuff == null ? DescriptorImpl.defaultStuff : stuff;\n}\n\n@DataBoundSetter\npublic void setStuff(@NonNull String "
  },
  "2893": {
    "source_file": "pipeline-integration.txt",
    "text": "l\npublic String getStuff() {\n    return stuff == null ? DescriptorImpl.defaultStuff : stuff;\n}\n\n@DataBoundSetter\npublic void setStuff(@NonNull String stuff) {\n    this.stuff = stuff.equals(DescriptorImpl.defaultStuff) ? null : stuff;\n}\n\nNone of these considerations apply to mandatory parameters with no default,\nwhich should be requested in the `@DataBoundConstructor` and have a simple getter.\n\nTIP"
  },
  "2894": {
    "source_file": "pipeline-integration.txt",
    "text": " considerations apply to mandatory parameters with no default,\nwhich should be requested in the `@DataBoundConstructor` and have a simple getter.\n\nTIP: You could still have a `default` in the configuration form as a hint to new users, as a complement to a\nfull description in `help-stuff.html`, but the value chosen will always be saved.\n\nIf your plugin ever stored secrets (such as passwords) in a p"
  },
  "2895": {
    "source_file": "pipeline-integration.txt",
    "text": " to a\nfull description in `help-stuff.html`, but the value chosen will always be saved.\n\nIf your plugin ever stored secrets (such as passwords) in a plain `String`-valued fields, it was already insecure\nand should at least have been using `Secret`.\n`Secret`-valued fields are more secure, but are not really appropriate for projects defined in source code,\nlike Pipeline jobs.\n\nInstead you should int"
  },
  "2896": {
    "source_file": "pipeline-integration.txt",
    "text": "Secret`-valued fields are more secure, but are not really appropriate for projects defined in source code,\nlike Pipeline jobs.\n\nInstead you should integrate with the plugin:credentials[Credentials plugin].\nThen your builder etc. would typically have a `credentialsId` field which just refers to the ID of the credentials.\n(The user can pick a mnemonic ID for use in scripted jobs.)\nTypically the `con"
  },
  "2897": {
    "source_file": "pipeline-integration.txt",
    "text": "a `credentialsId` field which just refers to the ID of the credentials.\n(The user can pick a mnemonic ID for use in scripted jobs.)\nTypically the `config.jelly` used in _Snippet Generator_ will have a `<c:select/>` control,\nbacked by a `doFillCredentialsId` web method on the `Descriptor` to enumerate credentials currently available\nof the intended type (such as `StandardUsernamePasswordCredentials"
  },
  "2898": {
    "source_file": "pipeline-integration.txt",
    "text": "ialsId` web method on the `Descriptor` to enumerate credentials currently available\nof the intended type (such as `StandardUsernamePasswordCredentials`) and perhaps restricted to some domain\n(such as a hostname obtained via a `@QueryParameter` from a nearby form field).\nAt runtime, you will look up the credentials by ID and use them.\n\nPlugins formerly using `Secret` will generally need to use an `"
  },
  "2899": {
    "source_file": "pipeline-integration.txt",
    "text": " nearby form field).\nAt runtime, you will look up the credentials by ID and use them.\n\nPlugins formerly using `Secret` will generally need to use an `@Initializer` to migrate the configuration of\nfreestyle projects to use Credentials instead.\n\nNOTE: The details of adopting Credentials are too numerous to list here. Please refer to Credentials plugin documentation\n\nBy default, scripts making use of"
  },
  "2900": {
    "source_file": "pipeline-integration.txt",
    "text": "The details of adopting Credentials are too numerous to list here. Please refer to Credentials plugin documentation\n\nBy default, scripts making use of your plugin will need to refer to the (simple) Java class name of the extension.\nFor example, if you defined\n\npublic class ForgetBuilder extends Builder implements SimpleBuildStep {\n    private final String what;\n\n    @DataBoundConstructor\n    publi"
  },
  "2901": {
    "source_file": "pipeline-integration.txt",
    "text": "u defined\n\npublic class ForgetBuilder extends Builder implements SimpleBuildStep {\n    private final String what;\n\n    @DataBoundConstructor\n    public ForgetBuilder(String what) {\n        this.what = what;\n    }\n\n    public String getWhat() {\n        return what;\n    }\n\n    @Override\n    public void perform(Run build,\n                        FilePath workspace,\n                        Launcher la"
  },
  "2902": {
    "source_file": "pipeline-integration.txt",
    "text": "  return what;\n    }\n\n    @Override\n    public void perform(Run build,\n                        FilePath workspace,\n                        Launcher launcher,\n                        TaskListener listener) throws InterruptedException, IOException {\n        listener.getLogger().println(\"What was \" + what + \"?\");\n    }\n\n    @Extension\n    public static class DescriptorImpl extends BuildStepDescriptor"
  },
  "2903": {
    "source_file": "pipeline-integration.txt",
    "text": "      listener.getLogger().println(\"What was \" + what + \"?\");\n    }\n\n    @Extension\n    public static class DescriptorImpl extends BuildStepDescriptor<Builder> {\n\n        @Override\n        public String getDisplayName() {\n            return \"Forget things\";\n        }\n\n        @Override\n        public boolean isApplicable(Class<? extends AbstractProject> t) {\n            return true;\n        }\n    "
  },
  "2904": {
    "source_file": "pipeline-integration.txt",
    "text": "hings\";\n        }\n\n        @Override\n        public boolean isApplicable(Class<? extends AbstractProject> t) {\n            return true;\n        }\n    }\n}\n\nthen scripts would use this builder as follows:\n\nstep([$class: 'ForgetBuilder', what: 'everything'])\n\nTo make for a more attractive and mnemonic usage style, you can depend on `org.jenkins-ci.plugins:structs`\nand add a `@Symbol` to your `Descrip"
  },
  "2905": {
    "source_file": "pipeline-integration.txt",
    "text": "ng'])\n\nTo make for a more attractive and mnemonic usage style, you can depend on `org.jenkins-ci.plugins:structs`\nand add a `@Symbol` to your `Descriptor`, uniquely identifying it among extensions of its kind\n(in this example, ``SimpleBuildStep``s):\n\n@Symbol(\"forget\")\n@Extension\npublic static class DescriptorImpl extends BuildStepDescriptor<Builder> {\n\nNow when users of sufficiently new versions o"
  },
  "2906": {
    "source_file": "pipeline-integration.txt",
    "text": "\n@Symbol(\"forget\")\n@Extension\npublic static class DescriptorImpl extends BuildStepDescriptor<Builder> {\n\nNow when users of sufficiently new versions of Pipeline wish to run your builder, they can use a shorter syntax:\n\nforget 'everything'\n\n``@Symbol``s are not limited to extensions used at \u201ctop level\u201d by metasteps such as `step`.\nAny `Descriptor` can have an associated symbol.\nTherefore if your pl"
  },
  "2907": {
    "source_file": "pipeline-integration.txt",
    "text": "`s are not limited to extensions used at \u201ctop level\u201d by metasteps such as `step`.\nAny `Descriptor` can have an associated symbol.\nTherefore if your plugin uses other ``Describable``s for any kind of structured configuration,\nyou should also annotate those implementations.\nFor example if you have defined an extension point\n\npublic abstract Timeframe extends AbstractDescribableImpl<Timeframe> implem"
  },
  "2908": {
    "source_file": "pipeline-integration.txt",
    "text": "those implementations.\nFor example if you have defined an extension point\n\npublic abstract Timeframe extends AbstractDescribableImpl<Timeframe> implements ExtensionPoint {\n    public abstract boolean areWeThereYet();\n}\n\nwith some implementations such as\n\n@Extension\npublic class Immediately extends Timeframe {\n    @DataBoundConstructor\n    public Immediately() {}\n\n    @Override\n    public boolean a"
  },
  "2909": {
    "source_file": "pipeline-integration.txt",
    "text": " as\n\n@Extension\npublic class Immediately extends Timeframe {\n    @DataBoundConstructor\n    public Immediately() {}\n\n    @Override\n    public boolean areWeThereYet() {\n        return true;\n    }\n\n    @Symbol(\"now\")\n    @Extension\n    public static DescriptorImpl extends Descriptor<Timeframe> {\n        @Override\n        public String getDisplayName() {\n            return \"Right now\";\n        }\n    }"
  },
  "2910": {
    "source_file": "pipeline-integration.txt",
    "text": "criptorImpl extends Descriptor<Timeframe> {\n        @Override\n        public String getDisplayName() {\n            return \"Right now\";\n        }\n    }\n}\n\nor\n\n@Extension\npublic class HoursAway extends Timeframe {\n    private final long hours;\n\n    @DataBoundConstructor\n    public HoursAway(long hours) {\n        this.hours = hours;\n    }\n\n    public long getHours() {\n        return hours;\n    }\n\n   "
  },
  "2911": {
    "source_file": "pipeline-integration.txt",
    "text": "taBoundConstructor\n    public HoursAway(long hours) {\n        this.hours = hours;\n    }\n\n    public long getHours() {\n        return hours;\n    }\n\n    @Override\n    public boolean areWeThereYet() {/* \u2026 */}\n\n    @Symbol(\"soon\")\n    @Extension\n    public static DescriptorImpl extends Descriptor<Timeframe> {\n        @Override\n        public String getDisplayName() {\n            return \"Pretty soon\";\n"
  },
  "2912": {
    "source_file": "pipeline-integration.txt",
    "text": "ic static DescriptorImpl extends Descriptor<Timeframe> {\n        @Override\n        public String getDisplayName() {\n            return \"Pretty soon\";\n        }\n    }\n}\n\nwhich are selectable in your configuration\n\nprivate Timeframe when = new Immediately();\n\npublic Timeframe getWhen() {\n    return when;\n}\n\n@DataBoundSetter\npublic void setWhen(Timeframe when) {\n    this.when = when;\n}\n\nthen a script"
  },
  "2913": {
    "source_file": "pipeline-integration.txt",
    "text": "ely();\n\npublic Timeframe getWhen() {\n    return when;\n}\n\n@DataBoundSetter\npublic void setWhen(Timeframe when) {\n    this.when = when;\n}\n\nthen a script could select a timeframe using the symbols you have defined:\n\nforget 'nothing' // whenever\nforget what: 'something', when: now()\nforget what: 'everything else', when: soon(1)\n\n_Snippet Generator_ will offer the simplified syntax wherever available.\n"
  },
  "2914": {
    "source_file": "pipeline-integration.txt",
    "text": "hat: 'something', when: now()\nforget what: 'everything else', when: soon(1)\n\n_Snippet Generator_ will offer the simplified syntax wherever available.\nFreestyle project configuration will ignore the symbol, though a future version of the Job DSL plugin may take advantage of it.\n\nNOTE: See the https://github.com/jenkinsci/workflow-scm-step-plugin/blob/master/README.md[user documentation] for backgro"
  },
  "2915": {
    "source_file": "pipeline-integration.txt",
    "text": "n may take advantage of it.\n\nNOTE: See the https://github.com/jenkinsci/workflow-scm-step-plugin/blob/master/README.md[user documentation] for background.\n\nThe `checkout` metastep uses an `SCM`.\n\nAs the author of an SCM plugin, there are some changes you should make to ensure your plugin can be used from pipelines.\nYou can use `mercurial-plugin` as a relatively straightforward code example.\n\nMake "
  },
  "2916": {
    "source_file": "pipeline-integration.txt",
    "text": " you should make to ensure your plugin can be used from pipelines.\nYou can use `mercurial-plugin` as a relatively straightforward code example.\n\nMake sure your Jenkins baseline is at least `1.568` (or `1.580.1`, the next LTS).\nCheck your plugin for compilation warnings relating to `hudson.scm.*` classes to see outstanding changes you need to make.\nMost importantly, various methods in `SCM` which f"
  },
  "2917": {
    "source_file": "pipeline-integration.txt",
    "text": "ompilation warnings relating to `hudson.scm.*` classes to see outstanding changes you need to make.\nMost importantly, various methods in `SCM` which formerly took an `AbstractBuild` now take a more generic `Run`\n(i.e., potentially a Pipeline build) plus a `FilePath` (i.e., a workspace).\nUse the specified workspace rather than the former `build.getWorkspace()`, which only worked for traditional\npro"
  },
  "2918": {
    "source_file": "pipeline-integration.txt",
    "text": "lus a `FilePath` (i.e., a workspace).\nUse the specified workspace rather than the former `build.getWorkspace()`, which only worked for traditional\nprojects with a single workspace.\nSimilarly, some methods formerly taking `AbstractProject` now take the more generic `Job`.\nBe sure to use `@Override` wherever possible to make sure you are using the right overloads.\n\nNOTE: `changelogFile` may now be n"
  },
  "2919": {
    "source_file": "pipeline-integration.txt",
    "text": "e more generic `Job`.\nBe sure to use `@Override` wherever possible to make sure you are using the right overloads.\n\nNOTE: `changelogFile` may now be null in `checkout`.\nIf so, just skip changelog generation.\n`checkout` also now takes an `SCMRevisionState` so you can know what to compare against without referring back to the build.\n\n`SCMDescriptor.isApplicable` should be switched to the `Job` overl"
  },
  "2920": {
    "source_file": "pipeline-integration.txt",
    "text": "tate` so you can know what to compare against without referring back to the build.\n\n`SCMDescriptor.isApplicable` should be switched to the `Job` overload.\nTypically you will unconditionally return `true`.\n\nYou should override the new `getKey`.\nThis allows a Pipeline job to match up checkouts from build to build so it knows how to look for changes.\n\nYou may override the new `guessBrowser`, so that "
  },
  "2921": {
    "source_file": "pipeline-integration.txt",
    "text": "llows a Pipeline job to match up checkouts from build to build so it knows how to look for changes.\n\nYou may override the new `guessBrowser`, so that scripts do not need to specify the changelog browser to display.\n\nIf you have a commit trigger, generally an `UnprotectedRootAction` which schedules builds, it will need a few changes.\nUse `SCMTriggerItem` rather than the deprecated `SCMedItem`;\nuse "
  },
  "2922": {
    "source_file": "pipeline-integration.txt",
    "text": "rally an `UnprotectedRootAction` which schedules builds, it will need a few changes.\nUse `SCMTriggerItem` rather than the deprecated `SCMedItem`;\nuse `SCMTriggerItem.SCMTriggerItems.asSCMTriggerItem` rather than checking `instanceof`.\nIts `getSCMs` method can be used to enumerate configured SCMs, which in the case of a pipeline will be those run in the last build.\nUse its `getSCMTrigger` method to"
  },
  "2923": {
    "source_file": "pipeline-integration.txt",
    "text": "ethod can be used to enumerate configured SCMs, which in the case of a pipeline will be those run in the last build.\nUse its `getSCMTrigger` method to look for a configured trigger (for example to check `isIgnorePostCommitHooks`).\n\nIdeally you will already be integrated with the `scm-api` plugin and implementing `SCMSource`; if not, now is a good time to try it.\nIn the future pipelines may take ad"
  },
  "2924": {
    "source_file": "pipeline-integration.txt",
    "text": "lready be integrated with the `scm-api` plugin and implementing `SCMSource`; if not, now is a good time to try it.\nIn the future pipelines may take advantage of this API to support automatic creation of subprojects for each detected branch.\n\nIf you want to provide a smoother experience for Pipeline users than is possible via the generic `scm` step,\nyou can add a (perhaps optional) dependency on `w"
  },
  "2925": {
    "source_file": "pipeline-integration.txt",
    "text": "ant to provide a smoother experience for Pipeline users than is possible via the generic `scm` step,\nyou can add a (perhaps optional) dependency on `workflow-scm-step` to your plugin.\nDefine a `SCMStep` using `SCMStepDescriptor` and you can define a friendly, script-oriented syntax.\nYou still need to make the aforementioned changes, since at the end you are just preconfiguring an `SCM`.\n\nNOTE: See"
  },
  "2926": {
    "source_file": "pipeline-integration.txt",
    "text": "friendly, script-oriented syntax.\nYou still need to make the aforementioned changes, since at the end you are just preconfiguring an `SCM`.\n\nNOTE: See the https://github.com/jenkinsci/workflow-basic-steps-plugin/blob/master/CORE-STEPS.md[user documentation] for background.\n\nThe metastep is `step`.\n\nTo add support for use of a `Builder` or `Publisher` from a pipeline,\nimplement `SimpleBuildStep`, f"
  },
  "2927": {
    "source_file": "pipeline-integration.txt",
    "text": "tation] for background.\n\nThe metastep is `step`.\n\nTo add support for use of a `Builder` or `Publisher` from a pipeline,\nimplement `SimpleBuildStep`, following the guidelines in https://javadoc.jenkins.io/jenkins/tasks/SimpleBuildStep.html[its Javadoc].\nAlso prefer ``@DataBoundSetter``s to a sprawling `@DataBoundConstructor` (see <<Constructor vs. setters>>).\n\nNote that if a freestyle `Builder` mer"
  },
  "2928": {
    "source_file": "pipeline-integration.txt",
    "text": "].\nAlso prefer ``@DataBoundSetter``s to a sprawling `@DataBoundConstructor` (see <<Constructor vs. setters>>).\n\nNote that if a freestyle `Builder` merely ran some external build tool,\nit should _not_ be translated this way.\nUser pipelines should run that tool from `sh` steps\n(directly, or indirectly in the middle of some longer script),\nand in many cases there is no need for any special Jenkins pl"
  },
  "2929": {
    "source_file": "pipeline-integration.txt",
    "text": "that tool from `sh` steps\n(directly, or indirectly in the middle of some longer script),\nand in many cases there is no need for any special Jenkins plugin at all.\nIf there is some special behavior in Jenkins itself which would benefit from a plugin,\ntypically this would be implemented as a block-scoped Pipeline step.\n\nNote that a `SimpleBuildStep` is designed to work also in a freestyle project, a"
  },
  "2930": {
    "source_file": "pipeline-integration.txt",
    "text": "typically this would be implemented as a block-scoped Pipeline step.\n\nNote that a `SimpleBuildStep` is designed to work also in a freestyle project, and thus assumes that a\n`FilePath workspace` is available (as well as some associated services, like a `Launcher`).\nThat is always true in a freestyle build, but is a potential limitation for use from a Pipeline build.\nFor example, you might legitimat"
  },
  "2931": {
    "source_file": "pipeline-integration.txt",
    "text": "a `Launcher`).\nThat is always true in a freestyle build, but is a potential limitation for use from a Pipeline build.\nFor example, you might legitimately want to take some action outside the context of any workspace:\n\nnode('win64') {\n  bat 'make all'\n  archive 'myapp.exe'\n}\ninput 'Ready to tell the world?' // could pause indefinitely, do not tie up an agent\nstep([$class: 'FunkyNotificationBuilder'"
  },
  "2932": {
    "source_file": "pipeline-integration.txt",
    "text": "\n  archive 'myapp.exe'\n}\ninput 'Ready to tell the world?' // could pause indefinitely, do not tie up an agent\nstep([$class: 'FunkyNotificationBuilder', artifact: 'myapp.exe']) // \u2190 FAILS!\n\nEven if `FunkyNotificationBuilder` implements `SimpleBuildStep`, the above will fail, because the `workspace` required by `SimpleBuildStep.perform` is missing.\nYou could grab an arbitrary workspace just to run t"
  },
  "2933": {
    "source_file": "pipeline-integration.txt",
    "text": "p`, the above will fail, because the `workspace` required by `SimpleBuildStep.perform` is missing.\nYou could grab an arbitrary workspace just to run the builder:\n\nnode('win64') {\n  bat 'make all'\n  archive 'myapp.exe'\n}\ninput 'Ready to tell the world?'\nnode {\n  step([$class: 'FunkyNotificationBuilder', artifact: 'myapp.exe']) // OK\n}\n\nbut if the `workspace` is being ignored anyway (in this case be"
  },
  "2934": {
    "source_file": "pipeline-integration.txt",
    "text": "?'\nnode {\n  step([$class: 'FunkyNotificationBuilder', artifact: 'myapp.exe']) // OK\n}\n\nbut if the `workspace` is being ignored anyway (in this case because `FunkyNotificationBuilder` only cares\nabout artifacts that have already been archived), it may be better to just write a custom step (described below).\n\nFor code which genuinely has to run after the build completes, there is `RunListener`.\nIf t"
  },
  "2935": {
    "source_file": "pipeline-integration.txt",
    "text": " be better to just write a custom step (described below).\n\nFor code which genuinely has to run after the build completes, there is `RunListener`.\nIf the behavior of this hook needs to be customizable at the job level, the usual technique would be to define a `JobProperty`.\n(One distinction from freestyle projects is that in the case of Pipeline there is no way to introspect the\n\u201clist of build step"
  },
  "2936": {
    "source_file": "pipeline-integration.txt",
    "text": "define a `JobProperty`.\n(One distinction from freestyle projects is that in the case of Pipeline there is no way to introspect the\n\u201clist of build steps\u201d or \u201clist of publishers\u201d or \u201clist of build wrappers\u201d so any decisions based on such metadata are impossible.)\n\nIn most other cases, you just want some code to run after some _portion_ of the build completes,\nwhich is typically handled with a `Publi"
  },
  "2937": {
    "source_file": "pipeline-integration.txt",
    "text": "mpossible.)\n\nIn most other cases, you just want some code to run after some _portion_ of the build completes,\nwhich is typically handled with a `Publisher` if you wish to share a code base with freestyle projects.\nFor regular ``Publisher``s, which are run as part of the build, a Pipeline script would use the `step` metastep.\nThere are two subtypes:\n\n* ``Recorder``s generally should be placed inlin"
  },
  "2938": {
    "source_file": "pipeline-integration.txt",
    "text": "e run as part of the build, a Pipeline script would use the `step` metastep.\nThere are two subtypes:\n\n* ``Recorder``s generally should be placed inline with other build steps in whatever order makes sense.\n* ``Notifier``s can be placed in a `finally` block, or you can use the `catchError` step.\n\nNOTE: https://github.com/jenkinsci/workflow-basic-steps-plugin/blob/master/CORE-STEPS.md#interacting-wi"
  },
  "2939": {
    "source_file": "pipeline-integration.txt",
    "text": " block, or you can use the `catchError` step.\n\nNOTE: https://github.com/jenkinsci/workflow-basic-steps-plugin/blob/master/CORE-STEPS.md#interacting-with-build-status[This document]\ngoes into depth.\n\nHere the metastep is `wrap`.\nTo add support for a `BuildWrapper`, depend on Jenkins `1.599+` (typically `1.609.1`), and implement `SimpleBuildWrapper`,\nfollowing the guidelines in https://javadoc.jenki"
  },
  "2940": {
    "source_file": "pipeline-integration.txt",
    "text": "BuildWrapper`, depend on Jenkins `1.599+` (typically `1.609.1`), and implement `SimpleBuildWrapper`,\nfollowing the guidelines in https://javadoc.jenkins.io/jenkins/tasks/SimpleBuildWrapper.html[its Javadoc].\n\nLike `SimpleBuildStep`, wrappers written this way always require a workspace.\nIf that would be constricting, consider writing a custom step instead.\n\nReplace `Trigger<AbstractProject>` with `"
  },
  "2941": {
    "source_file": "pipeline-integration.txt",
    "text": "this way always require a workspace.\nIf that would be constricting, consider writing a custom step instead.\n\nReplace `Trigger<AbstractProject>` with `Trigger<X>` where `X` is `Job` or perhaps `ParameterizedJob`\nor `SCMTriggerItem` and implement `TriggerDescriptor.isApplicable` accordingly.\n\nUse `EnvironmentContributor` rather than `RunListener.setUpEnvironment`.\n\nDo not necessarily need any specia"
  },
  "2942": {
    "source_file": "pipeline-integration.txt",
    "text": "gerDescriptor.isApplicable` accordingly.\n\nUse `EnvironmentContributor` rather than `RunListener.setUpEnvironment`.\n\nDo not necessarily need any special integration,\nbut \u201cone-shot\u201d-style agent implementations are encouraged to use `OnceRetentionStrategy` from `durable-task`\n(or otherwise use `ExecutorListener` and consider `ContinuableExecutable`)\nto allow Pipeline builds to survive restarts.\nYou s"
  },
  "2943": {
    "source_file": "pipeline-integration.txt",
    "text": "gy` from `durable-task`\n(or otherwise use `ExecutorListener` and consider `ContinuableExecutable`)\nto allow Pipeline builds to survive restarts.\nYou should _not_ implement `EphemeralNode` or listen to `Run` events.\n\nPlugins can also implement custom Pipeline steps with specialized behavior.\n\nNOTE: See https://github.com/jenkinsci/workflow-step-api-plugin/blob/master/README.md[here] for more.\n\nTrad"
  },
  "2944": {
    "source_file": "pipeline-integration.txt",
    "text": "Pipeline steps with specialized behavior.\n\nNOTE: See https://github.com/jenkinsci/workflow-step-api-plugin/blob/master/README.md[here] for more.\n\nTraditional Jenkins ``Job``s are defined in a fairly deep type hierarchy:\n`FreestyleProject` \u2192 `Project` \u2192 `AbstractProject` \u2192 `Job` \u2192 `AbstractItem` \u2192 `Item`.\n(As well as paired `Run` types: `FreestyleBuild`, etc.)\nIn older versions of Jenkins, much of "
  },
  "2945": {
    "source_file": "pipeline-integration.txt",
    "text": " \u2192 `AbstractProject` \u2192 `Job` \u2192 `AbstractItem` \u2192 `Item`.\n(As well as paired `Run` types: `FreestyleBuild`, etc.)\nIn older versions of Jenkins, much of the interesting implementation was in `AbstractProject` (or `AbstractBuild`),\nwhich was packed full of assorted features not present in `Job` (or `Run`).\nSome of these features were also needed by Pipeline, like having a programmatic way to start a b"
  },
  "2946": {
    "source_file": "pipeline-integration.txt",
    "text": "of assorted features not present in `Job` (or `Run`).\nSome of these features were also needed by Pipeline, like having a programmatic way to start a build (optionally with parameters),\nor lazy-load build records, or integrate with SCM triggers.\nOthers were not applicable to Pipeline, like declaring a single SCM and a single workspace per build,\nor being tied to a specific label, or running a linea"
  },
  "2947": {
    "source_file": "pipeline-integration.txt",
    "text": "s were not applicable to Pipeline, like declaring a single SCM and a single workspace per build,\nor being tied to a specific label, or running a linear sequence of build steps within the scope of a single Java method call,\nor having a simple list of build steps and wrappers whose configuration is guaranteed to remain the same from build to build.\n\n`WorkflowJob` directly extends `Job` since it cann"
  },
  "2948": {
    "source_file": "pipeline-integration.txt",
    "text": "build steps and wrappers whose configuration is guaranteed to remain the same from build to build.\n\n`WorkflowJob` directly extends `Job` since it cannot act like an `AbstractProject`.\nTherefore some refactoring was needed, to make the relevant features available to other `Job` types without code or API duplication.\nRather than introduce yet another level into the type hierarchy (and freezing for a"
  },
  "2949": {
    "source_file": "pipeline-integration.txt",
    "text": "es available to other `Job` types without code or API duplication.\nRather than introduce yet another level into the type hierarchy (and freezing for all time the decision about which\nfeatures are more \u201cgeneric\u201d than others), mixins were introduced.\nEach encapsulates a set of related functionality originally tied to `AbstractProject` but now also usable from\n`WorkflowJob` (and potentially other fut"
  },
  "2950": {
    "source_file": "pipeline-integration.txt",
    "text": "ach encapsulates a set of related functionality originally tied to `AbstractProject` but now also usable from\n`WorkflowJob` (and potentially other future `Job` types).\n\n* `ParameterizedJobMixIn` allows a job to be scheduled to the queue (the older `BuildableItem` was inadequate),\ntaking care also of build parameters and the REST build trigger.\n* `SCMTriggerItem` integrates with `SCMTrigger`, inclu"
  },
  "2951": {
    "source_file": "pipeline-integration.txt",
    "text": "uildableItem` was inadequate),\ntaking care also of build parameters and the REST build trigger.\n* `SCMTriggerItem` integrates with `SCMTrigger`, including a definition of which SCM or SCMs a job is using,\nand how it should perform polling. It also allows various plugins to interoperate with the Multiple SCMs plugin\nwithout needing an explicit dependency. Supersedes and deprecates `SCMedItem`.\n* `L"
  },
  "2952": {
    "source_file": "pipeline-integration.txt",
    "text": "lows various plugins to interoperate with the Multiple SCMs plugin\nwithout needing an explicit dependency. Supersedes and deprecates `SCMedItem`.\n* `LazyBuildMixIn` handles the plumbing of lazy-loading build records (a system introduced in Jenkins `1.485`).\n\nFor Pipeline compatibility, plugins formerly referring to `AbstractProject`/`AbstractBuild` will generally\nneed to start dealing with `Job`/`"
  },
  "2953": {
    "source_file": "pipeline-integration.txt",
    "text": ".485`).\n\nFor Pipeline compatibility, plugins formerly referring to `AbstractProject`/`AbstractBuild` will generally\nneed to start dealing with `Job`/`Run` but may also need to refer to `ParameterizedJobMixIn` and/or `SCMTriggerItem`.\n(`LazyBuildMixIn` is rarely needed from outside code, as the methods defined in `Job`/`Run` suffice for typical purposes.)\n\nFuture improvements to Pipeline may well r"
  },
  "2954": {
    "source_file": "pipeline-integration.txt",
    "text": "` is rarely needed from outside code, as the methods defined in `Job`/`Run` suffice for typical purposes.)\n\nFuture improvements to Pipeline may well require yet more implementation code to be extracted from `AbstractProject`/`AbstractBuild`.\nThe main constraint is the need to retain binary compatibility."
  },
  "2955": {
    "source_file": "pipeline-integration.txt",
    "text": " constraint is the need to retain binary compatibility."
  },
  "2956": {
    "source_file": "pipeline-run-details.txt",
    "text": "layout: section\ntitle: Pipeline Run Details View\n\n\nifdef::env-github[:imagesdir: ../resources]\nifndef::env-github[:imagesdir: ../../resources]\n\n// Show 1/3 of the Blue ocean admonitions\n// :pipeline-visualization-admonition: true\n// :pipeline-creation-admonition: true\n\nThe Blue Ocean Pipeline Run Details view shows the information related to a single Pipeline Run, and allows users to edit or repla"
  },
  "2957": {
    "source_file": "pipeline-run-details.txt",
    "text": "n-admonition: true\n\nThe Blue Ocean Pipeline Run Details view shows the information related to a single Pipeline Run, and allows users to edit or replay that run.\nBelow is a detailed overview of the parts of the Run Details view.\n\n*Run Status* - An icon indicating the status of this Pipeline run.\nThe color of the navigation bar matches the status icon.\n*Pipeline Name* - The name of this run's Pipel"
  },
  "2958": {
    "source_file": "pipeline-run-details.txt",
    "text": "on indicating the status of this Pipeline run.\nThe color of the navigation bar matches the status icon.\n*Pipeline Name* - The name of this run's Pipeline.\n*Run Number* - The id number for this Pipeline run.\nId numbers are unique for each Branch and Pull Request of a Pipeline.\n*View Tabs* - Access the *Pipeline*, *Changes*, *Tests*, and *Artifacts* views with one of the <<tabs, tabs>> for this run."
  },
  "2959": {
    "source_file": "pipeline-run-details.txt",
    "text": "ull Request of a Pipeline.\n*View Tabs* - Access the *Pipeline*, *Changes*, *Tests*, and *Artifacts* views with one of the <<tabs, tabs>> for this run.\nThe default view is \"<<pipeline, Pipeline>>\".\n*Re-run Pipeline* - Execute this run's Pipeline again.\n*Edit Pipeline* - Open this run's Pipeline in the <<pipeline-editor#, Pipeline Editor>>.\n*Configure* - Open the Pipeline configuration page in Jenki"
  },
  "2960": {
    "source_file": "pipeline-run-details.txt",
    "text": ".\n*Edit Pipeline* - Open this run's Pipeline in the <<pipeline-editor#, Pipeline Editor>>.\n*Configure* - Open the Pipeline configuration page in Jenkins.\n*Go to Classic* - Switch to the \"Classic\" UI view of the details for this run.\n*Close Details* - Closes the Details view and returns the user to the <<activity#, Activity view>> for this Pipeline.\n*Branch* or *Pull Request* - The branch or pull r"
  },
  "2961": {
    "source_file": "pipeline-run-details.txt",
    "text": " Closes the Details view and returns the user to the <<activity#, Activity view>> for this Pipeline.\n*Branch* or *Pull Request* - The branch or pull request for this run.\n*Commit Id* - The commit id for this run.\n*Duration* - The duration of this run.\n*Completed Time* - When this run was completed.\n*Change Author* - Names of the authors with changes in this run.\n*Tab View* - Shows the information "
  },
  "2962": {
    "source_file": "pipeline-run-details.txt",
    "text": ".\n*Completed Time* - When this run was completed.\n*Change Author* - Names of the authors with changes in this run.\n*Tab View* - Shows the information for the selected tab.\n\nBlue Ocean makes it easy to see the status of the current Pipeline Run, by changing the color of the top menu bar to match the status:\n\n* Blue for \"In progress\"\n* Green for \"Passed\"\n* Yellow for \"Unstable\"\n* Red for \"Failed\"\n* "
  },
  "2963": {
    "source_file": "pipeline-run-details.txt",
    "text": "anging the color of the top menu bar to match the status:\n\n* Blue for \"In progress\"\n* Green for \"Passed\"\n* Yellow for \"Unstable\"\n* Red for \"Failed\"\n* Gray for \"Aborted\"\n\nBlue Ocean is optimized for working with Pipelines in Source Control, but can display details for other kinds of projects.\nBlue Ocean offers the same <<tabs, tabs>> for all supported projects types, but those tabs display differen"
  },
  "2964": {
    "source_file": "pipeline-run-details.txt",
    "text": "splay details for other kinds of projects.\nBlue Ocean offers the same <<tabs, tabs>> for all supported projects types, but those tabs display different information depending on the type.\n\nFor Pipelines that are not based in Source Control, Blue Ocean shows the \"Commit Id\", \"Branch\", and \"Changes\", but those fields are left blank.\nIn this case, the top menu bar does not include the \"Edit\" option.\n\n"
  },
  "2965": {
    "source_file": "pipeline-run-details.txt",
    "text": " shows the \"Commit Id\", \"Branch\", and \"Changes\", but those fields are left blank.\nIn this case, the top menu bar does not include the \"Edit\" option.\n\nFor Freestyle projects, Blue Ocean offers the same <<tabs, tabs>>, but the Pipeline tab only displays the console log output.\nThe \"Rerun\" or \"Edit\" options are not available in the top menu bar.\n\nMatrix projects are not supported in Blue Ocean.\nViewi"
  },
  "2966": {
    "source_file": "pipeline-run-details.txt",
    "text": "s the console log output.\nThe \"Rerun\" or \"Edit\" options are not available in the top menu bar.\n\nMatrix projects are not supported in Blue Ocean.\nViewing a Matrix project will redirect to the \"Classic UI\" view for that project.\n\nEach tab of the Run Detail view provides information on a specific aspect of a run.\n\n*Pipeline* is the default tab and gives an overall view of the flow of this Pipeline Ru"
  },
  "2967": {
    "source_file": "pipeline-run-details.txt",
    "text": "tail view provides information on a specific aspect of a run.\n\n*Pipeline* is the default tab and gives an overall view of the flow of this Pipeline Run.\nIt shows each stage and parallel branch, the steps in those stages, and the console output from those steps.\nThe overview image above shows a successful Pipeline run.\nIf a particular step during the run fails, this tab automatically defaults to sh"
  },
  "2968": {
    "source_file": "pipeline-run-details.txt",
    "text": "hose steps.\nThe overview image above shows a successful Pipeline run.\nIf a particular step during the run fails, this tab automatically defaults to showing the console log from the failed step.\nThe image below shows a failed Run.\n\nThe *Changes* tab displays the information of any changes made between the most recently completed and current runs.\nThis includes the commit id for the change, change a"
  },
  "2969": {
    "source_file": "pipeline-run-details.txt",
    "text": "isplays the information of any changes made between the most recently completed and current runs.\nThis includes the commit id for the change, change author, message, and date completed.\n\nThe *Tests* tab shows information about test results for this run.\nThis tab only contains information if a test result publishing step is present, such as the \"Publish JUnit test results\" (`junit`) step.\nIf no res"
  },
  "2970": {
    "source_file": "pipeline-run-details.txt",
    "text": "un.\nThis tab only contains information if a test result publishing step is present, such as the \"Publish JUnit test results\" (`junit`) step.\nIf no results are recorded, this table displays a message.\nIf all tests pass, this tab will report the total number of passing tests.\nIf there are failures, the tab will display log details from the failures as shown below.\n\nWhen a previous run has failures, "
  },
  "2971": {
    "source_file": "pipeline-run-details.txt",
    "text": "number of passing tests.\nIf there are failures, the tab will display log details from the failures as shown below.\n\nWhen a previous run has failures, and the current run fixes those failures, this tab notes the fixes and displays their logs.\n\nThe *Artifacts* tab shows a list of any artifacts saved using the \"Archive Artifacts\" (`archiveArtifacts`) step.\nSelecting an item in the list downloads it.\n"
  },
  "2972": {
    "source_file": "pipeline-run-details.txt",
    "text": "tifacts* tab shows a list of any artifacts saved using the \"Archive Artifacts\" (`archiveArtifacts`) step.\nSelecting an item in the list downloads it.\nThe full output log from the Run can be downloaded from this list."
  },
  "2973": {
    "source_file": "pluggable-storage.txt",
    "text": "layout: section\ntitle: \"Pluggable Storage\"\nsummary: Storage alternatives for artifacts, build logs, credentials, test results, and fingerprints\ntags:\n- pluggable-storage\n- cloud-native\n- cloud-native-sig\n- external-logging\n- external-artifacts\n\n\nThe current default approach of storing everything into the filesystem is the main reason why Jenkins does not fit the \"Cloud Native\" model, with features"
  },
  "2974": {
    "source_file": "pluggable-storage.txt",
    "text": "current default approach of storing everything into the filesystem is the main reason why Jenkins does not fit the \"Cloud Native\" model, with features like high availability, zero downtime, or pay per use.\nWhile there are plenty of plugins that implement parts of this vision, this becomes cumbersome to configure and a usability nightmare for users, as jep:300[] has pointed out.\nGoing towards a mod"
  },
  "2975": {
    "source_file": "pluggable-storage.txt",
    "text": "ment parts of this vision, this becomes cumbersome to configure and a usability nightmare for users, as jep:300[] has pointed out.\nGoing towards a model where cloud services are consumed where it makes sense, the overall complexity on operating Jenkins in a cloud or containerized environment is greatly reduced.\nOther related projects would greatly benefit from cloud native storage for Jenkins.\n\nTh"
  },
  "2976": {
    "source_file": "pluggable-storage.txt",
    "text": "ns in a cloud or containerized environment is greatly reduced.\nOther related projects would greatly benefit from cloud native storage for Jenkins.\n\nThere are several clear areas open for improvement.\nA major pain point is the usage of local disk as all-purpose storage, which causes issues running on containerized or distributed environments, requiring highly performant filesystems, and all the con"
  },
  "2977": {
    "source_file": "pluggable-storage.txt",
    "text": "ll-purpose storage, which causes issues running on containerized or distributed environments, requiring highly performant filesystems, and all the configuration pain like initial sizing and resizing with downtime.\nWe believe that by using cloud provided services the overall usability, performance and scalability can be improved while enabling new demanded functionality.\n\nYou can find more informat"
  },
  "2978": {
    "source_file": "pluggable-storage.txt",
    "text": "ded services the overall usability, performance and scalability can be improved while enabling new demanded functionality.\n\nYou can find more information about Pluggable Storage and priorities\nin .\n\nBelow you can find a summary of ongoing activities and their current status:\n\n[frame=\"topbot\",grid=\"all\",options=\"header\", cols=\"20%,50%,30%\"]\n|========================================================="
  },
  "2979": {
    "source_file": "pluggable-storage.txt",
    "text": "and their current status:\n\n[frame=\"topbot\",grid=\"all\",options=\"header\", cols=\"20%,50%,30%\"]\n|=========================================================\n|Type / Status | Comment | Implementation(s)\n\n| **Artifacts** +\n  **(Available)**\n| Fully delivered, with support for uploading artifacts directly from agents.\n  Related JEPs: jep:202[].\n\n| plugin:artifact-manager-s3[Artifact Manager on S3],\n  plugi"
  },
  "2980": {
    "source_file": "pluggable-storage.txt",
    "text": ", with support for uploading artifacts directly from agents.\n  Related JEPs: jep:202[].\n\n| plugin:artifact-manager-s3[Artifact Manager on S3],\n  plugin:azure-artifact-manager[Azure Artifact Manager],\n\n| **Credentials** +\n  **(Available)**\n| Completed before the JEP process was introduced.\n\n| plugin:kubernetes-credentials-provider[Kubernetes Credentials Provider],\n  plugin:aws-secrets-manager-crede"
  },
  "2981": {
    "source_file": "pluggable-storage.txt",
    "text": " before the JEP process was introduced.\n\n| plugin:kubernetes-credentials-provider[Kubernetes Credentials Provider],\n  plugin:aws-secrets-manager-credentials-provider[AWS Secrets Manager Credentials Provider],\n\n| Build logs +\n  (Preview / Paused)\n| Pipeline Log Storage API and reference implementations are available for preview, only Jenkins Pipeline job types are supported.\n  Related JEP: jep:210["
  },
  "2982": {
    "source_file": "pluggable-storage.txt",
    "text": "peline Log Storage API and reference implementations are available for preview, only Jenkins Pipeline job types are supported.\n  Related JEP: jep:210[].\n\n  Jenkins core APIs and reference implementations have not been merged/released yet,\n  but prototypes are available for evaluation.\n  Related JEPs: jep:207[], jep:212[]\na| Pipeline logging:\n\n* https://github.com/jenkinsci/pipeline-cloudwatch-logs"
  },
  "2983": {
    "source_file": "pluggable-storage.txt",
    "text": "types are available for evaluation.\n  Related JEPs: jep:207[], jep:212[]\na| Pipeline logging:\n\n* https://github.com/jenkinsci/pipeline-cloudwatch-logs-plugin[AWS CloudWatch]\n* https://github.com/SAP/elasticsearch-logs-plugin[Elasticsearch]\n\nJenkins core:\n\n* https://github.com/jenkinsci/external-logging-api-plugin[External Logging API]\n* https://github.com/jenkinsci/external-logging-elasticsearch-p"
  },
  "2984": {
    "source_file": "pluggable-storage.txt",
    "text": "ore:\n\n* https://github.com/jenkinsci/external-logging-api-plugin[External Logging API]\n* https://github.com/jenkinsci/external-logging-elasticsearch-plugin[Elasticsearch]\n\n| **System logs** +\n  **(Available)**\n| Jenkins supports custom log appenders using standard `java.util.logging`\n  .\n| plugin:syslog-logger[Syslog logger],\n  non-Jenkins implementation\n\n| Task logs +\n  (Not started)\n| Storage of"
  },
  "2985": {
    "source_file": "pluggable-storage.txt",
    "text": "using standard `java.util.logging`\n  .\n| plugin:syslog-logger[Syslog logger],\n  non-Jenkins implementation\n\n| Task logs +\n  (Not started)\n| Storage of system logs and various tasks (e.g. agent connection or SCM polling)\n| N/A\n\n| Configurations +\n  (Paused)\n| Largely replaced by the plugin:configuration-as-code[Configuration as Code] plugin\n  which allows storing Jenkins configurations in SCM or ot"
  },
  "2986": {
    "source_file": "pluggable-storage.txt",
    "text": "aused)\n| Largely replaced by the plugin:configuration-as-code[Configuration as Code] plugin\n  which allows storing Jenkins configurations in SCM or other locations without a database.\n\n  Related JEPs: jep:213[]\n| N/A\n\n| **Test Results** +\n  **(Available)**\n| API is available in plugin:junit[JUnit Plugin].\n| plugin:junit-sql-storage[Junit SQL Storage]\n\n| Code Coverage results +\n  (Not started)\n| Pl"
  },
  "2987": {
    "source_file": "pluggable-storage.txt",
    "text": "ble)**\n| API is available in plugin:junit[JUnit Plugin].\n| plugin:junit-sql-storage[Junit SQL Storage]\n\n| Code Coverage results +\n  (Not started)\n| Planned only for plugins based on plugin:code-coverage-api[Code Coverage API] which unifies the storage implementation.\n  See _Runs_ for other coverage report types.\n| N/A\n\n| Builds/Runs +\n  (Not started)\n| Storage of full build records in an external "
  },
  "2988": {
    "source_file": "pluggable-storage.txt",
    "text": "e implementation.\n  See _Runs_ for other coverage report types.\n| N/A\n\n| Builds/Runs +\n  (Not started)\n| Storage of full build records in an external database.\n  Includes storing build data which is not otherwise listed (such as logs or test results).\n| N/A\n\n| Jobs +\n  (Not started)\n| Storage of Job configurations and job-specific metadata in an external database.\n  Existing plugins like Jenkins P"
  },
  "2989": {
    "source_file": "pluggable-storage.txt",
    "text": ".\n| N/A\n\n| Jobs +\n  (Not started)\n| Storage of Job configurations and job-specific metadata in an external database.\n  Existing plugins like Jenkins Pipeline and JobDSL partially address this case\n  by keeping configurations in SCM.\n| N/A\n\n| **Fingerprints** +\n  **(Preview)**\n| Jenkins 2.252+ include the external fingerprint storage API which can be consumed by plugins.\n  More info:\n\n  Related JEP"
  },
  "2990": {
    "source_file": "pluggable-storage.txt",
    "text": "prints** +\n  **(Preview)**\n| Jenkins 2.252+ include the external fingerprint storage API which can be consumed by plugins.\n  More info:\n\n  Related JEPs: jep:226[]\n| plugin:redis-fingerprint-storage[Redis],\n\n| Workspaces +\n  (Not started)\n| Proposed as a GSoC 2019 project:\n\n| N/A\n\n|=========================================================\n\nThe list above is not complete.\nOther storage types may be "
  },
  "2991": {
    "source_file": "pluggable-storage.txt",
    "text": "s a GSoC 2019 project:\n\n| N/A\n\n|=========================================================\n\nThe list above is not complete.\nOther storage types may be considered according to the feedback.\nYou can find more information about Pluggable Storage and priorities\nin .\n\nThere are many existing plugins allowing to upload and download artifacts from external storage\n(e.g. S3, Artifactory, Publish over SFTP,"
  },
  "2992": {
    "source_file": "pluggable-storage.txt",
    "text": "rities\nin .\n\nThere are many existing plugins allowing to upload and download artifacts from external storage\n(e.g. S3, Artifactory, Publish over SFTP, etc., etc.),\nbut there are no plugins which can do it transparently without using\nnew steps.\nIn many cases the artifacts also get uploaded through the Jenkins controller,\nand it increases load on the system.\nIt would be great if there was a layer wh"
  },
  "2993": {
    "source_file": "pluggable-storage.txt",
    "text": "y cases the artifacts also get uploaded through the Jenkins controller,\nand it increases load on the system.\nIt would be great if there was a layer which would allow storing artifacts externally\nwhen using common steps like _Archive Artifacts_.\n\nJenkins 2.118+ offers an extended jenkinsdoc:jenkins.util.VirtualFile[] API\nwhich allows implementing external artifact managers using the\n\nextension poin"
  },
  "2994": {
    "source_file": "pluggable-storage.txt",
    "text": "ins 2.118+ offers an extended jenkinsdoc:jenkins.util.VirtualFile[] API\nwhich allows implementing external artifact managers using the\n\nextension point.\n\nImplementation example(s):\n\n* plugin:artifact-manager-s3[Artifact Manager for S3]\n\nRelated JEPs:\n\n* jep:202[External Artifact Storage]\n\nLogs disk usage causes the same issues previously mentioned for artifacts.\nPlus an external focused log storag"
  },
  "2995": {
    "source_file": "pluggable-storage.txt",
    "text": "\n\n* jep:202[External Artifact Storage]\n\nLogs disk usage causes the same issues previously mentioned for artifacts.\nPlus an external focused log storage such as https://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/WhatIsCloudWatchLogs.html[AWS CloudWatch Logs] allows demanded features as centralized log management, log retention policies, advanced querying, etc.\nThere are already options to ext"
  },
  "2996": {
    "source_file": "pluggable-storage.txt",
    "text": "udWatch Logs] allows demanded features as centralized log management, log retention policies, advanced querying, etc.\nThere are already options to externally ship the logs to a backend, or plugins that would do that like the  https://github.com/jenkinsci/aws-cloudwatch-logs-publisher-plugin[aws-cloudwatch-logs-publisher-plugin], but there is no integrated way to both send and display logs from ext"
  },
  "2997": {
    "source_file": "pluggable-storage.txt",
    "text": "nsci/aws-cloudwatch-logs-publisher-plugin[aws-cloudwatch-logs-publisher-plugin], but there is no integrated way to both send and display logs from external log storage.\nThe External log storage work is tracked as jira:JENKINS-38313[].\n\nReference implementation(s):\n\n*\n*\n\nRelated JEPs:\n\n* jep:207[External Build Logging support in the Jenkins Core]\n* jep:210[External log storage for Pipeline]\n* jep:2"
  },
  "2998": {
    "source_file": "pluggable-storage.txt",
    "text": "ementation(s):\n\n*\n*\n\nRelated JEPs:\n\n* jep:207[External Build Logging support in the Jenkins Core]\n* jep:210[External log storage for Pipeline]\n* jep:212[External Logging API Plugin]\n* jep:206[Use UTF-8 for Pipeline build logs]\n\nAlthough configurations are not big, externalizing them is a critical task\nfor getting highly-available or disposable Jenkins controllers.\nThere are many ways to store conf"
  },
  "2999": {
    "source_file": "pluggable-storage.txt",
    "text": "s are not big, externalizing them is a critical task\nfor getting highly-available or disposable Jenkins controllers.\nThere are many ways to store configurations in Jenkins,\nbut 95% of cases are covered by the `XmlFile` layer which\nserializes objects to disk and reads them using the XStream library.\nExternalizing these ``XmlFile``s would be a great step forward.\n\nThere are several prototypes for ex"
  },
  "3000": {
    "source_file": "pluggable-storage.txt",
    "text": "to disk and reads them using the XStream library.\nExternalizing these ``XmlFile``s would be a great step forward.\n\nThere are several prototypes for externalizing configurations, e.g. in DotCI.\nThere are also other implementations which could be upstreamed to the Jenkins core.\n\nRelated JEPs:\n\n* jep:213[Configuration Storage API in the Jenkins Core]\n\nIn plugin:credentials[Credentials Plugin] 1.15+ t"
  },
  "3001": {
    "source_file": "pluggable-storage.txt",
    "text": "eamed to the Jenkins core.\n\nRelated JEPs:\n\n* jep:213[Configuration Storage API in the Jenkins Core]\n\nIn plugin:credentials[Credentials Plugin] 1.15+ there\nis a\nextension point which allows referencing and resolving external credentials.\nThis engine allows implementing external credentials for plugins implementing Credentials API..\n\nImplementation example(s):\n\n* plugin:kubernetes-credentials-provid"
  },
  "3002": {
    "source_file": "pluggable-storage.txt",
    "text": "llows implementing external credentials for plugins implementing Credentials API..\n\nImplementation example(s):\n\n* plugin:kubernetes-credentials-provider[Kubernetes Credentials Provider]\n\nOther credentials API in Jenkins (like jenkinsdoc:hudson.util.Secret) are not supported.\n\nIn common CI/CD use-cases a lot of the space is being consumed by test reports.\nThis data is stored within `JENKINS_HOME`,\n"
  },
  "3003": {
    "source_file": "pluggable-storage.txt",
    "text": "ecret) are not supported.\n\nIn common CI/CD use-cases a lot of the space is being consumed by test reports.\nThis data is stored within `JENKINS_HOME`,\nand the current storage format requires huge overheads when retrieving statistics and, especially, trends.\nIn order to display trends, each report has to be loaded and then processed in-memory.\n\nThe main purpose of externalising Test Results is to op"
  },
  "3004": {
    "source_file": "pluggable-storage.txt",
    "text": "rends.\nIn order to display trends, each report has to be loaded and then processed in-memory.\n\nThe main purpose of externalising Test Results is to optimize Jenkins logic\nby querying the desired data from specialized external storages,\ne.g. from Document-based databases like Elasticsearch.\nAccording to the current plan, plugin:junit[JUnit Plugin] will be extended\nin order to support such external "
  },
  "3005": {
    "source_file": "pluggable-storage.txt",
    "text": "ment-based databases like Elasticsearch.\nAccording to the current plan, plugin:junit[JUnit Plugin] will be extended\nin order to support such external storage in its APIs being widely used by test reporting plugins.\n\nStatus:\n\n* A SQL implementation is available https://plugins.jenkins.io/junit-sql-storage/[Junit SQL Storage] plugin.\n\nPlease try it out, report issues to  and general feedback to .\n\nT"
  },
  "3006": {
    "source_file": "pluggable-storage.txt",
    "text": " available https://plugins.jenkins.io/junit-sql-storage/[Junit SQL Storage] plugin.\n\nPlease try it out, report issues to  and general feedback to .\n\nThe fingerprints are stored within `JENKINS_HOME` inside a local XML-based database.\nExternalizing fingerprints decreases the dependence of Jenkins on the physical disk storage of the controller, and allows configuring of cloud storages which can be c"
  },
  "3007": {
    "source_file": "pluggable-storage.txt",
    "text": "ngerprints decreases the dependence of Jenkins on the physical disk storage of the controller, and allows configuring of cloud storages which can be cheaper, and more reliable.\nAnother advantage is that it would allow tracing fingerprints across Jenkins controllers and the entire CI/CD flow.\n\nStatus:\n\n* In progress\n* Related JEP: jep:226[External Fingerprint Storage]\n*\n* Reference Implementation:"
  },
  "3008": {
    "source_file": "pluggable-storage.txt",
    "text": "ins controllers and the entire CI/CD flow.\n\nStatus:\n\n* In progress\n* Related JEP: jep:226[External Fingerprint Storage]\n*\n* Reference Implementation:"
  },
  "3009": {
    "source_file": "plugin-release-tips.txt",
    "text": "layout: developersection\ntitle: Plugin Release Tips\n\n\nBefore you release a plugin, you should exercise it in ways that you probably didn't try while you were developing.\nWalking through these steps yourself can save you a first round of bug reports from your users, and thus make your plugin higher quality and lower cost to deploy.\n\nBe sure to test the plugin with agent nodes running on remote mach"
  },
  "3010": {
    "source_file": "plugin-release-tips.txt",
    "text": "rom your users, and thus make your plugin higher quality and lower cost to deploy.\n\nBe sure to test the plugin with agent nodes running on remote machines before you release.\n\nWatch the Jenkins console (not just the build output) for exceptions.\n\nJust testing a plugin with `mvn hpi:run` is insufficient. It will not expose classloader issues.\nRun Jenkins with `java -jar jenkins.war` and install you"
  },
  "3011": {
    "source_file": "plugin-release-tips.txt",
    "text": "t testing a plugin with `mvn hpi:run` is insufficient. It will not expose classloader issues.\nRun Jenkins with `java -jar jenkins.war` and install your plugin into it.\n\nTest a new plugin in a non-production clone of a production server, with the actual projects that the plugin will run on in production.\nOften plugin bugs are revealed by real data that weren't revealed by test data.\nBeware hubris! "
  },
  "3012": {
    "source_file": "plugin-release-tips.txt",
    "text": "al projects that the plugin will run on in production.\nOften plugin bugs are revealed by real data that weren't revealed by test data.\nBeware hubris! When you are testing a plugin and trying to simulate real-world usage, you have to restart Jenkins whenever you think you've got a release candidate.\nDoing this on a production server will aggravate users and make Jenkins look flaky.\n\nIf you don't cu"
  },
  "3013": {
    "source_file": "plugin-release-tips.txt",
    "text": "henever you think you've got a release candidate.\nDoing this on a production server will aggravate users and make Jenkins look flaky.\n\nIf you don't cut releases via  yet, we recommend using GitHub releases for release notes.\nThe  has a native integration with GitHub releases, making it easier for users to keep track of changes in the plugin.\nSimply add the \"Publish changelogs to GitHub Release\" wo"
  },
  "3014": {
    "source_file": "plugin-release-tips.txt",
    "text": "tion with GitHub releases, making it easier for users to keep track of changes in the plugin.\nSimply add the \"Publish changelogs to GitHub Release\" workflow to your repository, by replacing \"yourPlugin\" with your plugin name: `https://github.com/jenkinsci/yourPlugin/actions/new` and follow the steps in the workflow.\nPublishing release notes in a separate file, such as \"Changes.md\", is considered d"
  },
  "3015": {
    "source_file": "plugin-release-tips.txt",
    "text": "insci/yourPlugin/actions/new` and follow the steps in the workflow.\nPublishing release notes in a separate file, such as \"Changes.md\", is considered dated and not recommended.\nGitHub releases allow users to quickly view what has changed, including new features or bug fixes.\nThat makes it easier for them to decide whether to upgrade."
  },
  "3016": {
    "source_file": "plugin-release-tips.txt",
    "text": "w features or bug fixes.\nThat makes it easier for them to decide whether to upgrade."
  },
  "3017": {
    "source_file": "plugin-site.txt",
    "text": "title: Plugin Site\nlayout: developersection\nreferences:\n- url: https://plugins.jenkins.io/\n  title: Plugin site\n- url: ../documentation/\n  title: Plugin documentation\n\n\nThis page explains how https://plugins.jenkins.io/[the plugins site]\nworks.\n\nThis is not a manual on how to _use_ the site to e.g. find plugins, but\nrather explains how it gets its data and how plugin developers can\nchange the data"
  },
  "3018": {
    "source_file": "plugin-site.txt",
    "text": " is not a manual on how to _use_ the site to e.g. find plugins, but\nrather explains how it gets its data and how plugin developers can\nchange the data on it.\n\nAll plugins published to the current (weekly) update center are listed.\n\nThis uses the monthly data from https://stats.jenkins.io as gathered\nfrom Jenkins controllers that have not opted out of reporting data.\n\nLearn more on the .\n\nThis rank"
  },
  "3019": {
    "source_file": "plugin-site.txt",
    "text": "hly data from https://stats.jenkins.io as gathered\nfrom Jenkins controllers that have not opted out of reporting data.\n\nLearn more on the .\n\nThis ranks plugins by the number of different Jenkins controllers that\nreported the plugin installed during the previous month.\n\nThis is based on metadata created by the update site generator, which\nuses the creation date of a plugin release.\n\nNote that very "
  },
  "3020": {
    "source_file": "plugin-site.txt",
    "text": "he previous month.\n\nThis is based on metadata created by the update site generator, which\nuses the creation date of a plugin release.\n\nNote that very recent plugin releases may not appear here due to caching\nand delays in data aggregation.\n\nThis is an attempt to capture the plugins whose popularity is growing\nrapidly.\nAs we only have the monthly installation stats for this, it's\nnecessarily a wors"
  },
  "3021": {
    "source_file": "plugin-site.txt",
    "text": "n attempt to capture the plugins whose popularity is growing\nrapidly.\nAs we only have the monthly installation stats for this, it's\nnecessarily a worse approximation than what you'd likely see e.g. in app\nstores.\n\nCurrently (2019-10) this just divides the previous month's install count\nby the month before that.\nPlugins with the greatest numbers are shown in\ndescending order.\n\nCategories are based "
  },
  "3022": {
    "source_file": "plugin-site.txt",
    "text": "s the previous month's install count\nby the month before that.\nPlugins with the greatest numbers are shown in\ndescending order.\n\nCategories are based on\n in the  GitHub repository.\n\nSee  for further documentation.\n\nPlugin labels are assigned to plugin repositories by their maintainers as .\nGitHub topics that match entries from the  are displayed on the plugin site.\nThe  includes instructions for ,"
  },
  "3023": {
    "source_file": "plugin-site.txt",
    "text": "n repositories by their maintainers as .\nGitHub topics that match entries from the  are displayed on the plugin site.\nThe  includes instructions for , categorizing, and  plugins.\n\nThe plugin site will pull content from a specified Markdown or AsciiDoc file in plugin's GitHub repository, defaulting to the README file.\nSee  for\nhow to configure GitHub documentation.\n\nNOTE: In the past it was possibl"
  },
  "3024": {
    "source_file": "plugin-site.txt",
    "text": "c file in plugin's GitHub repository, defaulting to the README file.\nSee  for\nhow to configure GitHub documentation.\n\nNOTE: In the past it was possible to use Jenkins Wiki as the source of documentation.\nAfter the wiki shutdown the contents are still available, but maintainers are encouraged to .\n\nThese are taken from the plugin's latest released version's metadata,\nand additionally (if not redund"
  },
  "3025": {
    "source_file": "plugin-site.txt",
    "text": " available, but maintainers are encouraged to .\n\nThese are taken from the plugin's latest released version's metadata,\nand additionally (if not redundant) includes the user who released that\nversion.\n\nThese are all taken from the plugin's latest released version's pom.xml\nmetadata.\n\nImplicit dependencies (plugins split from core) are included with '(Implied)' after the plugin name.\n\nThe plugin sit"
  },
  "3026": {
    "source_file": "plugin-site.txt",
    "text": "ased version's pom.xml\nmetadata.\n\nImplicit dependencies (plugins split from core) are included with '(Implied)' after the plugin name.\n\nThe plugin site caches wiki pages as needed. The cached copy of each\nwiki page is marked invalid after several (2019-10: six) hours.\n\nThe data for the plugins site is periodically collected based on the\nstats.jenkins.io data and the current update-center.json, and"
  },
  "3027": {
    "source_file": "plugin-site.txt",
    "text": "19-10: six) hours.\n\nThe data for the plugins site is periodically collected based on the\nstats.jenkins.io data and the current update-center.json, and made\navailable to the plugins site at a known URL.\n\nThe plugins site periodically (2019-10: every hour) updates its internal\nstorage from that URL."
  },
  "3028": {
    "source_file": "plugin-site.txt",
    "text": "our) updates its internal\nstorage from that URL."
  },
  "3029": {
    "source_file": "plugins.txt",
    "text": "layout: section\n\n\nifdef::env-github[:imagesdir: ../resources]\nifndef::env-github[:imagesdir: ../../resources]\n\nPlugins are the primary means of enhancing the functionality of a Jenkins\nenvironment to suit organization- or user-specific needs. There are\n\nwhich can be installed on a Jenkins controller and to integrate various\nbuild tools, cloud providers, analysis tools, and much more.\n\nPlugins can "
  },
  "3030": {
    "source_file": "plugins.txt",
    "text": "re\n\nwhich can be installed on a Jenkins controller and to integrate various\nbuild tools, cloud providers, analysis tools, and much more.\n\nPlugins can be automatically downloaded, with their dependencies, from the\n<<../glossary#update-center,Update Center>>. The Update Center is a service\noperated by the Jenkins project which provides an inventory of open source\nplugins which have been developed an"
  },
  "3031": {
    "source_file": "plugins.txt",
    "text": "nter>>. The Update Center is a service\noperated by the Jenkins project which provides an inventory of open source\nplugins which have been developed and maintained by various members of the\nJenkins community.\n\nThis section covers everything from the basics of managing plugins within\nthe Jenkins web UI, to making changes on the <<../glossary#controller,controller's>>\nfile system.\n\nJenkins provides t"
  },
  "3032": {
    "source_file": "plugins.txt",
    "text": "asics of managing plugins within\nthe Jenkins web UI, to making changes on the <<../glossary#controller,controller's>>\nfile system.\n\nJenkins provides two methods for installing plugins on the controller:\n\nUsing the \"Plugin Manager\" in the web UI.\nUsing the <<install-with-cli,Jenkins CLI>> `install-plugin` command.\n\nEach approach will result in the plugin being loaded by Jenkins but may require\ndiff"
  },
  "3033": {
    "source_file": "plugins.txt",
    "text": "g the <<install-with-cli,Jenkins CLI>> `install-plugin` command.\n\nEach approach will result in the plugin being loaded by Jenkins but may require\ndifferent levels of access and trade-offs in order to use.\n\nThe two approaches require that the Jenkins controller be able to download\nmeta-data from an Update Center, whether the primary Update Center operated by\nthe Jenkins project\nfootnote:uc[https://"
  },
  "3034": {
    "source_file": "plugins.txt",
    "text": "controller be able to download\nmeta-data from an Update Center, whether the primary Update Center operated by\nthe Jenkins project\nfootnote:uc[https://updates.jenkins.io],\nor a custom Update Center.\n\nThe plugins are packaged as self-contained `.hpi` files, which have all the\nnecessary code, images, and other resources which the plugin needs to operate\nsuccessfully.\n\nThe simplest and most common way"
  },
  "3035": {
    "source_file": "plugins.txt",
    "text": "iles, which have all the\nnecessary code, images, and other resources which the plugin needs to operate\nsuccessfully.\n\nThe simplest and most common way of installing plugins is through the\n*Manage Jenkins* > *Plugins* view, available to administrators of a\nJenkins environment.\n\nUnder the *Available* tab, plugins available for download from the configured\nUpdate Center can be searched and considered"
  },
  "3036": {
    "source_file": "plugins.txt",
    "text": " of a\nJenkins environment.\n\nUnder the *Available* tab, plugins available for download from the configured\nUpdate Center can be searched and considered:\n\nMost plugins can be installed and used immediately by checking the box adjacent\nto the plugin and clicking *Install without restart*.\n\n[CAUTION]\n\nIf the list of available plugins is empty, the controller may be incorrectly\nconfigured or has not ye"
  },
  "3037": {
    "source_file": "plugins.txt",
    "text": " clicking *Install without restart*.\n\n[CAUTION]\n\nIf the list of available plugins is empty, the controller may be incorrectly\nconfigured or has not yet downloaded plugin meta-data from the Update Center.\nClicking the *Check now* button forces Jenkins to attempt to contact its\nconfigured Update Center.\n\n[[install-with-cli]]\n\n.Installing Jenkins plugins using Jenkins CLI\nvideo::bTFMvXIkNIg[youtube,w"
  },
  "3038": {
    "source_file": "plugins.txt",
    "text": " to attempt to contact its\nconfigured Update Center.\n\n[[install-with-cli]]\n\n.Installing Jenkins plugins using Jenkins CLI\nvideo::bTFMvXIkNIg[youtube,width=800,height=420]\n\nAdministrators may also use the <<cli#,Jenkins CLI>> which provides a command\nto install plugins. Scripts to manage Jenkins environments, or configuration\nmanagement code, may need to install plugins without direct user interact"
  },
  "3039": {
    "source_file": "plugins.txt",
    "text": "to install plugins. Scripts to manage Jenkins environments, or configuration\nmanagement code, may need to install plugins without direct user interaction in\nthe web UI. The Jenkins CLI allows a command line user or automation tool to\ndownload a plugin and its dependencies.\n\njava -jar jenkins-cli.jar -s http://localhost:8080/ install-plugin SOURCE ... [-deploy] [-name VAL] [-restart]\n\nInstalls a pl"
  },
  "3040": {
    "source_file": "plugins.txt",
    "text": "n and its dependencies.\n\njava -jar jenkins-cli.jar -s http://localhost:8080/ install-plugin SOURCE ... [-deploy] [-name VAL] [-restart]\n\nInstalls a plugin either from a file, an URL, or from update center.\n\n SOURCE    : If this points to a local file, that file will be installed. If\n             this is an URL, Jenkins downloads the URL and installs that as a\n             plugin.Otherwise the name"
  },
  "3041": {
    "source_file": "plugins.txt",
    "text": ", that file will be installed. If\n             this is an URL, Jenkins downloads the URL and installs that as a\n             plugin.Otherwise the name is assumed to be the short name of the\n             plugin in the existing update center (like \"findbugs\"),and the\n             plugin will be installed from the update center.\n -deploy   : Deploy plugins right away without postponing them until the"
  },
  "3042": {
    "source_file": "plugins.txt",
    "text": "dbugs\"),and the\n             plugin will be installed from the update center.\n -deploy   : Deploy plugins right away without postponing them until the reboot.\n -name VAL : If specified, the plugin will be installed as this short name\n             (whereas normally the name is inferred from the source name\n             automatically).\n -restart  : Restart Jenkins upon successful installation.\n\nThe "
  },
  "3043": {
    "source_file": "plugins.txt",
    "text": "ereas normally the name is inferred from the source name\n             automatically).\n -restart  : Restart Jenkins upon successful installation.\n\nThe Update Center only allows the installation of the most recently released\nversion of a plugin. In cases where an older release of the plugin is desired,\na Jenkins administrator can download an older `.hpi` archive and manually\ninstall that on the Jenk"
  },
  "3044": {
    "source_file": "plugins.txt",
    "text": "es where an older release of the plugin is desired,\na Jenkins administrator can download an older `.hpi` archive and manually\ninstall that on the Jenkins controller.\n\nJenkins stores plugins it has downloaded in the `plugins` directory with a `.jpi` suffix, whether the plugins originally had a `.jpi` or an `.hpi` suffix.\n\nIf an administrator manually copies a plugin archive into the `plugins` direc"
  },
  "3045": {
    "source_file": "plugins.txt",
    "text": "uffix, whether the plugins originally had a `.jpi` or an `.hpi` suffix.\n\nIf an administrator manually copies a plugin archive into the `plugins` directory, it should be named with a `.jpi` suffix to match the file names used by plugins installed from the update center.\n\nAssuming a `.hpi` file has been downloaded, a logged-in Jenkins administrator\nmay upload the file from within the web UI:\n\nNaviga"
  },
  "3046": {
    "source_file": "plugins.txt",
    "text": " the update center.\n\nAssuming a `.hpi` file has been downloaded, a logged-in Jenkins administrator\nmay upload the file from within the web UI:\n\nNavigate to the *Manage Jenkins* > *Plugins* page in the web UI.\nClick on the *Advanced* tab.\nChoose the `.hpi` file from your system or enter a URL to the archive file under the *Deploy Plugin* section.\n*Deploy* the plugin file.\n\nOnce a plugin file has be"
  },
  "3047": {
    "source_file": "plugins.txt",
    "text": ".hpi` file from your system or enter a URL to the archive file under the *Deploy Plugin* section.\n*Deploy* the plugin file.\n\nOnce a plugin file has been uploaded, the Jenkins controller must be manually\nrestarted in order for the changes to take effect.\n\nAssuming a `.hpi` file has been explicitly downloaded by a system\nadministrator, the administrator can manually place the file in a\nspecific loca"
  },
  "3048": {
    "source_file": "plugins.txt",
    "text": "ct.\n\nAssuming a `.hpi` file has been explicitly downloaded by a system\nadministrator, the administrator can manually place the file in a\nspecific location on the file system.\n\nCopy the downloaded `.hpi`` file into the `JENKINS_HOME/plugins` directory on\nthe Jenkins controller (for example, on Debian systems `JENKINS_HOME` is generally\n`/var/lib/jenkins`).\nIf an administrator manually copies a plug"
  },
  "3049": {
    "source_file": "plugins.txt",
    "text": " on\nthe Jenkins controller (for example, on Debian systems `JENKINS_HOME` is generally\n`/var/lib/jenkins`).\nIf an administrator manually copies a plugin archive into the `plugins` directory, it should be named with a `.jpi` suffix to match the file names used by plugins installed from the update center.\n\nThe controller must be restarted before the plugin is loaded and\nmade available in the Jenkins"
  },
  "3050": {
    "source_file": "plugins.txt",
    "text": "ames used by plugins installed from the update center.\n\nThe controller must be restarted before the plugin is loaded and\nmade available in the Jenkins environment.\n\nThe names of the plugin directories in the Update Site footnote:uc[] are\nnot always the same as the plugin's display name. Searching\n\nfor the desired plugin will provide the appropriate link to the archive file.\n\nUpdates are listed in "
  },
  "3051": {
    "source_file": "plugins.txt",
    "text": "he same as the plugin's display name. Searching\n\nfor the desired plugin will provide the appropriate link to the archive file.\n\nUpdates are listed in the *Updates* tab of the *Plugins* page and can be\ninstalled by checking the checkboxes of the desired plugin updates and clicking\nthe *Download now and install after restart* button.\n\nBy default, the Jenkins controller will check for updates from th"
  },
  "3052": {
    "source_file": "plugins.txt",
    "text": "ed plugin updates and clicking\nthe *Download now and install after restart* button.\n\nBy default, the Jenkins controller will check for updates from the Update Center\nonce every 24 hours. To manually trigger a check for updates, simply click on\nthe *Check now* button in the *Updates* tab.\n\nThe simplest way to retrieve the list of installed plugins and their versions is by using the Jenkins Script C"
  },
  "3053": {
    "source_file": "plugins.txt",
    "text": "heck now* button in the *Updates* tab.\n\nThe simplest way to retrieve the list of installed plugins and their versions is by using the Jenkins Script Console.\n\nFollow these steps:\n\n1. Open the Jenkins :\n\n   - Navigate to `Manage Jenkins` > `Script Console`.\n2. Run the following script to list installed plugins and their versions:\n\n   Jenkins.instance.pluginManager.plugins.each {\n      println(\"${it"
  },
  "3054": {
    "source_file": "plugins.txt",
    "text": "sole`.\n2. Run the following script to list installed plugins and their versions:\n\n   Jenkins.instance.pluginManager.plugins.each {\n      println(\"${it.getShortName()}: ${it.getVersion()}\")\n   }\n\nThis script iterates through each installed plugin and prints its short name along with the version.\n\nWhen a plugin is no longer used in a Jenkins environment, it is prudent to\nremove the plugin from the J"
  },
  "3055": {
    "source_file": "plugins.txt",
    "text": "prints its short name along with the version.\n\nWhen a plugin is no longer used in a Jenkins environment, it is prudent to\nremove the plugin from the Jenkins controller. This provides a number of benefits\nsuch as reducing memory overhead at boot or runtime, reducing configuration\noptions in the web UI, and removing the potential for future conflicts with new\nplugin updates.\n\nThis video reviews the "
  },
  "3056": {
    "source_file": "plugins.txt",
    "text": "ntime, reducing configuration\noptions in the web UI, and removing the potential for future conflicts with new\nplugin updates.\n\nThis video reviews the process of uninstalling a plugin from Jenkins.\n\nvideo::Keh6riX7574[youtube,width=800,height=420]\n\nThe simplest way to uninstall a plugin is to navigate to the *Installed* tab on\nthe *Plugins* page. From there, Jenkins will automatically determine\nwhi"
  },
  "3057": {
    "source_file": "plugins.txt",
    "text": "e simplest way to uninstall a plugin is to navigate to the *Installed* tab on\nthe *Plugins* page. From there, Jenkins will automatically determine\nwhich plugins are safe to uninstall, those which are not dependencies of other\nplugins, and present a button for doing so.\n\nA plugin may also be uninstalled by removing the corresponding `.jpi`\nfile from the `JENKINS_HOME/plugins` directory on the contr"
  },
  "3058": {
    "source_file": "plugins.txt",
    "text": "utton for doing so.\n\nA plugin may also be uninstalled by removing the corresponding `.jpi`\nfile from the `JENKINS_HOME/plugins` directory on the controller. The plugin will\ncontinue to function until the controller has been restarted.\n\n[CAUTION]\n\nIf a plugin file is removed but required by other plugins, the Jenkins\ncontroller may fail to boot correctly.\n\nUninstalling a plugin does *not* remove th"
  },
  "3059": {
    "source_file": "plugins.txt",
    "text": "a plugin file is removed but required by other plugins, the Jenkins\ncontroller may fail to boot correctly.\n\nUninstalling a plugin does *not* remove the configuration that the plugin may\nhave created. If there are existing jobs/nodes/views/builds/etc configurations\nthat reference data created by the plugin, during boot Jenkins will warn that\nsome configurations could not be fully loaded and ignore "
  },
  "3060": {
    "source_file": "plugins.txt",
    "text": "configurations\nthat reference data created by the plugin, during boot Jenkins will warn that\nsome configurations could not be fully loaded and ignore the unrecognized data.\n\nSince the configuration(s) will be preserved until they are overwritten,\nre-installing the plugin will result in those configuration values reappearing.\n\nJenkins provides a facility for purging configuration left behind by\nuni"
  },
  "3061": {
    "source_file": "plugins.txt",
    "text": "installing the plugin will result in those configuration values reappearing.\n\nJenkins provides a facility for purging configuration left behind by\nuninstalled plugins. Navigate to *Manage Jenkins* and then click on *Manage\nOld Data* to review and remove old data.\n\nDisabling a plugin is a softer way to retire a plugin. Jenkins will continue to\nrecognize that the plugin is installed, but it will not"
  },
  "3062": {
    "source_file": "plugins.txt",
    "text": "ove old data.\n\nDisabling a plugin is a softer way to retire a plugin. Jenkins will continue to\nrecognize that the plugin is installed, but it will not start the plugin, and\nno extensions contributed from this plugin will be visible.\n\nA Jenkins administrator may disable a plugin by unchecking the box on the\n*Installed* tab of the *Plugins* page (see below).\n\nA systems administrator may also disable"
  },
  "3063": {
    "source_file": "plugins.txt",
    "text": "strator may disable a plugin by unchecking the box on the\n*Installed* tab of the *Plugins* page (see below).\n\nA systems administrator may also disable a plugin by creating a file on the\nJenkins controller, such as: `JENKINS_HOME/plugins/PLUGIN_NAME.jpi.disabled`.\n\nThe configuration(s) created by the disabled plugin behave as if the plugin\nwere uninstalled, insofar that they result in warnings on b"
  },
  "3064": {
    "source_file": "plugins.txt",
    "text": "pi.disabled`.\n\nThe configuration(s) created by the disabled plugin behave as if the plugin\nwere uninstalled, insofar that they result in warnings on boot but are\notherwise ignored.\n\nIt is also possible to enable or disable plugins via the <<cli#,Jenkins CLI>>\nusing the `enable-plugin` or `disable-plugin` commands.\n\nThe `enable-plugin` command was added to Jenkins in .\nThe `disable-plugin` command "
  },
  "3065": {
    "source_file": "plugins.txt",
    "text": "ins CLI>>\nusing the `enable-plugin` or `disable-plugin` commands.\n\nThe `enable-plugin` command was added to Jenkins in .\nThe `disable-plugin` command was added to Jenkins in .\n\nThe `enable-plugin` command receives a list of plugins to be enabled.\nAny plugins which a selected plugin depends on will also be enabled by this command.\n\njava -jar jenkins-cli.jar -s http://localhost:8080/ enable-plugin P"
  },
  "3066": {
    "source_file": "plugins.txt",
    "text": " plugins which a selected plugin depends on will also be enabled by this command.\n\njava -jar jenkins-cli.jar -s http://localhost:8080/ enable-plugin PLUGIN ... [-restart]\n\nEnables one or more installed plugins transitively.\n\n PLUGIN   : Enables the plugins with the given short names and their\n            dependencies.\n -restart : Restart Jenkins after enabling plugins.\n\nThe `disable-plugin` comman"
  },
  "3067": {
    "source_file": "plugins.txt",
    "text": "lugins with the given short names and their\n            dependencies.\n -restart : Restart Jenkins after enabling plugins.\n\nThe `disable-plugin` command receives a list of plugins to be disabled. The\noutput will display messages for both successful and failed operations. If you\nonly want to see error messages, the `-quiet` option can be specified.\nThe `-strategy` option controls what action will be"
  },
  "3068": {
    "source_file": "plugins.txt",
    "text": "d failed operations. If you\nonly want to see error messages, the `-quiet` option can be specified.\nThe `-strategy` option controls what action will be taken when one of the specified plugins\nis listed as an optional or mandatory dependency of another enabled plugin.\n\njava -jar jenkins-cli.jar -s http://localhost:8080/ disable-plugin PLUGIN ... [-quiet (-q)]\n[-restart (-r)] [-strategy (-s) strategy"
  },
  "3069": {
    "source_file": "plugins.txt",
    "text": " enabled plugin.\n\njava -jar jenkins-cli.jar -s http://localhost:8080/ disable-plugin PLUGIN ... [-quiet (-q)]\n[-restart (-r)] [-strategy (-s) strategy]\n\nDisable one or more installed plugins.\nDisable the plugins with the given short names. You can define how to proceed with the\ndependant plugins and if a restart after should be done. You can also set the quiet mode\nto avoid extra info in the conso"
  },
  "3070": {
    "source_file": "plugins.txt",
    "text": "fine how to proceed with the\ndependant plugins and if a restart after should be done. You can also set the quiet mode\nto avoid extra info in the console.\n\n PLUGIN                  : Plugins to be disabled.\n -quiet (-q)             : Be quiet, print only the error messages\n -restart (-r)           : Restart Jenkins after disabling plugins.\n -strategy (-s) strategy : How to process the dependant plu"
  },
  "3071": {
    "source_file": "plugins.txt",
    "text": "nly the error messages\n -restart (-r)           : Restart Jenkins after disabling plugins.\n -strategy (-s) strategy : How to process the dependant plugins.\n                           - none: if a mandatory dependant plugin exists and\n                           it is enabled, the plugin cannot be disabled\n                           (default value).\n                           - mandatory: all mandat"
  },
  "3072": {
    "source_file": "plugins.txt",
    "text": "           it is enabled, the plugin cannot be disabled\n                           (default value).\n                           - mandatory: all mandatory dependant plugins are\n                           also disabled, optional dependant plugins remain\n                           enabled.\n                           - all: all dependant plugins are also disabled, no\n                           matter "
  },
  "3073": {
    "source_file": "plugins.txt",
    "text": "n\n                           enabled.\n                           - all: all dependant plugins are also disabled, no\n                           matter if its dependency is optional or mandatory.\n\n[CAUTION]\n\nIn the same way than enabling and disabling plugins from the UI requires a restart\nto complete the process, the changes made with the CLI commands will take effect\nonce Jenkins is restarted. The"
  },
  "3074": {
    "source_file": "plugins.txt",
    "text": "plugins from the UI requires a restart\nto complete the process, the changes made with the CLI commands will take effect\nonce Jenkins is restarted. The `-restart` option forces a safe restart of the\ncontroller once the command has successfully finished, so the changes will be\nimmediately applied.\n\n[CAUTION]\n\nPinned plugins feature was removed in Jenkins 2.0. Versions later than Jenkins\n2.0 do not b"
  },
  "3075": {
    "source_file": "plugins.txt",
    "text": "d, so the changes will be\nimmediately applied.\n\n[CAUTION]\n\nPinned plugins feature was removed in Jenkins 2.0. Versions later than Jenkins\n2.0 do not bundle plugins, instead providing a wizard to install the most\nuseful plugins.\n\nThe notion of *pinned plugins* applies to plugins that are bundled with\nJenkins 1.x, such as the\nplugin:matrix-auth[*Matrix Authorization plugin*].\n\nBy default, whenever J"
  },
  "3076": {
    "source_file": "plugins.txt",
    "text": " plugins* applies to plugins that are bundled with\nJenkins 1.x, such as the\nplugin:matrix-auth[*Matrix Authorization plugin*].\n\nBy default, whenever Jenkins is upgraded, its bundled plugins overwrite the\nversions of the plugins that are currently installed in `JENKINS_HOME`.\n\nHowever, when a bundled plugin has been manually updated, Jenkins will mark\nthat plugin as pinned to the particular version"
  },
  "3077": {
    "source_file": "plugins.txt",
    "text": "talled in `JENKINS_HOME`.\n\nHowever, when a bundled plugin has been manually updated, Jenkins will mark\nthat plugin as pinned to the particular version. On the file system, Jenkins\ncreates an empty file called `JENKINS_HOME/plugins/PLUGIN_NAME.jpi.pinned`\nto indicate the pinning.\n\nPinned plugins will never be overwritten by bundled plugins during Jenkins\nstartup. (Newer versions of Jenkins do warn "
  },
  "3078": {
    "source_file": "plugins.txt",
    "text": "ned`\nto indicate the pinning.\n\nPinned plugins will never be overwritten by bundled plugins during Jenkins\nstartup. (Newer versions of Jenkins do warn you if a pinned plugin is _older_\nthan what is currently bundled.)\n\nIt is safe to update a bundled plugin to a version offered by the Update\nCenter. This is often necessary to pick up the newest features and fixes. The\nbundled version is occasionally"
  },
  "3079": {
    "source_file": "plugins.txt",
    "text": "lugin to a version offered by the Update\nCenter. This is often necessary to pick up the newest features and fixes. The\nbundled version is occasionally updated, but not consistently.\n\nThe Plugin Manager allows plugins to be explicitly unpinned. The\n`JENKINS_HOME/plugins/PLUGIN_NAME.hpi.pinned` file can also be manually\ncreated/deleted to control the pinning behavior. If the `pinned` file is\npresent"
  },
  "3080": {
    "source_file": "plugins.txt",
    "text": "ENKINS_HOME/plugins/PLUGIN_NAME.hpi.pinned` file can also be manually\ncreated/deleted to control the pinning behavior. If the `pinned` file is\npresent, Jenkins will use whatever plugin version the user has specified.\nIf the file is absent, Jenkins will restore the plugin to the default version\non startup.\n\nFeatures are sometimes detached (or split off) from Jenkins core and moved into a plugin.\n\nM"
  },
  "3081": {
    "source_file": "plugins.txt",
    "text": "ll restore the plugin to the default version\non startup.\n\nFeatures are sometimes detached (or split off) from Jenkins core and moved into a plugin.\n\nMany plugins, like plugin:subversion[Subversion] and plugin:junit[JUnit], got their beginnings as Jenkins core functionalities.\nWhen a plugin was attached to Jenkins core prior to being detached, it may or may not have used its full functionality with"
  },
  "3082": {
    "source_file": "plugins.txt",
    "text": "kins core functionalities.\nWhen a plugin was attached to Jenkins core prior to being detached, it may or may not have used its full functionality with other plugins that relied on the same version of Jenkins.\nTo ensure that plugins do not fail when a functionality on which they rely is separated from Jenkins core, it is necessary to have a dependency in the detached plugin, if it specifies a depen"
  },
  "3083": {
    "source_file": "plugins.txt",
    "text": " functionality on which they rely is separated from Jenkins core, it is necessary to have a dependency in the detached plugin, if it specifies a dependency on a version of Jenkins core prior to the split.\nIt is assumed that there is a dependency on the detached plugin, even when it isn't stated explicitly.\n\nImplied dependencies build up over time for plugins that don't frequently update which Jenk"
  },
  "3084": {
    "source_file": "plugins.txt",
    "text": "he detached plugin, even when it isn't stated explicitly.\n\nImplied dependencies build up over time for plugins that don't frequently update which Jenkins core version they depend on.\n\nIt is \"implied\" since it is not stated explicitly in the plugin, and it is a dependency because Jenkins core is uncertain if the APIs available in Jenkins core, prior to the separation of the plugin, are necessary or"
  },
  "3085": {
    "source_file": "plugins.txt",
    "text": "nd it is a dependency because Jenkins core is uncertain if the APIs available in Jenkins core, prior to the separation of the plugin, are necessary or not.\n\nFor example, because the Instance Identity plugin was separated from Jenkins core, Jenkins core is uninformed if the dependent plugin needs any functionality that was previously present in Jenkins core.\nThis creates an implied dependency.\n\nAs "
  },
  "3086": {
    "source_file": "plugins.txt",
    "text": "re is uninformed if the dependent plugin needs any functionality that was previously present in Jenkins core.\nThis creates an implied dependency.\n\nAs a Jenkins administrator, you can see the plugins that have an implied dependency from the plugin manager page.\nHover over the \"uninstall\" button and a list of plugins with an implied dependency is displayed.\n\nThe implied dependency can be removed by "
  },
  "3087": {
    "source_file": "plugins.txt",
    "text": "ager page.\nHover over the \"uninstall\" button and a list of plugins with an implied dependency is displayed.\n\nThe implied dependency can be removed by releasing a new version of the plugin that depends on a newer minimum Jenkins core.\nThe  provides steps that can assist plugin developers as they update the plugin to .\n\n[[plugin-health-score]]\n\nThere is a metric available next to the plugins in the "
  },
  "3088": {
    "source_file": "plugins.txt",
    "text": "eps that can assist plugin developers as they update the plugin to .\n\n[[plugin-health-score]]\n\nThere is a metric available next to the plugins in the Plugin Manager called \"Health Score\".\n\nYou can find the same metric in the available update and the installed page of the plugin manager.\n\nNOTE: The score value is always based on the latest available data.\nThis means that there is no score of a spec"
  },
  "3089": {
    "source_file": "plugins.txt",
    "text": "installed page of the plugin manager.\n\nNOTE: The score value is always based on the latest available data.\nThis means that there is no score of a specific release of a plugin.\nWhat is available on the installed and updates page of the plugin manager does not stand for the version already installed.\n\nThis metric is coming from .\n\nThis service is gathering data from each plugin.\n\nThe data can be rel"
  },
  "3090": {
    "source_file": "plugins.txt",
    "text": "does not stand for the version already installed.\n\nThis metric is coming from .\n\nThis service is gathering data from each plugin.\n\nThe data can be related to the source code of the plugin, the content of the plugin repository, or external metrics about the plugin such as number of open pull requests.\n\nThat data is then used to evaluate the status of the project.\nAll plugins are evaluated the same "
  },
  "3091": {
    "source_file": "plugins.txt",
    "text": "ut the plugin such as number of open pull requests.\n\nThat data is then used to evaluate the status of the project.\nAll plugins are evaluated the same way, meaning there is a fair way to compare plugins.\n\nWhile only the score is shown, the details behind this value are available on the  in the health score section of each plugin:\n\nIt is also possible to find the details directly on the  service.\nTo"
  },
  "3092": {
    "source_file": "plugins.txt",
    "text": "ind this value are available on the  in the health score section of each plugin:\n\nIt is also possible to find the details directly on the  service.\nTo access it, you need to append the plugin name to the score URL.\nFor example, the health score URL for the `Mailer` plugin is `https://plugin-health.jenkins.io/scores/mailer`.\n\nEach section of the score can have one or multiple elements evaluated.\nEa"
  },
  "3093": {
    "source_file": "plugins.txt",
    "text": "or the `Mailer` plugin is `https://plugin-health.jenkins.io/scores/mailer`.\n\nEach section of the score can have one or multiple elements evaluated.\nEach component of the section can have more or less impact on the global score.\n\nThe data gathered by the Plugin Health Scoring project on every plugin is evaluated frequently.\nReview the recommendations on the plugins site to improve the plugin score."
  },
  "3094": {
    "source_file": "plugins.txt",
    "text": "the Plugin Health Scoring project on every plugin is evaluated frequently.\nReview the recommendations on the plugins site to improve the plugin score.\n\nAdopting a plugin or contributing to each and every plugin is always welcome."
  },
  "3095": {
    "source_file": "post.txt",
    "text": "layout: documentation\ntitle: Cleaning up and notifications\n\n\nSince the `post` section of a Pipeline is guaranteed to run at the end of a\nPipeline's execution, we can add some notification or other steps to perform\nfinalization, notification, or other end-of-Pipeline tasks.\n\nNOTE: See\nfor the different build statuses: SUCCESS, UNSTABLE, and FAILED.\n\n[pipeline]\n\n// Declarative //\npipeline {\n    agen"
  },
  "3096": {
    "source_file": "post.txt",
    "text": " end-of-Pipeline tasks.\n\nNOTE: See\nfor the different build statuses: SUCCESS, UNSTABLE, and FAILED.\n\n[pipeline]\n\n// Declarative //\npipeline {\n    agent any\n    stages {\n        stage('No-op') {\n            steps {\n                sh 'ls'\n            }\n        }\n    }\n    post {\n        always {\n            echo 'One way or another, I have finished'\n            deleteDir() /* clean up our workspace"
  },
  "3097": {
    "source_file": "post.txt",
    "text": "}\n        }\n    }\n    post {\n        always {\n            echo 'One way or another, I have finished'\n            deleteDir() /* clean up our workspace */\n        }\n        success {\n            echo 'I succeeded!'\n        }\n        unstable {\n            echo 'I am unstable :/'\n        }\n        failure {\n            echo 'I failed :('\n        }\n        changed {\n            echo 'Things were diff"
  },
  "3098": {
    "source_file": "post.txt",
    "text": "     echo 'I am unstable :/'\n        }\n        failure {\n            echo 'I failed :('\n        }\n        changed {\n            echo 'Things were different before...'\n        }\n    }\n}\n// Scripted //\nnode {\n    try {\n        stage('No-op') {\n            sh 'ls'\n        }\n    }\n    catch (exc) {\n        echo 'I failed'\n    }\n    finally {\n        if (currentBuild.result == 'UNSTABLE') {\n           "
  },
  "3099": {
    "source_file": "post.txt",
    "text": "    sh 'ls'\n        }\n    }\n    catch (exc) {\n        echo 'I failed'\n    }\n    finally {\n        if (currentBuild.result == 'UNSTABLE') {\n            echo 'I am unstable :/'\n        } else {\n            echo 'One way or another, I have finished'\n        }\n    }\n}\n\nThere are plenty of ways to send notifications, below are a few snippets\ndemonstrating how to send notifications about a Pipeline to a"
  },
  "3100": {
    "source_file": "post.txt",
    "text": "     }\n    }\n}\n\nThere are plenty of ways to send notifications, below are a few snippets\ndemonstrating how to send notifications about a Pipeline to an email or a Slack channel.\n\npost {\n    failure {\n        mail to: 'team@example.com',\n             subject: \"Failed Pipeline: ${currentBuild.fullDisplayName}\",\n             body: \"Something is wrong with ${env.BUILD_URL}\"\n    }\n}\n\npost {\n    success"
  },
  "3101": {
    "source_file": "post.txt",
    "text": "subject: \"Failed Pipeline: ${currentBuild.fullDisplayName}\",\n             body: \"Something is wrong with ${env.BUILD_URL}\"\n    }\n}\n\npost {\n    success {\n        slackSend channel: '#ops-room',\n                  color: 'good',\n                  message: \"The pipeline ${currentBuild.fullDisplayName} completed successfully.\"\n    }\n}\n\nNow that the team is being notified when things are failing, unstab"
  },
  "3102": {
    "source_file": "post.txt",
    "text": "e: \"The pipeline ${currentBuild.fullDisplayName} completed successfully.\"\n    }\n}\n\nNow that the team is being notified when things are failing, unstable, or even\nsucceeding we can finish our continuous delivery pipeline with the exciting\npart: shipping!\n\n\n\n'''\n+++\n\n+++"
  },
  "3103": {
    "source_file": "post.txt",
    "text": "ng!\n\n\n\n'''\n+++\n\n+++"
  },
  "3104": {
    "source_file": "preparation.txt",
    "text": "title: Before you start\nsummary: Read this before you start\nlayout: developer\n\n\nWe welcome contributions from anyone, but for the benefit of Jenkins users we ask that you look for plugins solving the same or similar problems to see whether you can join forces with existing maintainers.\nYou can find an overview of existing plugins on https://plugins.jenkins.io. Feel free to ask on the  to see wheth"
  },
  "3105": {
    "source_file": "preparation.txt",
    "text": "in forces with existing maintainers.\nYou can find an overview of existing plugins on https://plugins.jenkins.io. Feel free to ask on the  to see whether anyone is aware of another plugin implementing something similar to what you're planning to do.\n\nMake sure your plugin follows .\n\nAll plugins distributed by the Jenkins project need to be free and open source software.\nThis applies to the plugin s"
  },
  "3106": {
    "source_file": "preparation.txt",
    "text": "Make sure your plugin follows .\n\nAll plugins distributed by the Jenkins project need to be free and open source software.\nThis applies to the plugin source code as well as all its dependencies.\nMake sure to specify the license both in the `pom.xml` file, as well as a `LICENSE` file in your repository.\n\nWe recommend use of the MIT license which is used for Jenkins core and most plugins and librarie"
  },
  "3107": {
    "source_file": "preparation.txt",
    "text": "ile, as well as a `LICENSE` file in your repository.\n\nWe recommend use of the MIT license which is used for Jenkins core and most plugins and libraries, but any  or  license or public domain dedication will do.\n\nLibrary plugins, which exist only to wrap some third-party library to implement dynamic linking,\nmay be licensed under either the MIT license or the license of the library being wrapped.\nW"
  },
  "3108": {
    "source_file": "preparation.txt",
    "text": "rap some third-party library to implement dynamic linking,\nmay be licensed under either the MIT license or the license of the library being wrapped.\nWhen these library plugins deliver nontrivial Jenkins-specific production code, the MIT license is appropriate;\nhowever, when the only Jenkins-specific code is in build and test logic, we prefer the license of the library being wrapped for simplicity "
  },
  "3109": {
    "source_file": "preparation.txt",
    "text": "propriate;\nhowever, when the only Jenkins-specific code is in build and test logic, we prefer the license of the library being wrapped for simplicity and consistency.\n\nWe recommend that plugins include user documentation so users understand quickly what the plugin does and how to use it.\nWe recommend following the documentation-as-code approach and keeping the documentation directly in the plugin "
  },
  "3110": {
    "source_file": "preparation.txt",
    "text": "hat the plugin does and how to use it.\nWe recommend following the documentation-as-code approach and keeping the documentation directly in the plugin repository.\n\nSee  for more information.\n\nJenkins plugins distributed via Jenkins project update sites need to be hosted in the , so you will need a user account on GitHub.\n\nTo actually release your plugin, you will need a  that will give you access t"
  },
  "3111": {
    "source_file": "preparation.txt",
    "text": "s need to be hosted in the , so you will need a user account on GitHub.\n\nTo actually release your plugin, you will need a  that will give you access to the  and .\n\nYou should receive a welcome email confirming your Jenkins community account was created successfully.\nIf you do not receive any email, please open a ticket on the .\n\nEven if you choose to track your plugin's issues on GitHub, ."
  },
  "3112": {
    "source_file": "preparation.txt",
    "text": "ed successfully.\nIf you do not receive any email, please open a ticket on the .\n\nEven if you choose to track your plugin's issues on GitHub, ."
  },
  "3113": {
    "source_file": "prepare-a-groovy-view.txt",
    "text": "title: Preparing a Groovy-based View for Localization\nlayout: developer\nwip: true"
  },
  "3114": {
    "source_file": "prepare-a-java-source-file.txt",
    "text": "title: Prepare a Java Source File for Localization\nlayout: developer\nreferences:\n- url: https://en.wikipedia.org/wiki/.properties\n  title: .properties file format on Wikipedia\n\n\nThis guide explains how to prepare a Java source file in Jenkins core or a plugin for localization.\n\nFirst, we need to identify the localizable strings that should be translated.\nIn general, everything shown on any user in"
  },
  "3115": {
    "source_file": "prepare-a-java-source-file.txt",
    "text": " a plugin for localization.\n\nFirst, we need to identify the localizable strings that should be translated.\nIn general, everything shown on any user interface should be internationalized (i.e. prepared for localization into the user's language).\n\nHistorically, log messages to be written to the Jenkins server log file from a logger aren't translated, but could also be.\n\nLet's consider the following "
  },
  "3116": {
    "source_file": "prepare-a-java-source-file.txt",
    "text": "orically, log messages to be written to the Jenkins server log file from a logger aren't translated, but could also be.\n\nLet's consider the following example, taken from the sample `HelloWorldBuilder`:\n\n.HelloWorldBuilder.java (excerpt)\n\npublic FormValidation doCheckName(@QueryParameter String value)\n        throws IOException, ServletException {\n    if (value.length() == 0)\n        return FormVal"
  },
  "3117": {
    "source_file": "prepare-a-java-source-file.txt",
    "text": "alidation doCheckName(@QueryParameter String value)\n        throws IOException, ServletException {\n    if (value.length() == 0)\n        return FormValidation.error(\"Please set a name\"); // <1> if (value.length() < 4)\n        return FormValidation.warning(\"Isn't the name too short?\"); // <2> return FormValidation.ok();\n}\n\n...\n\n/**\n * This human readable name is used in the configuration screen.\n */"
  },
  "3118": {
    "source_file": "prepare-a-java-source-file.txt",
    "text": "ning(\"Isn't the name too short?\"); // <2> return FormValidation.ok();\n}\n\n...\n\n/**\n * This human readable name is used in the configuration screen.\n */\npublic String getDisplayName() {\n    return \"Say hello world\"; // <3> }\n\n@Override\npublic boolean configure(StaplerRequest req, JSONObject formData) throws FormException {\n    // To persist global configuration information,\n    // set that to proper"
  },
  "3119": {
    "source_file": "prepare-a-java-source-file.txt",
    "text": "onfigure(StaplerRequest req, JSONObject formData) throws FormException {\n    // To persist global configuration information,\n    // set that to properties and call save().\n    useFrench = formData.getBoolean(\"useFrench\"); // <4> // ^Can also use req.bindJSON(this, formData);\n    //  (easier when there are many fields; need set* methods for this, like setUseFrench)\n    save();\n    return super.conf"
  },
  "3120": {
    "source_file": "prepare-a-java-source-file.txt",
    "text": "bindJSON(this, formData);\n    //  (easier when there are many fields; need set* methods for this, like setUseFrench)\n    save();\n    return super.configure(req,formData);\n}\n\n<1> This string should be internationalized, as it is used as a form validation response.\n<2> This string should also be internationalized, as it is another form validation response.\n<3> This is the display name of the build s"
  },
  "3121": {
    "source_file": "prepare-a-java-source-file.txt",
    "text": "ion response.\n<2> This string should also be internationalized, as it is another form validation response.\n<3> This is the display name of the build step on the UI, and should also be internationalized.\n<4> This is an internal identifier for a form configuration option and must not be internationalized.\n\nSee  for plugins that make this and the following steps easier.\n\nThe localized strings for the"
  },
  "3122": {
    "source_file": "prepare-a-java-source-file.txt",
    "text": "onfiguration option and must not be internationalized.\n\nSee  for plugins that make this and the following steps easier.\n\nThe localized strings for the default language (typically English), unless they are reused within the same component, are typically added to a `Messages.properties` file in the same package as the class that uses it.\n\n[IMPORTANT]\n\nDo not reference other components (e.g. core's) "
  },
  "3123": {
    "source_file": "prepare-a-java-source-file.txt",
    "text": "ly added to a `Messages.properties` file in the same package as the class that uses it.\n\n[IMPORTANT]\n\nDo not reference other components (e.g. core's) `Messages` classes.\nThey typically do not consider their localized messages stable API, so your plugin might break if they change their messages.\n\nUsing the default Maven project layout, the `HelloWorldBuilder` class stored in the source file `src/ma"
  },
  "3124": {
    "source_file": "prepare-a-java-source-file.txt",
    "text": "in might break if they change their messages.\n\nUsing the default Maven project layout, the `HelloWorldBuilder` class stored in the source file `src/main/java/org/jenkinsci/plugins/example/HelloWorldBuilder.java` would use the localized strings in the resources file `src/main/resources/org/jenkinsci/plugins/example/Messages.properties` (basically, in the same package).\nCreate that file if it doesn'"
  },
  "3125": {
    "source_file": "prepare-a-java-source-file.txt",
    "text": " resources file `src/main/resources/org/jenkinsci/plugins/example/Messages.properties` (basically, in the same package).\nCreate that file if it doesn't exist.\n\nNow, let's add entries for the localizable strings identified above to that file:\n\n.Messages.properties\n\nHelloWorldBuilder.NoName=Please set a name // <1> HelloWorldBuilder.ShortName=\\// <2> Isn''t the name too short? // <3> # Unicode varia"
  },
  "3126": {
    "source_file": "prepare-a-java-source-file.txt",
    "text": "es.properties\n\nHelloWorldBuilder.NoName=Please set a name // <1> HelloWorldBuilder.ShortName=\\// <2> Isn''t the name too short? // <3> # Unicode variant of the line above: // <4> # Isn\\u2019t the name too short? // <5> HelloWorldBuilder.DisplayName=Say hello world\n\n<1> This sets the value for the key `HelloWorldBuilder.NoName`.\nWhile the key can be freely chosen, it's typically a good idea to indi"
  },
  "3127": {
    "source_file": "prepare-a-java-source-file.txt",
    "text": "ay hello world\n\n<1> This sets the value for the key `HelloWorldBuilder.NoName`.\nWhile the key can be freely chosen, it's typically a good idea to indicate where it's used, as multiple files may share the same `Messages.properties` file.\nThis is also the format generated by the Stapler Plugins for IntelliJ IDEA and NetBeans.\n<2> Line breaks, mostly useful with very long values, e.g. usage instructi"
  },
  "3128": {
    "source_file": "prepare-a-java-source-file.txt",
    "text": "the format generated by the Stapler Plugins for IntelliJ IDEA and NetBeans.\n<2> Line breaks, mostly useful with very long values, e.g. usage instructions, can be escaped with a back slash.\nMake sure to not add whitespace after it.\n<3> In properties files, single quotes need to be escaped with another single quote.\nAlternatively, a Unicode apostrophe could be used here as well.\n<4> Lines starting w"
  },
  "3129": {
    "source_file": "prepare-a-java-source-file.txt",
    "text": "iles, single quotes need to be escaped with another single quote.\nAlternatively, a Unicode apostrophe could be used here as well.\n<4> Lines starting with the `#` character are comments.\n<5> The file encoding for .properties files is ISO-8859-1 (Latin 1), so characters not in that set need to be specified using their Unicode code point, e.g. `\\u2019` for the apostrophe.\n\nAfter adding new entries to"
  },
  "3130": {
    "source_file": "prepare-a-java-source-file.txt",
    "text": " 1), so characters not in that set need to be specified using their Unicode code point, e.g. `\\u2019` for the apostrophe.\n\nAfter adding new entries to any `Messages.properties` file (or renaming existing ones), the project needs to be rebuilt so the localizer can generate source code from it.\nWhile we can refer to them in source code without that, we only get autocompletion once the `Messages` cla"
  },
  "3131": {
    "source_file": "prepare-a-java-source-file.txt",
    "text": "localizer can generate source code from it.\nWhile we can refer to them in source code without that, we only get autocompletion once the `Messages` class has been generated.\n\nAfter code generation has run, we can add references to the generated class to the source code.\nExample:\n\n.HelloWorldBuilder.java (excerpt)\n\npublic FormValidation doCheckName(@QueryParameter String value)\n        throws IOExce"
  },
  "3132": {
    "source_file": "prepare-a-java-source-file.txt",
    "text": "to the source code.\nExample:\n\n.HelloWorldBuilder.java (excerpt)\n\npublic FormValidation doCheckName(@QueryParameter String value)\n        throws IOException, ServletException {\n    if (value.length() == 0)\n        return FormValidation.error(Messages.HelloWorldBuilder_NoName());\n    if (value.length() < 4)\n        return FormValidation.warning(Messages.HelloWorldBuilder_ShortName());\n    return For"
  },
  "3133": {
    "source_file": "prepare-a-java-source-file.txt",
    "text": "HelloWorldBuilder_NoName());\n    if (value.length() < 4)\n        return FormValidation.warning(Messages.HelloWorldBuilder_ShortName());\n    return FormValidation.ok();\n}\n\nIf your IDE doesn't offer autocompletion even after building the project once, make sure the output folder of the localizer, `target/generated-sources/localizer`, is configured and recognized as a directory containing generated s"
  },
  "3134": {
    "source_file": "prepare-a-java-source-file.txt",
    "text": "make sure the output folder of the localizer, `target/generated-sources/localizer`, is configured and recognized as a directory containing generated source code."
  },
  "3135": {
    "source_file": "prepare-a-jelly-view.txt",
    "text": "title: Prepare a Jelly-based View for Localization\nlayout: developer\nwip: true"
  },
  "3136": {
    "source_file": "prepare.txt",
    "text": "layout: developer\ntitle: Preparing for Plugin Development\nreferences:\n- url: https://adoptium.net/\n  title: Eclipse Temurin Java\n- url: https://maven.apache.org # TODO redundant?\n  title: Apache Maven website\n\n\n-\n-\n-\n-\n\n// TIMEBASED\nJenkins is based on Java, so to build Jenkins plugins you need to install a Java Development Kit (JDK).\nJava 21 is the version we recommend to users, so that's what we"
  },
  "3137": {
    "source_file": "prepare.txt",
    "text": "on Java, so to build Jenkins plugins you need to install a Java Development Kit (JDK).\nJava 21 is the version we recommend to users, so that's what we're using in this tutorial.\n\nYou can download and install Java 21 from the .\n\nNOTE: Many Linux distributions provide packages for Java for an easier install and upgrade experience.\nConsult your distribution's documentation for details.\nTo check if yo"
  },
  "3138": {
    "source_file": "prepare.txt",
    "text": "ibutions provide packages for Java for an easier install and upgrade experience.\nConsult your distribution's documentation for details.\nTo check if you have Java already installed, run `java -version` on a command prompt.\n\n// Install and configure Apache Maven\n\nPlease ensure that the versions you install are compatible with the  of the HPI plugin.\n\nTo verify that Maven is installed, run the follow"
  },
  "3139": {
    "source_file": "prepare.txt",
    "text": "ache Maven\n\nPlease ensure that the versions you install are compatible with the  of the HPI plugin.\n\nTo verify that Maven is installed, run the following command:\n\nmvn -version\n\nThis command prints some diagnostic output, including the versions of Java and Maven, and which Java installation was found by Maven.\nIt should indicate a _21_ version of Java, and list the path to where Java is located.\nI"
  },
  "3140": {
    "source_file": "prepare.txt",
    "text": "va and Maven, and which Java installation was found by Maven.\nIt should indicate a _21_ version of Java, and list the path to where Java is located.\nIf you don't see this information, see <<Troubleshooting>>.\n\nIntelliJ users just need to open the project and all should work out of the box.\n\nYou are advised to use the , features it provides can be found in its .\n\nYou can create a new plugin using o"
  },
  "3141": {
    "source_file": "prepare.txt",
    "text": "ject and all should work out of the box.\n\nYou are advised to use the , features it provides can be found in its .\n\nYou can create a new plugin using one of the Jenkins plugin .\nCreate a new Maven project using **Create from archetype** and **Add an Archetype**.\nSelect the GroupId and ArtifactId as above, and choose RELEASE as version.\nOn the next screen, select io.jenkins.plugins as groupID and ch"
  },
  "3142": {
    "source_file": "prepare.txt",
    "text": "rchetype**.\nSelect the GroupId and ArtifactId as above, and choose RELEASE as version.\nOn the next screen, select io.jenkins.plugins as groupID and choose an artifactId (Project name) and Version to your liking.\nThis will automatically create a maven project based on the specified artifact (for example, `empty-plugin`).\n\nNetBeans users can use the IDE's Maven support to open the project directly.\n"
  },
  "3143": {
    "source_file": "prepare.txt",
    "text": " project based on the specified artifact (for example, `empty-plugin`).\n\nNetBeans users can use the IDE's Maven support to open the project directly.\n\nAs you navigate through the code, you can tell NetBeans to attach source code JAR files by clicking the \"Attach\" button that appears in the top of the main content window. This allows you to read the Jenkins core source code as you develop plugins. "
  },
  "3144": {
    "source_file": "prepare.txt",
    "text": " the \"Attach\" button that appears in the top of the main content window. This allows you to read the Jenkins core source code as you develop plugins. (Or just select Download Sources on the Dependencies node.)\n\nYou are advised to use the . This offers many Jenkins-specific features. Most visibly, create a new plugin using New Project \u00bb Maven \u00bb Jenkins Plugin, and use Run project to test it.\n\n// An"
  },
  "3145": {
    "source_file": "prepare.txt",
    "text": "s many Jenkins-specific features. Most visibly, create a new plugin using New Project \u00bb Maven \u00bb Jenkins Plugin, and use Run project to test it.\n\n// Any eclipse users around who know more?\n\nOpen the project as an existing Maven Project.\n\nNOTE: Anything not working for you? Ask for help on our community forum  or ."
  },
  "3146": {
    "source_file": "prepare.txt",
    "text": "g not working for you? Ask for help on our community forum  or ."
  },
  "3147": {
    "source_file": "proofread-content.txt",
    "text": "title: How to proofread translation suggestions\nlayout: developersection\n\n\nThis guide provides information for project maintainers and proofreaders, how to review translation suggestions through the crowdin web interface.\n\nProject maintainers or people with elevated proofreading permissions on a project, need to look over suggested strings by translators first and approve them, in order to have th"
  },
  "3148": {
    "source_file": "proofread-content.txt",
    "text": "le with elevated proofreading permissions on a project, need to look over suggested strings by translators first and approve them, in order to have them available as pull request on GitHub.\n\nA click on \"Crowdsourcing\" opens a sidebar on the left, where you can switch between \"Crowdsourcing\" and \"Proofreading\".\n\nLet's break down how to use the proofreading view.\n\nOn the left part, you can see a tab"
  },
  "3149": {
    "source_file": "proofread-content.txt",
    "text": "re you can switch between \"Crowdsourcing\" and \"Proofreading\".\n\nLet's break down how to use the proofreading view.\n\nOn the left part, you can see a table with two columns, \"String\" and \"Translate: German\". The \"String\" column lists the source string, as it is used in the plugin's source files and how it is shown to the translators in the \"Crowdsourcing\" view. The \"Translation: German\" table shows a"
  },
  "3150": {
    "source_file": "proofread-content.txt",
    "text": "as it is used in the plugin's source files and how it is shown to the translators in the \"Crowdsourcing\" view. The \"Translation: German\" table shows a proposed translation in German.\n\nIf you think the translation proposal is appropriate, you can click on the tick on the right side to accept a string.\n\nIf more work is needed, or you disagree with a proposal, you can either address the concerns your"
  },
  "3151": {
    "source_file": "proofread-content.txt",
    "text": "k on the tick on the right side to accept a string.\n\nIf more work is needed, or you disagree with a proposal, you can either address the concerns yourself in the proofreading tab or leave a comment.\n\nOnce all strings in a file have been approved, the translation lands as pull request on GitHub within the next 24 hours. Considering you have already reviewed the strings on crowdin, you don't need to"
  },
  "3152": {
    "source_file": "proofread-content.txt",
    "text": " translation lands as pull request on GitHub within the next 24 hours. Considering you have already reviewed the strings on crowdin, you don't need to review them on GitHub again."
  },
  "3153": {
    "source_file": "read-access.txt",
    "text": "title: Restricting HTTP Access to <code>AccessControlled</code> Objects\nlayout: developer\n\n\n## Overview\n\nTypes with Jelly/Groovy views or web methods may be restricted to users with a certain permission.\nSome examples:\n\n* `Item` (or `AbstractItem`) must only be accessed by users with the `Item.READ` permission.\n* `Run` must only be accessed by users with the `Item.READ` permission on the owning `J"
  },
  "3154": {
    "source_file": "read-access.txt",
    "text": "ust only be accessed by users with the `Item.READ` permission.\n* `Run` must only be accessed by users with the `Item.READ` permission on the owning `Job`.\n* `AdministrativeMonitor` must only be accessed by users with `Overall/Administer` permission.\n\nThis was typically implemented in the past by having the getters returning the object in question check the permission, as in https://github.com/jenk"
  },
  "3155": {
    "source_file": "read-access.txt",
    "text": "\nThis was typically implemented in the past by having the getters returning the object in question check the permission, as in https://github.com/jenkinsci/jenkins/blob/389c5a7e606fefa184959d7722c95c3b976b3375/core/src/main/java/jenkins/model/Jenkins.java#L2714...L2725[`Jenkins#getItem(String)`].\nA major downside to this approach is that every Stapler-accessible method returning an `AccessControll"
  },
  "3156": {
    "source_file": "read-access.txt",
    "text": ".java#L2714...L2725[`Jenkins#getItem(String)`].\nA major downside to this approach is that every Stapler-accessible method returning an `AccessControlled` object needs to implement such a permission check.\nOtherwise, a different getter or field could be used to access the object in question, bypassing the permission check.\nVarious security issues have resulted from this strategy, so it is not gener"
  },
  "3157": {
    "source_file": "read-access.txt",
    "text": "be used to access the object in question, bypassing the permission check.\nVarious security issues have resulted from this strategy, so it is not generally considered sufficient to restrict access to objects on its own.\n\n## Using `StaplerProxy`\n\nA more robust approach to prevent HTTP request handling by objects is to implement `StaplerProxy`.\nWhile originally intended to forward request handling to"
  },
  "3158": {
    "source_file": "read-access.txt",
    "text": "e robust approach to prevent HTTP request handling by objects is to implement `StaplerProxy`.\nWhile originally intended to forward request handling to a different object on certain conditions, it can also be used to just perform a permission check, and returning different values depending on the outcome of that check:\n\n* `return this` will continue routing with the current object.\n* Since Jenkins "
  },
  "3159": {
    "source_file": "read-access.txt",
    "text": "nd returning different values depending on the outcome of that check:\n\n* `return this` will continue routing with the current object.\n* Since Jenkins 2.147 and Jenkins LTS 2.138.3 `return null` will continue routing using a different approach, as the current object is not eligible for routing.\n  This is useful if even the existence of an object should be hidden from users without the permission to"
  },
  "3160": {
    "source_file": "read-access.txt",
    "text": " current object is not eligible for routing.\n  This is useful if even the existence of an object should be hidden from users without the permission to access it.\n  For `Item`, this is the difference between having no permissions, and having `Item.DISCOVER`.\n* Throwing exceptions will interrupt routing.\n\nA good minimal example for this is .\nA more complex example is , as it incorporates two differe"
  },
  "3161": {
    "source_file": "read-access.txt",
    "text": "COVER`.\n* Throwing exceptions will interrupt routing.\n\nA good minimal example for this is .\nA more complex example is , as it incorporates two different permission checks, and different behaviors in each case.\n\nWARNING: If your plugin depends on Jenkins versions older than 2.147 or LTS 2.138.3, and you want to use the `return null` variant, please note that this behaves the same way as `return thi"
  },
  "3162": {
    "source_file": "read-access.txt",
    "text": "ins versions older than 2.147 or LTS 2.138.3, and you want to use the `return null` variant, please note that this behaves the same way as `return this` in Jenkins 2.146 and earlier.\nA possible alternative to achieve the same result can be seen https://github.com/jenkinsci/jenkins/blob/ba33bd67cdaef87aba8a4e95dca8dcf108a7d73f/core/src/main/java/hudson/model/AbstractItem.java#L848...L853[here]."
  },
  "3163": {
    "source_file": "read-access.txt",
    "text": "://github.com/jenkinsci/jenkins/blob/ba33bd67cdaef87aba8a4e95dca8dcf108a7d73f/core/src/main/java/hudson/model/AbstractItem.java#L848...L853[here]."
  },
  "3164": {
    "source_file": "read-only.txt",
    "text": "title: Read only view\nlayout: developer\n\n\nExtended read and system read permission allow read only access\nto parts of Jenkins.\n\nThe jelly taglib's in core will render a read only look and feel,\nif the user only has access to read the view.\n\nThis is handled for developers transparently if they are already using one\nof the supported views, like the `job` configure view.\n\nThere are 3 permissions curr"
  },
  "3165": {
    "source_file": "read-only.txt",
    "text": "andled for developers transparently if they are already using one\nof the supported views, like the `job` configure view.\n\nThere are 3 permissions currently that interact with read-only views:\n\n* Overall/SystemRead\n* Agent/ExtendedRead\n* Job/ExtendedRead\n\nThey are currently not enabled by default, the easiest way to enable them is to install\nthe plugin:extended-read-permission[Extended read permiss"
  },
  "3166": {
    "source_file": "read-only.txt",
    "text": "ead\n\nThey are currently not enabled by default, the easiest way to enable them is to install\nthe plugin:extended-read-permission[Extended read permission plugin] v3.2 or above.\n\nJelly example:\n\n<!-- configure permissions on a job required for write access -->\n<j:set var=\"readOnlyMode\" value=\"${!it.hasPermission(it.CONFIGURE)}\" />\n\n<!-- administrator permissions required for write access -->\n<j:set"
  },
  "3167": {
    "source_file": "read-only.txt",
    "text": "ccess -->\n<j:set var=\"readOnlyMode\" value=\"${!it.hasPermission(it.CONFIGURE)}\" />\n\n<!-- administrator permissions required for write access -->\n<j:set var=\"readOnlyMode\" value=\"${!app.hasPermission(app.ADMINISTER)}\" />\n\nGroovy example:\n\n// configure permissions on a job required for write access\nset(\"readOnlyMode\", !it.hasPermission(it.CONFIGURE))\n\n// administrator permissions required for write a"
  },
  "3168": {
    "source_file": "read-only.txt",
    "text": "permissions on a job required for write access\nset(\"readOnlyMode\", !it.hasPermission(it.CONFIGURE))\n\n// administrator permissions required for write access\nset(\"readOnlyMode\", !app.hasPermission(app.ADMINISTER))\n\nIt's also possible to only use read-only mode for part of a view,\n\nThis is an example taken from the /configure page showing the\n`SYSTEM_READ` and `MANAGE` permissions working together, n"
  },
  "3169": {
    "source_file": "read-only.txt",
    "text": "nly mode for part of a view,\n\nThis is an example taken from the /configure page showing the\n`SYSTEM_READ` and `MANAGE` permissions working together, non-editable parts of the view\nrender in a read only manner:\n\n<j:forEach var=\"descriptor\" items=\"${h.getSortedDescriptorsForGlobalConfigUnclassifiedReadable()}\">\n    <j:set var=\"editable\" value=\"${h.getSortedDescriptorsForGlobalConfigUnclassified()}\"/"
  },
  "3170": {
    "source_file": "read-only.txt",
    "text": "getSortedDescriptorsForGlobalConfigUnclassifiedReadable()}\">\n    <j:set var=\"editable\" value=\"${h.getSortedDescriptorsForGlobalConfigUnclassified()}\"/>\n    <j:set var=\"readOnlyMode\" value=\"${!editable.contains(descriptor)}\" />\n  <!-- (unnecessary context removed) -->\n  <st:include page=\"${descriptor.globalConfigPage}\" from=\"${descriptor}\" />\n  <!-- (unnecessary context removed) -->\n</j:forEach>\n\nI"
  },
  "3171": {
    "source_file": "read-only.txt",
    "text": "text removed) -->\n  <st:include page=\"${descriptor.globalConfigPage}\" from=\"${descriptor}\" />\n  <!-- (unnecessary context removed) -->\n</j:forEach>\n\nIf you provide your own taglib that isn't in Jenkins core you may need to make some changes.\n\nDepending on what change is required there are a few different changes you might need to make,\nhere are a few examples.\n\nWe also add a default text when it i"
  },
  "3172": {
    "source_file": "read-only.txt",
    "text": "ng on what change is required there are a few different changes you might need to make,\nhere are a few examples.\n\nWe also add a default text when it is empty (N/A in this case):\n\n<j:choose>\n    <j:when test=\"${readOnlyMode}\">\n        <j:choose>\n            <j:when test=\"${empty(value)}\">\n                <span class=\"jenkins-not-applicable\">N/A</span>\n            </j:when>\n            <j:otherwise>"
  },
  "3173": {
    "source_file": "read-only.txt",
    "text": "       <j:when test=\"${empty(value)}\">\n                <span class=\"jenkins-not-applicable\">N/A</span>\n            </j:when>\n            <j:otherwise><pre class=\"jenkins-readonly\">${value}</pre></j:otherwise>\n        </j:choose>\n    </j:when>\n    <j:otherwise>\n    ... your normal default configuration\n    </j:otherwise>\n</j:choose>\n\nIt is preferable to render plain text or some other method that i"
  },
  "3174": {
    "source_file": "read-only.txt",
    "text": "otherwise>\n    ... your normal default configuration\n    </j:otherwise>\n</j:choose>\n\nIt is preferable to render plain text or some other method that is obvious to the user\nwhat is going on (disabled controls aren't very obvious), but a lot of the javascript\nand jelly taglibs depend on inputs of specific types being there for rendering,\nso sometimes it is preferable to just disable the control:\n\n<i"
  },
  "3175": {
    "source_file": "read-only.txt",
    "text": "ascript\nand jelly taglibs depend on inputs of specific types being there for rendering,\nso sometimes it is preferable to just disable the control:\n\n<input type=\"radio\"\n    checked=\"${attrs.checked?'true':null}\"\n    disabled=\"${readOnlyMode?'true':null}\"\n/>\n\nLike an X button on a repeatable element:\n\n<j:if test=\"${!readOnlyMode}\">\n    <f:block>\n    <div align=\"right\">\n        <f:repeatableDeleteBut"
  },
  "3176": {
    "source_file": "read-only.txt",
    "text": "l}\"\n/>\n\nLike an X button on a repeatable element:\n\n<j:if test=\"${!readOnlyMode}\">\n    <f:block>\n    <div align=\"right\">\n        <f:repeatableDeleteButton value=\"${attrs.deleteCaption}\" />\n    </div>\n    </f:block>\n</j:if>\n\nNormally in Jenkins the layout tag of a page will have a permission\nattribute which governs which permission is required to access the page.\n\nJenkins has a concept of 'impliedBy"
  },
  "3177": {
    "source_file": "read-only.txt",
    "text": "out tag of a page will have a permission\nattribute which governs which permission is required to access the page.\n\nJenkins has a concept of 'impliedBy' in it's permission, which means that each permission is allowed to be automatically granted by another one.\n_Job/ExtendedRead_ is implied by _Job/Configure_, which means that requiring _Job/ExtendedRead_\nto access a view, will also grant _Job/Confi"
  },
  "3178": {
    "source_file": "read-only.txt",
    "text": "ther one.\n_Job/ExtendedRead_ is implied by _Job/Configure_, which means that requiring _Job/ExtendedRead_\nto access a view, will also grant _Job/Configure_ access.\n\nHere are some examples that show what you will need to update the layout tag to:\n\nRequiring the _Job/ExtendedRead_ permission in Jelly:\n\n<l:layout permission=\"${it.EXTENDED_READ}\">\n...\n</l:layout>\n\n_Overall/SystemRead_ Jelly:\n\n<l:layou"
  },
  "3179": {
    "source_file": "read-only.txt",
    "text": "uiring the _Job/ExtendedRead_ permission in Jelly:\n\n<l:layout permission=\"${it.EXTENDED_READ}\">\n...\n</l:layout>\n\n_Overall/SystemRead_ Jelly:\n\n<l:layout permission=\"${app.SYSTEM_READ}\">\n...\n</l:layout>\n\n_Overall/SystemRead_ Groovy:\n\nl.layout(permission: app.SYSTEM_READ) {\n...\n}\n\nOften it makes sense to remove parts of a view, such as 'Save' or 'Apply' buttons.\n\nFor system read the simplest way to d"
  },
  "3180": {
    "source_file": "read-only.txt",
    "text": "n: app.SYSTEM_READ) {\n...\n}\n\nOften it makes sense to remove parts of a view, such as 'Save' or 'Apply' buttons.\n\nFor system read the simplest way to do this is to use the `l:isAdmin` tag:\n\n_isAdmin_ Jelly:\n\n<l:isAdmin>\n\n</l:isAdmin>\n\n_isAdmin_ Groovy:\n\nl.isAdmin() {\n...\n}\n\nThere's also a `l:hasAdministerOrManage` tag that can be used to check for the `Jenkins/Administer or `Jenkins/Manage` permiss"
  },
  "3181": {
    "source_file": "read-only.txt",
    "text": ":\n\nl.isAdmin() {\n...\n}\n\nThere's also a `l:hasAdministerOrManage` tag that can be used to check for the `Jenkins/Administer or `Jenkins/Manage` permissions.\n\nIf those don't fit, then you can write your own permission check:\n\n_hasPermission_ Jelly:\n\n<j:if test=\"${it.hasPermission(it.CONFIGURE)\">\n\n</j:if>\n\n_hasPermission_ Groovy:\n\nif (!it.hasPermission(it.CONFIGURE)) {\n...\n}\n\nFirstly you will need to"
  },
  "3182": {
    "source_file": "read-only.txt",
    "text": ":if test=\"${it.hasPermission(it.CONFIGURE)\">\n\n</j:if>\n\n_hasPermission_ Groovy:\n\nif (!it.hasPermission(it.CONFIGURE)) {\n...\n}\n\nFirstly you will need to update any server side permission checks to now check\non load for the _Read_ permission, rather than the _Configure_  or _Administer_ permission.\nSee  for more information\non this feature.\n\ni.e.\n\npublic Object getTarget() {\n    checkPermission(Jenki"
  },
  "3183": {
    "source_file": "read-only.txt",
    "text": "n the _Configure_  or _Administer_ permission.\nSee  for more information\non this feature.\n\ni.e.\n\npublic Object getTarget() {\n    checkPermission(Jenkins.SYSTEM_READ);\n}\n\nThen you will need to review if additional permission checks are required,\ni.e. any methods that allow saving or sensitive data access should now require the\npermission that was previously in use.\n\nSearching for 'public .* do' is "
  },
  "3184": {
    "source_file": "read-only.txt",
    "text": "any methods that allow saving or sensitive data access should now require the\npermission that was previously in use.\n\nSearching for 'public .* do' is a good start as web methods normally start with 'do', but\nyou should carefully review to make sure nothing is now exposed that shouldn't be.\n\npublic void doInstallPlugin() {\n    checkPermission(Jenkins.ADMINISTER);\n}\n\nYou do not need to worry about b"
  },
  "3185": {
    "source_file": "read-only.txt",
    "text": "othing is now exposed that shouldn't be.\n\npublic void doInstallPlugin() {\n    checkPermission(Jenkins.ADMINISTER);\n}\n\nYou do not need to worry about bumping your minimum required Jenkins core version\nas this feature is driven by variables set in the jelly context,\nold versions of Jenkins will just ignore it.\n\nThis was released in 2.222"
  },
  "3186": {
    "source_file": "read-only.txt",
    "text": "jelly context,\nold versions of Jenkins will just ignore it.\n\nThis was released in 2.222"
  },
  "3187": {
    "source_file": "referencing-another-project-by-name.txt",
    "text": "layout: section\ntitle: Referencing another project by name\n\n\nIn many places throughout Jenkins, you can refer to another project/job by name. For example, in a Pipeline Script, you might want to plugin:copyartifact/[copy artifacts] from another project:\n\n....\ncopyArtifacts projectName: 'myproject'\n....\n\nThat's all you need to do if your target project's name is simply alphanumeric, and is a simple"
  },
  "3188": {
    "source_file": "referencing-another-project-by-name.txt",
    "text": "ct:\n\n....\ncopyArtifacts projectName: 'myproject'\n....\n\nThat's all you need to do if your target project's name is simply alphanumeric, and is a simple project without subprojects, and has a unique name throughout your entire Jenkins controller. Read on for more complex scenarios\u2026\n\nIf you're using the plugin:cloudbees-folder[Folders Plugin] and you have multiple projects with the same name that are"
  },
  "3189": {
    "source_file": "referencing-another-project-by-name.txt",
    "text": "on for more complex scenarios\u2026\n\nIf you're using the plugin:cloudbees-folder[Folders Plugin] and you have multiple projects with the same name that are in different folders, you can differentiate between them using a path, similar to a Unix filesystem path. There are two types of paths:\n\nAbsolute paths begin with a forward slash, and refer to a project by describing the complete path to navigate to"
  },
  "3190": {
    "source_file": "referencing-another-project-by-name.txt",
    "text": " path. There are two types of paths:\n\nAbsolute paths begin with a forward slash, and refer to a project by describing the complete path to navigate to the project from the home page of your Jenkins controller. For example, to reference a project in the root of your Jenkins controller:\n\n....\n/myproject\n....\n\nOr, to reference a project in a subfolder:\n\n....\n/myfolder/myproject\n....\n\nRelative paths b"
  },
  "3191": {
    "source_file": "referencing-another-project-by-name.txt",
    "text": "he root of your Jenkins controller:\n\n....\n/myproject\n....\n\nOr, to reference a project in a subfolder:\n\n....\n/myfolder/myproject\n....\n\nRelative paths begin with something other than a forward slash, and refer to another project in relation to the current project. For example, say you have projects with the following absolute paths:\n\n....\n/thatproject\n/folder/someproject\n/folder/subfolder/myproject\n"
  },
  "3192": {
    "source_file": "referencing-another-project-by-name.txt",
    "text": "ent project. For example, say you have projects with the following absolute paths:\n\n....\n/thatproject\n/folder/someproject\n/folder/subfolder/myproject\n/folder/subfolder/anotherproject\n....\n\nIn a Pipeline Script for `+/folder/subfolder/myproject+`, you could refer to `+/folder/subfolder/anotherproject+` using this relative path:\n\n....\nanotherproject\n....\n\nAnd you could refer to `+/folder/someproject"
  },
  "3193": {
    "source_file": "referencing-another-project-by-name.txt",
    "text": " could refer to `+/folder/subfolder/anotherproject+` using this relative path:\n\n....\nanotherproject\n....\n\nAnd you could refer to `+/folder/someproject+` using this relative path, where `+..+` means to look in the parent folder:\n\n....\n../someproject\n....\n\nAnd you could refer to `+/thatproject+` using this relative path:\n\n....\n../../thatproject\n....\n\nSome types of projects \u2014 such as Maven projects, "
  },
  "3194": {
    "source_file": "referencing-another-project-by-name.txt",
    "text": "...\n\nAnd you could refer to `+/thatproject+` using this relative path:\n\n....\n../../thatproject\n....\n\nSome types of projects \u2014 such as Maven projects, Matrix projects, and Multibranch projects \u2014 have subcomponents. You can refer to these subcomponents as follows:\n\nYou can refer to an entire Maven project:\n\n....\nmymavenproject\n....\n\nOr to a group within a Maven project:\n\n....\nmymavenproject/my.group"
  },
  "3195": {
    "source_file": "referencing-another-project-by-name.txt",
    "text": " as follows:\n\nYou can refer to an entire Maven project:\n\n....\nmymavenproject\n....\n\nOr to a group within a Maven project:\n\n....\nmymavenproject/my.group\n....\n\nOr to a particular module:\n\n....\nmymavenproject/my.group$MyModule\n....\n\nYou can refer to all configurations of a Matrix project:\n\n....\nmymatrixproject\n....\n\nOr to a particular configuration, restricted by a axis:\n\n....\nmymatrixproject/someaxis"
  },
  "3196": {
    "source_file": "referencing-another-project-by-name.txt",
    "text": "configurations of a Matrix project:\n\n....\nmymatrixproject\n....\n\nOr to a particular configuration, restricted by a axis:\n\n....\nmymatrixproject/someaxis=somevalue\n....\n\nOr restricted by multiple axes:\n\n....\nmymatrixproject/someaxis=somevalue,anotheraxis=anothervalue\n....\n\nYou can refer to a particular branch:\n\n....\nmymultibranchproject/mybranch\n....\n\nSpecial characters in paths should be URL-encoded"
  },
  "3197": {
    "source_file": "referencing-another-project-by-name.txt",
    "text": "s=anothervalue\n....\n\nYou can refer to a particular branch:\n\n....\nmymultibranchproject/mybranch\n....\n\nSpecial characters in paths should be URL-encoded. For example, if your Multibranch Pipeline has a branch with a slash in it (`+feature/myfeature+`), replace the slash with `+%2F+`:\n\n....\nmymultibranchproject/feature%2Fmyfeature\n....\n\nSee the https://javadoc.jenkins.io/jenkins/model/Jenkins.html#ge"
  },
  "3198": {
    "source_file": "referencing-another-project-by-name.txt",
    "text": " replace the slash with `+%2F+`:\n\n....\nmymultibranchproject/feature%2Fmyfeature\n....\n\nSee the https://javadoc.jenkins.io/jenkins/model/Jenkins.html#getItem-java.lang.String-hudson.model.ItemGroup-[`+Jenkins::getItem()+`] function."
  },
  "3199": {
    "source_file": "releasing-cd.txt",
    "text": "title: Setting up plugin releases through GitHub\nlayout: developer\nreferences:\n- url: https://github.com/jenkinsci/jep/blob/master/jep/229/README.adoc\n  title: 'JEP-229: Continuous Delivery of Jenkins Components and Plugins'\n\n\nMaintainers of Jenkins plugin repositories on GitHub can opt into continuous delivery (CD).\nIn this mode, any successful build of the default branch (`master` or `main`) by "
  },
  "3200": {
    "source_file": "releasing-cd.txt",
    "text": "plugin repositories on GitHub can opt into continuous delivery (CD).\nIn this mode, any successful build of the default branch (`master` or `main`) by ci.jenkins.io can result in a new plugin release.\nGitHub Actions are used to rebuild the code and deploy it to Artifactory,\nwithout the need for maintainers to use personal credentials or local builds.\nRelease notes are generated automatically accord"
  },
  "3201": {
    "source_file": "releasing-cd.txt",
    "text": "ploy it to Artifactory,\nwithout the need for maintainers to use personal credentials or local builds.\nRelease notes are generated automatically according to pull request (PR) titles and some predefined labels.\n\nIMPORTANT: `maven-release-plugin` (MRP) is not used in this mode.\nRather than traditional version numbers like `1.23` or `2.3.4` which are chosen by the maintainer,\na CD release will have a"
  },
  "3202": {
    "source_file": "releasing-cd.txt",
    "text": " is not used in this mode.\nRather than traditional version numbers like `1.23` or `2.3.4` which are chosen by the maintainer,\na CD release will have a version of the form `123.vabcdef456789`:\nan integer component determined by the Git history depth,\nand an informational component with the Git commit hash.\n\nNOTE: Push the work to prepare your plugin for CD to a dedicated branch, which you file a pu"
  },
  "3203": {
    "source_file": "releasing-cd.txt",
    "text": "and an informational component with the Git commit hash.\n\nNOTE: Push the work to prepare your plugin for CD to a dedicated branch, which you file a pull request from to your default branch.\nWhen enabling CD, the hosting team reviews this PR containing all necessary changes in your plugin, to prevent improper releases and mistakes.\nDon't push the changes directly to the default branch or merge the "
  },
  "3204": {
    "source_file": "releasing-cd.txt",
    "text": "g all necessary changes in your plugin, to prevent improper releases and mistakes.\nDon't push the changes directly to the default branch or merge the PR before the hosting team has reviewed it.\n\nVerify that the plugin has already been .\nThe file `pom.xml` should contain `<version>$\\{revision}$\\{changelist}</version>` and the files `.mvn/extensions.xml` and `.mvn/maven.config` should exist *before "
  },
  "3205": {
    "source_file": "releasing-cd.txt",
    "text": ".xml` should contain `<version>$\\{revision}$\\{changelist}</version>` and the files `.mvn/extensions.xml` and `.mvn/maven.config` should exist *before proceeding with subsequent steps*.\n\nNOTE: A new plugin created from the  will already have this setup.\n\nHere are some PR examples for various plugins to enable CD:\n\n-\n-\n-\n\nCreate the CD workflow as a copy of the template:\n\nmkdir -p .github/workflows\n"
  },
  "3206": {
    "source_file": "releasing-cd.txt",
    "text": "p.\n\nHere are some PR examples for various plugins to enable CD:\n\n-\n-\n-\n\nCreate the CD workflow as a copy of the template:\n\nmkdir -p .github/workflows\ncurl --silent --show-error --location --output .github/workflows/cd.yaml https://raw.githubusercontent.com/jenkinsci/.github/master/workflow-templates/cd.yaml\ngit add .github/workflows/cd.yaml\n\nIf you want to prevent automatic releases after PRs are "
  },
  "3207": {
    "source_file": "releasing-cd.txt",
    "text": "nt.com/jenkinsci/.github/master/workflow-templates/cd.yaml\ngit add .github/workflows/cd.yaml\n\nIf you want to prevent automatic releases after PRs are merged, edit the `.github/workflows/cd.yaml` and remove the `check_run` workflow trigger, leaving only `workflow_dispatch`:\n\n--- a/workflow-templates/cd.yaml\n++ b/workflow-templates/cd.yaml\n@@ -3,9 +3,6 @@\n name: cd\n on:\n   workflow_dispatch:\n-  chec"
  },
  "3208": {
    "source_file": "releasing-cd.txt",
    "text": "ly `workflow_dispatch`:\n\n--- a/workflow-templates/cd.yaml\n++ b/workflow-templates/cd.yaml\n@@ -3,9 +3,6 @@\n name: cd\n on:\n   workflow_dispatch:\n-  check_run:\n-    types:\n-      - completed\n\n permissions:\n   checks: read\n\nYou can delete any existing Release Drafter configuration,\nas the default is to assume ;\nand/or workflow, as that will be subsumed by the CD workflow:\n\ngit rm .github/release-draft"
  },
  "3209": {
    "source_file": "releasing-cd.txt",
    "text": "lease Drafter configuration,\nas the default is to assume ;\nand/or workflow, as that will be subsumed by the CD workflow:\n\ngit rm .github/release-drafter.y*ml\ngit rm .github/workflows/release-drafter.y*ml\n\nAlso  if it was configured that way.\n\nIMPORTANT: These files may have been set up this way by the https://github.com/jenkinsci/archetypes/[plugin archetype] that you used to initialize the plugin"
  },
  "3210": {
    "source_file": "releasing-cd.txt",
    "text": "NT: These files may have been set up this way by the https://github.com/jenkinsci/archetypes/[plugin archetype] that you used to initialize the plugin.\n\nNOTE: If you have  configured (normally in `renovate.json` or `.github/renovate.json`) do not configure Dependabot.\n\nIf you have a `.github/dependabot.yml`, add:\n\n- package-ecosystem: github-actions\n  directory: /\n  schedule:\n    interval: monthly"
  },
  "3211": {
    "source_file": "releasing-cd.txt",
    "text": "figure Dependabot.\n\nIf you have a `.github/dependabot.yml`, add:\n\n- package-ecosystem: github-actions\n  directory: /\n  schedule:\n    interval: monthly\n\nIf you did not yet have such a file, create it now:\n\ncurl --silent --show-error --location --output .github/dependabot.yml https://raw.githubusercontent.com/jenkinsci/archetypes/master/common-files/.github/dependabot.yml\n\nUpdate the file `.mvn/mave"
  },
  "3212": {
    "source_file": "releasing-cd.txt",
    "text": "t .github/dependabot.yml https://raw.githubusercontent.com/jenkinsci/archetypes/master/common-files/.github/dependabot.yml\n\nUpdate the file `.mvn/maven.config` so it looks like this:\n\n-Pconsume-incrementals\n-Pmight-produce-incrementals\n-Dchangelist.format=%d.v%s\n\nUpdate the Maven `pom.xml` as described below, depending on your preferred version number format.\n\n// Putting this here because definiti"
  },
  "3213": {
    "source_file": "releasing-cd.txt",
    "text": "ormat=%d.v%s\n\nUpdate the Maven `pom.xml` as described below, depending on your preferred version number format.\n\n// Putting this here because definition lists have no indentation, making it impossible to tell this isn't part of the last item.\nOnce you're done with these changes, commit all of the source file changes in a branch and file a pull request for them.\nDo not forget to `git add .` to make"
  },
  "3214": {
    "source_file": "releasing-cd.txt",
    "text": "u're done with these changes, commit all of the source file changes in a branch and file a pull request for them.\nDo not forget to `git add .` to make sure any newly created files are included.\nMerge this PR activating CD.\nBe sure to apply one of the\nto this and every subsequent PR before merging so that Release Drafter can properly categorize changes.\n\nFully automated versioning (recommended)::\nF"
  },
  "3215": {
    "source_file": "releasing-cd.txt",
    "text": "\nto this and every subsequent PR before merging so that Release Drafter can properly categorize changes.\n\nFully automated versioning (recommended)::\nFor a regular component whose version number is not that meaningful, let the version number be automatically determined by setting a top-level `<version>+++${changelist}+++</version>` and having an entry `<changelist>999999-SNAPSHOT</changelist>` in t"
  },
  "3216": {
    "source_file": "releasing-cd.txt",
    "text": "tically determined by setting a top-level `<version>+++${changelist}+++</version>` and having an entry `<changelist>999999-SNAPSHOT</changelist>` in the `<properties>` section, removing `<revision>` and `<project.build.outputTimestamp>` (if present):\n--- a/.mvn/maven.config\n++ b/.mvn/maven.config\n@@ -1,2 +1,3 @@\n -Pconsume-incrementals\n -Pmight-produce-incrementals\n-Dchangelist.format=%d.v%s\n--- a"
  },
  "3217": {
    "source_file": "releasing-cd.txt",
    "text": "\n--- a/.mvn/maven.config\n++ b/.mvn/maven.config\n@@ -1,2 +1,3 @@\n -Pconsume-incrementals\n -Pmight-produce-incrementals\n-Dchangelist.format=%d.v%s\n--- a/pom.xml\n++ b/pom.xml\n@@ -7,7 +7,7 @@\n-    <version>${revision}${changelist}</version>\n<version>${changelist}</version>\n     <packaging>hpi</packaging>\n@@ -26,8 +26,7 @@\n     <properties>\n-        <revision>1.23</revision>\n-        <changelist>-SNAPS"
  },
  "3218": {
    "source_file": "releasing-cd.txt",
    "text": "angelist}</version>\n     <packaging>hpi</packaging>\n@@ -26,8 +26,7 @@\n     <properties>\n-        <revision>1.23</revision>\n-        <changelist>-SNAPSHOT</changelist>\n<changelist>999999-SNAPSHOT</changelist>\n         <jenkins.version>2.361.4</jenkins.version>\n-        <project.build.outputTimestamp>2023-01-01T00:00:00Z</project.build.outputTimestamp>\n     </properties>\n\nIn this typical case, a CI/"
  },
  "3219": {
    "source_file": "releasing-cd.txt",
    "text": ".version>\n-        <project.build.outputTimestamp>2023-01-01T00:00:00Z</project.build.outputTimestamp>\n     </properties>\n\nIn this typical case, a CI/release build (`-Dset.changelist` specified) will be of the form `123.vabcdef456789`.\nA snapshot build will be `999999-SNAPSHOT`: arbitrary but treated as a snapshot by Maven and newer than any release.\nYou can see examples of the proposed snapshot a"
  },
  "3220": {
    "source_file": "releasing-cd.txt",
    "text": "ld will be `999999-SNAPSHOT`: arbitrary but treated as a snapshot by Maven and newer than any release.\nYou can see examples of the proposed snapshot and release versions in your case by running:\nmvn validate help:evaluate -Dexpression=project.version\nmvn validate help:evaluate -Dexpression=project.version -Dset.changelist -Dignore.dirt\n\nIMPORTANT: Note that you will very quickly create releases wi"
  },
  "3221": {
    "source_file": "releasing-cd.txt",
    "text": "\nmvn validate help:evaluate -Dexpression=project.version -Dset.changelist -Dignore.dirt\n\nIMPORTANT: Note that you will very quickly create releases with version numbers greater than 100, as the major version component corresponds to the number of commits in the branch you're releasing from.\nIf you're not ready to commit to all future versions of your plugin being this large, see the next option.\nN"
  },
  "3222": {
    "source_file": "releasing-cd.txt",
    "text": "mits in the branch you're releasing from.\nIf you're not ready to commit to all future versions of your plugin being this large, see the next option.\nNOTE: It is worth communicating this to your users, as they will see a very different version number format than before.\nThe best way to do this is to add a line to the release notes: .\n\nManually controlled prefix (optional)::\nIf you do not want to ha"
  },
  "3223": {
    "source_file": "releasing-cd.txt",
    "text": "format than before.\nThe best way to do this is to add a line to the release notes: .\n\nManually controlled prefix (optional)::\nIf you do not want to have large major version numbers, like with fully automated versioning described above, keep `<revision>` in the `<properties>` section, setting it to the prefix (`major`, `major.minor`, etc., depending on how much of the version number you want to man"
  },
  "3224": {
    "source_file": "releasing-cd.txt",
    "text": "n>` in the `<properties>` section, setting it to the prefix (`major`, `major.minor`, etc., depending on how much of the version number you want to manually manage) and use it as part of the top-level `<version>` element, removing `<project.build.outputTimestamp>` (if present):\n--- a/.mvn/maven.config\n++ b/.mvn/maven.config\n@@ -1,2 +1,3 @@\n -Pconsume-incrementals\n -Pmight-produce-incrementals\n-Dcha"
  },
  "3225": {
    "source_file": "releasing-cd.txt",
    "text": "utTimestamp>` (if present):\n--- a/.mvn/maven.config\n++ b/.mvn/maven.config\n@@ -1,2 +1,3 @@\n -Pconsume-incrementals\n -Pmight-produce-incrementals\n-Dchangelist.format=%d.v%s\n--- a/pom.xml\n++ b/pom.xml\n@@ -10,12 +10,12 @@\n   <artifactId>some-library-wrapper</artifactId>\n-  <version>${revision}${changelist}</version>\n<version>${revision}.${changelist}</version>\n   <packaging>hpi</packaging>\n   <proper"
  },
  "3226": {
    "source_file": "releasing-cd.txt",
    "text": "pper</artifactId>\n-  <version>${revision}${changelist}</version>\n<version>${revision}.${changelist}</version>\n   <packaging>hpi</packaging>\n   <properties>\n-    <revision>1.2.3</revision>\n-    <changelist>-SNAPSHOT</changelist>\n<revision>1</revision>\n<changelist>999999-SNAPSHOT</changelist>\n     <jenkins.version>2.361.4</jenkins.version>\n-    <project.build.outputTimestamp>2023-01-01T00:00:00Z</pr"
  },
  "3227": {
    "source_file": "releasing-cd.txt",
    "text": "\n<changelist>999999-SNAPSHOT</changelist>\n     <jenkins.version>2.361.4</jenkins.version>\n-    <project.build.outputTimestamp>2023-01-01T00:00:00Z</project.build.outputTimestamp>\n\nHere the version numbers will look like `1.321.vabcdef456789` or `1.999999-SNAPSHOT`, respectively.\nThis could be appropriate if you are leery of committing up front to having major version numbers be in the triple digit"
  },
  "3228": {
    "source_file": "releasing-cd.txt",
    "text": "9999-SNAPSHOT`, respectively.\nThis could be appropriate if you are leery of committing up front to having major version numbers be in the triple digits,\nwith no option of going back to `maven-release-plugin`-style versioning except by starting at say `1000.1`,\nbecause version numbers going forward must be mathematically larger than any currently on the update center.\nYou can see examples of the pr"
  },
  "3229": {
    "source_file": "releasing-cd.txt",
    "text": " `1000.1`,\nbecause version numbers going forward must be mathematically larger than any currently on the update center.\nYou can see examples of the proposed snapshot and release versions in your case by running:\nmvn validate help:evaluate -Dexpression=project.version\nmvn validate help:evaluate -Dexpression=project.version -Dset.changelist -Dignore.dirt\n\nIMPORTANT: It is _not recommended_ to implem"
  },
  "3230": {
    "source_file": "releasing-cd.txt",
    "text": "n=project.version\nmvn validate help:evaluate -Dexpression=project.version -Dset.changelist -Dignore.dirt\n\nIMPORTANT: It is _not recommended_ to implement actual semantic versioning with automated releases performed by CD, as that requires great care in always changing the `revision` as part of the changes that semantically would require a `revision` change for the next release.\nOtherwise, automate"
  },
  "3231": {
    "source_file": "releasing-cd.txt",
    "text": "in always changing the `revision` as part of the changes that semantically would require a `revision` change for the next release.\nOtherwise, automated releases may have version numbers that semantically would not make sense.\n\nVersioning with wrapped components (optional)::\nSimilar to the previous option, for a component whose version number ought to reflect a release version of some wrapped compo"
  },
  "3232": {
    "source_file": "releasing-cd.txt",
    "text": " components (optional)::\nSimilar to the previous option, for a component whose version number ought to reflect a release version of some wrapped component, use a hyphen (`-`) as the separator between the prefix corresponding to the wrapped component's version and the CD-generated suffix, removing `<project.build.outputTimestamp>` (if present):\n--- a/.mvn/maven.config\n++ b/.mvn/maven.config\n@@ -1,2"
  },
  "3233": {
    "source_file": "releasing-cd.txt",
    "text": "s version and the CD-generated suffix, removing `<project.build.outputTimestamp>` (if present):\n--- a/.mvn/maven.config\n++ b/.mvn/maven.config\n@@ -1,2 +1,3 @@\n -Pconsume-incrementals\n -Pmight-produce-incrementals\n-Dchangelist.format=%d.v%s\n--- a/pom.xml\n++ b/pom.xml\n@@ -10,12 +10,12 @@\n   <artifactId>some-library-wrapper</artifactId>\n-  <version>${revision}${changelist}</version>\n<version>${revisi"
  },
  "3234": {
    "source_file": "releasing-cd.txt",
    "text": "xml\n++ b/pom.xml\n@@ -10,12 +10,12 @@\n   <artifactId>some-library-wrapper</artifactId>\n-  <version>${revision}${changelist}</version>\n<version>${revision}-${changelist}</version>\n   <packaging>hpi</packaging>\n   <properties>\n-    <revision>4.0.0-1.3</revision>\n-    <changelist>-SNAPSHOT</changelist>\n<revision>4.0.0</revision>\n<changelist>999999-SNAPSHOT</changelist>\n     <jenkins.version>2.361.4</j"
  },
  "3235": {
    "source_file": "releasing-cd.txt",
    "text": "revision>\n-    <changelist>-SNAPSHOT</changelist>\n<revision>4.0.0</revision>\n<changelist>999999-SNAPSHOT</changelist>\n     <jenkins.version>2.361.4</jenkins.version>\n-    <project.build.outputTimestamp>2023-01-01T00:00:00Z</project.build.outputTimestamp>\n\nHere the version numbers will look like `4.0.0-123.vabcdef456789` or `4.0.0-999999-SNAPSHOT`, respectively.\nYou can see examples of the proposed"
  },
  "3236": {
    "source_file": "releasing-cd.txt",
    "text": "amp>\n\nHere the version numbers will look like `4.0.0-123.vabcdef456789` or `4.0.0-999999-SNAPSHOT`, respectively.\nYou can see examples of the proposed snapshot and release versions in your case by running:\nmvn validate help:evaluate -Dexpression=project.version\nmvn validate help:evaluate -Dexpression=project.version -Dset.changelist -Dignore.dirt\n\nUse the `revision` property for the `<dependency>`"
  },
  "3237": {
    "source_file": "releasing-cd.txt",
    "text": "ect.version\nmvn validate help:evaluate -Dexpression=project.version -Dset.changelist -Dignore.dirt\n\nUse the `revision` property for the `<dependency>` declaration to ensure they always match:\n<dependency>\n    <groupId>org.elsewhere</groupId>\n    <artifactId>some-lib</artifactId>\n    <version>${revision}</version>\n</dependency>\n\nRemember that changes to this property mean that the wrapped component"
  },
  "3238": {
    "source_file": "releasing-cd.txt",
    "text": "ifactId>some-lib</artifactId>\n    <version>${revision}</version>\n</dependency>\n\nRemember that changes to this property mean that the wrapped component has been updated, which would typically be a significant change that deserves an appropriate release-triggering label (`developer`, `enhancement`, or `bug`).\nYou may wish to edit your Dependabot configuration to automatically apply `developer` rathe"
  },
  "3239": {
    "source_file": "releasing-cd.txt",
    "text": "e-triggering label (`developer`, `enhancement`, or `bug`).\nYou may wish to edit your Dependabot configuration to automatically apply `developer` rather than `dependencies` for bumps to this special dependency.\n\nEnable the continuous delivery flag in  (RPU) for your plugin by filing a pull request adding to `permissions/plugin-xxx.yml`:\n\ncd:\n  enabled: true\n\nBy default, this enables https://github."
  },
  "3240": {
    "source_file": "releasing-cd.txt",
    "text": " (RPU) for your plugin by filing a pull request adding to `permissions/plugin-xxx.yml`:\n\ncd:\n  enabled: true\n\nBy default, this enables https://github.com/jenkins-infra/repository-permissions-updater?tab=readme-ov-file#exclusively-using-jep-229-cd[exclusive JEP-229 CD], which does not grant the listed account upload permissions.\n\nIn your PR towards the repository permission updater, include a link "
  },
  "3241": {
    "source_file": "releasing-cd.txt",
    "text": "lusive JEP-229 CD], which does not grant the listed account upload permissions.\n\nIn your PR towards the repository permission updater, include a link to the PR in your plugin, which contains all the necessary changes, like described above.\n\nOnce that has been merged, start checking `https://github.com/jenkinsci/your-plugin/settings/secrets/actions`\nuntil you see `MAVEN_TOKEN` and `MAVEN_USERNAME` "
  },
  "3242": {
    "source_file": "releasing-cd.txt",
    "text": " has been merged, start checking `https://github.com/jenkinsci/your-plugin/settings/secrets/actions`\nuntil you see `MAVEN_TOKEN` and `MAVEN_USERNAME` appear under *Repository secrets*.\n\nIf you use `cd.yaml` unchanged::\nWhenever Jenkins reports a successful build of your default branch,\nand at least one pull request had a label indicating it was of interest to users\n(e.g., `enhancement` rather than"
  },
  "3243": {
    "source_file": "releasing-cd.txt",
    "text": "essful build of your default branch,\nand at least one pull request had a label indicating it was of interest to users\n(e.g., `enhancement` rather than `chore`), your component will be released to Artifactory and\nrelease notes published in GitHub.\nYou do not need any special credentials or local checkout; just merge pull requests with suitable titles and labels.\nYou will see a lot of workflow runs "
  },
  "3244": {
    "source_file": "releasing-cd.txt",
    "text": " do not need any special credentials or local checkout; just merge pull requests with suitable titles and labels.\nYou will see a lot of workflow runs in the *Actions* tab in GitHub, only a small proportion of which are actual releases.\nDue to technical limitations in GitHub Actions it is not possible to suppress the extraneous runs.\nActual releases will display a green check next to the *release* "
  },
  "3245": {
    "source_file": "releasing-cd.txt",
    "text": "al limitations in GitHub Actions it is not possible to suppress the extraneous runs.\nActual releases will display a green check next to the *release* stage.\nYou can also trigger a deployment explicitly, if the current commit has a passing check from Jenkins.\nVisit https://github.com/jenkinsci/your-plugin/actions/workflows/cd.yaml and click Run workflow.\n\nIf you changed `cd.yaml` to only run on `wo"
  },
  "3246": {
    "source_file": "releasing-cd.txt",
    "text": "Jenkins.\nVisit https://github.com/jenkinsci/your-plugin/actions/workflows/cd.yaml and click Run workflow.\n\nIf you changed `cd.yaml` to only run on `workflow_dispatch`::\nYou can trigger a release explicitly, if the current commit has a passing check from Jenkins.\nVisit https://github.com/jenkinsci/your-plugin/actions/workflows/cd.yaml and click Run workflow.\n\nIt is best to avoid ever making incompa"
  },
  "3247": {
    "source_file": "releasing-cd.txt",
    "text": "rom Jenkins.\nVisit https://github.com/jenkinsci/your-plugin/actions/workflows/cd.yaml and click Run workflow.\n\nIt is best to avoid ever making incompatible changes to your plugin.\nIf you must make one, then you can define `hpi.compatibleSinceVersion` as for .\nIf `master` is currently `123.vXXX` according to\n\nmvn validate help:evaluate -Dexpression=project.version -Dset.changelist\n\nthen you can set"
  },
  "3248": {
    "source_file": "releasing-cd.txt",
    "text": " as for .\nIf `master` is currently `123.vXXX` according to\n\nmvn validate help:evaluate -Dexpression=project.version -Dset.changelist\n\nthen you can set\n\n<hpi.compatibleSinceVersion>124</hpi.compatibleSinceVersion>\n\nin your pull request with the breaking changes,\nsince the new release version will be `124.vXXX` if you squash-merge this PR,\nor something higher (at least `125.vXXX`) if you true-merge "
  },
  "3249": {
    "source_file": "releasing-cd.txt",
    "text": "ng changes,\nsince the new release version will be `124.vXXX` if you squash-merge this PR,\nor something higher (at least `125.vXXX`) if you true-merge it.\n(It is only important that the value is greater than that of the previous actual release,\nand less than or equal to that of the release containing the breaking change.)\n\nDo not forget to mark the PR with the label `breaking` (or `removed`) to get"
  },
  "3250": {
    "source_file": "releasing-cd.txt",
    "text": "ss than or equal to that of the release containing the breaking change.)\n\nDo not forget to mark the PR with the label `breaking` (or `removed`) to get an appropriate categorization in release notes.\n(These labels also normally cause a release to be triggered automatically upon merge.)\n\nIf https://github.com/jenkins-infra/repository-permissions-updater?tab=readme-ov-file#exclusively-using-jep-229-c"
  },
  "3251": {
    "source_file": "releasing-cd.txt",
    "text": "riggered automatically upon merge.)\n\nIf https://github.com/jenkins-infra/repository-permissions-updater?tab=readme-ov-file#exclusively-using-jep-229-cd[exclusive JEP-229 CD] is disabled for your component, you can also release manually if you have configured your machine for .\nTo cut a release:\n\n# Checkout the primary branch of the repository.\n# If your branch is not named 'main' or 'master', upda"
  },
  "3252": {
    "source_file": "releasing-cd.txt",
    "text": "nfigured your machine for .\nTo cut a release:\n\n# Checkout the primary branch of the repository.\n# If your branch is not named 'main' or 'master', update it as needed.\ngit checkout main || git checkout master\ngit pull --ff-only\nmvn -Dset.changelist \\\n  -Pquick-build \\\n  -P-consume-incrementals \\\n  -DaltDeploymentRepository=maven.jenkins-ci.org::default::https://repo.jenkins-ci.org/releases/ \\\n  cle"
  },
  "3253": {
    "source_file": "releasing-cd.txt",
    "text": "  -Pquick-build \\\n  -P-consume-incrementals \\\n  -DaltDeploymentRepository=maven.jenkins-ci.org::default::https://repo.jenkins-ci.org/releases/ \\\n  clean deploy\n\nCheck that `MAVEN_TOKEN` and `MAVEN_USERNAME` appear under Repository secrets.\n\nEnsure that the pull request has a label indicating it was of interest to users (e.g., `enhancement` rather than `chore`).\n\nSee the complete list of label cate"
  },
  "3254": {
    "source_file": "releasing-cd.txt",
    "text": "at the pull request has a label indicating it was of interest to users (e.g., `enhancement` rather than `chore`).\n\nSee the complete list of label categories at https://github.com/jenkinsci/.github/blob/master/.github/release-drafter.yml and the list of \"interesting\" categories at https://github.com/jenkins-infra/interesting-category-action/blob/main/action.yaml#L13.\n\nYou can use the `developer` la"
  },
  "3255": {
    "source_file": "releasing-cd.txt",
    "text": "of \"interesting\" categories at https://github.com/jenkins-infra/interesting-category-action/blob/main/action.yaml#L13.\n\nYou can use the `developer` label to release a pull request even if its not interesting to end users, e.g. it is a dependency of a downstream pull request or it fixes tests for Plugin Compatibility Testing.\n\nIf you add an \"interesting\" label on a pull request already merged then "
  },
  "3256": {
    "source_file": "releasing-cd.txt",
    "text": " downstream pull request or it fixes tests for Plugin Compatibility Testing.\n\nIf you add an \"interesting\" label on a pull request already merged then merge another pull request (even with an uninteresting label), you will get a release since the workflow will see that there has been at least one interesting pull request since the last release.\n\nFinally, if you manually trigger the CD action and th"
  },
  "3257": {
    "source_file": "releasing-cd.txt",
    "text": "flow will see that there has been at least one interesting pull request since the last release.\n\nFinally, if you manually trigger the CD action and the build is passing on the primary branch, it will publish a new release regardless of any labels.\n\nUnauthorized means that the credentials were invalid, or not sent by Maven.\n\nThis normally means that the secrets configured in the repository have exp"
  },
  "3258": {
    "source_file": "releasing-cd.txt",
    "text": "nauthorized means that the credentials were invalid, or not sent by Maven.\n\nThis normally means that the secrets configured in the repository have expired, create an issue in the INFRA helpdesk on , and let the team know in #jenkins-infra on .\n\nAlternatively you can temporarily update the secrets yourself with your own personal credentials.\n\nThe two most common explanations for this error are:\n\n* "
  },
  "3259": {
    "source_file": "releasing-cd.txt",
    "text": "natively you can temporarily update the secrets yourself with your own personal credentials.\n\nThe two most common explanations for this error are:\n\n* You don't have permission to upload to the specified path.\n  .\n  Check that the path you're allowed to upload to matches the actual upload attempt (i.e. no typos).\n* The specified release already exists and you try to overwrite it.\n  We do not allow "
  },
  "3260": {
    "source_file": "releasing-cd.txt",
    "text": "to upload to matches the actual upload attempt (i.e. no typos).\n* The specified release already exists and you try to overwrite it.\n  We do not allow replacing existing releases.\n\nIf none of the provided solutions help, send an email to the  and explain what you did, and how it failed."
  },
  "3261": {
    "source_file": "releasing-cd.txt",
    "text": "ain what you did, and how it failed."
  },
  "3262": {
    "source_file": "releasing-experimental-updates.txt",
    "text": "title: Publishing Experimental Plugin Releases\nlayout: developer\n\nOne of the methods to release experimental updates is using the  combined with  builds:\n\n- The plugin installation manager tool enables easier import into an instance of Jenkins by downloading plugins and their respective dependencies into a folder.\n- It allows the administrator to use incremental builds without requiring a \"beta\" r"
  },
  "3263": {
    "source_file": "releasing-experimental-updates.txt",
    "text": "nloading plugins and their respective dependencies into a folder.\n- It allows the administrator to use incremental builds without requiring a \"beta\" release.\n- The tool provides handy information about the downloaded plugns, such as available updates, security warnings, and many more.\n- This method provides the user with flexibility to create incremental versions of Jenkins core or an upstream plu"
  },
  "3264": {
    "source_file": "releasing-experimental-updates.txt",
    "text": ", security warnings, and many more.\n- This method provides the user with flexibility to create incremental versions of Jenkins core or an upstream plugin with dependencies, while providing the ability to switch between and keep track of incremental versions.\n\n- Using the plugin installation manager with incremental builds makes it easier to test and explore unreleased plugin versions.\n\nThe other m"
  },
  "3265": {
    "source_file": "releasing-experimental-updates.txt",
    "text": "ersions.\n\n- Using the plugin installation manager with incremental builds makes it easier to test and explore unreleased plugin versions.\n\nThe other method is to simplify the delivery of plugin beta versions to interested users.\nThe Jenkins project publishes an _experimental update center_.\nThe experimental update center includes alpha and beta versions of plugins, which aren't usually included in"
  },
  "3266": {
    "source_file": "releasing-experimental-updates.txt",
    "text": "ublishes an _experimental update center_.\nThe experimental update center includes alpha and beta versions of plugins, which aren't usually included in the regular update center.\n\nNOTE: The experimental update center is deprecated in favor of incrementals, as described above.\n\nPlugin releases that contain `alpha` or `beta` in their version number will only appear in the experimental update site, no"
  },
  "3267": {
    "source_file": "releasing-experimental-updates.txt",
    "text": "tals, as described above.\n\nPlugin releases that contain `alpha` or `beta` in their version number will only appear in the experimental update site, not in the regular update center.\nThe experimental update center also serves regular releases.\nNewer releases hide older releases in all update centers.\nFor example, the release of version `1.4` will hide `1.3-beta-2` from the experimental update cente"
  },
  "3268": {
    "source_file": "releasing-experimental-updates.txt",
    "text": "eleases hide older releases in all update centers.\nFor example, the release of version `1.4` will hide `1.3-beta-2` from the experimental update center.\n\nNote that **only** `alpha` and `beta` strings in the version number will publish to the experimental update center.\nOther version strings like `proto`, `rc`, and `unstable` **will appear** in the regular update center.\n\nExperimental Update Center"
  },
  "3269": {
    "source_file": "releasing-experimental-updates.txt",
    "text": "ntal update center.\nOther version strings like `proto`, `rc`, and `unstable` **will appear** in the regular update center.\n\nExperimental Update Center is not enabled by default in Jenkins, additional steps are needed to enable it in Jenkins.\n\nUsers who are interested in downloading experimental plugin releases can go to _Plugin Manager_, then to the _Advanced_ tab, and configure the update center "
  },
  "3270": {
    "source_file": "releasing-experimental-updates.txt",
    "text": "ho are interested in downloading experimental plugin releases can go to _Plugin Manager_, then to the _Advanced_ tab, and configure the update center URL `https://updates.jenkins.io/experimental/update-center.json`.\nSubmit, and then select _Check Now_.\nExperimental plugin updates will be marked as such on the _Available_ and _Updates_ tabs of the _Plugin Manager_.\n\nOnce you install the beta plugin"
  },
  "3271": {
    "source_file": "releasing-experimental-updates.txt",
    "text": "_.\nExperimental plugin updates will be marked as such on the _Available_ and _Updates_ tabs of the _Plugin Manager_.\n\nOnce you install the beta plugins that you wanted, you can switch back to the default `https://updates.jenkins.io/update-center.json` update center URL.\nThe experimental update center only offers the latest version of each plugin, even if it is incompatible with your version of Jen"
  },
  "3272": {
    "source_file": "releasing-experimental-updates.txt",
    "text": "` update center URL.\nThe experimental update center only offers the latest version of each plugin, even if it is incompatible with your version of Jenkins.\n\nplugin:configuration-as-code[Jenkins Configuration-as-Code plugin] allows configuring update centers in configuration YAMLs.\nOnce configured, it will be possible to install experimenta plugins and versions from the _Plugin Manager_ Web UI.\n\n``"
  },
  "3273": {
    "source_file": "releasing-experimental-updates.txt",
    "text": "centers in configuration YAMLs.\nOnce configured, it will be possible to install experimenta plugins and versions from the _Plugin Manager_ Web UI.\n\n```yml\njenkins:\n  updateCenter:\n    sites:\n      - id: \"default\"\n        url: \"https://updates.jenkins.io/update-center.json\"\n      - id: \"experimental\"\n        url: \"https://updates.jenkins.io/experimental/update-center.json\"\n```\n\nThe official  includ"
  },
  "3274": {
    "source_file": "releasing-experimental-updates.txt",
    "text": ".io/update-center.json\"\n      - id: \"experimental\"\n        url: \"https://updates.jenkins.io/experimental/update-center.json\"\n```\n\nThe official  includes plugin management scripts, which allow preinstalling plugins from _the experimental update center_.\nThe container images support managing plugin versions as code, so that the administrator can define a container image including the exact plugin th"
  },
  "3275": {
    "source_file": "releasing-experimental-updates.txt",
    "text": "_.\nThe container images support managing plugin versions as code, so that the administrator can define a container image including the exact plugin they require.\n\nRefer to the  for additional information."
  },
  "3276": {
    "source_file": "releasing-manually.txt",
    "text": "title: Performing a Plugin Release manually\nlayout: developer\n\n\n[IMPORTANT]\n.Prefer automated releases instead of releasing manually\n\nSee  instead of this guide.\n\nMake sure you have permissions to release the plugin.\n\nYou will need to tell Maven your credentials to access .\nYou can obtain your encrypted password from Artifactory using `curl`.\n\nUse this command:\n\ncurl -u your_user_name:your_passwor"
  },
  "3277": {
    "source_file": "releasing-manually.txt",
    "text": " credentials to access .\nYou can obtain your encrypted password from Artifactory using `curl`.\n\nUse this command:\n\ncurl -u your_user_name:your_password https://repo.jenkins-ci.org/setup/settings.xml\n\nThis will print the configuration you need to your terminal. You should see something similar to this:\n\n$ curl -u mr_jenkins:j3nkinsr0ck5 https://repo.jenkins-ci.org/setup/settings.xml\n<settings xmlns"
  },
  "3278": {
    "source_file": "releasing-manually.txt",
    "text": " terminal. You should see something similar to this:\n\n$ curl -u mr_jenkins:j3nkinsr0ck5 https://repo.jenkins-ci.org/setup/settings.xml\n<settings xmlns=\"https://maven.apache.org/SETTINGS/1.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"https://maven.apache.org/SETTINGS/1.0.0 https://maven.apache.org/xsd/settings-1.0.0.xsd\">\n  <servers>\n    <server>\n      <id>maven.je"
  },
  "3279": {
    "source_file": "releasing-manually.txt",
    "text": ":schemaLocation=\"https://maven.apache.org/SETTINGS/1.0.0 https://maven.apache.org/xsd/settings-1.0.0.xsd\">\n  <servers>\n    <server>\n      <id>maven.jenkins-ci.org</id> // <1> <username>mr_jenkins</username>\n      <password>APrj80t4398w8fnytd498nft4dt8so</password>\n    </server>\n  </servers>\n</settings>\n\n<1> This is not a valid host name anymore, but still the ID used by default in the Jenkins plug"
  },
  "3280": {
    "source_file": "releasing-manually.txt",
    "text": "8so</password>\n    </server>\n  </servers>\n</settings>\n\n<1> This is not a valid host name anymore, but still the ID used by default in the Jenkins plugin parent POM.\n\nStore the output as `~/.m2/settings.xml` (`~` representing your user home directory, e.g. `/home/yourname` or `C:\\Users\\yourname`), creating the file if it doesn't exist yet.\nIf you already have this file, merge the `server` block pro"
  },
  "3281": {
    "source_file": "releasing-manually.txt",
    "text": " e.g. `/home/yourname` or `C:\\Users\\yourname`), creating the file if it doesn't exist yet.\nIf you already have this file, merge the `server` block provided in the output with your existing `servers` section, if any, and otherwise add the provided `servers` section to your file.\n\nMaven Release Plugin will automatically push to the repository when performing a release, so you need to .\n\nSee the  for"
  },
  "3282": {
    "source_file": "releasing-manually.txt",
    "text": "rvers` section to your file.\n\nMaven Release Plugin will automatically push to the repository when performing a release, so you need to .\n\nSee the  for more information.\n\nAlways test your SSH connection before performing a release:\n\nssh -T git@github.com\n\nIf you have been authenticated correctly, you see a message similar to the following example in your terminal:\n\n```txt\nHi yourGitHubUsername! You"
  },
  "3283": {
    "source_file": "releasing-manually.txt",
    "text": "com\n\nIf you have been authenticated correctly, you see a message similar to the following example in your terminal:\n\n```txt\nHi yourGitHubUsername! You've successfully authenticated, but GitHub does not provide shell access.\n```\n\n`yourGitHubUsername` is a placeholder representing your GitHub username.\n\nWith GitHub and Maven credentials set up, performing a release should be as easy as running the f"
  },
  "3284": {
    "source_file": "releasing-manually.txt",
    "text": "is a placeholder representing your GitHub username.\n\nWith GitHub and Maven credentials set up, performing a release should be as easy as running the following command:\n\nmvn release:prepare release:perform\n\n// Not sure about this:\n// NOTE: While it is be possible to specify the username and password on the command line, that would require your accounts on GitHub and the Jenkins community to match, "
  },
  "3285": {
    "source_file": "releasing-manually.txt",
    "text": " be possible to specify the username and password on the command line, that would require your accounts on GitHub and the Jenkins community to match, and prevent you from using two factor authentication on GitHub.\n// Neither is a recommend practice.\n\nFirst, make sure your plugin uses a reasonably up to date .\nThis will prevent the vast majority of problems in releasing the plugin, such as outdated"
  },
  "3286": {
    "source_file": "releasing-manually.txt",
    "text": "\nFirst, make sure your plugin uses a reasonably up to date .\nThis will prevent the vast majority of problems in releasing the plugin, such as outdated Maven plugins, or obsolete host names.\n\nUnauthorized means that your credentials were invalid, or not sent by Maven.\n\nMake sure you've updated your encrypted password since the last time you changed your password on .\n\nThe two most common explanatio"
  },
  "3287": {
    "source_file": "releasing-manually.txt",
    "text": "ot sent by Maven.\n\nMake sure you've updated your encrypted password since the last time you changed your password on .\n\nThe two most common explanations for this error:\n\n* You don't have permission to upload to the specified path.\n  .\n  Check that the path you're allowed to upload to matches the actual upload attempt (i.e. no typos).\n* The specified release already exists and you try to overwrite "
  },
  "3288": {
    "source_file": "releasing-manually.txt",
    "text": "e path you're allowed to upload to matches the actual upload attempt (i.e. no typos).\n* The specified release already exists and you try to overwrite it.\n  We do not allow replacing existing releases.\n  Specify a different, previously unused version number during the release process.\n\nIf none of the provided solutions help, send an email to the  and explain what you did, and how it failed."
  },
  "3289": {
    "source_file": "releasing-manually.txt",
    "text": "number during the release process.\n\nIf none of the provided solutions help, send an email to the  and explain what you did, and how it failed."
  },
  "3290": {
    "source_file": "releasing.txt",
    "text": "title: Performing a Plugin Release\nlayout: developer\nreferences:\n- url: ../releasing-cd\n  title: Through GitHub\n- url: ../releasing-manually\n  title: Manually on your machine\n\n\nHistorically Jenkins plugins were released on developer machines.\nWe now recommend plugins be released via GitHub, either automatically or with a manual trigger."
  },
  "3291": {
    "source_file": "releasing.txt",
    "text": "recommend plugins be released via GitHub, either automatically or with a manual trigger."
  },
  "3292": {
    "source_file": "remote-access-api.txt",
    "text": "layout: section\ntitle: Remote Access API\n\n\nJenkins provides machine-consumable remote access API to its\nfunctionalities.\nCurrently it comes in three flavors:\n\nXML\nJSON with JSONP support\nPython\n\nRemote access API is offered in a REST-like style.\nThat is, there is no single entry point for all features,\nand instead they are available under the `+\".../api/\"+`\nURL where `+\"...\"+` portion is the data "
  },
  "3293": {
    "source_file": "remote-access-api.txt",
    "text": " is, there is no single entry point for all features,\nand instead they are available under the `+\".../api/\"+`\nURL where `+\"...\"+` portion is the data that it acts on.\n\nFor example, if your Jenkins installation sits at https://ci.jenkins.io,\nvisiting https://ci.jenkins.io/api/ will show just the top-level API\nfeatures available \u2013 primarily a listing of the configured jobs for this\nJenkins controlle"
  },
  "3294": {
    "source_file": "remote-access-api.txt",
    "text": "https://ci.jenkins.io/api/ will show just the top-level API\nfeatures available \u2013 primarily a listing of the configured jobs for this\nJenkins controller. +\nOr if you want to access information about a particular build, e.g.\nhttps://ci.jenkins.io/job/Websites/job/jenkins.io/job/master/lastSuccessfulBuild/ , then go to\nhttps://ci.jenkins.io/job/Websites/job/jenkins.io/job/master/lastSuccessfulBuild/a"
  },
  "3295": {
    "source_file": "remote-access-api.txt",
    "text": "ebsites/job/jenkins.io/job/master/lastSuccessfulBuild/ , then go to\nhttps://ci.jenkins.io/job/Websites/job/jenkins.io/job/master/lastSuccessfulBuild/api/ and you'll\nsee the list of functionalities for that build.\n\n[[RemoteaccessAPI-Whatcanyoudowithit]]\n\nRemote API can be used to do things like these:\n\nretrieve information from Jenkins for programmatic consumption.\ntrigger a new build\ncreate/copy j"
  },
  "3296": {
    "source_file": "remote-access-api.txt",
    "text": "]]\n\nRemote API can be used to do things like these:\n\nretrieve information from Jenkins for programmatic consumption.\ntrigger a new build\ncreate/copy jobs\n\n[[RemoteaccessAPI-Submittingjobs]]\n\n*Jobs without parameters*\n\nYou merely need to perform an HTTP POST on\n`+JENKINS_URL/job/JOBNAME/build+`.\n\nThis also works for Multibranch Pipelines and Organization Folders. It would trigger a scan.\n\n*Jobs wit"
  },
  "3297": {
    "source_file": "remote-access-api.txt",
    "text": "TP POST on\n`+JENKINS_URL/job/JOBNAME/build+`.\n\nThis also works for Multibranch Pipelines and Organization Folders. It would trigger a scan.\n\n*Jobs with parameters*\n\nSimple example - sending \"String Parameters\":\n\ncurl JENKINS_URL/job/JOB_NAME/buildWithParameters \\\n  --user USER:TOKEN \\\n  --data id=123 --data verbosity=high\n\nAnother example - sending a \"File Parameter\":\n\ncurl JENKINS_URL/job/JOB_NAM"
  },
  "3298": {
    "source_file": "remote-access-api.txt",
    "text": "hParameters \\\n  --user USER:TOKEN \\\n  --data id=123 --data verbosity=high\n\nAnother example - sending a \"File Parameter\":\n\ncurl JENKINS_URL/job/JOB_NAME/buildWithParameters \\\n  --user USER:PASSWORD \\\n  --form FILE_LOCATION_AS_SET_IN_JENKINS=@PATH_TO_FILE\n\nThe symbol '@' is important in this example.\nAlso, the path to the file is absolute path.\nIn order to make this command work,\nyou need to configu"
  },
  "3299": {
    "source_file": "remote-access-api.txt",
    "text": "ILE\n\nThe symbol '@' is important in this example.\nAlso, the path to the file is absolute path.\nIn order to make this command work,\nyou need to configure your Jenkins job to take a file parameter\nand match the *File location* field in the Jenkins job configuration with the key in the `--form` option.\n\n[[RemoteaccessAPI-RemoteAPIandsecurity]]\n\nWhen your Jenkins is secured, you can use HTTP BASIC aut"
  },
  "3300": {
    "source_file": "remote-access-api.txt",
    "text": "configuration with the key in the `--form` option.\n\n[[RemoteaccessAPI-RemoteAPIandsecurity]]\n\nWhen your Jenkins is secured, you can use HTTP BASIC authentication to authenticate remote API requests.\nSee  for more details.\n\n[[RemoteaccessAPI-CSRFProtection]]\n\n*Note*: API tokens are preferred instead of crumbs for CSRF protection.\n\n[[RemoteaccessAPI-XPathselection]]\n\nThe XML API supports a selection"
  },
  "3301": {
    "source_file": "remote-access-api.txt",
    "text": "ction]]\n\n*Note*: API tokens are preferred instead of crumbs for CSRF protection.\n\n[[RemoteaccessAPI-XPathselection]]\n\nThe XML API supports a selection by XPath by using the query parameter 'xpath'.\nThis is convenient for extracting information in environments\nwhere XML manipulation is tedious (such as shell script.)\nSee https://issues.jenkins.io/browse/JENKINS-626[issue #626] for an\nexample of how"
  },
  "3302": {
    "source_file": "remote-access-api.txt",
    "text": "ironments\nwhere XML manipulation is tedious (such as shell script.)\nSee https://issues.jenkins.io/browse/JENKINS-626[issue #626] for an\nexample of how to use this. +\nSee `+.../api/+` on your Jenkins server for more up-to-date details.\n\n[[RemoteaccessAPI-XPathexclusion]]\n\nSimilar to the 'xpath' query parameter above, you can use (possibly\nmultiple) 'exclude' query patterns to exclude nodes from the"
  },
  "3303": {
    "source_file": "remote-access-api.txt",
    "text": "API-XPathexclusion]]\n\nSimilar to the 'xpath' query parameter above, you can use (possibly\nmultiple) 'exclude' query patterns to exclude nodes from the resulting XML.\nAll the nodes that match the specified XPath will be removed from the XML. +\nSee `+.../api/+` on your Jenkins server for more up-to-date details.\n\n[[RemoteaccessAPI-Depthcontrol]]\n\nSometimes the remote API doesn't give you enough info"
  },
  "3304": {
    "source_file": "remote-access-api.txt",
    "text": "../api/+` on your Jenkins server for more up-to-date details.\n\n[[RemoteaccessAPI-Depthcontrol]]\n\nSometimes the remote API doesn't give you enough information in one call.\nFor example, if you'd like to find the last successful build of a given view,\nyou'd realize that the invocation to the remote API of the view won't give you this,\nand you'd have to recursively call the remote API of each project."
  },
  "3305": {
    "source_file": "remote-access-api.txt",
    "text": "ou'd realize that the invocation to the remote API of the view won't give you this,\nand you'd have to recursively call the remote API of each project.\nDepth control solves this problem.\nDepth control is fundamentally connected to the Jenkins data model.\n\nThe data model that Jenkins maintains internally can be thought of as a\nbig tree structure, and when you make a remote API call,\nyou are getting "
  },
  "3306": {
    "source_file": "remote-access-api.txt",
    "text": "el.\n\nThe data model that Jenkins maintains internally can be thought of as a\nbig tree structure, and when you make a remote API call,\nyou are getting a small subtree of it.\nThe subtree is rooted at the object for which you made a remote API call,\nand the sub-tree is cut beyond certain depth to avoid returning too much data.\nYou can adjust this cut-off behavior by specifying the depth query paramet"
  },
  "3307": {
    "source_file": "remote-access-api.txt",
    "text": " the sub-tree is cut beyond certain depth to avoid returning too much data.\nYou can adjust this cut-off behavior by specifying the depth query parameter.\nWhen you specify a positive depthvalue, the subtree cut-off happens that much later.\n\nSo the net result is, if you specify a bigger depth value,\nyou'll see that the remote API will now return more data.\nBecause of the algorithm,\nthis works in suc"
  },
  "3308": {
    "source_file": "remote-access-api.txt",
    "text": " result is, if you specify a bigger depth value,\nyou'll see that the remote API will now return more data.\nBecause of the algorithm,\nthis works in such a way that the data returned by a bigger depth value\nincludes all the data returned by smaller depth value.\n\nSee `+.../api/+` on your Jenkins server for more up-to-date details.\n\n[[RemoteaccessAPI-PythonAPIwrappers]]\n\nhttps://pypi.python.org/pypi/j"
  },
  "3309": {
    "source_file": "remote-access-api.txt",
    "text": "th value.\n\nSee `+.../api/+` on your Jenkins server for more up-to-date details.\n\n[[RemoteaccessAPI-PythonAPIwrappers]]\n\nhttps://pypi.python.org/pypi/jenkinsapi[JenkinsAPI],\nhttps://pypi.python.org/pypi/python-jenkins/[Python-Jenkins],\nhttps://pypi.org/project/api4jenkins/[api4jenkins],\nhttps://pypi.org/project/aiojenkins/[aiojenkins] are\nobject-oriented python wrappers for the Python REST API whic"
  },
  "3310": {
    "source_file": "remote-access-api.txt",
    "text": "g/project/api4jenkins/[api4jenkins],\nhttps://pypi.org/project/aiojenkins/[aiojenkins] are\nobject-oriented python wrappers for the Python REST API which aim to\nprovide a more conventionally pythonic way of controlling a Jenkins server.\nIt provides a higher-level API containing a number of convenience functions.\nServices offered currently include:\n\n* Query the test-results of a completed build\n* Get"
  },
  "3311": {
    "source_file": "remote-access-api.txt",
    "text": "igher-level API containing a number of convenience functions.\nServices offered currently include:\n\n* Query the test-results of a completed build\n* Get objects representing the latest builds of a job\n* Search for artifacts by simple criteria\n* Block until jobs are complete\n* Install artifacts to custom-specified directory structures\n* Authentication support for Jenkins controllers\n* Ability to sear"
  },
  "3312": {
    "source_file": "remote-access-api.txt",
    "text": "ntil jobs are complete\n* Install artifacts to custom-specified directory structures\n* Authentication support for Jenkins controllers\n* Ability to search for builds by subversion revision\n* Ability to add/remove/query Jenkins agents\n\n[[RemoteaccessAPI-RubyAPIwrappers]]\n\nhttps://rubygems.org/gems/jenkins_api_client[Jenkins API Client] is an\nobject oriented ruby wrapper project that consumes Jenkins'"
  },
  "3313": {
    "source_file": "remote-access-api.txt",
    "text": "-RubyAPIwrappers]]\n\nhttps://rubygems.org/gems/jenkins_api_client[Jenkins API Client] is an\nobject oriented ruby wrapper project that consumes Jenkins's JSON API\nand aims at providing access to all remote API Jenkins provides.\nIt is available as a Rubygem and can be useful to interact with the Job,\nNode, View, BuildQueue, and System related functionalities.\nServices currently offered include:\n\n* Cr"
  },
  "3314": {
    "source_file": "remote-access-api.txt",
    "text": "ygem and can be useful to interact with the Job,\nNode, View, BuildQueue, and System related functionalities.\nServices currently offered include:\n\n* Creating jobs by sending xml file or by specifying params as options\nwith more customization options including source control, notifications,\netc.\n* Building jobs (with params), stopping builds, querying details of\nrecent builds, obtaining build params"
  },
  "3315": {
    "source_file": "remote-access-api.txt",
    "text": "ncluding source control, notifications,\netc.\n* Building jobs (with params), stopping builds, querying details of\nrecent builds, obtaining build params, etc.\n* Listing jobs available in Jenkins with job name filter, job status\nfilter.\n* Adding/removing downstream projects.\n* Chaining jobs i.e given a list of projects each project is added as a\ndownstream project to the previous one.\n* Obtaining pro"
  },
  "3316": {
    "source_file": "remote-access-api.txt",
    "text": "g downstream projects.\n* Chaining jobs i.e given a list of projects each project is added as a\ndownstream project to the previous one.\n* Obtaining progressive console output.\n* Username/password based authentication.\n* Command Line Interface with a lot of options provided in the\nlibraries.\n* Creating, listing views.\n* Adding jobs to views and removing jobs from views.\n* Adding/removing Jenkins age"
  },
  "3317": {
    "source_file": "remote-access-api.txt",
    "text": "ot of options provided in the\nlibraries.\n* Creating, listing views.\n* Adding jobs to views and removing jobs from views.\n* Adding/removing Jenkins agents, querying details of agents.\n* Obtaining the tasks in build queue, and their age, cause, reason, ETA,\nID, params and much more.\n* Quiet down, cancel quiet down, safe restart, force restart, and wait\ntill Jenkins becomes available after a restart."
  },
  "3318": {
    "source_file": "remote-access-api.txt",
    "text": " ETA,\nID, params and much more.\n* Quiet down, cancel quiet down, safe restart, force restart, and wait\ntill Jenkins becomes available after a restart.\n* Ability to list installed/available plugins, obtain information about\nplugins, install/uninstall plugins and much more with plugins.\n\nThe project source code is at\nhttps://github.com/arangamani/jenkins_api_client[here].\n\n[[RemoteaccessAPI-JavaAPIw"
  },
  "3319": {
    "source_file": "remote-access-api.txt",
    "text": "plugins and much more with plugins.\n\nThe project source code is at\nhttps://github.com/arangamani/jenkins_api_client[here].\n\n[[RemoteaccessAPI-JavaAPIwrappers]]\n\nThe https://github.com/cdancy/jenkins-rest[jenkins-rest] library is an\nobject oriented Java project that provides access to the Jenkins REST\nAPI programmatically to some remote API Jenkins provides. It is built\nusing the https://jclouds.ap"
  },
  "3320": {
    "source_file": "remote-access-api.txt",
    "text": "va project that provides access to the Jenkins REST\nAPI programmatically to some remote API Jenkins provides. It is built\nusing the https://jclouds.apache.org/[jclouds toolkit] and can\neasily be extended to support more REST endpoints. Its feature set\nevolves and users are invited to contribute new endpoints via\npull-requests. In its current state it is possible with this library to\nsubmit a job, "
  },
  "3321": {
    "source_file": "remote-access-api.txt",
    "text": "t\nevolves and users are invited to contribute new endpoints via\npull-requests. In its current state it is possible with this library to\nsubmit a job, track its progress through the queue, and monitor its\nexecution until its completion, and obtain the build status. Services\ncurrently offered include:\n\n* Endpoint definition (property or environment variable)\n* Authentication (basic and API token via"
  },
  "3322": {
    "source_file": "remote-access-api.txt",
    "text": " build status. Services\ncurrently offered include:\n\n* Endpoint definition (property or environment variable)\n* Authentication (basic and API token via property or environment\nvariable)\n* Crumbs Issuer support (auto-detect crumbs)\n* Folder support\n* Jobs API (build, buildInfo, buildWithParameters, config, create,\ndelete, description, disable, enable, jobInfo, lastBuildNumber,\nlastBuildTimestamp and"
  },
  "3323": {
    "source_file": "remote-access-api.txt",
    "text": "obs API (build, buildInfo, buildWithParameters, config, create,\ndelete, description, disable, enable, jobInfo, lastBuildNumber,\nlastBuildTimestamp and progressiveText)\n* Plugin manager API (installNecessaryPlugins, list current plugins)\n* Queue API (cancel, list queue items, query queue item)\n* Statistics API (overall load)\n* Systems API (systemInfo)\n\nThe project can evolve rapidly, this list is a"
  },
  "3324": {
    "source_file": "remote-access-api.txt",
    "text": "cancel, list queue items, query queue item)\n* Statistics API (overall load)\n* Systems API (systemInfo)\n\nThe project can evolve rapidly, this list is accurate only as of the\ndate of writing.\n\n[[RemoteaccessAPI-DetectingJenkinsversion]]\n\nTo check the version of Jenkins, load the top page or any\n`+.../api/*+` page and check for the `+X-Jenkins+` response header.\nThis contains the version number of Je"
  },
  "3325": {
    "source_file": "remote-access-api.txt",
    "text": "ersion of Jenkins, load the top page or any\n`+.../api/*+` page and check for the `+X-Jenkins+` response header.\nThis contains the version number of Jenkins, like \"1.404\" This is also a\ngood way to check if an URL is a Jenkins URL."
  },
  "3326": {
    "source_file": "remote-api.txt",
    "text": "layout: redirect\nredirect_url: /doc/book/using/remote-access-api/"
  },
  "3327": {
    "source_file": "remoting-callables.txt",
    "text": "title: Remoting Callables\nlayout: developer\n\n\nRemoting is the library implementing communication between Jenkins processes using Java serialization.\nThis applies to controller/agent communications and agents communicating with the Maven process in plugin:maven-plugin[Maven Integration Plugin].\n\n`hudson.remoting.Callable` is the basic building block of this communication channel, representing a mes"
  },
  "3328": {
    "source_file": "remoting-callables.txt",
    "text": "ugin:maven-plugin[Maven Integration Plugin].\n\n`hudson.remoting.Callable` is the basic building block of this communication channel, representing a message and corresponding response.\nObjects implementing this interface get serialized and sent to the other end of the channel.\nThey're deserialized on the other end, where the `#call()` method is invoked.\nIts return value is then serialized and sent b"
  },
  "3329": {
    "source_file": "remoting-callables.txt",
    "text": "other end of the channel.\nThey're deserialized on the other end, where the `#call()` method is invoked.\nIts return value is then serialized and sent back through the channel.\n\nThink of each `Callable` implementation as an interface or API of Jenkins:\nJenkins will execute `Callables` it receives through a remoting channel, with fields in the `Callable` subtype being like parameters.\n\nIt is importan"
  },
  "3330": {
    "source_file": "remoting-callables.txt",
    "text": "\nJenkins will execute `Callables` it receives through a remoting channel, with fields in the `Callable` subtype being like parameters.\n\nIt is important to ensure that the less-privileged end of the channel (typically agents) cannot run arbitrary code on the more-privileged end (typically a controller), so care needs to be taken when implementing `Callables`.\nThe remoting library offers the `RoleSe"
  },
  "3331": {
    "source_file": "remoting-callables.txt",
    "text": " on the more-privileged end (typically a controller), so care needs to be taken when implementing `Callables`.\nThe remoting library offers the `RoleSensitive` interface for this which `Callable` extends.\nCallables can use it to limit where they can be executed by implementing `#checkRoles(RoleChecker)`.\n\nThe abstract supertypes `ControllerToAgentCallable` and `SlaveToMasterCallable` implement this"
  },
  "3332": {
    "source_file": "remoting-callables.txt",
    "text": "e executed by implementing `#checkRoles(RoleChecker)`.\n\nThe abstract supertypes `ControllerToAgentCallable` and `SlaveToMasterCallable` implement this interface with two well-defined modes:\n\n* `ControllerToAgentCallable` can be sent from a controller to an agent.\n  In practice, almost all `Callable` implementations will be ```ControllerToAgentCallable``s.\n  (Prior to Jenkins 2.485 when `Controller"
  },
  "3333": {
    "source_file": "remoting-callables.txt",
    "text": " to an agent.\n  In practice, almost all `Callable` implementations will be ```ControllerToAgentCallable``s.\n  (Prior to Jenkins 2.485 when `ControllerToAgentCallable` was introduced, use the abstract superclass ``MasterToSlaveCallable`.)\n* `SlaveToMasterCallable` can be sent from an agent to a controller.\n  This is extremely risky, as malicious agents can use poorly-reviewed implementations to run"
  },
  "3334": {
    "source_file": "remoting-callables.txt",
    "text": "sterCallable` can be sent from an agent to a controller.\n  This is extremely risky, as malicious agents can use poorly-reviewed implementations to run code on a controller.\n\nDespite their names, either implementation can be executed anywhere; the name just describes through which channels it can be sent for execution.\n`ControllerToAgentCallable` can be executed on the controller, just not sent fro"
  },
  "3335": {
    "source_file": "remoting-callables.txt",
    "text": "e just describes through which channels it can be sent for execution.\n`ControllerToAgentCallable` can be executed on the controller, just not sent from an agent to a controller for execution;\nwhereas `SlaveToMasterCallable` can be sent through a controller/agent channel in either direction.\n\nIn addition to the above, `NotReallyRoleSensitiveCallable` can be used for a `Callable` that is not intende"
  },
  "3336": {
    "source_file": "remoting-callables.txt",
    "text": "roller/agent channel in either direction.\n\nIn addition to the above, `NotReallyRoleSensitiveCallable` can be used for a `Callable` that is not intended to be sent through a channel.\nIts `#checkRoles` method will throw an exception, thereby preventing it from being executed on any side of a communication channel that performs a role check.\nThis would only be used when some API is defined using `hud"
  },
  "3337": {
    "source_file": "remoting-callables.txt",
    "text": " it from being executed on any side of a communication channel that performs a role check.\nThis would only be used when some API is defined using `hudson.remoting.Callable` rather than a more generic functional interface,\nfor example because it has a `Throwable` type parameter.\n\nIt is recommended to use one of these supertypes in your plugin, rather than implementing `#checkRoles(RoleChecker)` dir"
  },
  "3338": {
    "source_file": "remoting-callables.txt",
    "text": " `Throwable` type parameter.\n\nIt is recommended to use one of these supertypes in your plugin, rather than implementing `#checkRoles(RoleChecker)` directly.\n\nSince Jenkins 2.319 and LTS 2.303.3, `Callable` implementations providing an implementation of `#checkRoles(RoleChecker)` that neither throws an exception nor calls `RoleChecker#check` will result in the `Callable` being rejected when sent th"
  },
  "3339": {
    "source_file": "remoting-callables.txt",
    "text": "of `#checkRoles(RoleChecker)` that neither throws an exception nor calls `RoleChecker#check` will result in the `Callable` being rejected when sent through the channel to a side that requires a role check before execution.\nA typical implementation that breaks will look like the following:\n\nclass MyCallable implements Callable<ReturnType,ExceptionType> {\n    private String parameter;\n    public MyC"
  },
  "3340": {
    "source_file": "remoting-callables.txt",
    "text": "at breaks will look like the following:\n\nclass MyCallable implements Callable<ReturnType,ExceptionType> {\n    private String parameter;\n    public MyCallable(String parameter) {\n        this.parameter = parameter;\n    }\n    public ReturnType call() throws ExceptionType {\n        return Some.code().operatesOn(this.parameter);\n    }\n\n    public void checkRoles(RoleChecker checker) {\n        // this "
  },
  "3341": {
    "source_file": "remoting-callables.txt",
    "text": "hrows ExceptionType {\n        return Some.code().operatesOn(this.parameter);\n    }\n\n    public void checkRoles(RoleChecker checker) {\n        // this is an empty block // <1> }\n}\n\n<1> Nothing is being done here even though a call to `RoleChecker#check(...)` is expected.\n\nIf a plugin implementing an inadequate role check (like this example) attempts to send a `Callable` through the remoting channel"
  },
  "3342": {
    "source_file": "remoting-callables.txt",
    "text": "k(...)` is expected.\n\nIf a plugin implementing an inadequate role check (like this example) attempts to send a `Callable` through the remoting channel from the agent to the controller, the security improvement will detect it and throw an exception before `#call()` would be invoked.\n\nWhile administrators can allow specific `Callable` subtypes to bypass this protection mechanism (), plugin developer"
  },
  "3343": {
    "source_file": "remoting-callables.txt",
    "text": "fore `#call()` would be invoked.\n\nWhile administrators can allow specific `Callable` subtypes to bypass this protection mechanism (), plugin developers are advised to update their plugins:\n`Callable` implementations should extend from one of the classes mentioned above, with a strong preference for `ControllerToAgentCallable`, which should work in almost all cases.\nIf that does not work and the pl"
  },
  "3344": {
    "source_file": "remoting-callables.txt",
    "text": "ses mentioned above, with a strong preference for `ControllerToAgentCallable`, which should work in almost all cases.\nIf that does not work and the plugin cannot be restructured to work with a `ControllerToAgentCallable`, the `Callable` implementation should be changed to a `SlaveToMasterCallable`, and the best practices recommended below must be implemented to ensure it cannot be bypassed.\n\nUse `"
  },
  "3345": {
    "source_file": "remoting-callables.txt",
    "text": "n should be changed to a `SlaveToMasterCallable`, and the best practices recommended below must be implemented to ensure it cannot be bypassed.\n\nUse `ControllerToAgentCallable` wherever possible, restructure your plugin code as needed to allow this.\n\nFor ``Callable``s not intended to be sent through a channel, extend `NotReallyRoleSensitiveCallable` instead of implementing `Callable` directly.\n\nAl"
  },
  "3346": {
    "source_file": "remoting-callables.txt",
    "text": "\nFor ``Callable``s not intended to be sent through a channel, extend `NotReallyRoleSensitiveCallable` instead of implementing `Callable` directly.\n\nAll ``Callable``s are still deserialized on the controller, and `#checkRoles` is invoked to determine whether the `Callable` can be executed.\nDo not add code to https://docs.oracle.com/javase/8/docs/platform/serialization/spec/input.html#a5903[`#readRe"
  },
  "3347": {
    "source_file": "remoting-callables.txt",
    "text": "whether the `Callable` can be executed.\nDo not add code to https://docs.oracle.com/javase/8/docs/platform/serialization/spec/input.html#a5903[`#readResolve`] and related methods, or to `#checkRoles`, that would be unsafe to execute, as these methods will still be executed on the controller between receiving the `Callable` and invoking `#call()`.\n\nIf a `Callable` needs to be sent from an agent to a"
  },
  "3348": {
    "source_file": "remoting-callables.txt",
    "text": "will still be executed on the controller between receiving the `Callable` and invoking `#call()`.\n\nIf a `Callable` needs to be sent from an agent to a controller (`SlaveToMasterCallable`), keep the implementations minimal:\nUse few, simple parameters that are easy to reason about and validate, do not send complex trees of objects.\nDo not use (anonymous) inner classes for your Callables, instead mak"
  },
  "3349": {
    "source_file": "remoting-callables.txt",
    "text": "that are easy to reason about and validate, do not send complex trees of objects.\nDo not use (anonymous) inner classes for your Callables, instead make them top-level or static nested classes so they do not have a reference to an instance of the surrounding class, reducing complexity.\nPerform parameter validation inside `#call()` or https://docs.oracle.com/javase/8/docs/platform/serialization/spec"
  },
  "3350": {
    "source_file": "remoting-callables.txt",
    "text": "ounding class, reducing complexity.\nPerform parameter validation inside `#call()` or https://docs.oracle.com/javase/8/docs/platform/serialization/spec/input.html#a5903[`#readResolve()`] rather than (only) in constructors and setters, and do not rely on `private` or `final` modifiers for your fields to protect from unexpected values:\nreflection can be used to set fields to arbitrary, attacker-chose"
  },
  "3351": {
    "source_file": "remoting-callables.txt",
    "text": "on `private` or `final` modifiers for your fields to protect from unexpected values:\nreflection can be used to set fields to arbitrary, attacker-chosen values.\n\nThe vast majority of plugins should have their `Callables` extend from `ControllerToAgentCallable` (if they're implementing `Callable`) or `ControllerToAgentFileCallable` (if they're implementing `FileCallable`).\n\nThis will allow the contr"
  },
  "3352": {
    "source_file": "remoting-callables.txt",
    "text": "Callable` (if they're implementing `Callable`) or `ControllerToAgentFileCallable` (if they're implementing `FileCallable`).\n\nThis will allow the controller-side of a connection to initiate the Callable submission and invocation on both the controller and any agents and is the safest approach.\n\nThis is mostly equivalent to implementing `checkRoles` as follows:\n\n    public void checkRoles(RoleChecke"
  },
  "3353": {
    "source_file": "remoting-callables.txt",
    "text": " and any agents and is the safest approach.\n\nThis is mostly equivalent to implementing `checkRoles` as follows:\n\n    public void checkRoles(RoleChecker checker) {\n        checker.check(this,Roles.SLAVE);\n    }\n}\n\nIn very care cases, the agent-side of a connection will send a `Callable` to the controller for execution there.\nThis is tricky to do safely and it's generally recommended plugins are res"
  },
  "3354": {
    "source_file": "remoting-callables.txt",
    "text": " a connection will send a `Callable` to the controller for execution there.\nThis is tricky to do safely and it's generally recommended plugins are restructured so this isn't needed.\nIf this isn't possible, plugins can implement `SlaveToMasterCallable` or `SlaveToMasterFileCallable`, or implement `#checkRoles` as follows:\n\n    public void checkRoles(RoleChecker checker) {\n        checker.check(this"
  },
  "3355": {
    "source_file": "remoting-callables.txt",
    "text": "` or `SlaveToMasterFileCallable`, or implement `#checkRoles` as follows:\n\n    public void checkRoles(RoleChecker checker) {\n        checker.check(this,Roles.MASTER);\n    }\n}\n\nMake sure to carefully consider what your `Callable` implementation is able to do on the controller when sent from an untrusted agent.\nCarefully review the best practices above and adapt your `Callable` accordingly."
  },
  "3356": {
    "source_file": "remoting-callables.txt",
    "text": " to do on the controller when sent from an untrusted agent.\nCarefully review the best practices above and adapt your `Callable` accordingly."
  },
  "3357": {
    "source_file": "remoting.txt",
    "text": "title: Remoting\nlayout: developer\n\n\nJenkins remoting is an executable JAR, which implements the communication layer in Jenkins.\nIt's used for controller \\<\\=> agent and controller \\<\\=> CLI communications.\n\nThe documentation is hosted in the https://github.com/jenkinsci/remoting/blob/master/README.md[dedicated library repository]"
  },
  "3358": {
    "source_file": "remoting.txt",
    "text": "github.com/jenkinsci/remoting/blob/master/README.md[dedicated library repository]"
  },
  "3359": {
    "source_file": "removing-from-distribution.txt",
    "text": "title: Removing plugins from distribution\nlayout: developer\n\n\nIn rare cases it might be necessary to remove a plugin or an individual plugin release from distribution on Jenkins project update sites.\n\nSome reasons to stop distributing all versions of a plugin might be:\n\n* The plugin integrates a service with Jenkins, but the service has been shut down.\n* The plugin violates the open source license"
  },
  "3360": {
    "source_file": "removing-from-distribution.txt",
    "text": " a plugin might be:\n\n* The plugin integrates a service with Jenkins, but the service has been shut down.\n* The plugin violates the open source license requirements of the Jenkins project.\n\nThis is the more common case:\nA specific release of a plugin might introduce severe regressions, and fixing it is complicated and will take time.\nOr other plugins depend on the API of a given plugin, and its new"
  },
  "3361": {
    "source_file": "removing-from-distribution.txt",
    "text": "might introduce severe regressions, and fixing it is complicated and will take time.\nOr other plugins depend on the API of a given plugin, and its newest release contains accidental binary incompatible changes.\nMeanwhile, it should not be available to users.\n\n[NOTE]\nSimple fixes should just be released in a subsequent minor update.\nReviewing requests to remove versions from distribution takes time"
  },
  "3362": {
    "source_file": "removing-from-distribution.txt",
    "text": "o users.\n\n[NOTE]\nSimple fixes should just be released in a subsequent minor update.\nReviewing requests to remove versions from distribution takes time and effort, so make sure to only do this if there's no simpler solution.\n\n[IMPORTANT]\nThis will only remove versions from distribution on update sites; the corresponding artifacts will still exist in the Maven repository.\nThis means, for example, th"
  },
  "3363": {
    "source_file": "removing-from-distribution.txt",
    "text": "y remove versions from distribution on update sites; the corresponding artifacts will still exist in the Maven repository.\nThis means, for example, that the specified version numbers will not be made available for use again.\n\nTo remove plugins from distribution, file a pull request for the Jenkins update center generator and include a detailed explanation for your request. Please follow ."
  },
  "3364": {
    "source_file": "removing-from-distribution.txt",
    "text": "istribution, file a pull request for the Jenkins update center generator and include a detailed explanation for your request. Please follow ."
  },
  "3365": {
    "source_file": "rendering-user-content.txt",
    "text": "title: Rendering User Content\nlayout: developer\n\n\nPlugins need to be careful when presenting user-generated content on the Jenkins UI.\nThis usually takes one of two forms:\n\n1. The plugin archives a report of some kind that was generated during the build and makes it available on the Jenkins UI.\n2. The plugin parses a data file of some kind, usually as a post-build step, and presents the contents t"
  },
  "3366": {
    "source_file": "rendering-user-content.txt",
    "text": "ild and makes it available on the Jenkins UI.\n2. The plugin parses a data file of some kind, usually as a post-build step, and presents the contents to the user, e.g. through the use of a `ProminentProjectAction`.\n\nIn both scenarios, low-privilege users, perhaps with the permission to configure a job, or even just able to submit a pull request, will be able to influence the report contents.\nThey c"
  },
  "3367": {
    "source_file": "rendering-user-content.txt",
    "text": "ers, perhaps with the permission to configure a job, or even just able to submit a pull request, will be able to influence the report contents.\nThey could inject JavaScript code into the report, that would be rendered directly in Jenkins.\nIf an administrator then views the job or build, they are attacked and a malicious script would execute with that user's permissions.\n\n## Showing full reports vi"
  },
  "3368": {
    "source_file": "rendering-user-content.txt",
    "text": "istrator then views the job or build, they are attacked and a malicious script would execute with that user's permissions.\n\n## Showing full reports via `DirectoryBrowserSupport`\n\nTo circumvent this, Jenkins by default serves archived artifacts, including HTML reports, as well as workspace contents using Content-Security-Policy headers when using the `DirectoryBrowserSupport` class.\nThis protection"
  },
  "3369": {
    "source_file": "rendering-user-content.txt",
    "text": "ding HTML reports, as well as workspace contents using Content-Security-Policy headers when using the `DirectoryBrowserSupport` class.\nThis protection must not be circumvented by plugins.\n\nIf reports look broken due to these restrictions, Jenkins administrators should set up a  from which Jenkins would service user content like archived artifacts without compromising security.\n\n## Rendering Report"
  },
  "3370": {
    "source_file": "rendering-user-content.txt",
    "text": "inistrators should set up a  from which Jenkins would service user content like archived artifacts without compromising security.\n\n## Rendering Reports Inline\n\nPlugins that directly show report information on the Jenkins UI without going through `DirectoryBrowserSupport` need to be careful to not render potentially unsafe content unescaped.\njenkinsdoc:hudson.Util#xmlEscape-java.lang.String-[Util#x"
  },
  "3371": {
    "source_file": "rendering-user-content.txt",
    "text": "ectoryBrowserSupport` need to be careful to not render potentially unsafe content unescaped.\njenkinsdoc:hudson.Util#xmlEscape-java.lang.String-[Util#xmlEscape] is a good way to escape content.\nOtherwise, a dependency on a library such as https://github.com/OWASP/java-html-sanitizer[OWASP/java-html-sanitizer] could be used to sanitize HTML and only allow a known subset.\n\nThe advice on  may apply he"
  },
  "3372": {
    "source_file": "rendering-user-content.txt",
    "text": "ub.com/OWASP/java-html-sanitizer[OWASP/java-html-sanitizer] could be used to sanitize HTML and only allow a known subset.\n\nThe advice on  may apply here too, depending on implementation."
  },
  "3373": {
    "source_file": "replace-jsr-305-annotations.txt",
    "text": "layout: developersection\ntitle: Replace JSR-305\n\n\n# Replace JSR-305 annotations with Spotbugs annotations\n\nAnnotations for `Nonnull`, `CheckForNull`, and several others were proposed for Java as part of **dormant** .\nThe proposal never became a part of standard Java.\nJenkins plugins should switch from using JSR-305 annotations to use Spotbugs annotations that provide the same semantics.\n\nRefer to "
  },
  "3374": {
    "source_file": "replace-jsr-305-annotations.txt",
    "text": "of standard Java.\nJenkins plugins should switch from using JSR-305 annotations to use Spotbugs annotations that provide the same semantics.\n\nRefer to the  from James Nord.\n\n// Create the branch\n\n## Migrate Nonnull\n\nReplace imports of `javax.annotation.Nonnull` with imports of `edu.umd.cs.findbugs.annotations.NonNull`.\n\nReplace references to `Nonnull` with `NonNull`.\n\n## Migrate CheckForNull\n\nRepla"
  },
  "3375": {
    "source_file": "replace-jsr-305-annotations.txt",
    "text": "n.Nonnull` with imports of `edu.umd.cs.findbugs.annotations.NonNull`.\n\nReplace references to `Nonnull` with `NonNull`.\n\n## Migrate CheckForNull\n\nReplace imports of `javax.annotation.CheckForNull` with imports of `edu.umd.cs.findbugs.annotations.CheckForNull`.\n\n## Remove unused dependencies from pom file\n\nIf the pom file includes a `jsr305` dependency, remove it.\nThe spotbugs annotations are provid"
  },
  "3376": {
    "source_file": "replace-jsr-305-annotations.txt",
    "text": "ForNull`.\n\n## Remove unused dependencies from pom file\n\nIf the pom file includes a `jsr305` dependency, remove it.\nThe spotbugs annotations are provided by the parent pom.\n\n// Compile the plugin\n\nConfirm that JSR-305 is not mentioned in the compiler output and that compilation succeeds.\n\n// Create a pull request"
  },
  "3377": {
    "source_file": "replace-jsr-305-annotations.txt",
    "text": "output and that compilation succeeds.\n\n// Create a pull request"
  },
  "3378": {
    "source_file": "requesting-hosting.txt",
    "text": "title: Guide to Plugin Hosting\nlayout: developer\n\n\nThis guide will cover the entire plugin hosting process.\n\nOnce you've completed all steps described on this page you will have accomplished the following:\n\n* Your plugin source code will be hosted in a repository in the `jenkinsci` GitHub organization.\n  You will have admin access to this repository.\n* You will be allowed to release the plugin to "
  },
  "3379": {
    "source_file": "requesting-hosting.txt",
    "text": " a repository in the `jenkinsci` GitHub organization.\n  You will have admin access to this repository.\n* You will be allowed to release the plugin to the Jenkins project Maven repository, which serves as a source for the Jenkins project operated update sites.\n\nComplete the following steps before requesting plugin hosting with the Jenkins project:\n\nReview the  and make sure they're satisfied.\nMake "
  },
  "3380": {
    "source_file": "requesting-hosting.txt",
    "text": "te sites.\n\nComplete the following steps before requesting plugin hosting with the Jenkins project:\n\nReview the  and make sure they're satisfied.\nMake sure your plugin follows the plugin naming convention outlined in the .\nHave a public repository containing the plugin source code on GitHub.\n\nKindly refrain from asking questions or communicating in private channels.\nWe want the communications to ta"
  },
  "3381": {
    "source_file": "requesting-hosting.txt",
    "text": "taining the plugin source code on GitHub.\n\nKindly refrain from asking questions or communicating in private channels.\nWe want the communications to take place in an open environment, so that we can have healthier discussions within our community."
  },
  "3382": {
    "source_file": "required-role-check.txt",
    "text": "title: Required Role Check Security Improvement\nlayout: documentation\n\n\nifdef::env-github[:imagesdir: ../../resources]\nifndef::env-github[:imagesdir: ../../../resources]\n\nJenkins agents communicate with the controller using the https://github.com/jenkinsci/remoting/[remoting library].\nIndividual messages (implementations of the `Callable` interface) instruct the other side of the bidirectional com"
  },
  "3383": {
    "source_file": "required-role-check.txt",
    "text": "kinsci/remoting/[remoting library].\nIndividual messages (implementations of the `Callable` interface) instruct the other side of the bidirectional communication channel to perform operations and/or provide information.\n\nImplementations are expected to restrict where they can be executed by their implementation of a _role check_.\nThis role check is run after receiving the object through a communica"
  },
  "3384": {
    "source_file": "required-role-check.txt",
    "text": "o restrict where they can be executed by their implementation of a _role check_.\nThis role check is run after receiving the object through a communication channel and is expected to reject the execution of the `Callable` when it is determined to run on an unexpected side of that channel.\nFor example, the `Callable` implementing the functionality for Jenkins to run OS commands (usually build tools "
  },
  "3385": {
    "source_file": "required-role-check.txt",
    "text": "on an unexpected side of that channel.\nFor example, the `Callable` implementing the functionality for Jenkins to run OS commands (usually build tools and build scripts) on another system is only allowed to be sent from a controller to an agent, but not in the other direction.\n\nFrom Jenkins 2.319 and Jenkins LTS 2.303.3, Jenkins requires that role checks are performed by `Callable` implementations."
  },
  "3386": {
    "source_file": "required-role-check.txt",
    "text": "ot in the other direction.\n\nFrom Jenkins 2.319 and Jenkins LTS 2.303.3, Jenkins requires that role checks are performed by `Callable` implementations.\nThis change aims to prevent the execution on the controller of callables with an incomplete implementation.\nAny plugin that fails to work in the Jenkins releases mentioned above will need to be updated.\n\nThe security improvement detects when a plugi"
  },
  "3387": {
    "source_file": "required-role-check.txt",
    "text": "ntation.\nAny plugin that fails to work in the Jenkins releases mentioned above will need to be updated.\n\nThe security improvement detects when a plugin implementing an inadequate role check attempts to send a `Callable` through the remoting channel from the agent to the controller and throws a `SecurityException` causing a log message like the following:\n\nSecurity hardening prohibits the Callable "
  },
  "3388": {
    "source_file": "required-role-check.txt",
    "text": "rom the agent to the controller and throws a `SecurityException` causing a log message like the following:\n\nSecurity hardening prohibits the Callable implementation io.jenkins.demo.MyCallable \u21b5\n  from ignoring RoleChecker, see https://www.jenkins.io/redirect/required-role-check\n\nThis change will not prevent implementations from deliberately declaring themselves to be safe to execute on the control"
  },
  "3389": {
    "source_file": "required-role-check.txt",
    "text": "redirect/required-role-check\n\nThis change will not prevent implementations from deliberately declaring themselves to be safe to execute on the controller.\nInstead, this aims to prevent the impact of simple programming mistakes.\n\nAs of 2021-11-04, no plugins are known to be affected by this security hardening.\n\n// This is where we would keep track of affected plugins and their fixes.\n\nNot all plugi"
  },
  "3390": {
    "source_file": "required-role-check.txt",
    "text": "plugins are known to be affected by this security hardening.\n\n// This is where we would keep track of affected plugins and their fixes.\n\nNot all plugins that implement an empty role check are negatively impacted by this security hardening.\nThey may not require these callables to be sent from an agent to the controller for execution as part of their regular functionality.\nIn those cases, it is stil"
  },
  "3391": {
    "source_file": "required-role-check.txt",
    "text": "ot require these callables to be sent from an agent to the controller for execution as part of their regular functionality.\nIn those cases, it is still recommended to update the plugin as described .\n\nWhile fixes for affected plugins are not yet available, administrators can allow the execution of specific callables on the controller, or disable this security hardening altogether.\n\n[IMPORTANT]\n\nDo"
  },
  "3392": {
    "source_file": "required-role-check.txt",
    "text": "lable, administrators can allow the execution of specific callables on the controller, or disable this security hardening altogether.\n\n[IMPORTANT]\n\nDoing either will potentially allow attackers able to control an agent process to execute unsafe code on the Jenkins controller.\nIt is recommended that individual callables are only allowed after careful review of their code to ensure they're not unsaf"
  },
  "3393": {
    "source_file": "required-role-check.txt",
    "text": "on the Jenkins controller.\nIt is recommended that individual callables are only allowed after careful review of their code to ensure they're not unsafe to execute.\n for considerations what constitutes unsafe `Callable` behavior.\n\nTo allow specific, known safe callables to execute on any end of any remoting communication channel despite their empty role check, do either of the following:\n\nSet the  "
  },
  "3394": {
    "source_file": "required-role-check.txt",
    "text": "nown safe callables to execute on any end of any remoting communication channel despite their empty role check, do either of the following:\n\nSet the  to a comma-separated list of class names.\nThe class names are the same as in the error message.\n\nAlternatively, you can use the .\nThis approach is immediately effective and does not require Jenkins to be restarted first, but is only effective until J"
  },
  "3395": {
    "source_file": "required-role-check.txt",
    "text": "ernatively, you can use the .\nThis approach is immediately effective and does not require Jenkins to be restarted first, but is only effective until Jenkins is restarted.\nRun this script, replacing the callable class name as needed:\n\nimport hudson.remoting.ChannelBuilder\nChannelBuilder.SPECIFIC_CALLABLES_CAN_IGNORE_ROLECHECKER.add('io.jenkins.demo.MyCallable')\n\nRun this script once for every calla"
  },
  "3396": {
    "source_file": "required-role-check.txt",
    "text": "moting.ChannelBuilder\nChannelBuilder.SPECIFIC_CALLABLES_CAN_IGNORE_ROLECHECKER.add('io.jenkins.demo.MyCallable')\n\nRun this script once for every callable you want to allow.\n\nTo disable the security hardening altogether, set the  to `true`.\n\nAlternatively, you can use the .\nThis approach is immediately effective and does not require Jenkins to be restarted first, but is only effective until Jenkins"
  },
  "3397": {
    "source_file": "required-role-check.txt",
    "text": "vely, you can use the .\nThis approach is immediately effective and does not require Jenkins to be restarted first, but is only effective until Jenkins is restarted.\nRun this script:\n\nhudson.remoting.ChannelBuilder.CALLABLES_CAN_IGNORE_ROLECHECKER = true\n\n for advice how to change plugins to be compatible with this change while not creating a security vulnerability."
  },
  "3398": {
    "source_file": "required-role-check.txt",
    "text": "rue\n\n for advice how to change plugins to be compatible with this change while not creating a security vulnerability."
  },
  "3399": {
    "source_file": "responses.txt",
    "text": "title: Responding to Requests\nsummary: Discussing the various ways to respond to requests\nlayout: developersection\nwip: true\nreferences:\n- url: https://javadoc.jenkins.io/hudson/util/HttpResponses.html\n  title: HttpResponses Javadoc\n- url: https://javadoc.jenkins.io/component/stapler/org/kohsuke/stapler/interceptor/RespondSuccess.html\n  title: RespondSuccess Javadoc"
  },
  "3400": {
    "source_file": "responses.txt",
    "text": "vadoc.jenkins.io/component/stapler/org/kohsuke/stapler/interceptor/RespondSuccess.html\n  title: RespondSuccess Javadoc"
  },
  "3401": {
    "source_file": "reverse-proxy-configuration-apache.txt",
    "text": "layout: subsection\n\n\nifndef::env-github[:imagesdir: ../../../resources/managing]\n\n[[running-jenkins-behind-apache]]\n\nIn situations where you have existing web sites on your server,\nyou may find it useful to run Jenkins (or the servlet container\nthat Jenkins runs in) behind Apache, so that you can bind Jenkins\nto the part of a bigger website that you may have.\nThis section discusses some of the app"
  },
  "3402": {
    "source_file": "reverse-proxy-configuration-apache.txt",
    "text": "Jenkins runs in) behind Apache, so that you can bind Jenkins\nto the part of a bigger website that you may have.\nThis section discusses some of the approaches for doing this.\n\n*Make sure that you change the Jenkins httpListenAddress from its\ndefault of 0.0.0.0 to 127.0.0.1 or any Apache-level restrictions can be\neasily bypassed by accessing the Jenkins port directly.*\n\nThere are several different a"
  },
  "3403": {
    "source_file": "reverse-proxy-configuration-apache.txt",
    "text": "f 0.0.0.0 to 127.0.0.1 or any Apache-level restrictions can be\neasily bypassed by accessing the Jenkins port directly.*\n\nThere are several different alternatives to configure Jenkins with Apache.\nChoose the technique that best meets your needs:\n\n* <<mod_proxy>>\n* <<mod_proxy with HTTPS>>\n* <<mod_rewrite>>\n* <<mod_proxy_unix_sockets>>\n\nThis 6 minute tutorial from Darin Pope configures Apache httpd "
  },
  "3404": {
    "source_file": "reverse-proxy-configuration-apache.txt",
    "text": "mod_proxy>>\n* <<mod_proxy with HTTPS>>\n* <<mod_rewrite>>\n* <<mod_proxy_unix_sockets>>\n\nThis 6 minute tutorial from Darin Pope configures Apache httpd on Alma Linux as a reverse proxy with <<mod_proxy>>.\n\n.Configure Apache HTTP server as a reverse proxy\nvideo::E3_g5wYZlfk[youtube, width=640, height=360]\n\nhttp://httpd.apache.org/docs/2.0/mod/mod_proxy.html[mod_proxy] works by\nmaking Apache perform \""
  },
  "3405": {
    "source_file": "reverse-proxy-configuration-apache.txt",
    "text": "xy\nvideo::E3_g5wYZlfk[youtube, width=640, height=360]\n\nhttp://httpd.apache.org/docs/2.0/mod/mod_proxy.html[mod_proxy] works by\nmaking Apache perform \"reverse proxy\" \u2014 when a request arrives for\ncertain URLs, Apache becomes a proxy and forwards that request to\nJenkins, then forwards the response from Jenkins back to the client.\n\nThe following Apache modules must be installed :\n\na2enmod proxy\na2enmo"
  },
  "3406": {
    "source_file": "reverse-proxy-configuration-apache.txt",
    "text": "equest to\nJenkins, then forwards the response from Jenkins back to the client.\n\nThe following Apache modules must be installed :\n\na2enmod proxy\na2enmod proxy_http\na2enmod headers\n# Required for websocket\na2enmod proxy_wstunnel\na2enmod rewrite\n\nA typical set up for mod_proxy would look like this:\n\nProxyPass         /jenkins  http://localhost:8081/jenkins nocanon\nProxyPassReverse  /jenkins  http://l"
  },
  "3407": {
    "source_file": "reverse-proxy-configuration-apache.txt",
    "text": "cal set up for mod_proxy would look like this:\n\nProxyPass         /jenkins  http://localhost:8081/jenkins nocanon\nProxyPassReverse  /jenkins  http://localhost:8081/jenkins\nProxyRequests     Off\nAllowEncodedSlashes NoDecode\n\n# Required for Jenkins websocket agents\nRewriteEngine on\nRewriteCond %{HTTP:Upgrade} websocket [NC]\nRewriteCond %{HTTP:Connection} upgrade [NC]\nRewriteRule ^/jenkins/?(.*) \"ws:"
  },
  "3408": {
    "source_file": "reverse-proxy-configuration-apache.txt",
    "text": "socket agents\nRewriteEngine on\nRewriteCond %{HTTP:Upgrade} websocket [NC]\nRewriteCond %{HTTP:Connection} upgrade [NC]\nRewriteRule ^/jenkins/?(.*) \"ws://localhost:8081/jenkins/$1\" [P,L]\n\n# Local reverse proxy authorization override\n# Most unix distribution deny proxy by default\n# See /etc/apache2/mods-enabled/proxy.conf in Ubuntu\n<Proxy http://localhost:8081/jenkins*>\n  Order deny,allow\n  Allow fro"
  },
  "3409": {
    "source_file": "reverse-proxy-configuration-apache.txt",
    "text": "ution deny proxy by default\n# See /etc/apache2/mods-enabled/proxy.conf in Ubuntu\n<Proxy http://localhost:8081/jenkins*>\n  Order deny,allow\n  Allow from all\n</Proxy>\n\nThis assumes that you run Jenkins on port 8081.\n\n<<context-path>> provides more details on reverse proxy requires for the Jenkins context path.\n\nWhen running on a dedicated server and you are using / as context, make\nsure you add a sl"
  },
  "3410": {
    "source_file": "reverse-proxy-configuration-apache.txt",
    "text": "ils on reverse proxy requires for the Jenkins context path.\n\nWhen running on a dedicated server and you are using / as context, make\nsure you add a slash at the end of all URLs in proxy params in apache.\nOtherwise you might run into proxy errors. So\n\nProxyPass / http://localhost:8080/ nocanon\n\ninstead of\n\nProxyPass / http://localhost:8080 nocanon     # wont work\n\nNote that this does *not* apply to"
  },
  "3411": {
    "source_file": "reverse-proxy-configuration-apache.txt",
    "text": "\nProxyPass / http://localhost:8080/ nocanon\n\ninstead of\n\nProxyPass / http://localhost:8080 nocanon     # wont work\n\nNote that this does *not* apply to the `+ProxyPassMatch+` directive,\nwhich behaves differently than `+ProxyPass+`.\nBelow is an example of `+ProxyPassMatch+` to proxy all URLs other than\n`+/.well-known+` (a URL required by letsencrypt):\n\nProxyPassMatch  ^/(?\\!.well-known)  http://loca"
  },
  "3412": {
    "source_file": "reverse-proxy-configuration-apache.txt",
    "text": " of `+ProxyPassMatch+` to proxy all URLs other than\n`+/.well-known+` (a URL required by letsencrypt):\n\nProxyPassMatch  ^/(?\\!.well-known)  http://localhost:8080 nocanon\n\nThe _ProxyRequests Off_ prevents Apache from functioning as a forward\nproxy server (except for _ProxyPass_), it is advised to include it\nunless the server should function as a proxy.\n\nBoth the `+nocanon+` option to `+ProxyPass+`, "
  },
  "3413": {
    "source_file": "reverse-proxy-configuration-apache.txt",
    "text": "er (except for _ProxyPass_), it is advised to include it\nunless the server should function as a proxy.\n\nBoth the `+nocanon+` option to `+ProxyPass+`, _and_\n`+AllowEncodedSlashes NoDecode+`, are required for certain Jenkins\nfeatures to work.\n\nIf you are running Apache on a Security-Enhanced Linux (SE-Linux)\nmachine it is essential to make SE-Linux do the right thing by issuing\nas root\n\nsetsebool -P"
  },
  "3414": {
    "source_file": "reverse-proxy-configuration-apache.txt",
    "text": "re running Apache on a Security-Enhanced Linux (SE-Linux)\nmachine it is essential to make SE-Linux do the right thing by issuing\nas root\n\nsetsebool -P httpd_can_network_connect true\n\nIf this is not issued Apache will not be allowed to forward proxy\nrequests to Jenkins and only an error message will be displayed.\n\nBecause Jenkins already compress its output, you can not use the normal\nproxy-html fi"
  },
  "3415": {
    "source_file": "reverse-proxy-configuration-apache.txt",
    "text": "equests to Jenkins and only an error message will be displayed.\n\nBecause Jenkins already compress its output, you can not use the normal\nproxy-html filter to modify urls:\n\nSetOutputFilter proxy-html\n\nInstead you can use the following:\n\nSetOutputFilter INFLATE;proxy-html;DEFLATE\nProxyHTMLURLMap http://your_server:8080/jenkins /jenkins\n\nBut since Jenkins seems to be well behaved it's even better to "
  },
  "3416": {
    "source_file": "reverse-proxy-configuration-apache.txt",
    "text": "r INFLATE;proxy-html;DEFLATE\nProxyHTMLURLMap http://your_server:8080/jenkins /jenkins\n\nBut since Jenkins seems to be well behaved it's even better to just not\nuse SetOutputFilter and ProxyHTMLURLMap.\n\nIf there are problems with Jenkins sometimes servicing random garbage\npages, then the following may help:\n\nSetEnv proxy-nokeepalive 1\n\nSome plug-ins determine URLs from client requests from Host head"
  },
  "3417": {
    "source_file": "reverse-proxy-configuration-apache.txt",
    "text": "icing random garbage\npages, then the following may help:\n\nSetEnv proxy-nokeepalive 1\n\nSome plug-ins determine URLs from client requests from Host header, so\nif you experience some problems with wrong URLs, you can try to switch\non `+ProxyPreserveHost+` directive, which is switched off by default:\n\nProxyPreserveHost On\n\nYou can add an additional `+ProxyPassReverse+` directive\nto redirect non-SSL UR"
  },
  "3418": {
    "source_file": "reverse-proxy-configuration-apache.txt",
    "text": "+` directive, which is switched off by default:\n\nProxyPreserveHost On\n\nYou can add an additional `+ProxyPassReverse+` directive\nto redirect non-SSL URLs generated by Jenkins to the SSL side.\nAssuming that your webserver is `+your.host.com+`, placing the following within\nthe SSL virtual host definition will do the trick:\n\nProxyRequests     Off\nProxyPreserveHost On\nAllowEncodedSlashes NoDecode\n\n<Pro"
  },
  "3419": {
    "source_file": "reverse-proxy-configuration-apache.txt",
    "text": "the following within\nthe SSL virtual host definition will do the trick:\n\nProxyRequests     Off\nProxyPreserveHost On\nAllowEncodedSlashes NoDecode\n\n<Proxy http://localhost:8081/jenkins*>\n  Order deny,allow\n  Allow from all\n</Proxy>\n\nProxyPass         /jenkins  http://localhost:8081/jenkins nocanon\nProxyPassReverse  /jenkins  http://localhost:8081/jenkins\nProxyPassReverse  /jenkins  http://your.host."
  },
  "3420": {
    "source_file": "reverse-proxy-configuration-apache.txt",
    "text": "jenkins  http://localhost:8081/jenkins nocanon\nProxyPassReverse  /jenkins  http://localhost:8081/jenkins\nProxyPassReverse  /jenkins  http://your.host.com/jenkins\n\nYet another option is to rewrite the Location headers that contain\nnon-ssl URL's generated by Jenkins.\nIf you want to access Jenkins from https://www.example.com/jenkins,\nplacing the following within the SSL virtual host definition also "
  },
  "3421": {
    "source_file": "reverse-proxy-configuration-apache.txt",
    "text": "ted by Jenkins.\nIf you want to access Jenkins from https://www.example.com/jenkins,\nplacing the following within the SSL virtual host definition also works:\n\nProxyRequests     Off\nProxyPreserveHost On\nProxyPass /jenkins/ http://localhost:8081/jenkins/ nocanon\nAllowEncodedSlashes NoDecode\n\n<Location /jenkins/>\n  ProxyPassReverse /\n  Order deny,allow\n  Allow from all\n</Location>\n\nHeader edit Locatio"
  },
  "3422": {
    "source_file": "reverse-proxy-configuration-apache.txt",
    "text": "/ nocanon\nAllowEncodedSlashes NoDecode\n\n<Location /jenkins/>\n  ProxyPassReverse /\n  Order deny,allow\n  Allow from all\n</Location>\n\nHeader edit Location ^http://www.example.com/jenkins/ https://www.example.com/jenkins/\n\nBut it may also work fine to just use simple forwarding as above (the\nfirst HTTPS snippet), and add\n\nRequestHeader set X-Forwarded-Proto \"https\"\nRequestHeader set X-Forwarded-Port \""
  },
  "3423": {
    "source_file": "reverse-proxy-configuration-apache.txt",
    "text": "st use simple forwarding as above (the\nfirst HTTPS snippet), and add\n\nRequestHeader set X-Forwarded-Proto \"https\"\nRequestHeader set X-Forwarded-Port \"443\"\n\nin the HTTPS site configuration, as the Docker demo (below) does.\n(`+X-Forwarded-Port+` is not interpreted by Jenkins prior to\nhttps://issues.jenkins.io/browse/JENKINS-23294[JENKINS-23294] so it\nmay also be desirable to configure the servlet co"
  },
  "3424": {
    "source_file": "reverse-proxy-configuration-apache.txt",
    "text": " interpreted by Jenkins prior to\nhttps://issues.jenkins.io/browse/JENKINS-23294[JENKINS-23294] so it\nmay also be desirable to configure the servlet container to specify the\noriginating port.)\n\nNameVirtualHost *:80\nNameVirtualHost *:443\n\n<VirtualHost *:80>\n    ServerAdmin  webmaster@localhost\n    Redirect permanent / https://www.example.com/\n</VirtualHost>\n\n<VirtualHost *:443>\n    SSLEngine on\n    "
  },
  "3425": {
    "source_file": "reverse-proxy-configuration-apache.txt",
    "text": "*:80>\n    ServerAdmin  webmaster@localhost\n    Redirect permanent / https://www.example.com/\n</VirtualHost>\n\n<VirtualHost *:443>\n    SSLEngine on\n    SSLCertificateFile /etc/ssl/certs/cert.pem\n    ServerAdmin  webmaster@localhost\n    ProxyRequests     Off\n    ProxyPreserveHost On\n    AllowEncodedSlashes NoDecode\n    <Proxy *>\n        Order deny,allow\n        Allow from all\n    </Proxy>\n    ProxyPa"
  },
  "3426": {
    "source_file": "reverse-proxy-configuration-apache.txt",
    "text": "  Off\n    ProxyPreserveHost On\n    AllowEncodedSlashes NoDecode\n    <Proxy *>\n        Order deny,allow\n        Allow from all\n    </Proxy>\n    ProxyPass         /  http://localhost:8080/ nocanon\n    ProxyPassReverse  /  http://localhost:8080/\n    ProxyPassReverse  /  http://www.example.com/\n    RequestHeader set X-Forwarded-Proto \"https\"\n    RequestHeader set X-Forwarded-Port \"443\"\n\n    # Required"
  },
  "3427": {
    "source_file": "reverse-proxy-configuration-apache.txt",
    "text": "xyPassReverse  /  http://www.example.com/\n    RequestHeader set X-Forwarded-Proto \"https\"\n    RequestHeader set X-Forwarded-Port \"443\"\n\n    # Required for Jenkins websocket agents\n    RewriteEngine on\n    RewriteCond %{HTTP:Upgrade} websocket [NC]\n    RewriteCond %{HTTP:Connection} upgrade [NC]\n    RewriteRule ^/?(.*) \"ws://localhost:8080/$1\" [P,L]\n</VirtualHost>\n\nThe Apache mod_rewrite module can"
  },
  "3428": {
    "source_file": "reverse-proxy-configuration-apache.txt",
    "text": "  RewriteCond %{HTTP:Connection} upgrade [NC]\n    RewriteRule ^/?(.*) \"ws://localhost:8080/$1\" [P,L]\n</VirtualHost>\n\nThe Apache mod_rewrite module can be used to configure an Apache reverse proxy for Jenkins.\n\nThe following Apache modules must be installed :\n\na2enmod rewrite\na2enmod proxy\na2enmod proxy_http\n# Required for Jenkins websocket agents\na2enmod proxy_wstunnel\n\nA typical mod_rewrite confi"
  },
  "3429": {
    "source_file": "reverse-proxy-configuration-apache.txt",
    "text": "talled :\n\na2enmod rewrite\na2enmod proxy\na2enmod proxy_http\n# Required for Jenkins websocket agents\na2enmod proxy_wstunnel\n\nA typical mod_rewrite configuration would look like this:\n\n# Required for Jenkins websocket agents\nRewriteCond %{HTTP:Upgrade} websocket [NC]\nRewriteCond %{HTTP:Connection} upgrade [NC]\nRewriteRule ^/jenkins/?(.*) \"ws://localhost:8081/jenkins/$1\" [P,L]\n\n# Use last flag because"
  },
  "3430": {
    "source_file": "reverse-proxy-configuration-apache.txt",
    "text": "websocket [NC]\nRewriteCond %{HTTP:Connection} upgrade [NC]\nRewriteRule ^/jenkins/?(.*) \"ws://localhost:8081/jenkins/$1\" [P,L]\n\n# Use last flag because no more rewrite can be applied after proxy pass\n# NE makes sure slashes are not re-encoded.\n# Apache does not re-encode spaces though, we ask Apache to encode it again with the B flag\n# BNP tells apache to use %20 instead of + to re-encode the space"
  },
  "3431": {
    "source_file": "reverse-proxy-configuration-apache.txt",
    "text": "e does not re-encode spaces though, we ask Apache to encode it again with the B flag\n# BNP tells apache to use %20 instead of + to re-encode the space\nRewriteRule       ^/jenkins(.*)$  http://localhost:8081/jenkins$1 [P,L,NE,B=\\,BNP]\n\nProxyPassReverse  /jenkins        http://localhost:8081/jenkins\nProxyRequests     Off\n\nAllowEncodedSlashes NoDecode\n\n# Local reverse proxy authorization override\n# M"
  },
  "3432": {
    "source_file": "reverse-proxy-configuration-apache.txt",
    "text": "e  /jenkins        http://localhost:8081/jenkins\nProxyRequests     Off\n\nAllowEncodedSlashes NoDecode\n\n# Local reverse proxy authorization override\n# Most unix distribution deny proxy by default\n# See /etc/apache2/mods-enabled/proxy.conf in Ubuntu\n<Proxy http://localhost:8081/jenkins*>\n  Order deny,allow\n  Allow from all\n</Proxy>\n\n# If using HTTPS, add the following directives\n# RequestHeader set X"
  },
  "3433": {
    "source_file": "reverse-proxy-configuration-apache.txt",
    "text": "oxy http://localhost:8081/jenkins*>\n  Order deny,allow\n  Allow from all\n</Proxy>\n\n# If using HTTPS, add the following directives\n# RequestHeader set X-Forwarded-Proto \"https\"\n# RequestHeader set X-Forwarded-Port \"443\"\n\nThis assumes that you run Jenkins on port 8081.\nThe context path of Jenkins must be the same between Apache and Jenkins.\nJenkins can't run on http://example.com:8081/ci and be rever"
  },
  "3434": {
    "source_file": "reverse-proxy-configuration-apache.txt",
    "text": "ns on port 8081.\nThe context path of Jenkins must be the same between Apache and Jenkins.\nJenkins can't run on http://example.com:8081/ci and be reverse proxied at http://example.com/jenkins .\n<<context-path>> provides more details on reverse proxy requires for the Jenkins context path.\n\nThe _ProxyRequests Off_ prevents Apache from functioning as a forward\nproxy server (except for _ProxyPass_), it"
  },
  "3435": {
    "source_file": "reverse-proxy-configuration-apache.txt",
    "text": "equires for the Jenkins context path.\n\nThe _ProxyRequests Off_ prevents Apache from functioning as a forward\nproxy server (except for _ProxyPass_), it is advised to include it\nunless the server should function as a proxy.\n\nApache can be configured to proxy requests to Jenkins over a Unix domain socket instead of a TCP port.\nThis approach enhances security by eliminating network exposure of Jenkins"
  },
  "3436": {
    "source_file": "reverse-proxy-configuration-apache.txt",
    "text": " proxy requests to Jenkins over a Unix domain socket instead of a TCP port.\nThis approach enhances security by eliminating network exposure of Jenkins, and is particularly useful\nwhen Jenkins and Apache run on the same host.\n\nTo avoid repetitive use of `sudo` in the commands below, switch to a root shell first by running:\n\nsudo -i\n\n# Enable the modules using `a2enmod`\na2enmod proxy\na2enmod proxy_h"
  },
  "3437": {
    "source_file": "reverse-proxy-configuration-apache.txt",
    "text": "of `sudo` in the commands below, switch to a root shell first by running:\n\nsudo -i\n\n# Enable the modules using `a2enmod`\na2enmod proxy\na2enmod proxy_http\n\n# Restart Apache to apply changes\nsystemctl restart httpd\n\n# Allow HTTP and HTTPS traffic through the firewall\nufw allow http\nufw allow https\nufw reload\nufw status\n\n# Edit the Jenkins systemd service to disable TCP and enable a Unix socket\nsyste"
  },
  "3438": {
    "source_file": "reverse-proxy-configuration-apache.txt",
    "text": "gh the firewall\nufw allow http\nufw allow https\nufw reload\nufw status\n\n# Edit the Jenkins systemd service to disable TCP and enable a Unix socket\nsystemctl edit jenkins\n\n# Add the following override\n[Service]\nExecStart=\n# Set the new ExecStart with Unix socket\nExecStart=/usr/bin/jenkins --pluginroot=/var/cache/jenkins/plugins --httpPort=-1 --httpUnixDomainPath=/var/run/jenkins/jenkins.socket\n\n# Rel"
  },
  "3439": {
    "source_file": "reverse-proxy-configuration-apache.txt",
    "text": "ix socket\nExecStart=/usr/bin/jenkins --pluginroot=/var/cache/jenkins/plugins --httpPort=-1 --httpUnixDomainPath=/var/run/jenkins/jenkins.socket\n\n# Reload and restart Jenkins\nsystemctl daemon-reload\nsystemctl restart jenkins\n\n# Verify the socket exists\nls -l /var/run/jenkins/jenkins.socket\n\n# Ensure Apache can access the socket\nsudo chown jenkins:jenkins /var/run/jenkins/jenkins.socket\nsudo chmod 7"
  },
  "3440": {
    "source_file": "reverse-proxy-configuration-apache.txt",
    "text": "s\nls -l /var/run/jenkins/jenkins.socket\n\n# Ensure Apache can access the socket\nsudo chown jenkins:jenkins /var/run/jenkins/jenkins.socket\nsudo chmod 700 /var/run/jenkins/jenkins.socket\n\n# Create a new virtual host to proxy requests to the Unix socket\nnano /etc/apache2/sites-available/jenkins.conf\n\n# Add the following\n<VirtualHost *:80>\n    ServerName localhost\n\n    # Proxy to Unix domain socket\n  "
  },
  "3441": {
    "source_file": "reverse-proxy-configuration-apache.txt",
    "text": "\nnano /etc/apache2/sites-available/jenkins.conf\n\n# Add the following\n<VirtualHost *:80>\n    ServerName localhost\n\n    # Proxy to Unix domain socket\n    ProxyPass / unix:/var/run/jenkins/jenkins.socket|http://localhost/\n    ProxyPassReverse / unix:/var/run/jenkins/jenkins.socket|http://localhost/\n\n    # Preserve host header\n    ProxyPreserveHost On\n\n    # Logging\n    ErrorLog ${APACHE_LOG_DIR}/jenk"
  },
  "3442": {
    "source_file": "reverse-proxy-configuration-apache.txt",
    "text": "r/run/jenkins/jenkins.socket|http://localhost/\n\n    # Preserve host header\n    ProxyPreserveHost On\n\n    # Logging\n    ErrorLog ${APACHE_LOG_DIR}/jenkins_error.log\n    CustomLog ${APACHE_LOG_DIR}/jenkins_access.log combined\n</VirtualHost>\n\n# Enable the site and restart Apache\na2ensite jenkins.conf\nsystemctl restart apache2\n\n# If Apache needs to share socket access with Jenkins, update its user/gro"
  },
  "3443": {
    "source_file": "reverse-proxy-configuration-apache.txt",
    "text": "he site and restart Apache\na2ensite jenkins.conf\nsystemctl restart apache2\n\n# If Apache needs to share socket access with Jenkins, update its user/group\nnano /etc/apache2/envvars\n# Modify:\nexport APACHE_RUN_USER=jenkins\nexport APACHE_RUN_GROUP=jenkins\n\n# Restart Apache\nsystemctl restart apache2\n\nThe following video from Darin Pope provides a 16 minute tutorial on configuring Unix domain sockets wi"
  },
  "3444": {
    "source_file": "reverse-proxy-configuration-apache.txt",
    "text": "s\n\n# Restart Apache\nsystemctl restart apache2\n\nThe following video from Darin Pope provides a 16 minute tutorial on configuring Unix domain sockets with Apache HTTP Server and Jenkins running on AlmaLinux.\n\n.Configure Using Unix Domain Sockets With Apache HTTP Server and Jenkins\nvideo::KxFJh4184vk[youtube, width=640, height=360]\n\n# Ensure the modules are loaded by editing the module configuration\n"
  },
  "3445": {
    "source_file": "reverse-proxy-configuration-apache.txt",
    "text": "pache HTTP Server and Jenkins\nvideo::KxFJh4184vk[youtube, width=640, height=360]\n\n# Ensure the modules are loaded by editing the module configuration\ndnf install httpd -y  # Install Apache if not already present\n\n# Allow HTTP and HTTPS traffic through the firewall\nfirewall-cmd --zone=public --add-service=http --permanent\nfirewall-cmd --zone=public --add-service=https --permanent\nfirewall-cmd --rel"
  },
  "3446": {
    "source_file": "reverse-proxy-configuration-apache.txt",
    "text": "h the firewall\nfirewall-cmd --zone=public --add-service=http --permanent\nfirewall-cmd --zone=public --add-service=https --permanent\nfirewall-cmd --reload\n\n# Edit the Jenkins systemd service to disable TCP and enable a Unix socket\nsystemctl edit jenkins\n\n# Add the following override\n[Service]\nExecStart=/usr/lib/jenkins/jenkins --pluginroot=/var/cache/jenkins/plugins --httpPort=-1 --httpUnixDomainPa"
  },
  "3447": {
    "source_file": "reverse-proxy-configuration-apache.txt",
    "text": "ns\n\n# Add the following override\n[Service]\nExecStart=/usr/lib/jenkins/jenkins --pluginroot=/var/cache/jenkins/plugins --httpPort=-1 --httpUnixDomainPath=/var/run/jenkins/jenkins.socket\n\n# Reload and restart Jenkins\nsystemctl daemon-reload\nsystemctl restart jenkins\n\n# Verify the socket exists\nls -l /var/run/jenkins/jenkins.socket\n\n# Ensure Apache can access the socket\nsudo chown jenkins:jenkins /va"
  },
  "3448": {
    "source_file": "reverse-proxy-configuration-apache.txt",
    "text": "estart jenkins\n\n# Verify the socket exists\nls -l /var/run/jenkins/jenkins.socket\n\n# Ensure Apache can access the socket\nsudo chown jenkins:jenkins /var/run/jenkins\nsudo chmod 700 /var/run/jenkins\nsystemctl restart jenkins\n\n# Create a new virtual host to proxy requests to the Unix socket\nmv welcome.conf welcome.old\nvi /etc/httpd/conf.d/jenkins.conf\n\n# Add the following\nUser jenkins\nGroup jenkins\nPr"
  },
  "3449": {
    "source_file": "reverse-proxy-configuration-apache.txt",
    "text": " to proxy requests to the Unix socket\nmv welcome.conf welcome.old\nvi /etc/httpd/conf.d/jenkins.conf\n\n# Add the following\nUser jenkins\nGroup jenkins\nProxyPass / unix:/var/run/jenkins/jenkins.socket|http://localhost/ nocanon\nProxyPassReverse / unix:/var/run/jenkins/jenkins.socket|http://localhost/\n\n# To allow SE linux to traffic allow to the socket\nchcon -t httpd_sys_rw_content_t /var/run/jenkins/je"
  },
  "3450": {
    "source_file": "reverse-proxy-configuration-apache.txt",
    "text": "r/run/jenkins/jenkins.socket|http://localhost/\n\n# To allow SE linux to traffic allow to the socket\nchcon -t httpd_sys_rw_content_t /var/run/jenkins/jenkins.socket\n\n# Restart Apache\nsystemctl restart apache2\n\nOnce you have finished your configuration, access `http://localhost/` in a browser.\nIf you encounter any issues, check the logs for any errors with the corresponding commands:\n\ntail -f /var/lo"
  },
  "3451": {
    "source_file": "reverse-proxy-configuration-apache.txt",
    "text": " access `http://localhost/` in a browser.\nIf you encounter any issues, check the logs for any errors with the corresponding commands:\n\ntail -f /var/log/apache2/jenkins_error.log  #Debian\ntail -f /var/log/apache2/jenkins_access.log #Debian\n\ntail -f /var/log/httpd/jenkins_error.log  #RHEL\ntail -f /var/log/httpd/jenkins_access.log #RHEL\n\nUsing the plain CLI protocol with the HTTP(S) transport to acce"
  },
  "3452": {
    "source_file": "reverse-proxy-configuration-apache.txt",
    "text": "ar/log/httpd/jenkins_error.log  #RHEL\ntail -f /var/log/httpd/jenkins_access.log #RHEL\n\nUsing the plain CLI protocol with the HTTP(S) transport to access\nJenkins through an Apache reverse proxy does not work.\nSee https://issues.jenkins.io/browse/JENKINS-47279[JENKINS-47279 - Full-duplex HTTP(S) transport with plain CLI protocol does not work with Apache reverse proxy]\nfor more details.\nAs a workaro"
  },
  "3453": {
    "source_file": "reverse-proxy-configuration-apache.txt",
    "text": "NS-47279[JENKINS-47279 - Full-duplex HTTP(S) transport with plain CLI protocol does not work with Apache reverse proxy]\nfor more details.\nAs a workaround, you can use the .\n\nIf using Apache check that _nocanon_ is set on _ProxyPass_ and\nthat _AllowEncodedSlashes_ is set.\n\n_AllowEncodedSlashes_ is not inherited in Apache configs, so this\ndirective must be placed inside the _VirtualHost_ definition."
  },
  "3454": {
    "source_file": "reverse-proxy-configuration-apache.txt",
    "text": "codedSlashes_ is set.\n\n_AllowEncodedSlashes_ is not inherited in Apache configs, so this\ndirective must be placed inside the _VirtualHost_ definition."
  },
  "3455": {
    "source_file": "reverse-proxy-configuration-caddy.txt",
    "text": "layout: subsection\n\n\nifndef::env-github[:imagesdir: ../../../resources/managing]\n\n[[running-jenkins-behind-apache]]\n\nThis sets up Jenkins behind Caddy as an HTTPS reverse proxy using Docker Compose.\n\n* DNS for your domain pointing to the Docker host\n* Ports 80/443 open to the internet\n* (Optional, for sub-path) Decide your Jenkins context path (e.g., `/jenkins`)\n\nCreate these two files in the same"
  },
  "3456": {
    "source_file": "reverse-proxy-configuration-caddy.txt",
    "text": "* Ports 80/443 open to the internet\n* (Optional, for sub-path) Decide your Jenkins context path (e.g., `/jenkins`)\n\nCreate these two files in the same directory.\n\nversion: \"3.9\"\n\nservices:\n  jenkins:\n    image: jenkins/jenkins:lts-jdk21\n    container_name: jenkins\n    restart: unless-stopped\n    # If you want Jenkins on a sub-path like /jenkins, uncomment the next line\n    # environment:\n    #   -"
  },
  "3457": {
    "source_file": "reverse-proxy-configuration-caddy.txt",
    "text": "_name: jenkins\n    restart: unless-stopped\n    # If you want Jenkins on a sub-path like /jenkins, uncomment the next line\n    # environment:\n    #   - JENKINS_OPTS=--prefix=/jenkins\n    volumes:\n      - jenkins_home:/var/jenkins_home\n    expose:\n      - \"8080\"     # internal to the compose network\n      # - \"50000\"  # optional: classic JNLP agents (WebSocket usually removes the need)\n    networks:"
  },
  "3458": {
    "source_file": "reverse-proxy-configuration-caddy.txt",
    "text": "  - \"8080\"     # internal to the compose network\n      # - \"50000\"  # optional: classic JNLP agents (WebSocket usually removes the need)\n    networks:\n      - web\n\n  caddy:\n    image: caddy:2\n    container_name: caddy\n    restart: unless-stopped\n    depends_on:\n      - jenkins\n    ports:\n      - \"80:80\"\n      - \"443:443\"\n    volumes:\n      - ./Caddyfile:/etc/caddy/Caddyfile:ro\n      - caddy_data:/"
  },
  "3459": {
    "source_file": "reverse-proxy-configuration-caddy.txt",
    "text": "depends_on:\n      - jenkins\n    ports:\n      - \"80:80\"\n      - \"443:443\"\n    volumes:\n      - ./Caddyfile:/etc/caddy/Caddyfile:ro\n      - caddy_data:/data\n      - caddy_config:/config\n    networks:\n      - web\n\nnetworks:\n  web:\n    driver: bridge\n\nvolumes:\n  jenkins_home:\n  caddy_data:\n  caddy_config:\n\n# Replace with your real domain\njenkins.example.com {\n    encode zstd gzip\n    reverse_proxy jen"
  },
  "3460": {
    "source_file": "reverse-proxy-configuration-caddy.txt",
    "text": "lumes:\n  jenkins_home:\n  caddy_data:\n  caddy_config:\n\n# Replace with your real domain\njenkins.example.com {\n    encode zstd gzip\n    reverse_proxy jenkins:8080\n}\n\n# Replace with your real domain\nexample.com {\n    encode zstd gzip\n\n    @jenkins path /jenkins*\n    handle @jenkins {\n        handle_path /jenkins* {\n            reverse_proxy jenkins:8080\n        }\n    }\n}\n\ndocker compose up -d\n\nAfter s"
  },
  "3461": {
    "source_file": "reverse-proxy-configuration-caddy.txt",
    "text": "jenkins*\n    handle @jenkins {\n        handle_path /jenkins* {\n            reverse_proxy jenkins:8080\n        }\n    }\n}\n\ndocker compose up -d\n\nAfter startup, set the Jenkins URL under *Manage Jenkins \u2192 System \u2192 Jenkins Location* to either:\n\n* `https://jenkins.example.com/`  (subdomain)\n* `https://example.com/jenkins/`  (sub-path; ensure `JENKINS_OPTS=--prefix=/jenkins` is set as shown above)"
  },
  "3462": {
    "source_file": "reverse-proxy-configuration-caddy.txt",
    "text": "//jenkins.example.com/`  (subdomain)\n* `https://example.com/jenkins/`  (sub-path; ensure `JENKINS_OPTS=--prefix=/jenkins` is set as shown above)"
  },
  "3463": {
    "source_file": "reverse-proxy-configuration-haproxy.txt",
    "text": "layout: subsection\n\n\nifndef::env-github[:imagesdir: ../../../resources/managing]\n\nIn situations where you want a user friendly URL, different public\nports, or to terminate SSL connections before they reach Jenkins, you\nmay find it useful to run Jenkins (or the servlet container that Jenkins\nruns in) behind HAProxy.\nThis section discusses some of the approaches for doing this.\n\nThis 6 minute video "
  },
  "3464": {
    "source_file": "reverse-proxy-configuration-haproxy.txt",
    "text": "ns (or the servlet container that Jenkins\nruns in) behind HAProxy.\nThis section discusses some of the approaches for doing this.\n\nThis 6 minute video tutorial from Darin Pope configures an HAProxy reverse proxy.\n\n.Configuring an HAProxy reverse proxy\nvideo::TuTdvYfM8T8[youtube, width=640, height=360]\n\nUsing HAProxy 2.6.7, here is an example HAProxy.cfg to proxy over plain HTTP:\n\n# If you already h"
  },
  "3465": {
    "source_file": "reverse-proxy-configuration-haproxy.txt",
    "text": "\nvideo::TuTdvYfM8T8[youtube, width=640, height=360]\n\nUsing HAProxy 2.6.7, here is an example HAProxy.cfg to proxy over plain HTTP:\n\n# If you already have an haproxy.cfg file, you can probably leave the\n# global and defaults section as-is, but you might need to increase the\n# timeouts so that long-running CLI commands will work.\nglobal\n    maxconn 4096\n    log stdout local0 debug\n\ndefaults\n   log g"
  },
  "3466": {
    "source_file": "reverse-proxy-configuration-haproxy.txt",
    "text": "ht need to increase the\n# timeouts so that long-running CLI commands will work.\nglobal\n    maxconn 4096\n    log stdout local0 debug\n\ndefaults\n   log global\n   option httplog\n   option dontlognull\n   option forwardfor\n   maxconn 20\n   timeout connect 5s\n   timeout client 60s\n   timeout server 60s\n\nfrontend http-in\n  log stdout format raw local0 debug #for additional logging\n  bind *:80\n  mode http\n"
  },
  "3467": {
    "source_file": "reverse-proxy-configuration-haproxy.txt",
    "text": "5s\n   timeout client 60s\n   timeout server 60s\n\nfrontend http-in\n  log stdout format raw local0 debug #for additional logging\n  bind *:80\n  mode http\n  acl prefixed-with-jenkins  path_beg /jenkins\n  # Use http-request redirect prefix to add /jenkins prefix to URL's location\n  # to ensure jenkins base url (context path) is working properly.\n  http-request redirect code 301 prefix /jenkins unless pr"
  },
  "3468": {
    "source_file": "reverse-proxy-configuration-haproxy.txt",
    "text": "prefix to URL's location\n  # to ensure jenkins base url (context path) is working properly.\n  http-request redirect code 301 prefix /jenkins unless prefixed-with-jenkins\n  use_backend jenkins if prefixed-with-jenkins\n\nbackend jenkins\n  log stdout format raw local0 debug\n  mode http\n  server jenkins1 127.0.0.1:8080 check\n  http-request replace-path /jenkins(/)?(.*) /\\2\n  http-request set-header X-F"
  },
  "3469": {
    "source_file": "reverse-proxy-configuration-haproxy.txt",
    "text": "mat raw local0 debug\n  mode http\n  server jenkins1 127.0.0.1:8080 check\n  http-request replace-path /jenkins(/)?(.*) /\\2\n  http-request set-header X-Forwarded-Port %[dst_port]\n  http-request add-header X-Forwarded-Proto https if { ssl_fc }\n  http-request set-header X-Forwarded-Host %[req.hdr(Host)]\n\nThis assumes Jenkins is running locally on port 8080.\n\nThis assumes that you are using the http://l"
  },
  "3470": {
    "source_file": "reverse-proxy-configuration-haproxy.txt",
    "text": "uest set-header X-Forwarded-Host %[req.hdr(Host)]\n\nThis assumes Jenkins is running locally on port 8080.\n\nThis assumes that you are using the http://localhost/jenkins[/jenkins] context path for both the\nsite exposed from HAProxy and Jenkins itself.\nIf this is not the case, you will need to adjust the configuration.\nRefer to the HAProxy documentation on  for more information.\n\nIf you are experienci"
  },
  "3471": {
    "source_file": "reverse-proxy-configuration-haproxy.txt",
    "text": "f this is not the case, you will need to adjust the configuration.\nRefer to the HAProxy documentation on  for more information.\n\nIf you are experiencing the following error when attempting to run long\nCLI commands in Jenkins, and Jenkins is running behind HAProxy,\nit is probably due to HAProxy timing out the CLI connection.\nYou can increase the `+timeout client+` and `+timeout server+` settings as"
  },
  "3472": {
    "source_file": "reverse-proxy-configuration-haproxy.txt",
    "text": "ehind HAProxy,\nit is probably due to HAProxy timing out the CLI connection.\nYou can increase the `+timeout client+` and `+timeout server+` settings as\nnecessary so the command will complete successfully.\n\nWARNING: null\nhudson.cli.DiagnosedStreamCorruptionException\nRead back: 0x00 0x00 0x00 0x1e 0x07\n           'Started reverse-proxy-test #68'\n           0x00 0x00 0x00 0x01 0x07 0x0a\nRead ahead:\nDi"
  },
  "3473": {
    "source_file": "reverse-proxy-configuration-haproxy.txt",
    "text": "ptionException\nRead back: 0x00 0x00 0x00 0x1e 0x07\n           'Started reverse-proxy-test #68'\n           0x00 0x00 0x00 0x01 0x07 0x0a\nRead ahead:\nDiagnosis problem:\n    java.io.IOException: Premature EOF\n        at sun.net.www.http.ChunkedInputStream.readAheadBlocking(ChunkedInputStream.java:565)\n        ...\n    at hudson.cli.FlightRecorderInputStream.analyzeCrash(FlightRecorderInputStream.java:"
  },
  "3474": {
    "source_file": "reverse-proxy-configuration-haproxy.txt",
    "text": "am.readAheadBlocking(ChunkedInputStream.java:565)\n        ...\n    at hudson.cli.FlightRecorderInputStream.analyzeCrash(FlightRecorderInputStream.java:82)\n    at hudson.cli.PlainCLIProtocol$EitherSide$Reader.run(PlainCLIProtocol.java:153)\nCaused by: java.io.IOException: Premature EOF\n    at sun.net.www.http.ChunkedInputStream.readAheadBlocking(ChunkedInputStream.java:565)\n    ...\n    at java.io.Dat"
  },
  "3475": {
    "source_file": "reverse-proxy-configuration-haproxy.txt",
    "text": "ava.io.IOException: Premature EOF\n    at sun.net.www.http.ChunkedInputStream.readAheadBlocking(ChunkedInputStream.java:565)\n    ...\n    at java.io.DataInputStream.readInt(DataInputStream.java:387)\n    at hudson.cli.PlainCLIProtocol$EitherSide$Reader.run(PlainCLIProtocol.java:111)\n\nUsing HAProxy 2.6.7, here is an example HAProxy.cfg to connect to the\nproxy using SSL, terminate the SSL connection, a"
  },
  "3476": {
    "source_file": "reverse-proxy-configuration-haproxy.txt",
    "text": "run(PlainCLIProtocol.java:111)\n\nUsing HAProxy 2.6.7, here is an example HAProxy.cfg to connect to the\nproxy using SSL, terminate the SSL connection, and then talk to Jenkins\nusing plain HTTP:\n\n# If you already have an haproxy.cfg file, you can probably leave the\n# global and defaults section as-is, but you might need to increase the\n# timeouts so that long-running CLI commands will work.\n\nglobal\n "
  },
  "3477": {
    "source_file": "reverse-proxy-configuration-haproxy.txt",
    "text": "ly leave the\n# global and defaults section as-is, but you might need to increase the\n# timeouts so that long-running CLI commands will work.\n\nglobal\n    maxconn 4096\n    log stdout local0 debug\n\ndefaults\n   log global\n   option httplog\n   option dontlognull\n   option forwardfor\n   maxconn 20\n   timeout connect 5s\n   timeout client 5m\n   timeout server 5m\n\nfrontend http-in\n  log stdout format raw l"
  },
  "3478": {
    "source_file": "reverse-proxy-configuration-haproxy.txt",
    "text": "lognull\n   option forwardfor\n   maxconn 20\n   timeout connect 5s\n   timeout client 5m\n   timeout server 5m\n\nfrontend http-in\n  log stdout format raw local0 debug\n  bind *:80\n  bind *:443 ssl crt /usr/local/etc/haproxy/ssl/server.pem\n  mode http\n  acl prefixed-with-jenkins  path_beg /jenkins\n  http-request redirect code 301 prefix /jenkins unless prefixed-with-jenkins\n  redirect scheme https if !{ "
  },
  "3479": {
    "source_file": "reverse-proxy-configuration-haproxy.txt",
    "text": " prefixed-with-jenkins  path_beg /jenkins\n  http-request redirect code 301 prefix /jenkins unless prefixed-with-jenkins\n  redirect scheme https if !{ ssl_fc } # Redirect http requests to https\n  use_backend jenkins if prefixed-with-jenkins\n\nbackend jenkins\n  log stdout format raw  local0 debug\n  mode http\n  server jenkins1 127.0.0.1:8080 check\n  http-request replace-path /jenkins(/)?(.*) /\\2\n  htt"
  },
  "3480": {
    "source_file": "reverse-proxy-configuration-haproxy.txt",
    "text": "enkins\n  log stdout format raw  local0 debug\n  mode http\n  server jenkins1 127.0.0.1:8080 check\n  http-request replace-path /jenkins(/)?(.*) /\\2\n  http-request set-header X-Forwarded-Port %[dst_port]\n  http-request add-header X-Forwarded-Proto https if { ssl_fc }\n  http-request set-header X-Forwarded-Host %[req.hdr(Host)]"
  },
  "3481": {
    "source_file": "reverse-proxy-configuration-haproxy.txt",
    "text": "if { ssl_fc }\n  http-request set-header X-Forwarded-Host %[req.hdr(Host)]"
  },
  "3482": {
    "source_file": "reverse-proxy-configuration-iis.txt",
    "text": "layout: subsection\n\n\nifndef::env-github[:imagesdir: ../../../resources/managing]\n\nIn situations where you have existing web sites on your server, you may\nfind it useful to run Jenkins (or the servlet container that Jenkins\nruns in) behind IIS, so that you can bind Jenkins\nto the part of a bigger website that you may have.\nThis section discusses some of the approaches for doing this.\n\n*Make sure th"
  },
  "3483": {
    "source_file": "reverse-proxy-configuration-iis.txt",
    "text": "t you can bind Jenkins\nto the part of a bigger website that you may have.\nThis section discusses some of the approaches for doing this.\n\n*Make sure that you change the Jenkins httpListenAddress from its\ndefault of 0.0.0.0 to 127.0.0.1 or configure the firewall to block\nrequest on the port Jenkins is bound to, otherwise any IIS-level\nrestrictions can be easily bypassed by accessing the Jenkins port"
  },
  "3484": {
    "source_file": "reverse-proxy-configuration-iis.txt",
    "text": "e firewall to block\nrequest on the port Jenkins is bound to, otherwise any IIS-level\nrestrictions can be easily bypassed by accessing the Jenkins port\ndirectly.*\n\n* IIS 7.0 or greater.\n** IIS 8.5 or greater if you want\nhttps://docs.microsoft.com/en-us/iis/get-started/whats-new-in-iis-85/certificate-rebind-in-iis85[Certificate\nRebind].\n* https://www.iis.net/downloads/microsoft/url-rewrite[URL Rewri"
  },
  "3485": {
    "source_file": "reverse-proxy-configuration-iis.txt",
    "text": "s/iis/get-started/whats-new-in-iis-85/certificate-rebind-in-iis85[Certificate\nRebind].\n* https://www.iis.net/downloads/microsoft/url-rewrite[URL Rewrite 2.1]\nor greater.\n** As the https://blogs.iis.net/iisteam/url-rewrite-v2-1[announcement]\nexplains, it introduces a feature flag to turn off the default\nnon-compliant-RFC3986 behavior. Which is what we want.\n* https://www.iis.net/downloads/microsoft"
  },
  "3486": {
    "source_file": "reverse-proxy-configuration-iis.txt",
    "text": " it introduces a feature flag to turn off the default\nnon-compliant-RFC3986 behavior. Which is what we want.\n* https://www.iis.net/downloads/microsoft/application-request-routing[Application\nRequest Routing]  3.0 or greater.\n* Server access\n\nI have a dedicated Jenkins installation on a Windows Server 2012 R2\nserver with a Common Name of *VRTJENKINS01* in the Active Directory\ndomain *acme.example* "
  },
  "3487": {
    "source_file": "reverse-proxy-configuration-iis.txt",
    "text": " dedicated Jenkins installation on a Windows Server 2012 R2\nserver with a Common Name of *VRTJENKINS01* in the Active Directory\ndomain *acme.example* and is reachable by the Fully Qualified Domain\nName *vrtjenkins01.acme.example*.\nAdditionally Jenkins runs on port *8080* and already listens to *127.0.0.1*\ninstead of 0.0.0.0 and the server has additional DNS names: *jenkins* and\n*jenkins.acme.examp"
  },
  "3488": {
    "source_file": "reverse-proxy-configuration-iis.txt",
    "text": "s runs on port *8080* and already listens to *127.0.0.1*\ninstead of 0.0.0.0 and the server has additional DNS names: *jenkins* and\n*jenkins.acme.example*.\n\nI want to have an IIS installation which acts as a TLS/SSL terminating\nreverse proxy.\nIn combination with our in-house Active Directory Certificate Services\n(ADCS, Microsoft's Certificate Authority software) this should make\ncertificate managem"
  },
  "3489": {
    "source_file": "reverse-proxy-configuration-iis.txt",
    "text": "nation with our in-house Active Directory Certificate Services\n(ADCS, Microsoft's Certificate Authority software) this should make\ncertificate management a lot easier since Windows can be configured to\nautomatically renew certificates, and the IIS 8.5+ Certificate Rebind\nfeature can listen to renewal events (which contain the fingerprints of\nboth the old and new certificate) and update the relevan"
  },
  "3490": {
    "source_file": "reverse-proxy-configuration-iis.txt",
    "text": "5+ Certificate Rebind\nfeature can listen to renewal events (which contain the fingerprints of\nboth the old and new certificate) and update the relevant bind(s) to use\nthe fresh certificate.\nThis would ensure that after the initial manual request it would only be\nnecessary to manually change TLS/SSL related settings when the set of\nAlternate Subject Names on the certificate IIS presents should chan"
  },
  "3491": {
    "source_file": "reverse-proxy-configuration-iis.txt",
    "text": "ould only be\nnecessary to manually change TLS/SSL related settings when the set of\nAlternate Subject Names on the certificate IIS presents should change.\n\nIIS will only have to act as 1) a reverse proxy for Jenkins 2) redirect\nnon-canonical URLs to the canonical URL: _https://jenkins.acme.example/_\n\nI have installed the IIS (8.5) role using the _Add Roles and Features\nWizard_ with the all the defa"
  },
  "3492": {
    "source_file": "reverse-proxy-configuration-iis.txt",
    "text": "he canonical URL: _https://jenkins.acme.example/_\n\nI have installed the IIS (8.5) role using the _Add Roles and Features\nWizard_ with the all the default and also the following non-default\nfeatures:\n\n* HTTP Redirection (Under _Common HTTP Features_, to\nredirect http(s)://jenkins/, etc. to\nhttps://jenkins.acme.example/)\n* WebSocket Protocol (Under _Application Development_, because I felt\nlike it)\n"
  },
  "3493": {
    "source_file": "reverse-proxy-configuration-iis.txt",
    "text": "to\nredirect http(s)://jenkins/, etc. to\nhttps://jenkins.acme.example/)\n* WebSocket Protocol (Under _Application Development_, because I felt\nlike it)\n\nThen I installed URL Rewrite and Application Request Routing.\n\nIn the _Internet Information Services (IIS) Manager_ click on the\nVRTJENKINS01 server.\nGo to _Application Request Routing Cache_.\nIn the _Actions_ panel click on _Server Proxy Settings.."
  },
  "3494": {
    "source_file": "reverse-proxy-configuration-iis.txt",
    "text": "s (IIS) Manager_ click on the\nVRTJENKINS01 server.\nGo to _Application Request Routing Cache_.\nIn the _Actions_ panel click on _Server Proxy Settings..._\nEnable the proxy\nDisable the _Reverse rewrite host in response header_\n.. Don't worry, it will work, just follow the rest of the instructions\nSet the _Response buffer threshold (KB)_ to 0.\n.. This helps to prevent HTTP 502 errors on Jenkins' Repla"
  },
  "3495": {
    "source_file": "reverse-proxy-configuration-iis.txt",
    "text": "rk, just follow the rest of the instructions\nSet the _Response buffer threshold (KB)_ to 0.\n.. This helps to prevent HTTP 502 errors on Jenkins' Replay pages.\nApply (the _Actions_ panel again)\n\nOut of scope, there are enough tutorials on the rest of the interwebs\nfor this part.\nThe rest of this tutorial will assume it has been configured with a\ncertificate trusted by your browser of choice.\n\nGo to"
  },
  "3496": {
    "source_file": "reverse-proxy-configuration-iis.txt",
    "text": "the interwebs\nfor this part.\nThe rest of this tutorial will assume it has been configured with a\ncertificate trusted by your browser of choice.\n\nGo to the _Default Web Site_\nGo to __URL Rewrite__\nIn the _Actions_ panel click _View Server Variables..._\nAdd the following is not already define on the server level:\n.. Name: *HTTP_FORWARDED*\nClick on _Back to Rules_\n_Click on Add Rule(s)..._\nSelect _Re"
  },
  "3497": {
    "source_file": "reverse-proxy-configuration-iis.txt",
    "text": "_\nAdd the following is not already define on the server level:\n.. Name: *HTTP_FORWARDED*\nClick on _Back to Rules_\n_Click on Add Rule(s)..._\nSelect _Reverse Proxy_ and click on OK\nEnter _jenkins.acme.example_ and click on OK\nOpen the rule you just created\nUnder _Conditions_ add:\n.. Condition input: *\\{CACHE_URL}*\n.. Pattern: *^(http|ws)s://*\nUnder _Server Variables_ add:\n.. Name: *HTTP_FORWARDED*, "
  },
  "3498": {
    "source_file": "reverse-proxy-configuration-iis.txt",
    "text": "ated\nUnder _Conditions_ add:\n.. Condition input: *\\{CACHE_URL}*\n.. Pattern: *^(http|ws)s://*\nUnder _Server Variables_ add:\n.. Name: *HTTP_FORWARDED*, Value:\n*for=\\{REMOTE_ADDR};by=\\{LOCAL_ADDR};host=\"\\{HTTP_HOST}\";proto=\"https\"*,\nReplace: yes\n... Jenkins runs under Jetty, Jetty supports\nhttps://tools.ietf.org/html/rfc7239[RFC7239], so all should be well.\nUnder Action change:\n..  Rewrite URL to\n*\\{"
  },
  "3499": {
    "source_file": "reverse-proxy-configuration-iis.txt",
    "text": "kins runs under Jetty, Jetty supports\nhttps://tools.ietf.org/html/rfc7239[RFC7239], so all should be well.\nUnder Action change:\n..  Rewrite URL to\n*\\{C:1}\\://jenkins.acme.example:8080\\{UNENCODED_URL}*\n... Note that there is no slash between the port number and the opening\ncurly bracket\n.. *Remove* the check from the *Append query string* checkbox\nApply the changes.\nEdit _C:\\Windows\\System32\\driver"
  },
  "3500": {
    "source_file": "reverse-proxy-configuration-iis.txt",
    "text": "number and the opening\ncurly bracket\n.. *Remove* the check from the *Append query string* checkbox\nApply the changes.\nEdit _C:\\Windows\\System32\\drivers\\etc\\hosts_ so that\n*jenkins.acme.example* points to 127.0.0.1\n.. When resolving names Windows will check if the name is its own name\nbefore consulting the hosts file. Meaning that adding _vrtjenkins01_ or\n_vrtjenkins01.acme.example_ to the hosts fi"
  },
  "3501": {
    "source_file": "reverse-proxy-configuration-iis.txt",
    "text": " check if the name is its own name\nbefore consulting the hosts file. Meaning that adding _vrtjenkins01_ or\n_vrtjenkins01.acme.example_ to the hosts file won't have any effect.\n... The hosts file will however be consulted before consulting the DNS\ninfrastructure\n\nhttps://jenkins.acme.example/configure\nConfigure the _Jenkins URL_ to\nbe **https://jenkins.acme.example/**\nand save the change\nGo to _Sec"
  },
  "3502": {
    "source_file": "reverse-proxy-configuration-iis.txt",
    "text": "rastructure\n\nhttps://jenkins.acme.example/configure\nConfigure the _Jenkins URL_ to\nbe **https://jenkins.acme.example/**\nand save the change\nGo to _Security_ and enable\n_Enable proxy compatibility_ if you have already enabled _Prevent Cross\nSite Request Forgery exploits_\nGo to https://jenkins.acme.example/manage\nYou will still experience the \"It appears that your reverse\nproxy set up is broken.\" as"
  },
  "3503": {
    "source_file": "reverse-proxy-configuration-iis.txt",
    "text": "st Forgery exploits_\nGo to https://jenkins.acme.example/manage\nYou will still experience the \"It appears that your reverse\nproxy set up is broken.\" as expected\n.. If you do not get that at this point, then that is very weird...\nContinue anyway.\nRight click the _System_ link and choose to\ninspect the element.\n.. Make sure you are still on the Manage page as you will want\nit as your referrer\nChange "
  },
  "3504": {
    "source_file": "reverse-proxy-configuration-iis.txt",
    "text": " click the _System_ link and choose to\ninspect the element.\n.. Make sure you are still on the Manage page as you will want\nit as your referrer\nChange the value of the _href_ attribute to be\n_administrativeMonitor/hudson.diagnosis.ReverseProxySetupMonitor/test_\nOpen the link you just changed in a new tab.\n.. Keep this tab open\nObserve the \"https://jenkins.acme.example/manage\nvs http:\" error and bas"
  },
  "3505": {
    "source_file": "reverse-proxy-configuration-iis.txt",
    "text": "itor/test_\nOpen the link you just changed in a new tab.\n.. Keep this tab open\nObserve the \"https://jenkins.acme.example/manage\nvs http:\" error and bask in its glory\n.. a white page served with HTTP status code is 200 indicates\nall is well\n... If you do get that at this point, then that is very\nweird... Continue anyway.\n\nIn IIS Manager got to _Application Pools_ then edit\n_DefaultAppPool_ so that t"
  },
  "3506": {
    "source_file": "reverse-proxy-configuration-iis.txt",
    "text": "do get that at this point, then that is very\nweird... Continue anyway.\n\nIn IIS Manager got to _Application Pools_ then edit\n_DefaultAppPool_ so that the _.NET CLR version_ is *No Managed Code*\n.. You might find that this is not necessary (at far as you\ncan tell) for your setup, since IIS will only act as a TLS/SSL\noffloading reverse proxy, we don't need it.\nThen go to _Sites_ \u2192 _Default Web Site_ "
  },
  "3507": {
    "source_file": "reverse-proxy-configuration-iis.txt",
    "text": "ou\ncan tell) for your setup, since IIS will only act as a TLS/SSL\noffloading reverse proxy, we don't need it.\nThen go to _Sites_ \u2192 _Default Web Site_ \u2192 _Request\nFiltering_ and in the _Actions_ panel choose _Edit Feature Settings..._\nand turn on *Allow double escaping*\n.. This is so IIS forwards URLs like\nhttps://jenkins.acme.example/%2525 to Jenkins instead of\nshowing an IIS error page\nLast, but n"
  },
  "3508": {
    "source_file": "reverse-proxy-configuration-iis.txt",
    "text": "w double escaping*\n.. This is so IIS forwards URLs like\nhttps://jenkins.acme.example/%2525 to Jenkins instead of\nshowing an IIS error page\nLast, but not least, go to _Sites_ \u2192 _Default Web\nSite_ \u2192 __Configuration Editor__ and change the _Section_ to\n_system.webServer/rewrite/rules_\nNow you should see the URL Rewrite 2.1 property\n_useOriginalURLEncoding_ listed, if not install URL Rewrite 2.1 using"
  },
  "3509": {
    "source_file": "reverse-proxy-configuration-iis.txt",
    "text": "_system.webServer/rewrite/rules_\nNow you should see the URL Rewrite 2.1 property\n_useOriginalURLEncoding_ listed, if not install URL Rewrite 2.1 using\nthe x86 or x64 installer, not the WebPI one and resume from here after a\nreboot.\nChange _useOriginalURLEncoding_ to *False*\n.. As the URL Rewrite 2.1 announcement this will change the\nvalue of \\{UNENCODED_URL} to make it _RFC3986_ and usable for rev"
  },
  "3510": {
    "source_file": "reverse-proxy-configuration-iis.txt",
    "text": "lURLEncoding_ to *False*\n.. As the URL Rewrite 2.1 announcement this will change the\nvalue of \\{UNENCODED_URL} to make it _RFC3986_ and usable for reverse\nproxy forwarding purposes\n.. original as in pre 2.1 behaviour.\nRefresh that tab you were supposed to keep open, or recreate\nit.\n.. Again, take some time to bask in its glory\nIt should now be white, also the Manage page should no\nlonger complain!"
  },
  "3511": {
    "source_file": "reverse-proxy-configuration-iis.txt",
    "text": "ed to keep open, or recreate\nit.\n.. Again, take some time to bask in its glory\nIt should now be white, also the Manage page should no\nlonger complain!\n\nSome of the things you might want but I won't cover:\n\n* _Hypertext Strict Transport Security_ headers\n* Redirecting from non canonical URLs to the canonical URL\n(ok, sort of covered this in the web.config example)\n* The X-UA-Compatibility header so"
  },
  "3512": {
    "source_file": "reverse-proxy-configuration-iis.txt",
    "text": "ers\n* Redirecting from non canonical URLs to the canonical URL\n(ok, sort of covered this in the web.config example)\n* The X-UA-Compatibility header so that Internet Explorer 11\n(or 9, or ...) won't claim to be IE 7 for intranet sites\n* Use IIS Crypto to configure cipher suites\n* ...\n\n*web.config*\n\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<configuration>\n  <system.webServer>\n    <rewrite>\n      <rule"
  },
  "3513": {
    "source_file": "reverse-proxy-configuration-iis.txt",
    "text": " to configure cipher suites\n* ...\n\n*web.config*\n\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<configuration>\n  <system.webServer>\n    <rewrite>\n      <rules useOriginalURLEncoding=\"false\">\n        <rule name=\"CanonicalHostNameRule2\" stopProcessing=\"true\">\n          <match url=\"(.*)\" />\n          <conditions trackAllCaptures=\"true\">\n            <add input=\"{CACHE_URL}\" pattern=\"^(http|ws)://\" />\n       "
  },
  "3514": {
    "source_file": "reverse-proxy-configuration-iis.txt",
    "text": "\n          <match url=\"(.*)\" />\n          <conditions trackAllCaptures=\"true\">\n            <add input=\"{CACHE_URL}\" pattern=\"^(http|ws)://\" />\n            <add input=\"{HTTP_HOST}\"\n                 pattern=\"^jenkins$|^jenkins\\.acme\\.example$|\n                          ^vrtjenkins01$|^vrtjenkins01\\.acme\\.example$\" />\n          </conditions>\n          <action type=\"Redirect\"\n                  url=\"{C"
  },
  "3515": {
    "source_file": "reverse-proxy-configuration-iis.txt",
    "text": "                  ^vrtjenkins01$|^vrtjenkins01\\.acme\\.example$\" />\n          </conditions>\n          <action type=\"Redirect\"\n                  url=\"{C:1}s://jenkins.acme.example{UNENCODED_URL}\"\n                  appendQueryString=\"false\"\n                  redirectType=\"Permanent\" />\n        </rule>\n        <rule name=\"CanonicalHostNameRule1\" stopProcessing=\"true\">\n          <match url=\"(.*)\" />\n  "
  },
  "3516": {
    "source_file": "reverse-proxy-configuration-iis.txt",
    "text": "      redirectType=\"Permanent\" />\n        </rule>\n        <rule name=\"CanonicalHostNameRule1\" stopProcessing=\"true\">\n          <match url=\"(.*)\" />\n          <conditions trackAllCaptures=\"true\">\n            <add input=\"{CACHE_URL}\" pattern=\"^(https|wss)://\" />\n            <add input=\"{HTTP_HOST}\" pattern=\"^jenkins$|^vrtjenkins01$|\n                                              ^vrtjenkins01\\.acme\\."
  },
  "3517": {
    "source_file": "reverse-proxy-configuration-iis.txt",
    "text": "ss)://\" />\n            <add input=\"{HTTP_HOST}\" pattern=\"^jenkins$|^vrtjenkins01$|\n                                              ^vrtjenkins01\\.acme\\.example$\" />\n          </conditions>\n          <action type=\"Redirect\"\n                  url=\"{C:1}://jenkins.acme.example{UNENCODED_URL}\"\n                  appendQueryString=\"false\" redirectType=\"Permanent\" />\n        </rule>\n        <rule name=\"Rev"
  },
  "3518": {
    "source_file": "reverse-proxy-configuration-iis.txt",
    "text": "//jenkins.acme.example{UNENCODED_URL}\"\n                  appendQueryString=\"false\" redirectType=\"Permanent\" />\n        </rule>\n        <rule name=\"ReverseProxyInboundRule1\" stopProcessing=\"true\">\n          <match url=\"(.*)\" />\n          <action type=\"Rewrite\"\n                  url=\"{C:1}://jenkins.acme.example:8080{UNENCODED_URL}\"\n                  appendQueryString=\"false\" />\n          <serverVar"
  },
  "3519": {
    "source_file": "reverse-proxy-configuration-iis.txt",
    "text": "\"Rewrite\"\n                  url=\"{C:1}://jenkins.acme.example:8080{UNENCODED_URL}\"\n                  appendQueryString=\"false\" />\n          <serverVariables>\n            <set name=\"HTTP_FORWARDED\"\n                 value=\"for={REMOTE_ADDR};\n                        by={LOCAL_ADDR};\n                        host=&quot;{HTTP_HOST}&quot;;\n                        proto=&quot;https&quot;\" />\n          </s"
  },
  "3520": {
    "source_file": "reverse-proxy-configuration-iis.txt",
    "text": "              by={LOCAL_ADDR};\n                        host=&quot;{HTTP_HOST}&quot;;\n                        proto=&quot;https&quot;\" />\n          </serverVariables>\n          <conditions trackAllCaptures=\"true\">\n            <add input=\"{CACHE_URL}\" pattern=\"^(http|ws)s://\" />\n            <add input=\"{HTTP_HOST}\" pattern=\"^jenkins\\.acme\\.example$\" />\n          </conditions>\n        </rule>\n      <"
  },
  "3521": {
    "source_file": "reverse-proxy-configuration-iis.txt",
    "text": "pattern=\"^(http|ws)s://\" />\n            <add input=\"{HTTP_HOST}\" pattern=\"^jenkins\\.acme\\.example$\" />\n          </conditions>\n        </rule>\n      </rules>\n    </rewrite>\n    <security>\n      <requestFiltering allowDoubleEscaping=\"true\" />\n    </security>\n  </system.webServer>\n</configuration>"
  },
  "3522": {
    "source_file": "reverse-proxy-configuration-iis.txt",
    "text": "curity>\n  </system.webServer>\n</configuration>"
  },
  "3523": {
    "source_file": "reverse-proxy-configuration-iptables.txt",
    "text": "layout: subsection\n\n\nifndef::env-github[:imagesdir: ../../../resources/managing]\n\nThe default Jenkins installation runs on ports 8080 and 8443.\nTypically, HTTP/HTTPS servers run on ports 80 and 443, respectively.\nBut these ports are considered privileged on Unix/Linux systems,\nand the process using them must be owned by root.\nRunning Jenkins as root is not recommended - it should be run as its own"
  },
  "3524": {
    "source_file": "reverse-proxy-configuration-iptables.txt",
    "text": "eged on Unix/Linux systems,\nand the process using them must be owned by root.\nRunning Jenkins as root is not recommended - it should be run as its own user.\nOne solution is to front Jenkins with a web server such as Apache, and let\nit proxy requests to Jenkins, but this requires maintaining the Apache installation as well.\nIn situations where you are wanting to run Jenkins on port 80 or 443\n(i.e. "
  },
  "3525": {
    "source_file": "reverse-proxy-configuration-iptables.txt",
    "text": "to Jenkins, but this requires maintaining the Apache installation as well.\nIn situations where you are wanting to run Jenkins on port 80 or 443\n(i.e. HTTP/HTTPS), but you do not want to setup a proxy server you can\nuse _iptables_ on Linux to forward traffic.\n\nFollow the  to install and configure the initial Jenkins installation on a supported version of Ubuntu.\nThese instructions are known to not "
  },
  "3526": {
    "source_file": "reverse-proxy-configuration-iptables.txt",
    "text": "traffic.\n\nFollow the  to install and configure the initial Jenkins installation on a supported version of Ubuntu.\nThese instructions are known to not work on Ubuntu versions that are no longer supported by the Ubuntu project.\n\nIn order to forward traffic from 80/443 to 8080/8443, first you must\nensure that iptables has allowed traffic on all 4 of these ports.\nUse the following command to list the "
  },
  "3527": {
    "source_file": "reverse-proxy-configuration-iptables.txt",
    "text": "ffic from 80/443 to 8080/8443, first you must\nensure that iptables has allowed traffic on all 4 of these ports.\nUse the following command to list the current iptables configuration:\n\n iptables -L -n\n\nYou should see in the output entries for 80, 443, 8080, and 8443.\nHere is an example output for comparison.\n\nain INPUT (policy ACCEPT)target     prot opt source               destination\ntarget     pr"
  },
  "3528": {
    "source_file": "reverse-proxy-configuration-iptables.txt",
    "text": "8080, and 8443.\nHere is an example output for comparison.\n\nain INPUT (policy ACCEPT)target     prot opt source               destination\ntarget     prot opt source               destination\nACCEPT     tcp  --  0.0.0.0/0            0.0.0.0/0           tcp dpt:443\nACCEPT     tcp  --  0.0.0.0/0            0.0.0.0/0           tcp dpt:80\nACCEPT     tcp  --  0.0.0.0/0            0.0.0.0/0           tcp "
  },
  "3529": {
    "source_file": "reverse-proxy-configuration-iptables.txt",
    "text": " tcp dpt:443\nACCEPT     tcp  --  0.0.0.0/0            0.0.0.0/0           tcp dpt:80\nACCEPT     tcp  --  0.0.0.0/0            0.0.0.0/0           tcp dpt:8080\nACCEPT     tcp  --  0.0.0.0/0            0.0.0.0/0           tcp dpt:8443\nACCEPT     all  --  0.0.0.0/0            0.0.0.0/0           state RELATED,ESTABLISHED\nACCEPT     icmp --  0.0.0.0/0            0.0.0.0/0\nACCEPT     all  --  0.0.0.0/0"
  },
  "3530": {
    "source_file": "reverse-proxy-configuration-iptables.txt",
    "text": "-  0.0.0.0/0            0.0.0.0/0           state RELATED,ESTABLISHED\nACCEPT     icmp --  0.0.0.0/0            0.0.0.0/0\nACCEPT     all  --  0.0.0.0/0            0.0.0.0/0\nACCEPT     tcp  --  0.0.0.0/0            0.0.0.0/0           state NEW tcp dpt:22\nREJECT     all  --  0.0.0.0/0            0.0.0.0/0           reject-with icmp-host-prohibited\n\nChain FORWARD (policy ACCEPT)\ntarget     prot opt s"
  },
  "3531": {
    "source_file": "reverse-proxy-configuration-iptables.txt",
    "text": ":22\nREJECT     all  --  0.0.0.0/0            0.0.0.0/0           reject-with icmp-host-prohibited\n\nChain FORWARD (policy ACCEPT)\ntarget     prot opt source               destination\nREJECT     all  --  0.0.0.0/0            0.0.0.0/0           reject-with icmp-host-prohibited\n\nChain OUTPUT (policy ACCEPT)\ntarget     prot opt source               destination\ntarget     prot opt source\n\nIf you dont s"
  },
  "3532": {
    "source_file": "reverse-proxy-configuration-iptables.txt",
    "text": "with icmp-host-prohibited\n\nChain OUTPUT (policy ACCEPT)\ntarget     prot opt source               destination\ntarget     prot opt source\n\nIf you dont see entries for these ports, then you need to run commands\n(as root or with sudo) to add those ports.\nFor example, if you see none of these and need to add them all,\nyou would need to issue the following commands:\n\nsudo iptables -I INPUT 1 -p tcp --dp"
  },
  "3533": {
    "source_file": "reverse-proxy-configuration-iptables.txt",
    "text": "\nFor example, if you see none of these and need to add them all,\nyou would need to issue the following commands:\n\nsudo iptables -I INPUT 1 -p tcp --dport 8443 -j ACCEPT\nsudo iptables -I INPUT 1 -p tcp --dport 8080 -j ACCEPT\nsudo iptables -I INPUT 1 -p tcp --dport 443 -j ACCEPT\nsudo iptables -I INPUT 1 -p tcp --dport 80 -j ACCEPT\n\nNOTE:: I used -I INPUT 1. In a lot of iptables\ndocumentation/example"
  },
  "3534": {
    "source_file": "reverse-proxy-configuration-iptables.txt",
    "text": "p tcp --dport 443 -j ACCEPT\nsudo iptables -I INPUT 1 -p tcp --dport 80 -j ACCEPT\n\nNOTE:: I used -I INPUT 1. In a lot of iptables\ndocumentation/examples, you will see -A INPUT.\nThe difference is that -A appends to the list of rules,\nwhile -I INPUT 1 inserts before the first entry.\nUsually when adding new accept ports to iptables configuration,\nyou want to put them at the beginning of the ruleset, n"
  },
  "3535": {
    "source_file": "reverse-proxy-configuration-iptables.txt",
    "text": "nserts before the first entry.\nUsually when adding new accept ports to iptables configuration,\nyou want to put them at the beginning of the ruleset, not the end.\nRun iptables -L -n again and you should now see entries for these 4 ports.\n\nOnce traffic on the required ports are allowed, you can run the command\nto forward port 80 traffic to 8080, and port 443 traffic to 8443.\nThe commands look like t"
  },
  "3536": {
    "source_file": "reverse-proxy-configuration-iptables.txt",
    "text": " on the required ports are allowed, you can run the command\nto forward port 80 traffic to 8080, and port 443 traffic to 8443.\nThe commands look like this:\n\nsudo iptables -A PREROUTING -t nat -i eth0 -p tcp --dport 80 -j REDIRECT --to-port 8080\nsudo iptables -A PREROUTING -t nat -i eth0 -p tcp --dport 443 -j REDIRECT --to-port 8443\n\nYou can verify the forwarding rules using below command.\n\n[root@xy"
  },
  "3537": {
    "source_file": "reverse-proxy-configuration-iptables.txt",
    "text": "ptables -A PREROUTING -t nat -i eth0 -p tcp --dport 443 -j REDIRECT --to-port 8443\n\nYou can verify the forwarding rules using below command.\n\n[root@xyz~]# iptables -L -t nat\nChain PREROUTING (policy ACCEPT)\ntarget     prot opt source               destination\nREDIRECT   tcp  --  anywhere             anywhere             tcp dpt:http redir ports 8080\nREDIRECT   tcp  --  anywhere             anywher"
  },
  "3538": {
    "source_file": "reverse-proxy-configuration-iptables.txt",
    "text": "stination\nREDIRECT   tcp  --  anywhere             anywhere             tcp dpt:http redir ports 8080\nREDIRECT   tcp  --  anywhere             anywhere             tcp dpt:https redir ports 8443\n\nChain INPUT (policy ACCEPT)\ntarget     prot opt source               destination\n\nChain OUTPUT (policy ACCEPT)\ntarget     prot opt source               destination\n\nChain POSTROUTING (policy ACCEPT)\ntarge"
  },
  "3539": {
    "source_file": "reverse-proxy-configuration-iptables.txt",
    "text": "               destination\n\nChain OUTPUT (policy ACCEPT)\ntarget     prot opt source               destination\n\nChain POSTROUTING (policy ACCEPT)\ntarget     prot opt source               destination\n\nOnce these rules are set and confirmed with iptables -L -n, and once\nyour Jenkins controller is up and running on port 8080, attempt to access\nyour Jenkins controller on port 80 instead of 8080.\nIt sho"
  },
  "3540": {
    "source_file": "reverse-proxy-configuration-iptables.txt",
    "text": "s -L -n, and once\nyour Jenkins controller is up and running on port 8080, attempt to access\nyour Jenkins controller on port 80 instead of 8080.\nIt should work and your URL should stay on port 80 - in other words,\nit should not get redirected to 8080.\nThe fact that forwarding from 80 to 8080 (or 443 to 8443) should remain\nhidden from the client.\n\nUsing the iptables command to change port configurat"
  },
  "3541": {
    "source_file": "reverse-proxy-configuration-iptables.txt",
    "text": "\nThe fact that forwarding from 80 to 8080 (or 443 to 8443) should remain\nhidden from the client.\n\nUsing the iptables command to change port configuration and routing\nrules only changes the current, in-memory configuration.\nIt does not persist between restarts of the iptables service.\nSo, you need to make sure you save the configuration to make the changes permanent.\n\nSaving the configuration is sl"
  },
  "3542": {
    "source_file": "reverse-proxy-configuration-iptables.txt",
    "text": " restarts of the iptables service.\nSo, you need to make sure you save the configuration to make the changes permanent.\n\nSaving the configuration is slightly different between Red Hat rpm based and\nDebian-based systems.\nOn Red Hat-based systems (Red Hat Enterprise Linux, Fedora, Alma Linux, Rocky Linux, Oracle Linux, CentOS, etc), issue the following command:\n\nsudo iptables-save > /etc/sysconfig/ip"
  },
  "3543": {
    "source_file": "reverse-proxy-configuration-iptables.txt",
    "text": "at Enterprise Linux, Fedora, Alma Linux, Rocky Linux, Oracle Linux, CentOS, etc), issue the following command:\n\nsudo iptables-save > /etc/sysconfig/iptables\n\nOn a Debian-based system (Debian, Ubuntu, Mint, etc), issue the\nfollowing command:\n\nsudo sh -c \"iptables-save > /etc/iptables.rules\"\n\nThe iptables-restore command will need to be executed manually, or your\nsystem configured to automatically r"
  },
  "3544": {
    "source_file": "reverse-proxy-configuration-iptables.txt",
    "text": "-c \"iptables-save > /etc/iptables.rules\"\n\nThe iptables-restore command will need to be executed manually, or your\nsystem configured to automatically run it on boot, against the\n/etc/iptables.rules file you have created, in order for your iptables\nconfiguration to be retained across reboots.\nOn Ubuntu, the fastest way is to install `iptables-persistent` after configuring iptables.\nIt will automatic"
  },
  "3545": {
    "source_file": "reverse-proxy-configuration-iptables.txt",
    "text": "figuration to be retained across reboots.\nOn Ubuntu, the fastest way is to install `iptables-persistent` after configuring iptables.\nIt will automatically create the required files from the current configuration and load them on boot.\n\nsudo apt-get install iptables-persistent\n\nSee https://help.ubuntu.com/community/IptablesHowTo for other Ubuntu\noptions.\nThere are many other resources describing th"
  },
  "3546": {
    "source_file": "reverse-proxy-configuration-iptables.txt",
    "text": "nstall iptables-persistent\n\nSee https://help.ubuntu.com/community/IptablesHowTo for other Ubuntu\noptions.\nThere are many other resources describing this; please consult\nyour system's documentation or search on the internet for information\nspecific to your flavor of Linux.\n\nIf you are unsure at all about what kind of system you have, consult\nthat system's documentation on how to update iptables con"
  },
  "3547": {
    "source_file": "reverse-proxy-configuration-iptables.txt",
    "text": " your flavor of Linux.\n\nIf you are unsure at all about what kind of system you have, consult\nthat system's documentation on how to update iptables configuration.\n\nSome Linux distributions (Red Hat Enterprise Linux, Rocky Linux, Alma Linux, Oracle Linux, CentOS, etc.)\nship with firewalld which serves as a front-end for iptables.\nConfiguration thru firewalld is done via the *firewall-cmd* command.\nI"
  },
  "3548": {
    "source_file": "reverse-proxy-configuration-iptables.txt",
    "text": "ux, CentOS, etc.)\nship with firewalld which serves as a front-end for iptables.\nConfiguration thru firewalld is done via the *firewall-cmd* command.\nInstead of using any of the iptables commands mentioned above,\nall you should need to do is something like:\n\n# allow incoming connections on port 80.\n# You can also use --add-service=http instead of adding a port number\nsudo firewall-cmd --add-port=80"
  },
  "3549": {
    "source_file": "reverse-proxy-configuration-iptables.txt",
    "text": " like:\n\n# allow incoming connections on port 80.\n# You can also use --add-service=http instead of adding a port number\nsudo firewall-cmd --add-port=80/tcp --permanent\nsudo firewall-cmd --permanent \\\n                  --add-forward-port=port=80:proto=tcp:toaddr=127.0.0.1:toport=8080\n\n# allow incoming connections on port 443.\n# You can also use --add-service=https instead of adding a port number\nsud"
  },
  "3550": {
    "source_file": "reverse-proxy-configuration-iptables.txt",
    "text": "tcp:toaddr=127.0.0.1:toport=8080\n\n# allow incoming connections on port 443.\n# You can also use --add-service=https instead of adding a port number\nsudo firewall-cmd --add-port=443/tcp --permanen\nt\nsudo firewall-cmd --permanent \\\n                  --add-forward-port=port=443:proto=tcp:toaddr=127.0.0.1:toport=8443\nsudo firewall-cmd --reload\n\nWith the above commands, jenkins can be configured to run "
  },
  "3551": {
    "source_file": "reverse-proxy-configuration-iptables.txt",
    "text": "dd-forward-port=port=443:proto=tcp:toaddr=127.0.0.1:toport=8443\nsudo firewall-cmd --reload\n\nWith the above commands, jenkins can be configured to run on\nlocalhost:8080 and/or localhost:8443 (depending if you need or want to\ndo SSL or not)\n\nfirewalld will then create the required iptables rules so that incoming\nconnections on port 80 are forwarded to jenkins on 8080 (and 443 is\nforwarded to 8443)."
  },
  "3552": {
    "source_file": "reverse-proxy-configuration-iptables.txt",
    "text": "will then create the required iptables rules so that incoming\nconnections on port 80 are forwarded to jenkins on 8080 (and 443 is\nforwarded to 8443)."
  },
  "3553": {
    "source_file": "reverse-proxy-configuration-lighttpd.txt",
    "text": "layout: subsection\n\n\nifndef::env-github[:imagesdir: ../../../resources/managing]\n\n[[running-jenkins-behind-lighttpd]]\n\nIn situations where you have existing web sites on your server, you may find it useful to run Jenkins (or the servlet container that Jenkins runs in) behind https://www.lighttpd.net/[Lighttpd].\nThis allows you to bind Jenkins to the part of a bigger website that you may have or ce"
  },
  "3554": {
    "source_file": "reverse-proxy-configuration-lighttpd.txt",
    "text": "t Jenkins runs in) behind https://www.lighttpd.net/[Lighttpd].\nThis allows you to bind Jenkins to the part of a bigger website that you may have or centralize the TLS termination in a single place.\nThis section discusses some of the approaches for doing this.\n\nThe  works\nby making Lighttpd perform as a \"reverse proxy\".\nThis means when a request arrives for certain URLs, Lighttpd becomes a proxy an"
  },
  "3555": {
    "source_file": "reverse-proxy-configuration-lighttpd.txt",
    "text": "ing this.\n\nThe  works\nby making Lighttpd perform as a \"reverse proxy\".\nThis means when a request arrives for certain URLs, Lighttpd becomes a proxy and forwards that request to Jenkins, then forwards the response from Jenkins back to the client.\n\nThere are two alternatives to configure Jenkins with Lighttpd.\nSelect the technique that best meets your needs:\n\n* <<By host>>\n* <<By path>>\n\nBy , Lightt"
  },
  "3556": {
    "source_file": "reverse-proxy-configuration-lighttpd.txt",
    "text": "re are two alternatives to configure Jenkins with Lighttpd.\nSelect the technique that best meets your needs:\n\n* <<By host>>\n* <<By path>>\n\nBy , Lighttpd will force the URL normalization, thus mismatching the headers used by an internal Jenkins reverse\nproxy test.\nThis results in showing the message *It appears that your reverse proxy setup is broken* on the manage page.\nTo avoid this, explicit dis"
  },
  "3557": {
    "source_file": "reverse-proxy-configuration-lighttpd.txt",
    "text": "e\nproxy test.\nThis results in showing the message *It appears that your reverse proxy setup is broken* on the manage page.\nTo avoid this, explicit disable the option `url-path-2f-decode`.\n\nIn the configuration below there is no context path for Jenkins URL.\n\nWhen a request for the domain `jenkins.example.com` arrives, Lighttpd proxies this request to Jenkins.\n\nserver.http-parseopts = (\n  \"url-path"
  },
  "3558": {
    "source_file": "reverse-proxy-configuration-lighttpd.txt",
    "text": "ns URL.\n\nWhen a request for the domain `jenkins.example.com` arrives, Lighttpd proxies this request to Jenkins.\n\nserver.http-parseopts = (\n  \"url-path-2f-decode\" => \"disable\"\n)\n\nserver.modules += ( \"mod_proxy\" )\n\n$HTTP[\"host\"] == \"jenkins.example.com\" {\n  proxy.balance = \"hash\"\n  proxy.server = (\n    \"\" => (\n      \"jenkins\" => (\n        \"host\" => \"127.0.0.1\",\n        \"port\" => \"8080\"\n      )\n    )"
  },
  "3559": {
    "source_file": "reverse-proxy-configuration-lighttpd.txt",
    "text": "\" {\n  proxy.balance = \"hash\"\n  proxy.server = (\n    \"\" => (\n      \"jenkins\" => (\n        \"host\" => \"127.0.0.1\",\n        \"port\" => \"8080\"\n      )\n    )\n  )\n}\n\nThis assumes that you run Jenkins on port 8080.\n\nIn the configuration below there is a specific path `/jenkins` for Jenkins.\nThis path should be configured in Lighttpd with `$HTTP[\"url\"]`.\nIn Jenkins, set the context path by modifying the jen"
  },
  "3560": {
    "source_file": "reverse-proxy-configuration-lighttpd.txt",
    "text": "fic path `/jenkins` for Jenkins.\nThis path should be configured in Lighttpd with `$HTTP[\"url\"]`.\nIn Jenkins, set the context path by modifying the jenkins.xml configuration file and adding  `--prefix=/jenkins` (or similar) to the <arguments> entry.\n\nWhen a request is made to, for example `http://localhost/jenkins`, Lighttpd proxies this\nrequest to Jenkins.\n\nserver.http-parseopts = (\n  \"url-path-2f"
  },
  "3561": {
    "source_file": "reverse-proxy-configuration-lighttpd.txt",
    "text": "When a request is made to, for example `http://localhost/jenkins`, Lighttpd proxies this\nrequest to Jenkins.\n\nserver.http-parseopts = (\n  \"url-path-2f-decode\" => \"disable\"\n)\n\nserver.modules += ( \"mod_proxy\" )\n\n$HTTP[\"url\"] =~ \"^/jenkins(.*)$\" {\n  proxy.balance = \"hash\"\n  proxy.server = (\n    \"\" => (\n      \"jenkins\" => (\n        \"host\" => \"127.0.0.1\",\n        \"port\" => 8080\n      )\n    )\n  )\n}\n\nThi"
  },
  "3562": {
    "source_file": "reverse-proxy-configuration-lighttpd.txt",
    "text": "xy.balance = \"hash\"\n  proxy.server = (\n    \"\" => (\n      \"jenkins\" => (\n        \"host\" => \"127.0.0.1\",\n        \"port\" => 8080\n      )\n    )\n  )\n}\n\nThis assumes that you run Jenkins on port 8080."
  },
  "3563": {
    "source_file": "reverse-proxy-configuration-nginx.txt",
    "text": "layout: subsection\n\n\nifndef::env-github[:imagesdir: ../../../resources/managing]\n\nIn situations where you have existing web sites on your server, you may\nfind it useful to run Jenkins (or the servlet container that Jenkins\nruns in) behind https://nginx.org/[Nginx], so that you can bind Jenkins\nto the part of a bigger website that you may have.\nThis section discusses some of the approaches for doin"
  },
  "3564": {
    "source_file": "reverse-proxy-configuration-nginx.txt",
    "text": "nx.org/[Nginx], so that you can bind Jenkins\nto the part of a bigger website that you may have.\nThis section discusses some of the approaches for doing this.\n\nWhen a request arrives for certain URLs, Nginx becomes a proxy and forwards that request to Jenkins, then it forwards the response back to the client.\n\nThis 9 minute video tutorial from Darin Pope configures Nginx as a reverse proxy.\n\n.Confi"
  },
  "3565": {
    "source_file": "reverse-proxy-configuration-nginx.txt",
    "text": " Jenkins, then it forwards the response back to the client.\n\nThis 9 minute video tutorial from Darin Pope configures Nginx as a reverse proxy.\n\n.Configuring Nginx as a reverse proxy\nvideo::yixMeJGtLFk[youtube, width=640, height=360]\n\nThe Nginx configuration fragment below provides an example Nginx reverse proxy configuration.\nIt assumes the Jenkins controller and the Nginx reverse proxy are runnin"
  },
  "3566": {
    "source_file": "reverse-proxy-configuration-nginx.txt",
    "text": "uration fragment below provides an example Nginx reverse proxy configuration.\nIt assumes the Jenkins controller and the Nginx reverse proxy are running on the same computer.\n\nupstream jenkins {\n  keepalive 32; # keepalive connections\n  server 127.0.0.1:8080; # jenkins ip and port\n}\n\n# Required for Jenkins websocket agents\nmap $http_upgrade $connection_upgrade {\n  default upgrade;\n  '' close;\n}\n\nse"
  },
  "3567": {
    "source_file": "reverse-proxy-configuration-nginx.txt",
    "text": ".1:8080; # jenkins ip and port\n}\n\n# Required for Jenkins websocket agents\nmap $http_upgrade $connection_upgrade {\n  default upgrade;\n  '' close;\n}\n\nserver {\n  listen          80;       # Listen on port 80 for IPv4 requests\n\n  server_name     jenkins.example.com;  # replace 'jenkins.example.com' with your server domain name\n\n  # this is the jenkins web root directory\n  # (mentioned in the output of"
  },
  "3568": {
    "source_file": "reverse-proxy-configuration-nginx.txt",
    "text": "example.com;  # replace 'jenkins.example.com' with your server domain name\n\n  # this is the jenkins web root directory\n  # (mentioned in the output of \"systemctl cat jenkins\")\n  root            /var/run/jenkins/war/;\n\n  access_log      /var/log/nginx/jenkins.access.log;\n  error_log       /var/log/nginx/jenkins.error.log;\n\n  # pass through headers from Jenkins that Nginx considers invalid\n  ignore_"
  },
  "3569": {
    "source_file": "reverse-proxy-configuration-nginx.txt",
    "text": "/jenkins.access.log;\n  error_log       /var/log/nginx/jenkins.error.log;\n\n  # pass through headers from Jenkins that Nginx considers invalid\n  ignore_invalid_headers off;\n\n  location ~ \"^\\/static\\/[0-9a-fA-F]{8}\\/(.*)$\" {\n    # rewrite all static files into requests to the root\n    # E.g /static/12345678/css/something.css will become /css/something.css\n    rewrite \"^\\/static\\/[0-9a-fA-F]{8}\\/(.*)\""
  },
  "3570": {
    "source_file": "reverse-proxy-configuration-nginx.txt",
    "text": "es into requests to the root\n    # E.g /static/12345678/css/something.css will become /css/something.css\n    rewrite \"^\\/static\\/[0-9a-fA-F]{8}\\/(.*)\" /$1 last;\n  }\n\n  location /userContent {\n    # have nginx handle all the static requests to userContent folder\n    # note : This is the $JENKINS_HOME dir\n    root /var/lib/jenkins/;\n    if (!-f $request_filename){\n      # this file does not exist, m"
  },
  "3571": {
    "source_file": "reverse-proxy-configuration-nginx.txt",
    "text": "tent folder\n    # note : This is the $JENKINS_HOME dir\n    root /var/lib/jenkins/;\n    if (!-f $request_filename){\n      # this file does not exist, might be a directory or a /**view** url\n      rewrite (.*) /$1 last;\n      break;\n    }\n    sendfile on;\n  }\n\n  location / {\n      sendfile off;\n      proxy_pass         http://jenkins;\n      proxy_redirect     default;\n      proxy_http_version 1.1;\n\n"
  },
  "3572": {
    "source_file": "reverse-proxy-configuration-nginx.txt",
    "text": "on;\n  }\n\n  location / {\n      sendfile off;\n      proxy_pass         http://jenkins;\n      proxy_redirect     default;\n      proxy_http_version 1.1;\n\n      # Required for Jenkins websocket agents\n      proxy_set_header   Connection        $connection_upgrade;\n      proxy_set_header   Upgrade           $http_upgrade;\n\n      proxy_set_header   Host              $http_host;\n      proxy_set_header   X"
  },
  "3573": {
    "source_file": "reverse-proxy-configuration-nginx.txt",
    "text": "_upgrade;\n      proxy_set_header   Upgrade           $http_upgrade;\n\n      proxy_set_header   Host              $http_host;\n      proxy_set_header   X-Real-IP         $remote_addr;\n      proxy_set_header   X-Forwarded-For   $proxy_add_x_forwarded_for;\n      proxy_set_header   X-Forwarded-Proto $scheme;\n      proxy_max_temp_file_size 0;\n\n      #this is the maximum upload size\n      client_max_body_"
  },
  "3574": {
    "source_file": "reverse-proxy-configuration-nginx.txt",
    "text": ";\n      proxy_set_header   X-Forwarded-Proto $scheme;\n      proxy_max_temp_file_size 0;\n\n      #this is the maximum upload size\n      client_max_body_size       10m;\n      client_body_buffer_size    128k;\n\n      proxy_connect_timeout      90;\n      proxy_send_timeout         90;\n      proxy_read_timeout         90;\n      proxy_request_buffering    off; # Required for HTTP CLI commands\n  }\n\n}\n\nThis"
  },
  "3575": {
    "source_file": "reverse-proxy-configuration-nginx.txt",
    "text": "roxy_send_timeout         90;\n      proxy_read_timeout         90;\n      proxy_request_buffering    off; # Required for HTTP CLI commands\n  }\n\n}\n\nThis assumes that you run Jenkins on port 8080.\nRemember to create the folder /var/log/nginx/jenkins.\n\nMake sure you do not end the `proxy_pass` value with a slash, as it will cause problems like those described in .\n\nIf you are having problems with some"
  },
  "3576": {
    "source_file": "reverse-proxy-configuration-nginx.txt",
    "text": "ake sure you do not end the `proxy_pass` value with a slash, as it will cause problems like those described in .\n\nIf you are having problems with some paths (eg folders) with *Blue\nOcean*, you may need to add the following snippet to your proxy\nconfiguration:\n\nif ($request_uri ~* \"/blue(/.*)\") {\n    proxy_pass http://YOUR_SERVER_IP:YOUR_JENKINS_PORT/blue$1;\n    break;\n}\n\nTo give Nginx permission t"
  },
  "3577": {
    "source_file": "reverse-proxy-configuration-nginx.txt",
    "text": "guration:\n\nif ($request_uri ~* \"/blue(/.*)\") {\n    proxy_pass http://YOUR_SERVER_IP:YOUR_JENKINS_PORT/blue$1;\n    break;\n}\n\nTo give Nginx permission to read Jenkins web root folder, add the `nginx` user to\nthe Jenkins group:\n\nusermod -aG jenkins nginx\n\nIf the last command failed because the `nginx` user is not defined in the system,\nthen you can try adding the `www-data` user to the Jenkins group:"
  },
  "3578": {
    "source_file": "reverse-proxy-configuration-nginx.txt",
    "text": "x\n\nIf the last command failed because the `nginx` user is not defined in the system,\nthen you can try adding the `www-data` user to the Jenkins group:\n\nusermod -aG jenkins www-data\n\nIf you are experiencing timeouts when attempting to run long CLI\ncommands through a proxy in Jenkins, you can increase the\n`+proxy_read_timeout+` setting as necessary.\nOlder versions of Jenkins may not respect the `+pr"
  },
  "3579": {
    "source_file": "reverse-proxy-configuration-nginx.txt",
    "text": "mands through a proxy in Jenkins, you can increase the\n`+proxy_read_timeout+` setting as necessary.\nOlder versions of Jenkins may not respect the `+proxy_read_timeout+` setting.\n\nIf you are experiencing the following error when attempting to run long\nCLI commands in Jenkins and Jenkins is running behind Nginx, it\nis probably due to Nginx timing out the CLI connection.\nYou can increase the `+proxy_"
  },
  "3580": {
    "source_file": "reverse-proxy-configuration-nginx.txt",
    "text": "\nCLI commands in Jenkins and Jenkins is running behind Nginx, it\nis probably due to Nginx timing out the CLI connection.\nYou can increase the `+proxy_read_timeout+` setting as necessary so the command will\ncomplete successfully.\n\nWARNING: null\nhudson.cli.DiagnosedStreamCorruptionException\nRead back: 0x00 0x00 0x00 0x1e 0x07\n           'Started reverse-proxy-test #68'\n           0x00 0x00 0x00 0x01"
  },
  "3581": {
    "source_file": "reverse-proxy-configuration-nginx.txt",
    "text": ".cli.DiagnosedStreamCorruptionException\nRead back: 0x00 0x00 0x00 0x1e 0x07\n           'Started reverse-proxy-test #68'\n           0x00 0x00 0x00 0x01 0x07 0x0a\nRead ahead:\nDiagnosis problem:\n    java.io.IOException: Premature EOF\n        at sun.net.www.http.ChunkedInputStream.readAheadBlocking(ChunkedInputStream.java:565)\n        ...\n    at hudson.cli.FlightRecorderInputStream.analyzeCrash(Flight"
  },
  "3582": {
    "source_file": "reverse-proxy-configuration-nginx.txt",
    "text": "www.http.ChunkedInputStream.readAheadBlocking(ChunkedInputStream.java:565)\n        ...\n    at hudson.cli.FlightRecorderInputStream.analyzeCrash(FlightRecorderInputStream.java:82)\n    at hudson.cli.PlainCLIProtocol$EitherSide$Reader.run(PlainCLIProtocol.java:153)\nCaused by: java.io.IOException: Premature EOF\n    at sun.net.www.http.ChunkedInputStream.readAheadBlocking(ChunkedInputStream.java:565)\n "
  },
  "3583": {
    "source_file": "reverse-proxy-configuration-nginx.txt",
    "text": "ol.java:153)\nCaused by: java.io.IOException: Premature EOF\n    at sun.net.www.http.ChunkedInputStream.readAheadBlocking(ChunkedInputStream.java:565)\n    ...\n    at java.io.DataInputStream.readInt(DataInputStream.java:387)\n    at hudson.cli.PlainCLIProtocol$EitherSide$Reader.run(PlainCLIProtocol.java:111)"
  },
  "3584": {
    "source_file": "reverse-proxy-configuration-nginx.txt",
    "text": "otocol$EitherSide$Reader.run(PlainCLIProtocol.java:111)"
  },
  "3585": {
    "source_file": "reverse-proxy-configuration-pomerium.txt",
    "text": "layout: subsection\n\n\nifndef::env-github[:imagesdir: ../../../resources/managing]\n\nYou can secure your Jenkins application with JWT authentication and custom claims behind , an open source reverse proxy.\n\nYou can set up role-based permissions in Jenkins to control a user\u2019s privileges with Jenkins\u2019 built-in authorization matrix.\nHowever, this method requires a username and password to sign in and re"
  },
  "3586": {
    "source_file": "reverse-proxy-configuration-pomerium.txt",
    "text": "ns to control a user\u2019s privileges with Jenkins\u2019 built-in authorization matrix.\nHowever, this method requires a username and password to sign in and relies on Jenkins\u2019 user database to store credentials.\n\nJWT authentication is a more secure method of identity verification that authenticates and authorizes users against an identity provider, eliminating the need to store or share credentials to acce"
  },
  "3587": {
    "source_file": "reverse-proxy-configuration-pomerium.txt",
    "text": "identity verification that authenticates and authorizes users against an identity provider, eliminating the need to store or share credentials to access your Jenkins application.\n\nHowever, Jenkins doesn\u2019t support JWT authentication out of the box.\nWith Pomerium, you can implement JWT authentication and apply claims to your route\u2019s authorization policy to determine a user\u2019s role and privileges befo"
  },
  "3588": {
    "source_file": "reverse-proxy-configuration-pomerium.txt",
    "text": "th Pomerium, you can implement JWT authentication and apply claims to your route\u2019s authorization policy to determine a user\u2019s role and privileges before granting a user access to Jenkins.\n\nOnce you\u2019ve configured JWT authentication, you can assign permissions within Jenkins for a specific user, any authenticated user, anonymous users, or a user group.\n\nNote: This guide assumes v0.21 of Pomerium! Pl"
  },
  "3589": {
    "source_file": "reverse-proxy-configuration-pomerium.txt",
    "text": "missions within Jenkins for a specific user, any authenticated user, anonymous users, or a user group.\n\nNote: This guide assumes v0.21 of Pomerium! Please refer to Pomerium's  for the latest version of this guide.\n\nTo complete this guide, you need:\n\n1.  and\n2. An  (IdP)\n\nIf you haven\u2019t, complete the  to familiarize yourself with running Pomerium in a container environment. It is free and should ta"
  },
  "3590": {
    "source_file": "reverse-proxy-configuration-pomerium.txt",
    "text": "1.  and\n2. An  (IdP)\n\nIf you haven\u2019t, complete the  to familiarize yourself with running Pomerium in a container environment. It is free and should take no more than five minutes to get Pomerium open source proxy running.\n\nCreate a project and add a file called `docker-compose.yaml`.\n\nIn the `docker-compose.yaml` file, add the following code:\n\n```yaml title=docker-compose.yaml\njenkins:\n  networks:"
  },
  "3591": {
    "source_file": "reverse-proxy-configuration-pomerium.txt",
    "text": "file called `docker-compose.yaml`.\n\nIn the `docker-compose.yaml` file, add the following code:\n\n```yaml title=docker-compose.yaml\njenkins:\n  networks:\n    main: {}\n  image: jenkins/jenkins:lts-jdk21\n  privileged: true\n  user: root\n  ports:\n    - 8080:8080\n    - 50000:50000\n\n  volumes:\n    # File path to Jenkins_home -- stores configs, build logs, and artifacts\n    - ./home/jenkins_compose/jenkins_"
  },
  "3592": {
    "source_file": "reverse-proxy-configuration-pomerium.txt",
    "text": ":8080\n    - 50000:50000\n\n  volumes:\n    # File path to Jenkins_home -- stores configs, build logs, and artifacts\n    - ./home/jenkins_compose/jenkins_configuration:/var/jenkins_home\n    # \"sock\" is the Unix socket the Docker daemon listens on by default\n    - ./var/run/docker.sock:/var/run/docker.sock\n```\n\nNow, run `docker compose up`.\n\nIf your Jenkins container is set up correctly, the Setup Wiza"
  },
  "3593": {
    "source_file": "reverse-proxy-configuration-pomerium.txt",
    "text": "ult\n    - ./var/run/docker.sock:/var/run/docker.sock\n```\n\nNow, run `docker compose up`.\n\nIf your Jenkins container is set up correctly, the Setup Wizard guides you through several prompts before you can access your dashboard.\n\nTo set up your Jenkins controller:\n\n1. Go to `localhost:8080` and enter the admin user password to continue. You can find the admin user password in your Docker logs or in `"
  },
  "3594": {
    "source_file": "reverse-proxy-configuration-pomerium.txt",
    "text": "controller:\n\n1. Go to `localhost:8080` and enter the admin user password to continue. You can find the admin user password in your Docker logs or in `/var/jenkins_home/secrets/initialAdminPassword`.\n\n2. Install the suggested plugins\n\n3. Create an admin user. You can create your first admin user or select **Skip and continue as admin**. If you skip and continue as admin, the default username is **a"
  },
  "3595": {
    "source_file": "reverse-proxy-configuration-pomerium.txt",
    "text": "in user. You can create your first admin user or select **Skip and continue as admin**. If you skip and continue as admin, the default username is **admin** and the password is the admin user password.\n\n4. In the **Instance Configuration** window, accept the default hostname\n\nAfter completing the Setup Wizard prompts, you can access the Jenkins dashboard.\n\nNow, run `docker compose stop` so you can"
  },
  "3596": {
    "source_file": "reverse-proxy-configuration-pomerium.txt",
    "text": "cept the default hostname\n\nAfter completing the Setup Wizard prompts, you can access the Jenkins dashboard.\n\nNow, run `docker compose stop` so you can configure Pomerium.\n\nIn your project\u2019s root folder, create a `config.yaml` file.\n\nIn your `config.yaml` file, add the following code:\n\n```yaml title=config.yaml\nauthenticate_service_url: https://authenticate.localhost.pomerium.io\n\nidp_provider: REPL"
  },
  "3597": {
    "source_file": "reverse-proxy-configuration-pomerium.txt",
    "text": "aml` file, add the following code:\n\n```yaml title=config.yaml\nauthenticate_service_url: https://authenticate.localhost.pomerium.io\n\nidp_provider: REPLACE_ME\nidp_provider_url: REPLACE_ME\nidp_client_id: REPLACE_ME\nidp_client_secret: REPLACE_ME\n\nsigning_key: REPLACE_ME\n\nroutes:\n - from: https://verify.localhost.pomerium.io\n   to: http://verify:8000\n   pass_identity_headers: true\n   policy:\n     - all"
  },
  "3598": {
    "source_file": "reverse-proxy-configuration-pomerium.txt",
    "text": "_key: REPLACE_ME\n\nroutes:\n - from: https://verify.localhost.pomerium.io\n   to: http://verify:8000\n   pass_identity_headers: true\n   policy:\n     - allow:\n         and:\n\temail:\n\t      is: user@example.com\n - from: https://jenkins.localhost.pomerium.io\n   to: http://jenkins:8080/\n   host_rewrite_header: true\n   pass_identity_headers: true\n   policy:\n     - allow:\n         and:\n           - domain:\n "
  },
  "3599": {
    "source_file": "reverse-proxy-configuration-pomerium.txt",
    "text": "\n   to: http://jenkins:8080/\n   host_rewrite_header: true\n   pass_identity_headers: true\n   policy:\n     - allow:\n         and:\n           - domain:\n               is: example.com\n           - user:\n               is: username\n```\n\nNext, you need to:\n\n- Update the  configuration variables with your own\n- Replace `user@example.com` with the email associated with your IdP\n- Replace `example.com` wit"
  },
  "3600": {
    "source_file": "reverse-proxy-configuration-pomerium.txt",
    "text": "\n\n- Update the  configuration variables with your own\n- Replace `user@example.com` with the email associated with your IdP\n- Replace `example.com` with your organization\u2019s domain name\n- Replace `username` with the username associated with your IdP\n- Generate a signing key\n\nTo generate a , use the commands below:\n\n```bash\n# Generates a P-256 (ES256) signing key\nopenssl ecparam  -genkey  -name prime"
  },
  "3601": {
    "source_file": "reverse-proxy-configuration-pomerium.txt",
    "text": "Generate a signing key\n\nTo generate a , use the commands below:\n\n```bash\n# Generates a P-256 (ES256) signing key\nopenssl ecparam  -genkey  -name prime256v1  -noout  -out ec_private.pem\n# Prints the base64 encoded value of the signing key\ncat ec_private.pem | base64\n```\n\nAdd the base64-encoded signing key to the `signing_key` variable in your `config.yaml` file.\n\nIn your `docker-compose.yaml` file,"
  },
  "3602": {
    "source_file": "reverse-proxy-configuration-pomerium.txt",
    "text": "te.pem | base64\n```\n\nAdd the base64-encoded signing key to the `signing_key` variable in your `config.yaml` file.\n\nIn your `docker-compose.yaml` file, replace the code in the file with the Pomerium and Jenkins services below:\n\n```\nversion: '3'\nnetworks:\n main: {}\nservices:\n pomerium:\n   image: pomerium/pomerium:latest\n   volumes:\n     - ./config.yaml:/pomerium/config.yaml:ro\n   ports:\n     - 443:4"
  },
  "3603": {
    "source_file": "reverse-proxy-configuration-pomerium.txt",
    "text": "ks:\n main: {}\nservices:\n pomerium:\n   image: pomerium/pomerium:latest\n   volumes:\n     - ./config.yaml:/pomerium/config.yaml:ro\n   ports:\n     - 443:443\n   networks:\n     main:\n       aliases:\n       - authenticate.localhost.pomerium.io\n verify:\n   networks:\n     main: {}\n   image: pomerium/verify:latest\n   expose:\n     - 8000\n jenkins:\n   networks:\n     main: {}\n   image: jenkins/jenkins:lts-jdk2"
  },
  "3604": {
    "source_file": "reverse-proxy-configuration-pomerium.txt",
    "text": "etworks:\n     main: {}\n   image: pomerium/verify:latest\n   expose:\n     - 8000\n jenkins:\n   networks:\n     main: {}\n   image: jenkins/jenkins:lts-jdk21\n   privileged: true\n   user: root\n   ports:\n     - 8080:8080\n     - 50000:50000\n   volumes:\n     # File path to Jenkins_home -- stores configs, build logs, and artifacts\n     - ./home/jenkins_compose/jenkins_configuration:/var/jenkins_home\n     # \""
  },
  "3605": {
    "source_file": "reverse-proxy-configuration-pomerium.txt",
    "text": " File path to Jenkins_home -- stores configs, build logs, and artifacts\n     - ./home/jenkins_compose/jenkins_configuration:/var/jenkins_home\n     # \"sock\" is the Unix socket the Docker daemon listens on by default\n     - ./var/run/docker.sock:/var/run/docker.sock\n```\n\nRun `docker compose up` and navigate to the external Jenkins route at `https://jenkins.localhost.pomerium.io`.\n\nJenkins will promp"
  },
  "3606": {
    "source_file": "reverse-proxy-configuration-pomerium.txt",
    "text": "un/docker.sock\n```\n\nRun `docker compose up` and navigate to the external Jenkins route at `https://jenkins.localhost.pomerium.io`.\n\nJenkins will prompt you to sign in with your username and password. Sign in to continue to the Jenkins dashboard.\n\nNext, you need to add plugins to enable JWT authentication and bypass TLS validation.\n\nInstall the :\n\n1. Select **Manage Jenkins**\n2. Under **System Conf"
  },
  "3607": {
    "source_file": "reverse-proxy-configuration-pomerium.txt",
    "text": "t, you need to add plugins to enable JWT authentication and bypass TLS validation.\n\nInstall the :\n\n1. Select **Manage Jenkins**\n2. Under **System Configuration**, select **Manage Plugins**\n3. Select **Available Plugins**\n4. In the search bar, enter **JWT Auth**\n5. Select the JWT Auth plugin and **Install without restart**\n\nInstall the :\n\n1. Select **Available Plugins**\n2. In the search bar, enter "
  },
  "3608": {
    "source_file": "reverse-proxy-configuration-pomerium.txt",
    "text": "*JWT Auth**\n5. Select the JWT Auth plugin and **Install without restart**\n\nInstall the :\n\n1. Select **Available Plugins**\n2. In the search bar, enter **skip-certificate-check**\n3. Select the skip-certificate-check plugin and **Install without restart**\n\nOnce you\u2019ve installed both plugins, **stop your containers**.\n\nGo to your external Jenkins route.\n\nTo configure JWT authentication:\n\n1. Go to **Ma"
  },
  "3609": {
    "source_file": "reverse-proxy-configuration-pomerium.txt",
    "text": "**\n\nOnce you\u2019ve installed both plugins, **stop your containers**.\n\nGo to your external Jenkins route.\n\nTo configure JWT authentication:\n\n1. Go to **Manage Jenkins**\n2. Under **Security**, select **Configure Global Security**\n3. Under **Authentication** > **Security Realm**, select **JWT Header Authentication Plugin**\n\nUnder **Global JWT Auth Settings**, you\u2019ll see form fields where you can enter J"
  },
  "3610": {
    "source_file": "reverse-proxy-configuration-pomerium.txt",
    "text": "** > **Security Realm**, select **JWT Header Authentication Plugin**\n\nUnder **Global JWT Auth Settings**, you\u2019ll see form fields where you can enter JWT claims. Pomerium forwards a user\u2019s associated  in a signed attestation JWT that\u2019s included in upstream requests in an `X-Pomerium-Jwt-Assertion` header.\n\nWith the plugin:jwt-auth[JWT Auth] plugin installed, Jenkins can receive and parse the assert"
  },
  "3611": {
    "source_file": "reverse-proxy-configuration-pomerium.txt",
    "text": "tream requests in an `X-Pomerium-Jwt-Assertion` header.\n\nWith the plugin:jwt-auth[JWT Auth] plugin installed, Jenkins can receive and parse the assertion header to authenticate users \u2013 you just need to give it the right instructions to find the header and JWT claims.\n\nEnter the following information in the **Global JWT Auth Settings** field:\n\n.Global JWT Auth Settings\n|===\n|Field |Value\n\n|**Header"
  },
  "3612": {
    "source_file": "reverse-proxy-configuration-pomerium.txt",
    "text": "r and JWT claims.\n\nEnter the following information in the **Global JWT Auth Settings** field:\n\n.Global JWT Auth Settings\n|===\n|Field |Value\n\n|**Header name**\n|`x-pomerium-jwt-assertion`\n\n|**Username claim name**\n|`name` or `email`\n\n|**Groups claim name**\n|`groups`\n\n|**Groups claim list separator**\n|`,`\n\n|**Email claim name**\n|`email`\n\n|**Acceptable issuers**\n|`authenticate.corp.example.com`\n\n|**Ac"
  },
  "3613": {
    "source_file": "reverse-proxy-configuration-pomerium.txt",
    "text": "me**\n|`groups`\n\n|**Groups claim list separator**\n|`,`\n\n|**Email claim name**\n|`email`\n\n|**Acceptable issuers**\n|`authenticate.corp.example.com`\n\n|**Acceptable audiences**\n|`jenkins.corp.example.com`\n\n|**JWKS JSON URL**\n|`https://jenkins.corp.example.com/.well-known/pomerium/jwks.json`\n|===\n\nNote the following details about the fields above:\n\n- **Username claim name** can be either your name or ema"
  },
  "3614": {
    "source_file": "reverse-proxy-configuration-pomerium.txt",
    "text": "com/.well-known/pomerium/jwks.json`\n|===\n\nNote the following details about the fields above:\n\n- **Username claim name** can be either your name or email\n- **Acceptable issuers** must be the URL of the authentication domain that issued the JWT. The `iss` claim tells the target application who the issuing authority is and provides context about the subject.\n- **Acceptable audiences** must be the URL"
  },
  "3615": {
    "source_file": "reverse-proxy-configuration-pomerium.txt",
    "text": "ss` claim tells the target application who the issuing authority is and provides context about the subject.\n- **Acceptable audiences** must be the URL of the target application. The `aud` claim defines what application the JWT is intended for.\n- **JWKS JSON URL** appends `/.well-known/pomerium/jwks.json` to the external route URL. The JWKS endpoint provides Jenkins the user\u2019s public key to verify "
  },
  "3616": {
    "source_file": "reverse-proxy-configuration-pomerium.txt",
    "text": "KS JSON URL** appends `/.well-known/pomerium/jwks.json` to the external route URL. The JWKS endpoint provides Jenkins the user\u2019s public key to verify their JWT signature.\n\nYou can go to the external `verify` route defined in your policy to view your JWT claims.\n\nIn the **Authorization** dropdown, configure Jenkins permissions so that **Anonymous** has **Administer** privileges.\n\n1. Select **Matrix"
  },
  "3617": {
    "source_file": "reverse-proxy-configuration-pomerium.txt",
    "text": "JWT claims.\n\nIn the **Authorization** dropdown, configure Jenkins permissions so that **Anonymous** has **Administer** privileges.\n\n1. Select **Matrix-based security**\n2. Under **Overall**, assign **Administer** to **Anonymous** and **Authenticated Users**\n\nIf JWT authentication doesn't authenticate you successfully, Jenkins signs you in as an anonymous user. With administer privileges, you can tr"
  },
  "3618": {
    "source_file": "reverse-proxy-configuration-pomerium.txt",
    "text": "sers**\n\nIf JWT authentication doesn't authenticate you successfully, Jenkins signs you in as an anonymous user. With administer privileges, you can troubleshoot JWT settings as an anonymous user and try again.\n\nSelect **save** to apply the security settings.\n\nRestart your container. If the JWT authentication worked, your name appears in the dashboard instead of **admin**. To see more details about"
  },
  "3619": {
    "source_file": "reverse-proxy-configuration-pomerium.txt",
    "text": "ettings.\n\nRestart your container. If the JWT authentication worked, your name appears in the dashboard instead of **admin**. To see more details about the request, add `/whoAmI` to the URL. For example, `https://jenkins.localhost.pomerium.io/whoAmI`.\n\nNow, you can configure your Jenkins authorization settings:\n\n1. Select **Matrix-based security**\n2. Select **Add user\u2026** and enter the name or email"
  },
  "3620": {
    "source_file": "reverse-proxy-configuration-pomerium.txt",
    "text": "\n\nNow, you can configure your Jenkins authorization settings:\n\n1. Select **Matrix-based security**\n2. Select **Add user\u2026** and enter the name or email associated with your IdP (the value depends on what claim you entered for **Username claim name**)\n\nAssign yourself **Administer** privileges and whatever privileges seem appropriate to **Authenticated Users** and **Anonymous** users.\n\nSelect **save"
  },
  "3621": {
    "source_file": "reverse-proxy-configuration-pomerium.txt",
    "text": "\nAssign yourself **Administer** privileges and whatever privileges seem appropriate to **Authenticated Users** and **Anonymous** users.\n\nSelect **save** to apply the security changes.\n\nYou can adjust the authorization policy within Jenkins to limit or broaden what privileges authenticated and anonymous users have, but you can also extend your authorization policies with Pomerium.\n\nFor example:\n\n- "
  },
  "3622": {
    "source_file": "reverse-proxy-configuration-pomerium.txt",
    "text": "r broaden what privileges authenticated and anonymous users have, but you can also extend your authorization policies with Pomerium.\n\nFor example:\n\n- You can build a policy that only allows users to access Jenkins at certain times of day or days of the week, or limit access to certain devices\n- You can import custom groups claims from your IdP and only allow access to members of the group"
  },
  "3623": {
    "source_file": "reverse-proxy-configuration-pomerium.txt",
    "text": "he week, or limit access to certain devices\n- You can import custom groups claims from your IdP and only allow access to members of the group"
  },
  "3624": {
    "source_file": "reverse-proxy-configuration-squid.txt",
    "text": "layout: subsection\n\n\nifndef::env-github[:imagesdir: ../../../resources/managing]\n\nIn situations where you want a user friendly url to access Jenkins (Not\nport 8080), it may make sense run Jenkins behind Squid, so that\nyou can access Jenkins on port 80 or 443.\nThis section discusses some of the approaches for doing this.\n\nUsing Squid 2.6:\n\nacl all src 0.0.0.0/0.0.0.0\nacl localhost src 127.0.0.1/255"
  },
  "3625": {
    "source_file": "reverse-proxy-configuration-squid.txt",
    "text": "0 or 443.\nThis section discusses some of the approaches for doing this.\n\nUsing Squid 2.6:\n\nacl all src 0.0.0.0/0.0.0.0\nacl localhost src 127.0.0.1/255.255.255.255\nacl manager proto cache_object\nacl to_localhost dst 127.0.0.0/8\nacl valid_dst dstdomain .YOUR_DOMAIN ci\n\ncache_replacement_policy heap LFUDA\nmemory_replacement_policy heap GDSF\n\ncache_dir ufs /var/spool/squid 512 16 256\ncache_mem 512 MB\n"
  },
  "3626": {
    "source_file": "reverse-proxy-configuration-squid.txt",
    "text": " .YOUR_DOMAIN ci\n\ncache_replacement_policy heap LFUDA\nmemory_replacement_policy heap GDSF\n\ncache_dir ufs /var/spool/squid 512 16 256\ncache_mem 512 MB\nmaximum_object_size 12000 KB\n\n## http --> https redirect\n## don't forget to update \"Jenkins URL\" on https://ci.YOUR_DOMAIN/configure\n#acl httpPort myport 80\n#http_access deny httpPort\n#deny_info https://ci.YOUR_DOMAIN/ httpPort\n\ncache_peer localhost "
  },
  "3627": {
    "source_file": "reverse-proxy-configuration-squid.txt",
    "text": "https://ci.YOUR_DOMAIN/configure\n#acl httpPort myport 80\n#http_access deny httpPort\n#deny_info https://ci.YOUR_DOMAIN/ httpPort\n\ncache_peer localhost parent 8080 0 originserver name=myAccel\ncoredump_dir /var/spool/squid\nhierarchy_stoplist cgi-bin\nhttp_access allow localhost\nhttp_access allow manager localhost\nhttp_access allow valid_dst\nhttp_access deny all\nhttp_access deny manager\n\n## mkdir /etc/"
  },
  "3628": {
    "source_file": "reverse-proxy-configuration-squid.txt",
    "text": "p_access allow localhost\nhttp_access allow manager localhost\nhttp_access allow valid_dst\nhttp_access deny all\nhttp_access deny manager\n\n## mkdir /etc/squid/ssl/ && cd /etc/squid/ssl/\n## to generate your self-signed certificate\n## openssl genrsa -out jenkins.key 1024\n## openssl req -new -key jenkins.key -x509 -out jenkins.crt -days 999\nhttp_port 80 vhost\n#https_port 443 cert=/etc/squid/ssl/jenkins."
  },
  "3629": {
    "source_file": "reverse-proxy-configuration-squid.txt",
    "text": "jenkins.key 1024\n## openssl req -new -key jenkins.key -x509 -out jenkins.crt -days 999\nhttp_port 80 vhost\n#https_port 443 cert=/etc/squid/ssl/jenkins.crt key=/etc/squid/ssl/jenkins.key vhost\n\nhttp_reply_access allow all\nicp_access allow all\n\nrefresh_pattern -i \\.jp(e?g|gif|png|ico)   300  20%  600 override-expire\n\n# Combine following THREE LINES into a SINGLE LINE for Squid\nlogformat combined %>a "
  },
  "3630": {
    "source_file": "reverse-proxy-configuration-squid.txt",
    "text": "pattern -i \\.jp(e?g|gif|png|ico)   300  20%  600 override-expire\n\n# Combine following THREE LINES into a SINGLE LINE for Squid\nlogformat combined %>a %ui %un \\[%tl\\]\n          \"%rm %ru HTTP/%rv\" %Hs %<st\n          \"%{Referer}>h\" \"%{User-Agent}>h\" %Ss:%Sh\nstrip_query_terms off\naccess_log /var/log/squid/access.log combined\n\nvisible_hostname ci.YOUR_DOMAIN\n\nThis assumes that you run Jenkins on localh"
  },
  "3631": {
    "source_file": "reverse-proxy-configuration-squid.txt",
    "text": ":%Sh\nstrip_query_terms off\naccess_log /var/log/squid/access.log combined\n\nvisible_hostname ci.YOUR_DOMAIN\n\nThis assumes that you run Jenkins on localhost port 8080.\nBut you can have it on an other server / different port\n(adjust line starting with cache_peer) +\n\nOf course replace  YOUR_DOMAIN with your domain. +\n\nRemove one level of comment\n\n sed s/^#// /etc/squid/squid.conf\n\nNote: If you use the "
  },
  "3632": {
    "source_file": "reverse-proxy-configuration-squid.txt",
    "text": "che_peer) +\n\nOf course replace  YOUR_DOMAIN with your domain. +\n\nRemove one level of comment\n\n sed s/^#// /etc/squid/squid.conf\n\nNote: If you use the swarm client plugin, the nodes may report:\n\nCaused by: sun.security.validator.ValidatorException:\n    PKIX path building failed: sun.security.provider.certpath.SunCertPathBuilderException:\n        unable to find valid certification path to requested "
  },
  "3633": {
    "source_file": "reverse-proxy-configuration-squid.txt",
    "text": "  PKIX path building failed: sun.security.provider.certpath.SunCertPathBuilderException:\n        unable to find valid certification path to requested target\n        at sun.security.validator.PKIXValidator.doBuild(PKIXValidator.java:285)\n        at sun.security.validator.PKIXValidator.engineValidate(PKIXValidator.java:191)\n        at sun.security.validator.Validator.validate(Validator.java:218)\n   "
  },
  "3634": {
    "source_file": "reverse-proxy-configuration-squid.txt",
    "text": "n.security.validator.PKIXValidator.engineValidate(PKIXValidator.java:191)\n        at sun.security.validator.Validator.validate(Validator.java:218)\n        at c.s.n.s.i.s.X509TrustManagerImpl.validate(X509TrustManagerImpl.java:126)\n        at c.s.n.s.i.s.X509TrustManagerImpl.checkServerTrusted(X509TrustManagerImpl.java:209)\n        at c.s.n.s.i.s.X509TrustManagerImpl.checkServerTrusted(X509TrustMan"
  },
  "3635": {
    "source_file": "reverse-proxy-configuration-squid.txt",
    "text": "i.s.X509TrustManagerImpl.checkServerTrusted(X509TrustManagerImpl.java:209)\n        at c.s.n.s.i.s.X509TrustManagerImpl.checkServerTrusted(X509TrustManagerImpl.java:249)\n        at c.s.n.s.i.s.ClientHandshaker.serverCertificate(ClientHandshaker.java:1014)\n        ... 13 more\nCaused by: sun.security.provider.certpath.SunCertPathBuilderException:\n        unable to find valid certification path to req"
  },
  "3636": {
    "source_file": "reverse-proxy-configuration-squid.txt",
    "text": "014)\n        ... 13 more\nCaused by: sun.security.provider.certpath.SunCertPathBuilderException:\n        unable to find valid certification path to requested target\n\nYou may be able to avoid that message with the `-noCertificateCheck` argument to `agent.jar`.\nThat will disable server certificate checking from the agent."
  },
  "3637": {
    "source_file": "reverse-proxy-configuration-squid.txt",
    "text": "nt.jar`.\nThat will disable server certificate checking from the agent."
  },
  "3638": {
    "source_file": "reverse-proxy-configuration-troubleshooting.txt",
    "text": "layout: section\n\n\nifndef::env-github[:imagesdir: ../../resources/managing]\n\n[[jenkins-says-my-reverse-proxy-setup-is-broken]]\n\nAn error message is displayed in the \"Manage Jenkins\" page\n\n`+It appears that your reverse proxy setup is broken+`\n\nNOTE: This message can also appear if you don't access\nJenkins through a reverse proxy: Make sure the Jenkins URL configured in\nthe System Configuration matc"
  },
  "3639": {
    "source_file": "reverse-proxy-configuration-troubleshooting.txt",
    "text": "his message can also appear if you don't access\nJenkins through a reverse proxy: Make sure the Jenkins URL configured in\nthe System Configuration matches the URL you're using to access Jenkins.\n\n[[troubleshooting]]\n\nFor a reverse proxy to work correctly, it needs to rewrite both the\nrequest and the response.\nRequest rewriting involves receiving an inbound HTTP call and then making\na forwarding req"
  },
  "3640": {
    "source_file": "reverse-proxy-configuration-troubleshooting.txt",
    "text": "tly, it needs to rewrite both the\nrequest and the response.\nRequest rewriting involves receiving an inbound HTTP call and then making\na forwarding request to Jenkins (sometimes with some HTTP headers modified, sometimes not).\nFailing to configure the request rewriting is easy to catch, because you\njust won't see any pages at all.\n\nBut correct reverse proxying also involves *one of two options*, EI"
  },
  "3641": {
    "source_file": "reverse-proxy-configuration-troubleshooting.txt",
    "text": " request rewriting is easy to catch, because you\njust won't see any pages at all.\n\nBut correct reverse proxying also involves *one of two options*, EITHER\n\n* *rewrite the response* with a \"Location\" header in the response, which is used during redirects.\nJenkins sends `Location:{nbsp}http://actual.server:8080/jenkins/foobar`\nand the reverse proxy must\nrewrite it to `Location:{nbsp}http://nice.name"
  },
  "3642": {
    "source_file": "reverse-proxy-configuration-troubleshooting.txt",
    "text": "cts.\nJenkins sends `Location:{nbsp}http://actual.server:8080/jenkins/foobar`\nand the reverse proxy must\nrewrite it to `Location:{nbsp}http://nice.name/jenkins/foobar`.\nUnfortunately, failing to configure this correctly is harder to catch;\nOR\n* *set the headers* `+X-Forwarded-Host+` (and perhaps `+X-Forwarded-Port+`) on the forwarded request.\nJenkins will parse those headers and generate all the re"
  },
  "3643": {
    "source_file": "reverse-proxy-configuration-troubleshooting.txt",
    "text": "he headers* `+X-Forwarded-Host+` (and perhaps `+X-Forwarded-Port+`) on the forwarded request.\nJenkins will parse those headers and generate all the redirects and other\nlinks on the basis of those headers.\nDepending on your reverse proxy it may be easier to set `+X-Forwarded-Host+`\nand `+X-Forwarded-Port+` to the hostname and port in the original `+Host+`\nheader respectively or it may be easier to "
  },
  "3644": {
    "source_file": "reverse-proxy-configuration-troubleshooting.txt",
    "text": "ier to set `+X-Forwarded-Host+`\nand `+X-Forwarded-Port+` to the hostname and port in the original `+Host+`\nheader respectively or it may be easier to just pass the original `+Host+`\nheader through as  `+X-Forwarded-Host+` and delete the `+X-Forwarded-Port+` #\nheader from the request.\nYou will also need to set the `+X-Forwarded-Proto+` header if your reverse\nproxy is changing from `+https+` to `+ht"
  },
  "3645": {
    "source_file": "reverse-proxy-configuration-troubleshooting.txt",
    "text": "-Port+` #\nheader from the request.\nYou will also need to set the `+X-Forwarded-Proto+` header if your reverse\nproxy is changing from `+https+` to `+http+` or vice-versa.\n\nJenkins has proactive monitoring to make sure this is configured correctly.\nIt uses XmlHttpRequest to request a specific URL in Jenkins (via relative path,\nso this will always get through provided the request is properly rewritte"
  },
  "3646": {
    "source_file": "reverse-proxy-configuration-troubleshooting.txt",
    "text": "uses XmlHttpRequest to request a specific URL in Jenkins (via relative path,\nso this will always get through provided the request is properly rewritten),\nwhich will then redirect the user to another page in Jenkins (this only works\ncorrectly if you configured the response rewriting correctly), which then returns 200.\n\nThis error message indicates that this test is failing - and the most\nlikely cau"
  },
  "3647": {
    "source_file": "reverse-proxy-configuration-troubleshooting.txt",
    "text": "onfigured the response rewriting correctly), which then returns 200.\n\nThis error message indicates that this test is failing - and the most\nlikely cause is that the response rewriting is misconfigured.\nSee the   for additional tips about\nconfiguring a reverse proxy.\n\nBe sure to set the `+X-Forwarded-Proto+` header if your reverse proxy is\naccessed via HTTPS and then Jenkins itself is accessed via "
  },
  "3648": {
    "source_file": "reverse-proxy-configuration-troubleshooting.txt",
    "text": "a reverse proxy.\n\nBe sure to set the `+X-Forwarded-Proto+` header if your reverse proxy is\naccessed via HTTPS and then Jenkins itself is accessed via HTTP i.e.\nproxying HTTPS to HTTP.\n\nChanging the context path of Jenkins with a reverse proxy is fraught with danger.\nThere are many URLs that must be rewritten.\nEven if you rewrite all the URLs in HTML files, you may miss some in JavaScript, CSS, or "
  },
  "3649": {
    "source_file": "reverse-proxy-configuration-troubleshooting.txt",
    "text": "ght with danger.\nThere are many URLs that must be rewritten.\nEven if you rewrite all the URLs in HTML files, you may miss some in JavaScript, CSS, or XML resources.\n\nWhile it is technically possible to use rewrite rules to change the context path,\nyou should be aware that it would be a lot of work to find and fix everything in\nyour rewrite rules and the reverse proxy will spend most of its time re"
  },
  "3650": {
    "source_file": "reverse-proxy-configuration-troubleshooting.txt",
    "text": "u should be aware that it would be a lot of work to find and fix everything in\nyour rewrite rules and the reverse proxy will spend most of its time rewriting\nresponses from Jenkins.\nMuch easier to change Jenkins to run at the context path your reverse proxy is\nexpecting, e.g. if your reverse proxy is forwarding requests at\nhttps://manchu.example.org/foobar/ to Jenkins then you could just use\n`+jav"
  },
  "3651": {
    "source_file": "reverse-proxy-configuration-troubleshooting.txt",
    "text": "e proxy is\nexpecting, e.g. if your reverse proxy is forwarding requests at\nhttps://manchu.example.org/foobar/ to Jenkins then you could just use\n`+java -jar jenkins.war --prefix=/foobar+` to start jenkins using\n`+/foobar+` as the context path\n\nFor further diagnosis, try using cURL:\n\nBASE=administrativeMonitor/hudson.diagnosis.ReverseProxySetupMonitor\ncurl -iL -e http://your.reverse.proxy/jenkins/m"
  },
  "3652": {
    "source_file": "reverse-proxy-configuration-troubleshooting.txt",
    "text": "rther diagnosis, try using cURL:\n\nBASE=administrativeMonitor/hudson.diagnosis.ReverseProxySetupMonitor\ncurl -iL -e http://your.reverse.proxy/jenkins/manage \\\n            http://your.reverse.proxy/jenkins/${BASE}/test\n\n(assuming your Jenkins is located at\nhttp://your.reverse.proxy/jenkins/ - and is open to anonymous read\naccess)"
  },
  "3653": {
    "source_file": "reverse-proxy-configuration-troubleshooting.txt",
    "text": "d at\nhttp://your.reverse.proxy/jenkins/ - and is open to anonymous read\naccess)"
  },
  "3654": {
    "source_file": "review-build-status.txt",
    "text": "layout: developersection\ntitle: Review ci.jenkins.io build status\n\n\nThe GitHub checks tab includes a link to the ci.jenkins.io job that evaluates the pull request.\nOpen the GitHub checks tab and confirm that you can see the ci.jenkins.io link\n\nThe ci.jenkins.io job evaluates a broad range of Java runtimes on Windows and Linux.\nIt is a good way to confirm that your change is ready for review by oth"
  },
  "3655": {
    "source_file": "review-build-status.txt",
    "text": ".jenkins.io job evaluates a broad range of Java runtimes on Windows and Linux.\nIt is a good way to confirm that your change is ready for review by others."
  },
  "3656": {
    "source_file": "routing.txt",
    "text": "title: Routing Requests\nsummary: How requests in Jenkins are routed to the objects ultimately responding to them\nlayout: developersection\nreferences:\n- url: https://github.com/stapler/stapler/blob/master/docs/reference.adoc\n  title: Stapler URL Binding Reference\n- title: Figuring out URL binding in Stapler\n  url: https://wiki.jenkins.io/display/JENKINS/Figuring+out+URL+binding+of+Stapler\n\n\nLet's l"
  },
  "3657": {
    "source_file": "routing.txt",
    "text": "ng Reference\n- title: Figuring out URL binding in Stapler\n  url: https://wiki.jenkins.io/display/JENKINS/Figuring+out+URL+binding+of+Stapler\n\n\nLet's look at some real-world examples for the most common ways to process (part of) the path:\n\n* Traversing the model graph\n  - Getter: `/*log*/\u2026` \u2192 `jenkinsdoc:jenkins.model.Jenkins#getLog%28%29[Jenkins#getLog()]`\n  - Getter with argument: `/*job/foo*/\u2026` "
  },
  "3658": {
    "source_file": "routing.txt",
    "text": "g the model graph\n  - Getter: `/*log*/\u2026` \u2192 `jenkinsdoc:jenkins.model.Jenkins#getLog%28%29[Jenkins#getLog()]`\n  - Getter with argument: `/*job/foo*/\u2026` \u2192 `jenkinsdoc:hudson.model.Hudson#getJob%28java.lang.String%29[Hudson#getJob(\"foo\")]`\n  - Dynamic getter: `/job/foo/*1*/\u2026` \u2192 `jenkinsdoc:hudson.model.Job#getDynamic%28java.lang.String,%20org.kohsuke.stapler.StaplerRequest,%20org.kohsuke.stapler.Stapl"
  },
  "3659": {
    "source_file": "routing.txt",
    "text": "tter: `/job/foo/*1*/\u2026` \u2192 `jenkinsdoc:hudson.model.Job#getDynamic%28java.lang.String,%20org.kohsuke.stapler.StaplerRequest,%20org.kohsuke.stapler.StaplerResponse%29[Job#getDynamic(\"1\" \u2026)]`\n* Rendering views\n  - Index view: `/job/foo*/*` \u2192 `_index.jelly_` of `_jenkinsdoc:Job[]_` (or other `jenkinsdoc:TopLevelItem[]` implementations)\n  - Named view: `/job/foo/*changes*` \u2192 `_changes.jelly_` of `_jenki"
  },
  "3660": {
    "source_file": "routing.txt",
    "text": "y_` of `_jenkinsdoc:Job[]_` (or other `jenkinsdoc:TopLevelItem[]` implementations)\n  - Named view: `/job/foo/*changes*` \u2192 `_changes.jelly_` of `_jenkinsdoc:Job[]_`\n* Action methods\n** Action method\n  - `/job/foo/1/*artifact*` \u2192 `jenkinsdoc:hudson.model.Run#doArtifact%28%29[Run#doArtifact(\u2026)]`\n  - `/job.foo/*config.xml*` \u2192 `jenkinsdoc:hudson.model.AbstractItem#doConfigDotXml%28org.kohsuke.stapler.S"
  },
  "3661": {
    "source_file": "routing.txt",
    "text": "el.Run#doArtifact%28%29[Run#doArtifact(\u2026)]`\n  - `/job.foo/*config.xml*` \u2192 `jenkinsdoc:hudson.model.AbstractItem#doConfigDotXml%28org.kohsuke.stapler.StaplerRequest,%20org.kohsuke.stapler.StaplerResponse%29[@WebMethod(\"config.xml\") doConfigDotXml(\u2026)]`\n** Index action method\n  - `/search` \u2192 `jenkinsdoc:hudson.search.Search#doIndex(org.kohsuke.stapler.StaplerRequest,%20org.kohsuke.stapler.StaplerResp"
  },
  "3662": {
    "source_file": "routing.txt",
    "text": "\n** Index action method\n  - `/search` \u2192 `jenkinsdoc:hudson.search.Search#doIndex(org.kohsuke.stapler.StaplerRequest,%20org.kohsuke.stapler.StaplerResponse)[Search#doIndex(\u2026)]`\n\nAdditionally, objects can implement several interfaces to further control how Stapler processes URLs:\n\n* `staplerdoc:org.kohsuke.stapler.StaplerProxy[]` allows delegating the processing of a URL to another object.\n  So, for"
  },
  "3663": {
    "source_file": "routing.txt",
    "text": " how Stapler processes URLs:\n\n* `staplerdoc:org.kohsuke.stapler.StaplerProxy[]` allows delegating the processing of a URL to another object.\n  So, for `/foo/bar`, if `getFoo()` returns an object `x` that implements `StaplerProxy`'s `getTarget()` method, Stapler will call `x.getTarget()` and continue using that to process the rest of the URL (`bar`).\n  This has the *highest priority* among all poss"
  },
  "3664": {
    "source_file": "routing.txt",
    "text": "od, Stapler will call `x.getTarget()` and continue using that to process the rest of the URL (`bar`).\n  This has the *highest priority* among all possible URL processing options.\n  `getTarget()` may also return `this`, for example to implement permission checks: No getters or views of `x` will be available to anyone who doesn't have the necessary permissions via URLs.\n* `staplerdoc:org.kohsuke.sta"
  },
  "3665": {
    "source_file": "routing.txt",
    "text": "sion checks: No getters or views of `x` will be available to anyone who doesn't have the necessary permissions via URLs.\n* `staplerdoc:org.kohsuke.stapler.StaplerOverridable[]` is an interface allowing designated objects to selectively override URL mappings.\n  If the designated override objects do not have a handler for the request, the host object (that implements `StaplerOverridable`) will handl"
  },
  "3666": {
    "source_file": "routing.txt",
    "text": "appings.\n  If the designated override objects do not have a handler for the request, the host object (that implements `StaplerOverridable`) will handle the request.\n* `staplerdoc:org.kohsuke.stapler.StaplerFallback[]` allows delegating the processing of a URL to another object, similar to `StaplerProxy`, but has the *lowest priority* among all possible URL processing options.\n\nFor more information"
  },
  "3667": {
    "source_file": "routing.txt",
    "text": " of a URL to another object, similar to `StaplerProxy`, but has the *lowest priority* among all possible URL processing options.\n\nFor more information on how Stapler binds (or staples) a Java Object Model to a URL hierarchy, see the .\n\nNOTE: Since Jenkins 2.138.4 and 2.154, Jenkins places restrictions not inherent to Stapler on which methods and fields are eligible for routing.\n\nThe following stat"
  },
  "3668": {
    "source_file": "routing.txt",
    "text": "nkins 2.138.4 and 2.154, Jenkins places restrictions not inherent to Stapler on which methods and fields are eligible for routing.\n\nThe following static fields can be set to `true` (e.g. via Script Console) while Jenkins is running to enable various debugging aids:\n\n`org.kohsuke.stapler.Dispatcher.TRACE`::\nStapler responses will include `X-Stapler-Trace-\u2026` headers that explain how the correspondin"
  },
  "3669": {
    "source_file": "routing.txt",
    "text": "debugging aids:\n\n`org.kohsuke.stapler.Dispatcher.TRACE`::\nStapler responses will include `X-Stapler-Trace-\u2026` headers that explain how the corresponding request was routed.\nAdditionally, the 404 error page will also include this information, as well as alternative routes for the last path component (which resulted in the 404 error).\nThe corresponding Java system property is .\nThis is enabled by def"
  },
  "3670": {
    "source_file": "routing.txt",
    "text": "s alternative routes for the last path component (which resulted in the 404 error).\nThe corresponding Java system property is .\nThis is enabled by default if Jenkins is run using `mvn -pl war jetty:run` (core) or `mvn hpi:run` (plugins).\n\n`org.kohsuke.stapler.Dispatcher.TRACE_PER_REQUEST`::\nAs above, but only for requests that have the `X-Stapler-Trace` header.\nThe corresponding Java system proper"
  },
  "3671": {
    "source_file": "routing.txt",
    "text": "e.stapler.Dispatcher.TRACE_PER_REQUEST`::\nAs above, but only for requests that have the `X-Stapler-Trace` header.\nThe corresponding Java system property is ."
  },
  "3672": {
    "source_file": "run.txt",
    "text": "layout: developer\ntitle: Build and Run the Plugin\nreferences: []\n\n\n-\n-\n-\n-\n\nThe Maven HPI Plugin is used to build and package Jenkins plugins.\nIt also provides a convenient way to run a Jenkins controller with your plugin:\n\nmvn hpi:run\n\nNOTE: You may need to specify a port number for your plugin to use. You can specify a port like this\n\nmvn hpi:run -Dport=5000\n\nNOTE: To learn more about Maven HPI "
  },
  "3673": {
    "source_file": "run.txt",
    "text": " need to specify a port number for your plugin to use. You can specify a port like this\n\nmvn hpi:run -Dport=5000\n\nNOTE: To learn more about Maven HPI Plugin and the goals it provides, see .\n\nThis will set up a Jenkins controller on `http://localhost:8080/jenkins/`. Wait for the following console output, then open a web browser and look at what the plugin does.\n\n[listing]\nINFO: Jenkins is fully up "
  },
  "3674": {
    "source_file": "run.txt",
    "text": "8080/jenkins/`. Wait for the following console output, then open a web browser and look at what the plugin does.\n\n[listing]\nINFO: Jenkins is fully up and running\n\nNOTE: The Jenkins home directory used is the `work/` directory in the plugin directory. This means that subsequent runs will keep their data.\n\nCreate a new freestyle project in Jenkins, and give it any name.\n\nThen add the \"Say hello worl"
  },
  "3675": {
    "source_file": "run.txt",
    "text": " This means that subsequent runs will keep their data.\n\nCreate a new freestyle project in Jenkins, and give it any name.\n\nThen add the \"Say hello world\" build step. It will look like this:\n\nEnter a name, save the project, and start a new build. Navigate to the build on the UI, and click _Console Output_ to view the build log.\nIt will contain a message written by the build step that was just config"
  },
  "3676": {
    "source_file": "run.txt",
    "text": "ate to the build on the UI, and click _Console Output_ to view the build log.\nIt will contain a message written by the build step that was just configured:\n\n[listing]\n\nStarted by user anonymous\nBuilding in workspace /Users/mrjenkins/demo/work/workspace/testjob\nHello, Jenkins! // <1> Finished: SUCCESS\n\n<1> The Greeting added by the build step\n\n// TODO This is not present in version 1.2 of the arche"
  },
  "3677": {
    "source_file": "run.txt",
    "text": "ce/testjob\nHello, Jenkins! // <1> Finished: SUCCESS\n\n<1> The Greeting added by the build step\n\n// TODO This is not present in version 1.2 of the archetype\n//Additionally, the build step has global configuration options. Go to _Manage Jenkins \u00bb System_ and you'll see this:\n//\n//\n\nLet's stop Jenkins by pressing `Ctrl-C` (or your system's equivalent) in the terminal.\n\nNext step: .\n\nNOTE: Anything not"
  },
  "3678": {
    "source_file": "run.txt",
    "text": "_ and you'll see this:\n//\n//\n\nLet's stop Jenkins by pressing `Ctrl-C` (or your system's equivalent) in the terminal.\n\nNext step: .\n\nNOTE: Anything not working for you? Ask for help in  or ."
  },
  "3679": {
    "source_file": "running-multiple-steps.txt",
    "text": "layout: documentation\ntitle: Running multiple steps\nsection: doc\n\n\nPipelines are made up of multiple steps that allow you to build, test and\ndeploy applications. Jenkins Pipeline allows you to compose multiple steps in\nan easy way that can help you model any sort of automation process.\n\nThink of a \"step\" like a single command which performs a single action. When a\nstep succeeds it moves onto the n"
  },
  "3680": {
    "source_file": "running-multiple-steps.txt",
    "text": "odel any sort of automation process.\n\nThink of a \"step\" like a single command which performs a single action. When a\nstep succeeds it moves onto the next step. When a step fails to execute\ncorrectly the Pipeline will fail.\n\nWhen all the steps in the Pipeline have successfully completed, the Pipeline is\nconsidered to have successfully executed.\n\nOn Linux, BSD, and Mac OS (Unix-like) systems, the `s"
  },
  "3681": {
    "source_file": "running-multiple-steps.txt",
    "text": "Pipeline have successfully completed, the Pipeline is\nconsidered to have successfully executed.\n\nOn Linux, BSD, and Mac OS (Unix-like) systems, the `sh` step is used to execute\na shell command in a Pipeline.\n\n[pipeline]\n\n// Declarative //\npipeline {\n    agent any\n    stages {\n        stage('Build') {\n            steps {\n                sh 'echo \"Hello World\"'\n                sh '''\n               "
  },
  "3682": {
    "source_file": "running-multiple-steps.txt",
    "text": "    agent any\n    stages {\n        stage('Build') {\n            steps {\n                sh 'echo \"Hello World\"'\n                sh '''\n                    echo \"Multiline shell steps works too\"\n                    ls -lah\n                '''\n            }\n        }\n    }\n}\n// Scripted //\nnode {\n    stage('Build') {\n        sh 'echo \"Hello World\"'\n        sh '''\n            echo \"Multiline shell st"
  },
  "3683": {
    "source_file": "running-multiple-steps.txt",
    "text": "    }\n        }\n    }\n}\n// Scripted //\nnode {\n    stage('Build') {\n        sh 'echo \"Hello World\"'\n        sh '''\n            echo \"Multiline shell steps works too\"\n            ls -lah\n        '''\n    }\n}\n\nWindows-based systems should use the `bat` step for executing batch commands.\n\n[pipeline]\n\n// Declarative //\npipeline {\n    agent any\n    stages {\n        stage('Build') {\n            steps {\n  "
  },
  "3684": {
    "source_file": "running-multiple-steps.txt",
    "text": "tep for executing batch commands.\n\n[pipeline]\n\n// Declarative //\npipeline {\n    agent any\n    stages {\n        stage('Build') {\n            steps {\n                bat 'set'\n            }\n        }\n    }\n}\n// Scripted //\nnode {\n    stage('Build') {\n        bat 'set'\n    }\n}\n\nThere are some powerful steps that \"wrap\" other steps which can easily solve\nproblems like retrying (`retry`) steps until su"
  },
  "3685": {
    "source_file": "running-multiple-steps.txt",
    "text": "       bat 'set'\n    }\n}\n\nThere are some powerful steps that \"wrap\" other steps which can easily solve\nproblems like retrying (`retry`) steps until successful or exiting if a\nstep takes too long (`timeout`).\n\nWhen a step cannot be completed, timeouts help the controller avoid wasting resources.\nThis video reviews the process of setting up both stage and global timeouts.\n\n.How do I set a timeout in"
  },
  "3686": {
    "source_file": "running-multiple-steps.txt",
    "text": " help the controller avoid wasting resources.\nThis video reviews the process of setting up both stage and global timeouts.\n\n.How do I set a timeout in a Jenkins Pipeline\nvideo::OChOtpK0fUE[youtube,width=800,height=420]\n\n[pipeline]\n\n// Declarative //\npipeline {\n    agent any\n    stages {\n        stage('Deploy') {\n            steps {\n                retry(3) {\n                    sh './flakey-deploy"
  },
  "3687": {
    "source_file": "running-multiple-steps.txt",
    "text": "pipeline {\n    agent any\n    stages {\n        stage('Deploy') {\n            steps {\n                retry(3) {\n                    sh './flakey-deploy.sh'\n                }\n\n                timeout(time: 3, unit: 'MINUTES') {\n                    sh './health-check.sh'\n                }\n            }\n        }\n    }\n}\n// Scripted //\nnode {\n    stage('Deploy') {\n        retry(3) {\n            sh './"
  },
  "3688": {
    "source_file": "running-multiple-steps.txt",
    "text": "./health-check.sh'\n                }\n            }\n        }\n    }\n}\n// Scripted //\nnode {\n    stage('Deploy') {\n        retry(3) {\n            sh './flakey-deploy.sh'\n        }\n\n        timeout(time: 3, unit: 'MINUTES') {\n            sh './health-check.sh'\n        }\n    }\n}\n\nThe \"Deploy\" stage retries the `flakey-deploy.sh` script 3 times, and then\nwaits for up to 3 minutes for the `health-check."
  },
  "3689": {
    "source_file": "running-multiple-steps.txt",
    "text": "eck.sh'\n        }\n    }\n}\n\nThe \"Deploy\" stage retries the `flakey-deploy.sh` script 3 times, and then\nwaits for up to 3 minutes for the `health-check.sh` script to execute. If the\nhealth check script does not complete in 3 minutes, the Pipeline will be marked\nas having failed in the \"Deploy\" stage.\n\n\"Wrapper\" steps such as `timeout` and `retry` may contain other steps,\nincluding `timeout` or `retr"
  },
  "3690": {
    "source_file": "running-multiple-steps.txt",
    "text": "be marked\nas having failed in the \"Deploy\" stage.\n\n\"Wrapper\" steps such as `timeout` and `retry` may contain other steps,\nincluding `timeout` or `retry`.\n\n.How do I retry a Jenkins Job?\nvideo::g56OqkvG4wk[youtube,width=800,height=420]\n\nWe can compose these steps together. For example, if we wanted to retry our\ndeployment 5 times, but never want to spend more than 3 minutes in total before\nfailing "
  },
  "3691": {
    "source_file": "running-multiple-steps.txt",
    "text": " these steps together. For example, if we wanted to retry our\ndeployment 5 times, but never want to spend more than 3 minutes in total before\nfailing the stage:\n\n[pipeline]\n\n// Declarative //\npipeline {\n    agent any\n    stages {\n        stage('Deploy') {\n            steps {\n                timeout(time: 3, unit: 'MINUTES') {\n                    retry(5) {\n                        sh './flakey-depl"
  },
  "3692": {
    "source_file": "running-multiple-steps.txt",
    "text": "y') {\n            steps {\n                timeout(time: 3, unit: 'MINUTES') {\n                    retry(5) {\n                        sh './flakey-deploy.sh'\n                    }\n                }\n            }\n        }\n    }\n}\n// Scripted //\nnode {\n    stage('Deploy') {\n        timeout(time: 3, unit: 'MINUTES') {\n            retry(5) {\n                sh './flakey-deploy.sh'\n            }\n      "
  },
  "3693": {
    "source_file": "running-multiple-steps.txt",
    "text": "\n    stage('Deploy') {\n        timeout(time: 3, unit: 'MINUTES') {\n            retry(5) {\n                sh './flakey-deploy.sh'\n            }\n        }\n    }\n}\n\nWhen the Pipeline has finished executing, you may need to run clean-up steps or\nperform some actions based on the outcome of the Pipeline. These actions can be\nperformed in the `post` section.\n\n[pipeline]\n\n// Declarative //\npipeline {\n  "
  },
  "3694": {
    "source_file": "running-multiple-steps.txt",
    "text": " some actions based on the outcome of the Pipeline. These actions can be\nperformed in the `post` section.\n\n[pipeline]\n\n// Declarative //\npipeline {\n    agent any\n    stages {\n        stage('Test') {\n            steps {\n                sh 'echo \"Fail!\"; exit 1'\n            }\n        }\n    }\n    post {\n        always {\n            echo 'This will always run'\n        }\n        success {\n            e"
  },
  "3695": {
    "source_file": "running-multiple-steps.txt",
    "text": "\"; exit 1'\n            }\n        }\n    }\n    post {\n        always {\n            echo 'This will always run'\n        }\n        success {\n            echo 'This will run only if successful'\n        }\n        failure {\n            echo 'This will run only if failed'\n        }\n        unstable {\n            echo 'This will run only if the run was marked as unstable'\n        }\n        changed {\n      "
  },
  "3696": {
    "source_file": "running-multiple-steps.txt",
    "text": "nly if failed'\n        }\n        unstable {\n            echo 'This will run only if the run was marked as unstable'\n        }\n        changed {\n            echo 'This will run only if the state of the Pipeline has changed'\n            echo 'For example, if the Pipeline was previously failing but is now successful'\n        }\n    }\n}\n// Scripted //\nnode {\n    try {\n        stage('Test') {\n          "
  },
  "3697": {
    "source_file": "running-multiple-steps.txt",
    "text": "le, if the Pipeline was previously failing but is now successful'\n        }\n    }\n}\n// Scripted //\nnode {\n    try {\n        stage('Test') {\n            sh 'echo \"Fail!\"; exit 1'\n        }\n        echo 'This will run only if successful'\n    } catch (e) {\n        echo 'This will run only if failed'\n\n        // Since we're catching the exception in order to report on it,\n        // we need to re-thro"
  },
  "3698": {
    "source_file": "running-multiple-steps.txt",
    "text": ") {\n        echo 'This will run only if failed'\n\n        // Since we're catching the exception in order to report on it,\n        // we need to re-throw it, to ensure that the build is marked as failed\n        throw e\n    } finally {\n        def currentResult = currentBuild.result ?: 'SUCCESS'\n        if (currentResult == 'UNSTABLE') {\n            echo 'This will run only if the run was marked as u"
  },
  "3699": {
    "source_file": "running-multiple-steps.txt",
    "text": "ntResult = currentBuild.result ?: 'SUCCESS'\n        if (currentResult == 'UNSTABLE') {\n            echo 'This will run only if the run was marked as unstable'\n        }\n\n        def previousResult = currentBuild.previousBuild?.result\n        if (previousResult != null && previousResult != currentResult) {\n            echo 'This will run only if the state of the Pipeline has changed'\n            ec"
  },
  "3700": {
    "source_file": "running-multiple-steps.txt",
    "text": "iousResult != null && previousResult != currentResult) {\n            echo 'This will run only if the state of the Pipeline has changed'\n            echo 'For example, if the Pipeline was previously failing but is now successful'\n        }\n\n        echo 'This will always run'\n    }\n}\n\n\n\nWith the basics of defining multiple steps finished, let's\n\n\n'''\n+++\n\n+++"
  },
  "3701": {
    "source_file": "running-multiple-steps.txt",
    "text": "ho 'This will always run'\n    }\n}\n\n\n\nWith the basics of defining multiple steps finished, let's\n\n\n'''\n+++\n\n+++"
  },
  "3702": {
    "source_file": "running-pipelines.txt",
    "text": "layout: section\ntitle: Running Pipelines\n\n\nifdef::env-github[:imagesdir: ../resources]\nifndef::env-github[:imagesdir: ../../resources]\n\n// Show 2/3 of the Blue ocean admonitions\n\n// :pipeline-creation-admonition: true\n\n// TODO: WEBSITE-495 - flesh out placeholder sections.\n\nSee <<multibranch#, the Multibranch documentation>> for more information.\n\nSee <<jenkinsfile#handling-parameters, the Jenkins"
  },
  "3703": {
    "source_file": "running-pipelines.txt",
    "text": "t placeholder sections.\n\nSee <<multibranch#, the Multibranch documentation>> for more information.\n\nSee <<jenkinsfile#handling-parameters, the Jenkinsfile documentation>> for more information\n\nThere are a number of ways to rerun or restart a completed Pipeline.\n\nSee <<development#replay, the Replay documentation>> for more information.\n\nYou can restart any completed Declarative Pipeline from any\nt"
  },
  "3704": {
    "source_file": "running-pipelines.txt",
    "text": "d Pipeline.\n\nSee <<development#replay, the Replay documentation>> for more information.\n\nYou can restart any completed Declarative Pipeline from any\ntop-level stage which ran in that Pipeline. This allows you to rerun a Pipeline from a stage which failed due to\ntransient or environmental considerations, for example. All inputs to the Pipeline will be the same. This includes\nSCM information, build "
  },
  "3705": {
    "source_file": "running-pipelines.txt",
    "text": "iled due to\ntransient or environmental considerations, for example. All inputs to the Pipeline will be the same. This includes\nSCM information, build parameters, and the contents of any `stash` step calls in the original Pipeline, if specified.\n\nNo additional configuration is needed in the Jenkinsfile to allow you to restart stages in your Declarative Pipelines.\nThis is an inherent part of Declara"
  },
  "3706": {
    "source_file": "running-pipelines.txt",
    "text": "dditional configuration is needed in the Jenkinsfile to allow you to restart stages in your Declarative Pipelines.\nThis is an inherent part of Declarative Pipelines and is available automatically.\n\nOnce your Pipeline has completed, whether it succeeds or fails, you can go to the side panel for the run in the classic UI and select \"Restart from Stage\".\n\nYou will be prompted to choose from a list of"
  },
  "3707": {
    "source_file": "running-pipelines.txt",
    "text": "s or fails, you can go to the side panel for the run in the classic UI and select \"Restart from Stage\".\n\nYou will be prompted to choose from a list of top-level stages that were executed in the original run, in the order\nthey were executed. Stages which were skipped due to an earlier failure will not be available to be restarted, but\nstages which were skipped due to a `when` condition not being sa"
  },
  "3708": {
    "source_file": "running-pipelines.txt",
    "text": "ich were skipped due to an earlier failure will not be available to be restarted, but\nstages which were skipped due to a `when` condition not being satisfied will be available. The parent stage for a\ngroup of `parallel` stages, or a group of nested `stages` to be run sequentially will also not be available - only\ntop-level stages are allowed.\n\nOnce you choose a stage to restart from and click subm"
  },
  "3709": {
    "source_file": "running-pipelines.txt",
    "text": "stages` to be run sequentially will also not be available - only\ntop-level stages are allowed.\n\nOnce you choose a stage to restart from and click submit, a new build, with a new build number, will be started. All\nstages before the selected stage will be skipped, and the Pipeline will start executing at the selected stage. From\nthat point on, the Pipeline will run as normal.\n\nRestarting stages can "
  },
  "3710": {
    "source_file": "running-pipelines.txt",
    "text": " be skipped, and the Pipeline will start executing at the selected stage. From\nthat point on, the Pipeline will run as normal.\n\nRestarting stages can also be done in the Blue Ocean UI.  Once your Pipeline has completed, whether it succeeds\nor fails, you can click on the node which represents the stage.  You can then click on the `Restart` link for\nthat stage.\n\nNormally, when you run the `stash` st"
  },
  "3711": {
    "source_file": "running-pipelines.txt",
    "text": "you can click on the node which represents the stage.  You can then click on the `Restart` link for\nthat stage.\n\nNormally, when you run the `stash` step in your Pipeline, the resulting stash of artifacts is cleared when the\nPipeline completes, regardless of the result of the Pipeline. Since `stash` artifacts aren't accessible outside of the\nPipeline run that created them, this has not created any "
  },
  "3712": {
    "source_file": "running-pipelines.txt",
    "text": "less of the result of the Pipeline. Since `stash` artifacts aren't accessible outside of the\nPipeline run that created them, this has not created any limitations on usage. But with Declarative stage restarting,\nyou may want to be able to `unstash` artifacts from a stage which ran before the stage you're restarting from.\n\nTo enable this, there is a job property that allows you to configure a maximu"
  },
  "3713": {
    "source_file": "running-pipelines.txt",
    "text": "tifacts from a stage which ran before the stage you're restarting from.\n\nTo enable this, there is a job property that allows you to configure a maximum number of completed runs whose\n`stash` artifacts should be preserved for reuse in a restarted run. You can specify anywhere from 1 to 50 as the\nnumber of runs to preserve.\n\nThis job property can be configured in your Declarative Pipeline's `options"
  },
  "3714": {
    "source_file": "running-pipelines.txt",
    "text": " You can specify anywhere from 1 to 50 as the\nnumber of runs to preserve.\n\nThis job property can be configured in your Declarative Pipeline's `options` section, as below:\n\noptions {\n    preserveStashes() // <1> // or\n    preserveStashes(buildCount: 5) // <2> }\n\n<1> The default number of runs to preserve is 1, just the most recent completed build.\n<2> If a number for `buildCount` outside of the ran"
  },
  "3715": {
    "source_file": "running-pipelines.txt",
    "text": ") // <2> }\n\n<1> The default number of runs to preserve is 1, just the most recent completed build.\n<2> If a number for `buildCount` outside of the range of 1 to 50 is specified, the Pipeline will fail with a\nvalidation error.\n\nWhen a Pipeline completes, it will check to see if any previously completed runs should have their `stash` artifacts\ncleared.\n\nThe scheduling function lets you schedule jobs"
  },
  "3716": {
    "source_file": "running-pipelines.txt",
    "text": "es, it will check to see if any previously completed runs should have their `stash` artifacts\ncleared.\n\nThe scheduling function lets you schedule jobs to run automatically during off-hours or down times.\nScheduling jobs can help you to scale your environment as Jenkins usage increases.\nThis video provides insight on the scheduling function and its various configuration options.\n\nvideo::JhvVJtYFUm0"
  },
  "3717": {
    "source_file": "running-pipelines.txt",
    "text": "ironment as Jenkins usage increases.\nThis video provides insight on the scheduling function and its various configuration options.\n\nvideo::JhvVJtYFUm0[youtube,width=800,height=420]"
  },
  "3718": {
    "source_file": "scaling-jenkins-on-kubernetes.txt",
    "text": "layout: section\n\n\nWhen using the standalone Jenkins server you don\u2019t have to worry about multiple servers and nodes.\nHowever, the issue with this setup is that your server can become overloaded with numerous jobs running at the same time.\nThere are ways to solve this problem by increasing the number of executors, but you soon end up hitting a performance limit.\n\nTo overcome this problem, you can o"
  },
  "3719": {
    "source_file": "scaling-jenkins-on-kubernetes.txt",
    "text": "ays to solve this problem by increasing the number of executors, but you soon end up hitting a performance limit.\n\nTo overcome this problem, you can offload some of the jobs to different machines called Jenkins agents.\n\nScalability is a measure that shows the ability of a system to expand its capabilities to handle additional load.\nOne of the strongest sides of Jenkins is that it has a scaling fea"
  },
  "3720": {
    "source_file": "scaling-jenkins-on-kubernetes.txt",
    "text": "shows the ability of a system to expand its capabilities to handle additional load.\nOne of the strongest sides of Jenkins is that it has a scaling feature out-of-the-box.\nJenkins scaling is based on the controller/agents model, where you have a number of agents and one main Jenkins controller that is responsible mainly for distributing jobs across the agents.\nJenkins agents run a small program tha"
  },
  "3721": {
    "source_file": "scaling-jenkins-on-kubernetes.txt",
    "text": "r of agents and one main Jenkins controller that is responsible mainly for distributing jobs across the agents.\nJenkins agents run a small program that communicates with the Jenkins controller to check if there\u2019s any job it can run.\nWhen Jenkins finds a job scheduled, it transfers the build to the agent.\n\nTaking it a step further, running a container orchestrator such as Kubernetes, you can make J"
  },
  "3722": {
    "source_file": "scaling-jenkins-on-kubernetes.txt",
    "text": "s a job scheduled, it transfers the build to the agent.\n\nTaking it a step further, running a container orchestrator such as Kubernetes, you can make Jenkins do smarter things.\nThe Jenkins controller is responsible for the hosting configuration and the distribution of jobs to multiple agents.\nHowever, you don\u2019t need the agents to be preexisting, they can be created on the fly, as in when they\u2019re re"
  },
  "3723": {
    "source_file": "scaling-jenkins-on-kubernetes.txt",
    "text": "e distribution of jobs to multiple agents.\nHowever, you don\u2019t need the agents to be preexisting, they can be created on the fly, as in when they\u2019re required.\n\nAutohealing is possible::\nIf your build or your agent gets corrupted, you no longer need to worry \u2014 Jenkins will remove the unhealthy instance and spin up a new one.\n\nRun builds in parallel::\nYou no longer have to plan the executors and limi"
  },
  "3724": {
    "source_file": "scaling-jenkins-on-kubernetes.txt",
    "text": " worry \u2014 Jenkins will remove the unhealthy instance and spin up a new one.\n\nRun builds in parallel::\nYou no longer have to plan the executors and limit them; instead, Jenkins will spin up an agent instance and run your build in it.\n\nEven load distribution::\nKubernetes manages loads well, and it\u2019ll make sure your Jenkins agents spin up in the best available server, which makes your builds faster an"
  },
  "3725": {
    "source_file": "scaling-jenkins-on-kubernetes.txt",
    "text": "ution::\nKubernetes manages loads well, and it\u2019ll make sure your Jenkins agents spin up in the best available server, which makes your builds faster and more efficient.\n\nTo install a Jenkins controller, create your Docker image based on the base Jenkins image, which can be found in the official Docker repository (keep in mind that Docker should be installed on your local machine, see the installati"
  },
  "3726": {
    "source_file": "scaling-jenkins-on-kubernetes.txt",
    "text": "ns image, which can be found in the official Docker repository (keep in mind that Docker should be installed on your local machine, see the installation steps ).\nFor this, you need to create a Dockerfile.\nHaving your Jenkins setup as a Dockerfile is highly recommended to make your continuous integration infrastructure replicable and have it ready for setup from scratch.\nSo let\u2019s create our first e"
  },
  "3727": {
    "source_file": "scaling-jenkins-on-kubernetes.txt",
    "text": "highly recommended to make your continuous integration infrastructure replicable and have it ready for setup from scratch.\nSo let\u2019s create our first example Dockerfile for the Jenkins controller:\n\n.Dockerfile\n\nFROM jenkins/jenkins:lts-slim-jdk21 <1> # Pipelines with Blue Ocean UI and Kubernetes\nRUN jenkins-plugin-cli --plugins blueocean kubernetes <2> <1> `FROM [image_name]:[tag]` - this line mean"
  },
  "3728": {
    "source_file": "scaling-jenkins-on-kubernetes.txt",
    "text": "# Pipelines with Blue Ocean UI and Kubernetes\nRUN jenkins-plugin-cli --plugins blueocean kubernetes <2> <1> `FROM [image_name]:[tag]` - this line means that our Dockerfile will be based on an existing image.\nIt is obvious that for our Dockerfile, we take the Jenkins base image, which you can find in the .\n<2> `RUN [command]` - this line means that we are going to run this command inside the image "
  },
  "3729": {
    "source_file": "scaling-jenkins-on-kubernetes.txt",
    "text": "take the Jenkins base image, which you can find in the .\n<2> `RUN [command]` - this line means that we are going to run this command inside the image during the build process.\nIn our case we use the `RUN` command to install different common Jenkins plugins, which can be required for your Jenkins controller.\n\nYou can install additional plugins just by adding similar commands inside your Dockerfile "
  },
  "3730": {
    "source_file": "scaling-jenkins-on-kubernetes.txt",
    "text": "lugins, which can be required for your Jenkins controller.\n\nYou can install additional plugins just by adding similar commands inside your Dockerfile like we did above.\nHowever, one of the plugins above is critical for installation.\nIt is the plugin:kubernetes[Kubernetes plugin].\nThis plugin is designed to implement Jenkins scaling on top of a Kubernetes cluster.\n\nNext, we need to build the image "
  },
  "3731": {
    "source_file": "scaling-jenkins-on-kubernetes.txt",
    "text": "kubernetes[Kubernetes plugin].\nThis plugin is designed to implement Jenkins scaling on top of a Kubernetes cluster.\n\nNext, we need to build the image that can be used and run inside the Kubernetes cluster later on.\n\nTIP: Before building the image, if you use Minikube, then you need to keep in mind that Minikube runs on your local machine but inside a virtual machine.\nThat\u2019s why Minikube doesn\u2019t se"
  },
  "3732": {
    "source_file": "scaling-jenkins-on-kubernetes.txt",
    "text": " you use Minikube, then you need to keep in mind that Minikube runs on your local machine but inside a virtual machine.\nThat\u2019s why Minikube doesn\u2019t see the Docker images you created on your local machine.\nYou can build your Docker image right inside your Minikube virtual machine, but for this you need to execute this command:\n\neval $(minikube docker-env)\n\nThis command doesn\u2019t show any output after"
  },
  "3733": {
    "source_file": "scaling-jenkins-on-kubernetes.txt",
    "text": "your Minikube virtual machine, but for this you need to execute this command:\n\neval $(minikube docker-env)\n\nThis command doesn\u2019t show any output after execution so if you didn\u2019t get any errors then everything should be fine.\nTo build a Docker image based on the Dockerfile you created, all you need is to run this command from the same folder where you have created the Dockerfile:\n\ndocker build -t m"
  },
  "3734": {
    "source_file": "scaling-jenkins-on-kubernetes.txt",
    "text": "ased on the Dockerfile you created, all you need is to run this command from the same folder where you have created the Dockerfile:\n\ndocker build -t my-jenkins-image:1.1 .\n\nAfter the build process is finished, let\u2019s verify that the newly created image is there:\n\ndocker images\nREPOSITORY                    TAG                 IMAGE ID            CREATED             SIZE\nmy-jenkins-image            "
  },
  "3735": {
    "source_file": "scaling-jenkins-on-kubernetes.txt",
    "text": "e is there:\n\ndocker images\nREPOSITORY                    TAG                 IMAGE ID            CREATED             SIZE\nmy-jenkins-image              1.1                 d6e46aa2470d        10 minutes ago      969MB\n\nCongratulations! Your Jenkins controller image is created and can be used inside your Kubernetes cluster.\n\nAfter successfully creating your Jenkins image, follow the steps explained"
  },
  "3736": {
    "source_file": "scaling-jenkins-on-kubernetes.txt",
    "text": "ontroller image is created and can be used inside your Kubernetes cluster.\n\nAfter successfully creating your Jenkins image, follow the steps explained in the  to deploy your Jenkins controller.\n\nEnsure to replace the image in the `jenkins-deployment.yaml` file with your locally built image above.\n\nTo validate that creating the deployment was successful you can invoke:\n\nkubectl get deployments -n j"
  },
  "3737": {
    "source_file": "scaling-jenkins-on-kubernetes.txt",
    "text": "yaml` file with your locally built image above.\n\nTo validate that creating the deployment was successful you can invoke:\n\nkubectl get deployments -n jenkins\n\nTo validate that creating the service was successful you can run:\n\nkubectl get services -n jenkins\nNAME       TYPE        CLUSTER-IP       EXTERNAL-IP    PORT(S)           AGE\njenkins    NodePort    10.103.31.217    <none>         8080:32664/"
  },
  "3738": {
    "source_file": "scaling-jenkins-on-kubernetes.txt",
    "text": "enkins\nNAME       TYPE        CLUSTER-IP       EXTERNAL-IP    PORT(S)           AGE\njenkins    NodePort    10.103.31.217    <none>         8080:32664/TCP    59s\n\nSo now we have created a deployment and service, how do we access our Jenkins controller?\n\nFrom the output above we can see that the service has been exposed on port `32664`.\nIn addition to that, we need to know the IP of the Kubernetes c"
  },
  "3739": {
    "source_file": "scaling-jenkins-on-kubernetes.txt",
    "text": "?\n\nFrom the output above we can see that the service has been exposed on port `32664`.\nIn addition to that, we need to know the IP of the Kubernetes cluster itself.\nWe can get it by using this command:\n\nminikube ip\n192.168.99.100\n\nNow we can access the Jenkins controller at http://192.168.99.100:32664/\n\nNow it\u2019s time to configure Jenkins agents.\nAs you might remember, we installed the Kubernetes p"
  },
  "3740": {
    "source_file": "scaling-jenkins-on-kubernetes.txt",
    "text": "he Jenkins controller at http://192.168.99.100:32664/\n\nNow it\u2019s time to configure Jenkins agents.\nAs you might remember, we installed the Kubernetes plugin using the controller Dockerfile so we don\u2019t need to install anything separately and the required plugin should be already there.\n\nIn order to configure the Jenkins agents, we need to know the URL of the Kubernetes controller and the internal cl"
  },
  "3741": {
    "source_file": "scaling-jenkins-on-kubernetes.txt",
    "text": "ed plugin should be already there.\n\nIn order to configure the Jenkins agents, we need to know the URL of the Kubernetes controller and the internal cluster URL of the Jenkins pod.\nYou can get the Kubernetes controller URL by this specified command:\n\nkubectl cluster-info\nKubernetes control plane is running at https://192.168.49.2:8443\nKubeDNS is running at https://192.168.49.2:8443/api/v1/namespace"
  },
  "3742": {
    "source_file": "scaling-jenkins-on-kubernetes.txt",
    "text": "kubectl cluster-info\nKubernetes control plane is running at https://192.168.49.2:8443\nKubeDNS is running at https://192.168.49.2:8443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n\nThe Jenkins pod URL port is standard - `8080`, and you can get the IP address by following the steps below.\nFirst, we need to"
  },
  "3743": {
    "source_file": "scaling-jenkins-on-kubernetes.txt",
    "text": "ctl cluster-info dump'.\n\nThe Jenkins pod URL port is standard - `8080`, and you can get the IP address by following the steps below.\nFirst, we need to get the Jenkins pod id, which is the value of the output provided by this command:\n\nkubectl get pods -n jenkins | grep jenkins\n<pod_id>   1/1       Running   0          9m\n\nSecond, we need to run the command that describes the pods passing the pod i"
  },
  "3744": {
    "source_file": "scaling-jenkins-on-kubernetes.txt",
    "text": "s -n jenkins | grep jenkins\n<pod_id>   1/1       Running   0          9m\n\nSecond, we need to run the command that describes the pods passing the pod id as an argument.\nYou will find the IP address in the output:\n\nkubectl describe pod -n jenkins jenkins-5fdbf5d7c5-dj2rq\n\u2026..\nIP:             172.17.0.4\n\nNow, we are ready to fill in the Kubernetes plugin configuration.\nIn order to do that, open the Je"
  },
  "3745": {
    "source_file": "scaling-jenkins-on-kubernetes.txt",
    "text": "ns-5fdbf5d7c5-dj2rq\n\u2026..\nIP:             172.17.0.4\n\nNow, we are ready to fill in the Kubernetes plugin configuration.\nIn order to do that, open the Jenkins UI and navigate to \u201cManage Jenkins -> Nodes and Clouds -> Clouds -> Add a new cloud -> Kubernetes and fill in the `Kubernetes URL` and `Jenkins URL` appropriately, by using the values which we have just collected in the previous step.\n\nIn addit"
  },
  "3746": {
    "source_file": "scaling-jenkins-on-kubernetes.txt",
    "text": "tes and fill in the `Kubernetes URL` and `Jenkins URL` appropriately, by using the values which we have just collected in the previous step.\n\nIn addition to that, in the `Kubernetes Pod Template` section, we need to configure the image that will be used to spin up the agents.\nIf you have some custom requirements for your agents, you can build one more Dockerfile with the appropriate changes the sa"
  },
  "3747": {
    "source_file": "scaling-jenkins-on-kubernetes.txt",
    "text": "sed to spin up the agents.\nIf you have some custom requirements for your agents, you can build one more Dockerfile with the appropriate changes the same way we did for the Jenkins controller.\nOn the other hand, if you don\u2019t have unique requirements for your agents, you can use the default Jenkins agents image available on the .\nIn the \u2018Kubernetes Pod Template\u2019 section you need to specify the follo"
  },
  "3748": {
    "source_file": "scaling-jenkins-on-kubernetes.txt",
    "text": "or your agents, you can use the default Jenkins agents image available on the .\nIn the \u2018Kubernetes Pod Template\u2019 section you need to specify the following (the rest of the configuration is up to you):\n\nKubernetes Pod Template Name - can be any and will be shown as a prefix for unique generated agents' names, which will be run automatically during builds.\n\nDocker image - the Docker image name that "
  },
  "3749": {
    "source_file": "scaling-jenkins-on-kubernetes.txt",
    "text": "ll be shown as a prefix for unique generated agents' names, which will be run automatically during builds.\n\nDocker image - the Docker image name that will be used as a reference to spin up new Jenkins agents.\n\nNow all the configuration seems to be in place and we are ready for some tests.\nLet\u2019s create two different build plans.\n\nNow let\u2019s trigger the execution for both of the builds.\nYou should se"
  },
  "3750": {
    "source_file": "scaling-jenkins-on-kubernetes.txt",
    "text": " place and we are ready for some tests.\nLet\u2019s create two different build plans.\n\nNow let\u2019s trigger the execution for both of the builds.\nYou should see that both build plans appear in the `Build Queue` box almost immediately.\n\nIf you applied the correct configuration in the previous steps, you should see that you have two additional executors and both have the prefix `jenkins-agent`, in about 10-1"
  },
  "3751": {
    "source_file": "scaling-jenkins-on-kubernetes.txt",
    "text": "ect configuration in the previous steps, you should see that you have two additional executors and both have the prefix `jenkins-agent`, in about 10-15 seconds.\nThis means that these nodes were automatically launched inside the Kubernetes cluster by using the Jenkins Kubernetes plugin, and, most importantly, that they were run in parallel.\nYou can also confirm this from the Kubernetes dashboard, w"
  },
  "3752": {
    "source_file": "scaling-jenkins-on-kubernetes.txt",
    "text": "using the Jenkins Kubernetes plugin, and, most importantly, that they were run in parallel.\nYou can also confirm this from the Kubernetes dashboard, which will show you a couple of new pods.\nAfter both builds are completed, you should see that both build executors have been removed and are not available inside the cluster anymore.\n\nCongratulations! We've successfully set up scalable Jenkins on top"
  },
  "3753": {
    "source_file": "scaling-jenkins-on-kubernetes.txt",
    "text": "uild executors have been removed and are not available inside the cluster anymore.\n\nCongratulations! We've successfully set up scalable Jenkins on top of a Kubernetes cluster."
  },
  "3754": {
    "source_file": "scaling-pipeline.txt",
    "text": "layout: section\ntitle: Scaling Pipelines\n\n\nifdef::env-github[:imagesdir: ../resources]\nifndef::env-github[:imagesdir: ../../resources]\n\nOne of the main bottlenecks in Pipeline is that it writes transient data to disk *FREQUENTLY* so that running pipelines can handle an unexpected Jenkins restart or system crash. This durability is useful for many users but its performance cost can be a problem.\n\nP"
  },
  "3755": {
    "source_file": "scaling-pipeline.txt",
    "text": "lines can handle an unexpected Jenkins restart or system crash. This durability is useful for many users but its performance cost can be a problem.\n\nPipeline now includes features to let users improve performance by reducing how much data is written to disk and how often it is written -- at a small cost to durability.  In some special cases, users may not be able to resume or visualize running Pip"
  },
  "3756": {
    "source_file": "scaling-pipeline.txt",
    "text": "to disk and how often it is written -- at a small cost to durability.  In some special cases, users may not be able to resume or visualize running Pipelines if Jenkins shuts down suddenly without getting a chance to write data.\n\nBecause these settings include a trade-off of speed vs. durability, they are initially opt-in.  To enable performance-optimized modes, users need to explicitly set a _Spee"
  },
  "3757": {
    "source_file": "scaling-pipeline.txt",
    "text": "s include a trade-off of speed vs. durability, they are initially opt-in.  To enable performance-optimized modes, users need to explicitly set a _Speed/Durability Setting_ for Pipelines.  If no explicit choice is made, pipelines currently default to the \"maximum durability\" setting and write to disk as they have in the past.  There are some I/O optimizations to this mode included in the same plugi"
  },
  "3758": {
    "source_file": "scaling-pipeline.txt",
    "text": "the \"maximum durability\" setting and write to disk as they have in the past.  There are some I/O optimizations to this mode included in the same plugin releases, but the benefits are much smaller.\n\nThere are 3 ways to configure the durability setting:\n\n*Globally*, you can choose a global default durability setting under \"Manage Jenkins\" > \"System\", labelled \"Pipeline Speed/Durability Settings\".  Y"
  },
  "3759": {
    "source_file": "scaling-pipeline.txt",
    "text": ":\n\n*Globally*, you can choose a global default durability setting under \"Manage Jenkins\" > \"System\", labelled \"Pipeline Speed/Durability Settings\".  You can override these with the more specific settings below.\n\n*Per pipeline job:* at the top of the job configuration, labelled \"Custom Pipeline Speed/Durability Level\" - this overrides the global setting.  Or, use a \"properties\" step - the setting w"
  },
  "3760": {
    "source_file": "scaling-pipeline.txt",
    "text": "job configuration, labelled \"Custom Pipeline Speed/Durability Level\" - this overrides the global setting.  Or, use a \"properties\" step - the setting will apply to the NEXT run after the step is executed (same result).\n\n*Per-branch for a multibranch project:* configure a custom Branch Property Strategy (under the SCM) and add a property for Custom Pipeline Speed/Durability Level.  This overrides th"
  },
  "3761": {
    "source_file": "scaling-pipeline.txt",
    "text": "roject:* configure a custom Branch Property Strategy (under the SCM) and add a property for Custom Pipeline Speed/Durability Level.  This overrides the global setting. You can also use a \"properties\" step to override the setting, but remember that you may have to run the step again to undo this.\n\nDurability settings will take effect with the next applicable Pipeline run, not immediately.  The sett"
  },
  "3762": {
    "source_file": "scaling-pipeline.txt",
    "text": "u may have to run the step again to undo this.\n\nDurability settings will take effect with the next applicable Pipeline run, not immediately.  The setting will be displayed in the log.\n\n* Yes, if your Jenkins controller uses NFS, magnetic storage, runs many Pipelines at once, or shows high iowait.\n* Yes, if you are running Pipelines with many steps (more than several hundred).\n* Yes, if your Pipeli"
  },
  "3763": {
    "source_file": "scaling-pipeline.txt",
    "text": "s many Pipelines at once, or shows high iowait.\n* Yes, if you are running Pipelines with many steps (more than several hundred).\n* Yes, if your Pipeline stores large files or complex data to variables in the script, keeps that variable in scope for future use, and then runs steps.  This sounds oddly specific but happens more than you'd expect.\n** For example: `readFile` step with a large XML/JSON "
  },
  "3764": {
    "source_file": "scaling-pipeline.txt",
    "text": "uture use, and then runs steps.  This sounds oddly specific but happens more than you'd expect.\n** For example: `readFile` step with a large XML/JSON file, or using configuration information from parsing such a file with .\n** Another common pattern is a \"summary\" object containing data from many branches (logs, results, or statistics). Often this is visible because you'll be adding to it often via"
  },
  "3765": {
    "source_file": "scaling-pipeline.txt",
    "text": "s a \"summary\" object containing data from many branches (logs, results, or statistics). Often this is visible because you'll be adding to it often via an add/append or `Map.put()` operations.\n** Large arrays of data or ``Map``s of configuration information are another common example of this situation.\n* No, if your Pipelines spend almost all their time waiting for a few shell/batch scripts to fini"
  },
  "3766": {
    "source_file": "scaling-pipeline.txt",
    "text": "mation are another common example of this situation.\n* No, if your Pipelines spend almost all their time waiting for a few shell/batch scripts to finish.  This ISN'T a magic \"go fast\" button for everything!\n* No, if Pipelines are writing massive amounts of data to logs (logging is unchanged).\n* No, if you are not using Pipelines, or your system is loaded down by other factors.\n* No, if you don't e"
  },
  "3767": {
    "source_file": "scaling-pipeline.txt",
    "text": "nts of data to logs (logging is unchanged).\n* No, if you are not using Pipelines, or your system is loaded down by other factors.\n* No, if you don't enable higher-performance modes for pipelines.\n\n*Stability of Jenkins ITSELF is not changed regardless of this setting* - it only applies to Pipelines.  The worst-case behavior for Pipelines reverts to something like Freestyle builds -- running Pipeli"
  },
  "3768": {
    "source_file": "scaling-pipeline.txt",
    "text": "s of this setting* - it only applies to Pipelines.  The worst-case behavior for Pipelines reverts to something like Freestyle builds -- running Pipelines that cannot persist transient data may not be able to resume or be displayed in Blue Ocean/Stage View/etc, but will show logs.  This impacts _only_ running Pipelines and only when Jenkins is shut down abruptly and not gracefully before they get t"
  },
  "3769": {
    "source_file": "scaling-pipeline.txt",
    "text": " View/etc, but will show logs.  This impacts _only_ running Pipelines and only when Jenkins is shut down abruptly and not gracefully before they get to complete.\n\nA *\"graceful\" shutdown* is where Jenkins goes through a full shutdown process, such as visiting http://[jenkins-server]/exit,  or using normal service shutdown scripts (if Jenkins is healthy).  Sending a SIGTERM/SIGINT to Jenkins will tr"
  },
  "3770": {
    "source_file": "scaling-pipeline.txt",
    "text": "visiting http://[jenkins-server]/exit,  or using normal service shutdown scripts (if Jenkins is healthy).  Sending a SIGTERM/SIGINT to Jenkins will trigger a graceful shutdown.  Note that running Pipelines do not need to complete (you do not need to use /safeExit to shut down).\n\nA *\"dirty\" shutdown* is when Jenkins does not get to do normal shutdown processes. This can occur if the process is forc"
  },
  "3771": {
    "source_file": "scaling-pipeline.txt",
    "text": "use /safeExit to shut down).\n\nA *\"dirty\" shutdown* is when Jenkins does not get to do normal shutdown processes. This can occur if the process is forcibly terminated.  The most common causes are using SIGKILL to terminate the Jenkins process or killing the container/VM running Jenkins.  Simply stopping or pausing the container/VM will not cause this, as long as the Jenkins process is able to resum"
  },
  "3772": {
    "source_file": "scaling-pipeline.txt",
    "text": "ng the container/VM running Jenkins.  Simply stopping or pausing the container/VM will not cause this, as long as the Jenkins process is able to resume.\nA dirty shutdown can also happen due to catastrophic operating system failures, including the Linux OOMKiller attacking the Jenkins java process to free memory.\n\n*Atomic writes:* All settings *except* \"maximum durability\" currently avoid atomic wr"
  },
  "3773": {
    "source_file": "scaling-pipeline.txt",
    "text": "ux OOMKiller attacking the Jenkins java process to free memory.\n\n*Atomic writes:* All settings *except* \"maximum durability\" currently avoid atomic writes -- what this means is that if the operating system running Jenkins fails, data that is buffered for writing to disk will not be flushed, it will be lost.  This is quite rare, but can happen as a result of container or virtualization operations t"
  },
  "3774": {
    "source_file": "scaling-pipeline.txt",
    "text": " for writing to disk will not be flushed, it will be lost.  This is quite rare, but can happen as a result of container or virtualization operations that halt the operating system or disconnect storage.  Usually this data is flushed pretty quickly to disk, so the window for data loss is brief.  On Linux this flush-to-disk can be forced by running 'sync'.  In some rare cases this can also result in"
  },
  "3775": {
    "source_file": "scaling-pipeline.txt",
    "text": " disk, so the window for data loss is brief.  On Linux this flush-to-disk can be forced by running 'sync'.  In some rare cases this can also result in a build that cannot be loaded.\n\n* Jenkins LTS 2.73+ or higher (or a weekly 2.62+)\n* For *all* the Pipeline plugins below, at least the specified minimum version must be installed\n    - Pipeline: API (workflow-api) v2.25\n    - Pipeline: Groovy (workf"
  },
  "3776": {
    "source_file": "scaling-pipeline.txt",
    "text": "ipeline plugins below, at least the specified minimum version must be installed\n    - Pipeline: API (workflow-api) v2.25\n    - Pipeline: Groovy (workflow-cps) v2.43\n    - Pipeline: Job (workflow-job) v2.17\n    - Pipeline: Supporting APIs (workflow-support) v2.17\n    - Pipeline: Multibranch (workflow-multibranch) v2.17 - optional, only needed to enable this setting for multibranch pipelines.\n* Rest"
  },
  "3777": {
    "source_file": "scaling-pipeline.txt",
    "text": "pport) v2.17\n    - Pipeline: Multibranch (workflow-multibranch) v2.17 - optional, only needed to enable this setting for multibranch pipelines.\n* Restart the controller to use the updated plugins - note: you need all of them to take advantage.\n\n* Performance-optimized mode (\"PERFORMANCE_OPTIMIZED\") - *Greatly* reduces disk I/O.  If Pipelines do not finish AND Jenkins is not shut down gracefully, t"
  },
  "3778": {
    "source_file": "scaling-pipeline.txt",
    "text": "formance-optimized mode (\"PERFORMANCE_OPTIMIZED\") - *Greatly* reduces disk I/O.  If Pipelines do not finish AND Jenkins is not shut down gracefully, they may lose data and behave like Freestyle projects -- see details above.\n\n* Maximum survivability/durability (\"MAX_SURVIVABILITY\") - behaves just like Pipeline did before, slowest option.  Use this for running your most critical Pipelines.\n\n* Less "
  },
  "3779": {
    "source_file": "scaling-pipeline.txt",
    "text": "durability (\"MAX_SURVIVABILITY\") - behaves just like Pipeline did before, slowest option.  Use this for running your most critical Pipelines.\n\n* Less durable, a bit faster (\"SURVIVABLE_NONATOMIC\") - Writes data with every step but avoids atomic writes. This is faster than maximum durability mode, especially on networked filesystems.  It carries a small extra risk (details above under \"What Am I Gi"
  },
  "3780": {
    "source_file": "scaling-pipeline.txt",
    "text": "s. This is faster than maximum durability mode, especially on networked filesystems.  It carries a small extra risk (details above under \"What Am I Giving Up: Atomic Writes\").\n\n* Use the \"performance-optimized\" mode for most pipelines and especially basic build-test Pipelines or anything that can simply be run again if needed.\n* Use either the \"maximum durability\" or \"less durable\" mode for pipeli"
  },
  "3781": {
    "source_file": "scaling-pipeline.txt",
    "text": "basic build-test Pipelines or anything that can simply be run again if needed.\n* Use either the \"maximum durability\" or \"less durable\" mode for pipelines when you need a guaranteed record of their execution (auditing). These two modes record every step run. For example, use one of these two modes when:\n** you have a pipeline that modifies the state of critical infrastructure\n** you do a production"
  },
  "3782": {
    "source_file": "scaling-pipeline.txt",
    "text": "ep run. For example, use one of these two modes when:\n** you have a pipeline that modifies the state of critical infrastructure\n** you do a production deployment\n* Set a global default (see above) of \"performance-optimized\" for the Durability Setting, and then where needed set \"maximum durability\" on specific Pipeline jobs or Multibranch Pipeline branches (\"master\" or release branches).\n* You can "
  },
  "3783": {
    "source_file": "scaling-pipeline.txt",
    "text": ", and then where needed set \"maximum durability\" on specific Pipeline jobs or Multibranch Pipeline branches (\"master\" or release branches).\n* You can force a Pipeline to persist data by pausing it.\n\n* Use @NonCPS-annotated functions for more complex work. This means more involved processing, logic, and transformations. This lets you leverage additional Groovy & functional features for more powerfu"
  },
  "3784": {
    "source_file": "scaling-pipeline.txt",
    "text": "work. This means more involved processing, logic, and transformations. This lets you leverage additional Groovy & functional features for more powerful, concise, and performant code.\n** This still runs on controller so be aware of complexity of the work, but is much faster than native Pipeline code because it doesn\u2019t provide durability and uses a faster execution model. Still, be mindful of the CP"
  },
  "3785": {
    "source_file": "scaling-pipeline.txt",
    "text": "ork, but is much faster than native Pipeline code because it doesn\u2019t provide durability and uses a faster execution model. Still, be mindful of the CPU cost and offload to executors when the cost becomes too high.\n** @NonCPS functions can use a much broader subset of the Groovy language, such as iterators and functional features, which makes them more terse and fast to write.\n** @NonCPS functions "
  },
  "3786": {
    "source_file": "scaling-pipeline.txt",
    "text": "broader subset of the Groovy language, such as iterators and functional features, which makes them more terse and fast to write.\n** @NonCPS functions *should not use* Pipeline steps internally, however you can store the result of a Pipeline step to a variable and use it that as the input to a @NonCPS function.\n*** *Gotcha*: It\u2019s not guaranteed that use of a step will generate an error (there is an"
  },
  "3787": {
    "source_file": "scaling-pipeline.txt",
    "text": " variable and use it that as the input to a @NonCPS function.\n*** *Gotcha*: It\u2019s not guaranteed that use of a step will generate an error (there is an open RFE to implement that), but you should not rely on that behavior. You may see improper handling of exceptions.\n** While normal Pipeline is restricted to serializable local variables, @NonCPS functions can use more complex, nonserializable types"
  },
  "3788": {
    "source_file": "scaling-pipeline.txt",
    "text": "g of exceptions.\n** While normal Pipeline is restricted to serializable local variables, @NonCPS functions can use more complex, nonserializable types internally (for example regex matchers, etc). Parameters and return types should still be Serializable, however.\n*** *Gotcha*: improper usages are not guaranteed to raise an error with normal Pipeline (optimizations may mask the issue), but it is un"
  },
  "3789": {
    "source_file": "scaling-pipeline.txt",
    "text": "ble, however.\n*** *Gotcha*: improper usages are not guaranteed to raise an error with normal Pipeline (optimizations may mask the issue), but it is unsafe to rely on this behavior.\n** *General Gotcha*: when using running @NonCPS functions, the actual error can sometimes be swallowed by pipeline creating a confusing error message. Combat this by using a `try/catch` block and potentially using an `e"
  },
  "3790": {
    "source_file": "scaling-pipeline.txt",
    "text": " error can sometimes be swallowed by pipeline creating a confusing error message. Combat this by using a `try/catch` block and potentially using an `echo` to plain text print the error message in the `catch`\n* *Whenever possible, run Jenkins with fast SSD-backed storage and not hard drives.  This can make a _huge_ difference.*\n* In general try to fit the tool to the job.  Consider writing short Sh"
  },
  "3791": {
    "source_file": "scaling-pipeline.txt",
    "text": "t SSD-backed storage and not hard drives.  This can make a _huge_ difference.*\n* In general try to fit the tool to the job.  Consider writing short Shell/Batch/Groovy/Python scripts when running a complex process using a build agent.  Good examples include processing data, communicating interactively with REST APIs, and parsing/templating larger XML or JSON files.  The `sh` and `bat` steps are hel"
  },
  "3792": {
    "source_file": "scaling-pipeline.txt",
    "text": "nclude processing data, communicating interactively with REST APIs, and parsing/templating larger XML or JSON files.  The `sh` and `bat` steps are helpful to invoke these, especially with `returnStdout: true` to return the output from this script and save it as a variable (Scripted Pipeline).\n** The Pipeline DSL is not designed for arbitrary networking and computation tasks - it is intended for CI"
  },
  "3793": {
    "source_file": "scaling-pipeline.txt",
    "text": " save it as a variable (Scripted Pipeline).\n** The Pipeline DSL is not designed for arbitrary networking and computation tasks - it is intended for CI/CD scripting.\n* Use the latest versions of the Pipeline plugins and Script Security, if applicable.  These include regular performance improvements.\n* Try to simplify Pipeline code by reducing the number of steps run and using simpler Groovy code fo"
  },
  "3794": {
    "source_file": "scaling-pipeline.txt",
    "text": "  These include regular performance improvements.\n* Try to simplify Pipeline code by reducing the number of steps run and using simpler Groovy code for Scripted Pipelines.\n* Consolidate sequential steps of the same type if you can, for example by using one Shell step to invoke a helper script rather than running many steps.\n* Try to limit the amount of data written to logs by Pipelines.  If you ar"
  },
  "3795": {
    "source_file": "scaling-pipeline.txt",
    "text": "ng one Shell step to invoke a helper script rather than running many steps.\n* Try to limit the amount of data written to logs by Pipelines.  If you are writing several MB of log data, such as from a build tool, consider instead writing this to an external file, compressing it, and archiving it as a build artifact.\n* When using Jenkins with more than 6 GB of heap use the  to minimize garbage collec"
  },
  "3796": {
    "source_file": "scaling-pipeline.txt",
    "text": "ernal file, compressing it, and archiving it as a build artifact.\n* When using Jenkins with more than 6 GB of heap use the  to minimize garbage collection pause times and overhead."
  },
  "3797": {
    "source_file": "scan.txt",
    "text": "title: How to use the Jenkins Security Scan\nlayout: developer\nreferences:\n- title: Introductory blog post (2020)\n  url: https://www.jenkins.io/blog/2020/11/04/codeql/\n- title: GitHub CodeQL Repository\n  url: https://github.com/github/codeql\n- title: Jenkins CodeQL Repository\n  url: https://github.com/jenkins-infra/jenkins-codeql\n- title: Jenkins Security Scan Repository\n  url: https://github.com/j"
  },
  "3798": {
    "source_file": "scan.txt",
    "text": "Jenkins CodeQL Repository\n  url: https://github.com/jenkins-infra/jenkins-codeql\n- title: Jenkins Security Scan Repository\n  url: https://github.com/jenkins-infra/jenkins-security-scan\n\n\nJenkins uses the https://github.com/jenkinsci/stapler[Stapler web framework], instead of a more common framework.\nAs a result, generic static analysis tools are often unable to find common vulnerabilities in Jenki"
  },
  "3799": {
    "source_file": "scan.txt",
    "text": "eb framework], instead of a more common framework.\nAs a result, generic static analysis tools are often unable to find common vulnerabilities in Jenkins core and plugins.\n\nThe  created a custom code scanner based on GitHub's https://github.com/github/codeql[CodeQL].\nIt is capable of finding vulnerabilities common in Jenkins plugins.\n\nThis page explains how to set up code scanning with this tool.\n\n"
  },
  "3800": {
    "source_file": "scan.txt",
    "text": "/codeql[CodeQL].\nIt is capable of finding vulnerabilities common in Jenkins plugins.\n\nThis page explains how to set up code scanning with this tool.\n\nNOTE: We also publish the Jenkins-specific code scanning rules as a https://docs.github.com/en/code-security/codeql-cli/getting-started-with-the-codeql-cli/customizing-analysis-with-codeql-packs[CodeQL pack] for use in a standard CodeQL workflow.\nRef"
  },
  "3801": {
    "source_file": "scan.txt",
    "text": "security/codeql-cli/getting-started-with-the-codeql-cli/customizing-analysis-with-codeql-packs[CodeQL pack] for use in a standard CodeQL workflow.\nRefer to https://github.com/jenkins-infra/jenkins-codeql?tab=readme-ov-file#use-in-a-regular-codeql-workflow[the documentation] for usage instructions.\n\nIn your GitHub repository, select the \"Actions\" link on top.\nIf you already have some workflows in y"
  },
  "3802": {
    "source_file": "scan.txt",
    "text": "kflow[the documentation] for usage instructions.\n\nIn your GitHub repository, select the \"Actions\" link on top.\nIf you already have some workflows in your repository, click \"New Workflow\".\nIn the section \"By Jenkins\", select \"Jenkins Security Scan\".\n\nConfigure the YAML workflow file in your repository.\nYou can use it without changes.\nWe recommend committing to the default branch instead of adding t"
  },
  "3803": {
    "source_file": "scan.txt",
    "text": "Configure the YAML workflow file in your repository.\nYou can use it without changes.\nWe recommend committing to the default branch instead of adding this file via a pull request.\nThis way, the code scanning findings will not be visible in a pull request check.\nOnce saved, you should be able to see findings for branches in the \"Security\" tab under \"Code scanning alerts\".\nPull requests will have a n"
  },
  "3804": {
    "source_file": "scan.txt",
    "text": "est check.\nOnce saved, you should be able to see findings for branches in the \"Security\" tab under \"Code scanning alerts\".\nPull requests will have a new check that shows findings added in it.\n\nYou can use the same GitHub workflow in your Jenkins plugin project as long as it's hosted on GitHub.\nCopy the https://github.com/jenkinsci/.github/blob/master/workflow-templates/jenkins-security-scan.yaml[Y"
  },
  "3805": {
    "source_file": "scan.txt",
    "text": "in project as long as it's hosted on GitHub.\nCopy the https://github.com/jenkinsci/.github/blob/master/workflow-templates/jenkins-security-scan.yaml[YAML workflow template] into your repository's `.github/workflows` directory.\nYou need to replace the `$default-branch` placeholder as appropriate.\n\nNOTE: Your repository needs to be public or you need https://docs.github.com/en/get-started/learning-a"
  },
  "3806": {
    "source_file": "scan.txt",
    "text": " `$default-branch` placeholder as appropriate.\n\nNOTE: Your repository needs to be public or you need https://docs.github.com/en/get-started/learning-about-github/about-github-advanced-security[GitHub Advanced Security].\nUploading the report will fail with an error otherwise.\n\nRate limiting::\nThe scan fails to execute with the following error message:\n> `Called workflows cannot be queued onto self-"
  },
  "3807": {
    "source_file": "scan.txt",
    "text": " with an error otherwise.\n\nRate limiting::\nThe scan fails to execute with the following error message:\n> `Called workflows cannot be queued onto self-hosted runners across organisations/enterprises. Failed to queue this job. Labels: 'ubuntu-latest'.`\nAs of March 2022, https://github.community/t/called-workflows-cannot-be-queued-onto-self-hosted-runners-across-organisations-enterprises-failed-to-qu"
  },
  "3808": {
    "source_file": "scan.txt",
    "text": "\nAs of March 2022, https://github.community/t/called-workflows-cannot-be-queued-onto-self-hosted-runners-across-organisations-enterprises-failed-to-queue-this-job-labels-ubuntu-latest/229355/10[GitHub seems to rate limit actions].\nIf this error message appears, you are being rate-limited.\nYou can manually restart the scan.\nAction permissions::\nThe workflow has a _startup failure_ with an error mes"
  },
  "3809": {
    "source_file": "scan.txt",
    "text": "ge appears, you are being rate-limited.\nYou can manually restart the scan.\nAction permissions::\nThe workflow has a _startup failure_ with an error message like this:\n> `jenkins-infra/fetch-codeql-action@v1 is not allowed to be used in jenkinsci/your-plugin.`\nIn cases of errors like this, review _Settings \u00bb Code and automation \u00bb Actions \u00bb General \u00bb Action permissions_ in your repository.\nSelect eit"
  },
  "3810": {
    "source_file": "scan.txt",
    "text": "plugin.`\nIn cases of errors like this, review _Settings \u00bb Code and automation \u00bb Actions \u00bb General \u00bb Action permissions_ in your repository.\nSelect either _Allow all actions and workflows_ or _Allow jenkinsci, and select non-jenkinsci, actions and workflows_.\nIf you select the latter, add `jenkins-infra/*` to the list of specified actions and workflows being allowed.\nWorkflow permissions::\nThe work"
  },
  "3811": {
    "source_file": "scan.txt",
    "text": "kflows_.\nIf you select the latter, add `jenkins-infra/*` to the list of specified actions and workflows being allowed.\nWorkflow permissions::\nThe workflow has a _startup failure_ with an error message like this:\n> `The workflow is not valid. .github/workflows/jenkins-security-scan.yml (Line: 11, Col: 3): Error calling workflow 'jenkins-infra/jenkins-security-scan/.github/workflows/jenkins-security"
  },
  "3812": {
    "source_file": "scan.txt",
    "text": "workflows/jenkins-security-scan.yml (Line: 11, Col: 3): Error calling workflow 'jenkins-infra/jenkins-security-scan/.github/workflows/jenkins-security-scan.yaml@v2'. The workflow 'jenkins-infra/jenkins-security-scan/.github/workflows/jenkins-security-scan.yaml@v2' is requesting 'actions: read, security_events: write', but is only allowed 'actions: none, security_events: none'.`\nThis can happen if "
  },
  "3813": {
    "source_file": "scan.txt",
    "text": "-scan.yaml@v2' is requesting 'actions: read, security_events: write', but is only allowed 'actions: none, security_events: none'.`\nThis can happen if your repository is configured to limit workflow permissions to read-only access by default, and you're using an older version of the workflow that does not declare the permissions it requires.\nCompare with the https://github.com/jenkinsci/.github/blo"
  },
  "3814": {
    "source_file": "scan.txt",
    "text": "re using an older version of the workflow that does not declare the permissions it requires.\nCompare with the https://github.com/jenkinsci/.github/blob/master/workflow-templates/jenkins-security-scan.yaml[template file] and ensure you have the same `permissions` element in your workflow.\nError in Dependabot commits::\nThe _Upload Scan Results_ step in the workflow fails with the error:\n> `Error: Wo"
  },
  "3815": {
    "source_file": "scan.txt",
    "text": "permissions` element in your workflow.\nError in Dependabot commits::\nThe _Upload Scan Results_ step in the workflow fails with the error:\n> `Error: Workflows triggered by Dependabot on the \"push\" event run with read-only access. Uploading Code Scanning results requires write access. To use Code Scanning with Dependabot, please ensure you are using the \"pull_request\" event for this workflow and avo"
  },
  "3816": {
    "source_file": "scan.txt",
    "text": "ng results requires write access. To use Code Scanning with Dependabot, please ensure you are using the \"pull_request\" event for this workflow and avoid triggering on the \"push\" event for Dependabot branches. See https://docs.github.com/en/code-security/secure-coding/configuring-code-scanning#scanning-on-push for more information on how to configure these events.`\nYou're using an older version of "
  },
  "3817": {
    "source_file": "scan.txt",
    "text": "ity/secure-coding/configuring-code-scanning#scanning-on-push for more information on how to configure these events.`\nYou're using an older version of the workflow that does not declare the permissions it requires.\nCompare with the https://github.com/jenkinsci/.github/blob/master/workflow-templates/jenkins-security-scan.yaml[template file] and ensure you have the same `permissions` element in your "
  },
  "3818": {
    "source_file": "scan.txt",
    "text": "jenkinsci/.github/blob/master/workflow-templates/jenkins-security-scan.yaml[template file] and ensure you have the same `permissions` element in your workflow (https://docs.github.com/en/code-security/supply-chain-security/keeping-your-dependencies-updated-automatically/automating-dependabot-with-github-actions#changing-github_token-permissions[see documentation]).\nPull request check is unexpected"
  },
  "3819": {
    "source_file": "scan.txt",
    "text": "pdated-automatically/automating-dependabot-with-github-actions#changing-github_token-permissions[see documentation]).\nPull request check is unexpectedly successful::\nThe _Jenkins Security Scan_ check is successful even though the pull request introduces new issues.\nOnly some findings mark the check as failed.\nThe behavior can be customized in the repository configuration.\nGo to _Settings \u00bb Securit"
  },
  "3820": {
    "source_file": "scan.txt",
    "text": "ces new issues.\nOnly some findings mark the check as failed.\nThe behavior can be customized in the repository configuration.\nGo to _Settings \u00bb Security \u00bb Code security and analysis \u00bb Code scanning \u00bb Check Failure_ and select the behavior you want.\nMissing access to Code Scanning API::\nThe _Upload Scan Results_ step in the workflow fails with the error:\n> `Error: Advanced Security must be enabled f"
  },
  "3821": {
    "source_file": "scan.txt",
    "text": "ssing access to Code Scanning API::\nThe _Upload Scan Results_ step in the workflow fails with the error:\n> `Error: Advanced Security must be enabled for this repository to use code scanning.`\nThis happens for private repositories that do not have GitHub Advanced Security enabled.\nReview _Settings \u00bb Security \u00bb Code security and analysis \u00bb GitHub Advanced Security_ in your repository and ensure that"
  },
  "3822": {
    "source_file": "scan.txt",
    "text": "Hub Advanced Security enabled.\nReview _Settings \u00bb Security \u00bb Code security and analysis \u00bb GitHub Advanced Security_ in your repository and ensure that it is enabled.\nThis section of the configuration is only visible if you have an appropriate GitHub paid plan.\n\nThe custom GitHub workflow is hosted in https://github.com/jenkins-infra/jenkins-security-scan[`jenkins-infra/jenkins-security-scan`], alo"
  },
  "3823": {
    "source_file": "scan.txt",
    "text": "paid plan.\n\nThe custom GitHub workflow is hosted in https://github.com/jenkins-infra/jenkins-security-scan[`jenkins-infra/jenkins-security-scan`], alongside the wrapper script that invokes the CodeQL CLI.\nPlease file an issue there to provide feedback for the workflow and its use of actions.\n\nTo provide feedback about the findings, please file an issue in https://github.com/jenkins-infra/jenkins-c"
  },
  "3824": {
    "source_file": "scan.txt",
    "text": "k for the workflow and its use of actions.\n\nTo provide feedback about the findings, please file an issue in https://github.com/jenkins-infra/jenkins-codeql[`jenkins-infra/jenkins-codeql`].\nImprovements to the code scanning rules are also welcome."
  },
  "3825": {
    "source_file": "script-approval.txt",
    "text": "layout: section\n\n\nifdef::env-github[:imagesdir: ../resources]\nifndef::env-github[:imagesdir: ../../resources]\n\nJenkins, and a number of plugins, allow users to execute\nGroovy scripts _in_ Jenkins. These scripting capabilities are provided by:\n\n* <<script-console#, Script Console>>.\n* <<../pipeline#, Jenkins Pipeline>>.\n* The plugin:email-ext[Extended Email plugin].\n* The plugin:groovy[Groovy plugi"
  },
  "3826": {
    "source_file": "script-approval.txt",
    "text": "ript-console#, Script Console>>.\n* <<../pipeline#, Jenkins Pipeline>>.\n* The plugin:email-ext[Extended Email plugin].\n* The plugin:groovy[Groovy plugin] - when using the \"Execute system Groovy\n  script\" step.\n* The plugin:job-dsl[JobDSL plugin] as of version 1.60 and later.\n\nTo protect Jenkins from execution of malicious scripts,\nthese plugins execute user-provided scripts in a <<groovy-sandbox>>\n"
  },
  "3827": {
    "source_file": "script-approval.txt",
    "text": " version 1.60 and later.\n\nTo protect Jenkins from execution of malicious scripts,\nthese plugins execute user-provided scripts in a <<groovy-sandbox>>\nthat limits the internal APIs that are accessible.\nThis protection is provided by the plugin:script-security[Script Security plugin].\nAs soon as an unsafe method is used in any of the scripts, the administrator can use\nthe \"In-process Script Approval"
  },
  "3828": {
    "source_file": "script-approval.txt",
    "text": "security[Script Security plugin].\nAs soon as an unsafe method is used in any of the scripts, the administrator can use\nthe \"In-process Script Approval\" action appears in *Manage Jenkins*\nto allow the unsafe method.\nUnsafe methods should not be enabled without careful consideration of the impact.\n\nThe plugin:script-security[Script Security plugin] is installed automatically\nby the\n,\nalthough initia"
  },
  "3829": {
    "source_file": "script-approval.txt",
    "text": "d without careful consideration of the impact.\n\nThe plugin:script-security[Script Security plugin] is installed automatically\nby the\n,\nalthough initially no additional scripts or operations are approved for use.\n\n[IMPORTANT]\n\nOlder versions of this plugin may not be safe to use. Please review the\nsecurity warnings listed on plugin:script-security[the Script Security plugin page]\nin order to ensure"
  },
  "3830": {
    "source_file": "script-approval.txt",
    "text": "lugin may not be safe to use. Please review the\nsecurity warnings listed on plugin:script-security[the Script Security plugin page]\nin order to ensure that the plugin:script-security[Script Security plugin] is\nup to date.\n\nSecurity for in-process scripting is provided by two different mechanisms: the\n<<groovy-sandbox>> and <<script-approval>>. The first, the Groovy Sandbox, is\nenabled by default f"
  },
  "3831": {
    "source_file": "script-approval.txt",
    "text": "ipting is provided by two different mechanisms: the\n<<groovy-sandbox>> and <<script-approval>>. The first, the Groovy Sandbox, is\nenabled by default for  allowing\nuser-supplied Scripted and Declarative Pipeline to execute without prior\nAdministrator intervention. The second, Script\nApproval, allows Administrators to approve or deny unsandboxed scripts, or\nallow sandboxed scripts to execute additio"
  },
  "3832": {
    "source_file": "script-approval.txt",
    "text": "intervention. The second, Script\nApproval, allows Administrators to approve or deny unsandboxed scripts, or\nallow sandboxed scripts to execute additional methods.\n\nFor most systems, the combination of the Groovy Sandbox and the\n\nof approved method signatures, will be sufficient. It is strongly recommended\nthat Administrators only deviate from these defaults if absolutely necessary.\n\n[[groovy-sandb"
  },
  "3833": {
    "source_file": "script-approval.txt",
    "text": "gnatures, will be sufficient. It is strongly recommended\nthat Administrators only deviate from these defaults if absolutely necessary.\n\n[[groovy-sandbox]]\n\nTo reduce manual interventions by Administrators, most scripts will run in a\nGroovy Sandbox by default, including all\nThe sandbox only allows a subset of Groovy's methods deemed sufficiently safe\nfor \"untrusted\" access to be executed without pr"
  },
  "3834": {
    "source_file": "script-approval.txt",
    "text": " default, including all\nThe sandbox only allows a subset of Groovy's methods deemed sufficiently safe\nfor \"untrusted\" access to be executed without prior approval. Scripts using\nthe Groovy Sandbox are *all* subject to the same restrictions, therefore a\nPipeline authored by an Administrator is subject to the\nrestrictions as one authorized by a non-administrative user.\n\nWhen a script attempts to use"
  },
  "3835": {
    "source_file": "script-approval.txt",
    "text": " a\nPipeline authored by an Administrator is subject to the\nrestrictions as one authorized by a non-administrative user.\n\nWhen a script attempts to use features or methods unauthorized by the sandbox,\na script is halted immediately, as shown below with Jenkins Pipeline\n\n.Unauthorized method signature rejected at runtime via Blue Ocean\n\nThe Pipeline above will not execute until an Administrator\n<<ap"
  },
  "3836": {
    "source_file": "script-approval.txt",
    "text": "h Jenkins Pipeline\n\n.Unauthorized method signature rejected at runtime via Blue Ocean\n\nThe Pipeline above will not execute until an Administrator\n<<approving-method-signature, approves the method signature>> via the\n*In-process Script Approval* page.\n\nIn addition to adding approved method signatures, users may also disable the\nGroovy Sandbox entirely as shown below. Disabling the Groovy Sandbox re"
  },
  "3837": {
    "source_file": "script-approval.txt",
    "text": "\n\nIn addition to adding approved method signatures, users may also disable the\nGroovy Sandbox entirely as shown below. Disabling the Groovy Sandbox requires\nthat the **entire** script must be reviewed and\n<<approving-unsandboxed-pipeline, manually approved>> by an administrator.\n\n.Disabling the Groovy Sandbox for a Pipeline\n\n[[script-approval]]\n\nManual approval of entire scripts, or method signatu"
  },
  "3838": {
    "source_file": "script-approval.txt",
    "text": "proved>> by an administrator.\n\n.Disabling the Groovy Sandbox for a Pipeline\n\n[[script-approval]]\n\nManual approval of entire scripts, or method signatures, by an administrator\nprovides Administrators with additional flexibility to support more advanced\nusages of in-process scripting. When the <<groovy-sandbox>> is disabled, or a\nmethod outside of the built-in list is invoked, the Script Security pl"
  },
  "3839": {
    "source_file": "script-approval.txt",
    "text": "d\nusages of in-process scripting. When the <<groovy-sandbox>> is disabled, or a\nmethod outside of the built-in list is invoked, the Script Security plugin will\ncheck the Administrator-managed list of approved scripts and methods.\n\n[IMPORTANT]\n\nWhen a script is approved, it is approved for use in any Jenkins feature or plugin that integrates with script approval.\nScript approval is not tied to a sp"
  },
  "3840": {
    "source_file": "script-approval.txt",
    "text": " script is approved, it is approved for use in any Jenkins feature or plugin that integrates with script approval.\nScript approval is not tied to a specific job or to any other specific use of the script.\nDue to this, care must be taken when approving a script to ensure that any user supplied parameters can not be used to exploit the controller.\n\nFor scripts which wish to execute outside of the <<"
  },
  "3841": {
    "source_file": "script-approval.txt",
    "text": "g a script to ensure that any user supplied parameters can not be used to exploit the controller.\n\nFor scripts which wish to execute outside of the <<groovy-sandbox>>, the\nAdministrator must approve the *entire* script in the *In-process Script\nApproval* page:\n\n[[approving-unsandboxed-pipeline]]\n.Approving an unsandboxed Scripted Pipeline\n\nFor scripts which use the <<groovy-sandbox>>, but wish to "
  },
  "3842": {
    "source_file": "script-approval.txt",
    "text": "val* page:\n\n[[approving-unsandboxed-pipeline]]\n.Approving an unsandboxed Scripted Pipeline\n\nFor scripts which use the <<groovy-sandbox>>, but wish to execute an currently\nunapproved method signature will also be halted by Jenkins, and require an\nAdministrator to approve the specific method signature before the script is\nallowed to execute:\n\n[[approving-method-signature]]\n.Approving a new method si"
  },
  "3843": {
    "source_file": "script-approval.txt",
    "text": "nistrator to approve the specific method signature before the script is\nallowed to execute:\n\n[[approving-method-signature]]\n.Approving a new method signature\n\nScript approval provides three options: Approve, Deny, and \"Approve assuming\npermissions check.\" While the purpose of the first two are self-evident, the\nthird requires some additional understanding of what internal data scripts are\nable to "
  },
  "3844": {
    "source_file": "script-approval.txt",
    "text": "eck.\" While the purpose of the first two are self-evident, the\nthird requires some additional understanding of what internal data scripts are\nable to access and how permissions checks inside of Jenkins function.\n\nConsider a script which accesses the method\n`hudson.model.AbstractItem.getParent()`, which by itself is harmless and will\nreturn an object containing either the folder or root item which "
  },
  "3845": {
    "source_file": "script-approval.txt",
    "text": "method\n`hudson.model.AbstractItem.getParent()`, which by itself is harmless and will\nreturn an object containing either the folder or root item which contains the\ncurrently executing Pipeline or Job. Following that method invocation,\nexecuting `hudson.model.ItemGroup.getItems()`, which will list items in the\nfolder or root item, requires the `Job/Read` permission.\n\nThis could mean that approving t"
  },
  "3846": {
    "source_file": "script-approval.txt",
    "text": "n.model.ItemGroup.getItems()`, which will list items in the\nfolder or root item, requires the `Job/Read` permission.\n\nThis could mean that approving the `hudson.model.ItemGroup.getItems()` method\nsignature would allow a script to bypass built-in permissions checks.\n\nInstead, it is usually more desirable to click *Approve assuming permissions\ncheck* which will cause the Script Approval engine to al"
  },
  "3847": {
    "source_file": "script-approval.txt",
    "text": "issions checks.\n\nInstead, it is usually more desirable to click *Approve assuming permissions\ncheck* which will cause the Script Approval engine to allow the method\nsignature assuming the user running the script has the permissions to execute\nthe method, such as the `Job/Read` permission in this example."
  },
  "3848": {
    "source_file": "script-approval.txt",
    "text": "hod, such as the `Job/Read` permission in this example."
  },
  "3849": {
    "source_file": "script-console.txt",
    "text": "layout: section\n\n\nJenkins features a Groovy script console which allows one to run arbitrary\nGroovy scripts within the Jenkins controller runtime or in the runtime on\nagents.\n\n[IMPORTANT]\n\nIt is\u00a0_very_ *important*\u00a0to understand all of the following points because it\naffects the integrity of your Jenkins installation. The Jenkins Script Console:\n\n* Access is controlled by the\u00a0`+Administer+`\u00a0permiss"
  },
  "3850": {
    "source_file": "script-console.txt",
    "text": "oints because it\naffects the integrity of your Jenkins installation. The Jenkins Script Console:\n\n* Access is controlled by the\u00a0`+Administer+`\u00a0permission.\n\n* Is a web-based Groovy shell into the Jenkins runtime. Groovy is a very\npowerful language which offers the ability to do practically anything Java can\ndo including:\n\n** Create sub-processes and execute arbitrary commands on the Jenkins\ncontrol"
  },
  "3851": {
    "source_file": "script-console.txt",
    "text": "ch offers the ability to do practically anything Java can\ndo including:\n\n** Create sub-processes and execute arbitrary commands on the Jenkins\ncontroller and agents.\n** It can even read files in which the Jenkins controller has access to on\nthe host (like\u00a0`/etc/passwd`)\n** Decrypt credentials configured within Jenkins.\n\n* Offers no administrative controls to stop a User (or Admin) once they\nare ab"
  },
  "3852": {
    "source_file": "script-console.txt",
    "text": "(like\u00a0`/etc/passwd`)\n** Decrypt credentials configured within Jenkins.\n\n* Offers no administrative controls to stop a User (or Admin) once they\nare able to execute the Script Console from affecting all parts of the Jenkins\ninfrastructure. Granting a normal Jenkins user Script Console Access is\nessentially the same as giving them Administrator rights within Jenkins.\n\n* Can configure any Jenkins set"
  },
  "3853": {
    "source_file": "script-console.txt",
    "text": "normal Jenkins user Script Console Access is\nessentially the same as giving them Administrator rights within Jenkins.\n\n* Can configure any Jenkins setting. It can disable security,\nreconfigure security, even open a backdoor on the host operating system\ncompletely outside of the Jenkins process. Due to the mission critical\nimportance many organizations place on Jenkins in their infrastructure this\n"
  },
  "3854": {
    "source_file": "script-console.txt",
    "text": "em\ncompletely outside of the Jenkins process. Due to the mission critical\nimportance many organizations place on Jenkins in their infrastructure this\npoint is especially important because it would allow an attacker to move\nlaterally within infrastructure with little effort.\n\n* Is so powerful because it was originally intended as a debugging\ninterface for Jenkins developers but has since grown into"
  },
  "3855": {
    "source_file": "script-console.txt",
    "text": "ture with little effort.\n\n* Is so powerful because it was originally intended as a debugging\ninterface for Jenkins developers but has since grown into an interface used by\nJenkins Admins to configure Jenkins and debug Jenkins runtime issues.\n\nAdditional security considerations for administrative scripts:\n\n* Scripts can bypass all security controls and access any data.\n\n* Credentials accessed via s"
  },
  "3856": {
    "source_file": "script-console.txt",
    "text": "nal security considerations for administrative scripts:\n\n* Scripts can bypass all security controls and access any data.\n\n* Credentials accessed via scripts are decrypted.\n\n* Changes made via scripts may not be audited in the normal logs.\n\n* Scripts can modify Jenkins at the lowest levels, potentially making it unstable.\n\nBecause of the power offered by the Jenkins Script Console, Jenkins and its\n"
  },
  "3857": {
    "source_file": "script-console.txt",
    "text": "can modify Jenkins at the lowest levels, potentially making it unstable.\n\nBecause of the power offered by the Jenkins Script Console, Jenkins and its\nagents should never be run as the\u00a0`root`\u00a0user (on Linux) or system\nadministrator on any other flavor of OS. Videos linked in this page demonstrate\nand discuss security warnings.\n\n*Be sure to secure your Jenkins controller*\n\ntoc::[]\n\nThe Jenkins Scrip"
  },
  "3858": {
    "source_file": "script-console.txt",
    "text": " of OS. Videos linked in this page demonstrate\nand discuss security warnings.\n\n*Be sure to secure your Jenkins controller*\n\ntoc::[]\n\nThe Jenkins Script Console can run either on the controller or any configured\nagents.\n\nThis feature can be accessed from _\"Manage Jenkins\" > \"Script Console\"_.\u00a0\nOr by visiting the sub-URL\u00a0`/script`\u00a0on your Jenkins controller.\n\nVisit _\"Manage Jenkins\" > \"Manage Nodes\""
  },
  "3859": {
    "source_file": "script-console.txt",
    "text": "rom _\"Manage Jenkins\" > \"Script Console\"_.\u00a0\nOr by visiting the sub-URL\u00a0`/script`\u00a0on your Jenkins controller.\n\nVisit _\"Manage Jenkins\" > \"Manage Nodes\"_.\u00a0 Select any node to view the status\npage.\u00a0 In the menu on the left, a menu item is available to open a \"Script\nConsole\" on that specific agent.\n\nIt's also possible to run scripts from the controller Script Console on\nindividual agents.\u00a0 The follow"
  },
  "3860": {
    "source_file": "script-console.txt",
    "text": "pen a \"Script\nConsole\" on that specific agent.\n\nIt's also possible to run scripts from the controller Script Console on\nindividual agents.\u00a0 The following script is an example running a script on\nagents from the controller Script Console.\n\n*Script executes code on agent from Master Script Console*\n\nimport hudson.util.RemotingDiagnostics\nimport jenkins.model.Jenkins\n\nString agentName = 'your agent n"
  },
  "3861": {
    "source_file": "script-console.txt",
    "text": "cutes code on agent from Master Script Console*\n\nimport hudson.util.RemotingDiagnostics\nimport jenkins.model.Jenkins\n\nString agentName = 'your agent name'\n//groovy script you want executed on an agent\ngroovy_script = '''\nprintln System.getenv(\"PATH\")\nprintln \"uname -a\".execute().text\n'''.trim()\n\nString result\nJenkins.instance.slaves.find { agent ->\n    agent.name == agentName\n}.with { agent ->\n   "
  },
  "3862": {
    "source_file": "script-console.txt",
    "text": "\nprintln \"uname -a\".execute().text\n'''.trim()\n\nString result\nJenkins.instance.slaves.find { agent ->\n    agent.name == agentName\n}.with { agent ->\n    result = RemotingDiagnostics.executeGroovy(groovy_script, agent.channel)\n}\nprintln result\n\nFiles can be read and written directly on the controller or agents via the\ncontroller Script Console.\n\n*Write a file to the Jenkins controller*\n\nnew File('/tm"
  },
  "3863": {
    "source_file": "script-console.txt",
    "text": "n be read and written directly on the controller or agents via the\ncontroller Script Console.\n\n*Write a file to the Jenkins controller*\n\nnew File('/tmp/file.txt').withWriter('UTF-8') { writer ->\n    try {\n        writer << 'hello world\\n'\n    } finally {\n        writer.close()\n    }\n}\n\n*Reading a file from the Jenkins controller*\n\nnew File('/tmp/file.txt').text\n\n*Write file to agent through agent "
  },
  "3864": {
    "source_file": "script-console.txt",
    "text": "ly {\n        writer.close()\n    }\n}\n\n*Reading a file from the Jenkins controller*\n\nnew File('/tmp/file.txt').text\n\n*Write file to agent through agent channel*\n\nimport hudson.FilePath\nimport hudson.remoting.Channel\nimport jenkins.model.Jenkins\n\nString agentName = 'some-agent'\nString filePath = '/tmp/file.txt'\n\nChannel agentChannel = Jenkins.instance.slaves.find { agent ->\n    agent.name == agentNam"
  },
  "3865": {
    "source_file": "script-console.txt",
    "text": " agentName = 'some-agent'\nString filePath = '/tmp/file.txt'\n\nChannel agentChannel = Jenkins.instance.slaves.find { agent ->\n    agent.name == agentName\n}.channel\n\nnew FilePath(agentChannel, filePath).write().with { os ->\n    try {\n        os << 'hello world\\n'\n    } finally {\n        os.close()\n    }\n}\n\n*Read file from agent through agent channel*\n\nimport hudson.FilePath\nimport hudson.remoting.Cha"
  },
  "3866": {
    "source_file": "script-console.txt",
    "text": "o world\\n'\n    } finally {\n        os.close()\n    }\n}\n\n*Read file from agent through agent channel*\n\nimport hudson.FilePath\nimport hudson.remoting.Channel\nimport jenkins.model.Jenkins\n\nimport java.io.BufferedReader\nimport java.io.InputStreamReader\nimport java.nio.charset.StandardCharsets\nimport java.util.stream.Collectors\n\nString agentName = 'some-agent'\nString filePath = '/tmp/file.txt'\n\nChannel "
  },
  "3867": {
    "source_file": "script-console.txt",
    "text": "port java.nio.charset.StandardCharsets\nimport java.util.stream.Collectors\n\nString agentName = 'some-agent'\nString filePath = '/tmp/file.txt'\n\nChannel agentChannel = Jenkins.instance.slaves.find { agent ->\n    agent.name == agentName\n}.channel\n\nString fileContents = ''\nnew FilePath(agentChannel, filePath).read().with { is ->\n    try {\n        fileContents = new BufferedReader(\n            new Input"
  },
  "3868": {
    "source_file": "script-console.txt",
    "text": " fileContents = ''\nnew FilePath(agentChannel, filePath).read().with { is ->\n    try {\n        fileContents = new BufferedReader(\n            new InputStreamReader(is, StandardCharsets.UTF_8))\n                .lines()\n                .collect(Collectors.joining(\"\\n\"))\n    } finally {\n        is.close()\n    }\n}\n\n// print contents of the file from the agent\nprintln '==='\nprintln(fileContents)\nprintln"
  },
  "3869": {
    "source_file": "script-console.txt",
    "text": "rs.joining(\"\\n\"))\n    } finally {\n        is.close()\n    }\n}\n\n// print contents of the file from the agent\nprintln '==='\nprintln(fileContents)\nprintln '==='\n\nThe Script Console provides powerful administrative functions for managing Jenkins.\n\nBelow are common administrative tasks with examples:\n\nJenkins.instance.securityRealm.allUsers.each { user ->\n    println user.id + \": \" + user.fullName\n}\n\nim"
  },
  "3870": {
    "source_file": "script-console.txt",
    "text": "re common administrative tasks with examples:\n\nJenkins.instance.securityRealm.allUsers.each { user ->\n    println user.id + \": \" + user.fullName\n}\n\nimport hudson.model.User\nimport jenkins.model.Jenkins\n\nUser user = User.get('new-user', true)\nuser.fullName = \"New User\"\nuser.save()\n\nJenkins.instance.systemMessage = \"New system message\"\nJenkins.instance.save()\n\nprintln Jenkins.VERSION\n\nSystem.getProp"
  },
  "3871": {
    "source_file": "script-console.txt",
    "text": "lName = \"New User\"\nuser.save()\n\nJenkins.instance.systemMessage = \"New system message\"\nJenkins.instance.save()\n\nprintln Jenkins.VERSION\n\nSystem.getProperty(\"hudson.remoting.Launcher.pingIntervalSec\") // view current setting\nSystem.clearProperty(\"hudson.remoting.Launcher.pingIntervalSec\") // set to default\nSystem.setProperty(\"hudson.remoting.Launcher.pingIntervalSec\", \"\") // unset header\nSystem.setP"
  },
  "3872": {
    "source_file": "script-console.txt",
    "text": "n.remoting.Launcher.pingIntervalSec\") // set to default\nSystem.setProperty(\"hudson.remoting.Launcher.pingIntervalSec\", \"\") // unset header\nSystem.setProperty(\"hudson.remoting.Launcher.pingIntervalSec\", 0)\n\nJenkins.instance.pluginManager.plugins.each {\n    println \"${it.shortName}: ${it.version}\"\n}\nJenkins.instance.pluginManager.getPlugin('git').disable()\n\nJenkins.instance.nodes.each { node ->\n    "
  },
  "3873": {
    "source_file": "script-console.txt",
    "text": "{\n    println \"${it.shortName}: ${it.version}\"\n}\nJenkins.instance.pluginManager.getPlugin('git').disable()\n\nJenkins.instance.nodes.each { node ->\n    println \"${node.name}: ${node.numExecutors} executors\"\n}\nJenkins.instance.getNode('agent-name').computer.doDoDelete()\n\nJenkins.instance.getItemByFullName(\"<projectName\").getBuildByNumber(<BuildNumber).finish(\n    hudson.model.Result.ABORTED, new java"
  },
  "3874": {
    "source_file": "script-console.txt",
    "text": "uter.doDoDelete()\n\nJenkins.instance.getItemByFullName(\"<projectName\").getBuildByNumber(<BuildNumber).finish(\n    hudson.model.Result.ABORTED, new java.io.IOException(\"Aborting build\")\n);\n\nWhen using the Script Console for administrative tasks:\n\n* Always test scripts in a non-production environment first.\n*  before running scripts.\n* Use the  rather than direct filesystem manipulation when possible"
  },
  "3875": {
    "source_file": "script-console.txt",
    "text": "ays test scripts in a non-production environment first.\n*  before running scripts.\n* Use the  rather than direct filesystem manipulation when possible.\n* Limit script scope so that only necessary operations are performed.\n* Add comments to scripts for future reference.\n* Consider using plugins like plugin:job-dsl[Job DSL] or plugin:configuration-as-code[Configuration as Code] for repeatable config"
  },
  "3876": {
    "source_file": "script-console.txt",
    "text": "r future reference.\n* Consider using plugins like plugin:job-dsl[Job DSL] or plugin:configuration-as-code[Configuration as Code] for repeatable configurations.\n* Review scripts carefully to ensure they execute with full system privileges.\n* Monitor script execution as long-running scripts may impact performance.\n\ntry {\n    Jenkins.instance.doSomething()\n    Jenkins.instance.save()\n\n    println \"Op"
  },
  "3877": {
    "source_file": "script-console.txt",
    "text": "cript execution as long-running scripts may impact performance.\n\ntry {\n    Jenkins.instance.doSomething()\n    Jenkins.instance.save()\n\n    println \"Operation completed successfully\"\n} catch(Exception e) {\n    println \"Error: ${e.message}\"\n}\n\nA Jenkins Admin can execute groovy scripts remotely by sending an HTTP POST\nrequest to `/script/` url or `/scriptText/`.\n\n*curl example via bash*\n\ncurl -d \"sc"
  },
  "3878": {
    "source_file": "script-console.txt",
    "text": "s Admin can execute groovy scripts remotely by sending an HTTP POST\nrequest to `/script/` url or `/scriptText/`.\n\n*curl example via bash*\n\ncurl -d \"script=<your_script_here>\" https://jenkins/script\n# or to get output as a plain text result (no HTML)\ncurl -d \"script=<your_script_here>\" https://jenkins/scriptText\n\nAlso,\noffers the possibility to execute groovy scripts remotely using\n`groovy` command"
  },
  "3879": {
    "source_file": "script-console.txt",
    "text": "curl -d \"script=<your_script_here>\" https://jenkins/scriptText\n\nAlso,\noffers the possibility to execute groovy scripts remotely using\n`groovy` command or execute groovy interactively via `groovysh`.\nHowever, once again curl can be used to execute groovy scripts by making\nuse of bash command substitution. In the following example\n`somescript.groovy` is a groovy script in the current working\ndirecto"
  },
  "3880": {
    "source_file": "script-console.txt",
    "text": "ovy scripts by making\nuse of bash command substitution. In the following example\n`somescript.groovy` is a groovy script in the current working\ndirectory.\n\n*Curl submitting groovy file via bash*\n\ncurl --data-urlencode \"script=$(< ./somescript.groovy)\" https://jenkins/scriptText\n\nIf security is configured in Jenkins, then curl can be provided options to\nauthenticate using\u00a0the\u00a0`curl --user`\u00a0option.\n\n"
  },
  "3881": {
    "source_file": "script-console.txt",
    "text": " https://jenkins/scriptText\n\nIf security is configured in Jenkins, then curl can be provided options to\nauthenticate using\u00a0the\u00a0`curl --user`\u00a0option.\n\n*Curl submitting groovy file providing username and api token via bash*\n\ncurl --user 'username:api-token' --data-urlencode \\\n  \"script=$(< ./somescript.groovy)\" https://jenkins/scriptText\n\nHere is the equivalent command using python, not curl.\n\n*Pyth"
  },
  "3882": {
    "source_file": "script-console.txt",
    "text": "oken' --data-urlencode \\\n  \"script=$(< ./somescript.groovy)\" https://jenkins/scriptText\n\nHere is the equivalent command using python, not curl.\n\n*Python submitting groovy file providing username and api token*\n\nwith open('somescript.groovy', 'r') as fd:\n    data = fd.read()\nr = requests.post('https://jenkins/scriptText', auth=('username', 'api-token'), data={'script': data})\n\nYou can submit a scri"
  },
  "3883": {
    "source_file": "script-console.txt",
    "text": "fd:\n    data = fd.read()\nr = requests.post('https://jenkins/scriptText', auth=('username', 'api-token'), data={'script': data})\n\nYou can submit a script without mouse. Jenkins has a shortcut key which enables\nto submit with keyboard.\n\n* Windows / Linux: Ctrl + Enter\n* Mac: Command + Enter\n\nHere are some recorded videos on the Jenkins Script Console:\n\n* https://www.youtube.com/watch?v=qaUPESDcsGg[J"
  },
  "3884": {
    "source_file": "script-console.txt",
    "text": "ux: Ctrl + Enter\n* Mac: Command + Enter\n\nHere are some recorded videos on the Jenkins Script Console:\n\n* https://www.youtube.com/watch?v=qaUPESDcsGg[Jenkins World 2017:\nMastering the Jenkins Script Console] - 44 minutes - sample usage and\nsecurity discussion\n* https://www.youtube.com/watch?v=T1x2kCGRY1w[LA Jenkins Area Meetup\n2016 - Hacking on Jenkins Internals - Jenkins Script Console]\u00a0- 39\nminut"
  },
  "3885": {
    "source_file": "script-console.txt",
    "text": "scussion\n* https://www.youtube.com/watch?v=T1x2kCGRY1w[LA Jenkins Area Meetup\n2016 - Hacking on Jenkins Internals - Jenkins Script Console]\u00a0- 39\nminutes - sample usage\n\nTo expand your ability to write scripts in the script console, the following\nreferences are recommended:\n\n* http://groovy-lang.org/learn.html[Learn Groovy] - Learning Groovy is\nuseful for more than writing scripts for the Script Co"
  },
  "3886": {
    "source_file": "script-console.txt",
    "text": "rences are recommended:\n\n* http://groovy-lang.org/learn.html[Learn Groovy] - Learning Groovy is\nuseful for more than writing scripts for the Script Console.\u00a0 Groovy is also\nrelevant for other features of Jenkins like , the https://plugins.jenkins.io/groovy[Groovy\nPlugin], the https://plugins.jenkins.io/job-dsl[Job DSL plugin], and many other\nplugins which utilize Groovy (see section <<Plugins-enab"
  },
  "3887": {
    "source_file": "script-console.txt",
    "text": "groovy[Groovy\nPlugin], the https://plugins.jenkins.io/job-dsl[Job DSL plugin], and many other\nplugins which utilize Groovy (see section <<Plugins-enabling-Groovy-usage>>).\n\n* http://www.mdoninger.de/2011/11/07/write-groovy-scripts-for-jenkins-with-code-completion.html[Write\nGroovy scripts for Jenkins with Code completion]\u00a0- The gist of this is to\ncreate a Maven project within your IDE and to depen"
  },
  "3888": {
    "source_file": "script-console.txt",
    "text": "de-completion.html[Write\nGroovy scripts for Jenkins with Code completion]\u00a0- The gist of this is to\ncreate a Maven project within your IDE and to depend\non\u00a0org.jenkins-ci.main:jenkins-core (and any other plugins that you expect\npresent). You can then write a Groovy script with code completion of Jenkins\nAPI objects and methods.\n\nDue to the nature of Groovy scripts accessing Jenkins source code dire"
  },
  "3889": {
    "source_file": "script-console.txt",
    "text": "write a Groovy script with code completion of Jenkins\nAPI objects and methods.\n\nDue to the nature of Groovy scripts accessing Jenkins source code directly,\nScript Console scripts are easily out of date from the Jenkins source code. It\nis possible to run a script and get exceptions because public methods and\ninterfaces in Jenkins core or Jenkins plugins have changed. Keep this in mind\nwhen trying o"
  },
  "3890": {
    "source_file": "script-console.txt",
    "text": "run a script and get exceptions because public methods and\ninterfaces in Jenkins core or Jenkins plugins have changed. Keep this in mind\nwhen trying out examples. Jenkins is easily started from a local development\nmachine via the following command:\n\n*Starting a local copy of Jenkins*\n\nexport JENKINS_HOME=\"./my_jenkins_home\"\njava -jar jenkins.war\n\nUse CTRL+C to stop Jenkins. It is not recommended t"
  },
  "3891": {
    "source_file": "script-console.txt",
    "text": "*Starting a local copy of Jenkins*\n\nexport JENKINS_HOME=\"./my_jenkins_home\"\njava -jar jenkins.war\n\nUse CTRL+C to stop Jenkins. It is not recommended to try Script Console\nexamples in a production Jenkins controller.\n\nThe following repositories offer solid examples of Groovy scripts for Jenkins.\n\n* https://github.com/cloudbees/jenkins-scripts[CloudBees jenkins-scripts\nrepository].\n* \u00a0(scripts for t"
  },
  "3892": {
    "source_file": "script-console.txt",
    "text": "solid examples of Groovy scripts for Jenkins.\n\n* https://github.com/cloudbees/jenkins-scripts[CloudBees jenkins-scripts\nrepository].\n* \u00a0(scripts for the\n).\n* https://github.com/samrocketman/jenkins-script-console-scripts[Sam Gleske's\njenkins-script-console-scripts repository].\n* https://github.com/samrocketman/jenkins-bootstrap-shared[Sam Gleske's\njenkins-bootstrap-shared repository under the\u00a0`+sc"
  },
  "3893": {
    "source_file": "script-console.txt",
    "text": "onsole-scripts repository].\n* https://github.com/samrocketman/jenkins-bootstrap-shared[Sam Gleske's\njenkins-bootstrap-shared repository under the\u00a0`+scripts/+` directory].\n\nBrowse all\u00a0https://plugins.jenkins.io/scriptler[Scriptler Plugin] Groovy\nScripts and\u00a0*please share your scripts with the*\n*https://plugins.jenkins.io/scriptler[Scriptler Plugin].*\n\n* https://wiki.jenkins.io/display/JENKINS/Activ"
  },
  "3894": {
    "source_file": "script-console.txt",
    "text": "ts and\u00a0*please share your scripts with the*\n*https://plugins.jenkins.io/scriptler[Scriptler Plugin].*\n\n* https://wiki.jenkins.io/display/JENKINS/Activate+Chuck+Norris+Plugin[Activate\nChuck Norris Plugin] \u2014 This script activates Chuck Norris plugin for all jobs\nin your Jenkins server\n* https://wiki.jenkins.io/JENKINS/74416647.html[Add\na Maven Installation, Tool Installation, Modify System Config]\n*"
  },
  "3895": {
    "source_file": "script-console.txt",
    "text": "r all jobs\nin your Jenkins server\n* https://wiki.jenkins.io/JENKINS/74416647.html[Add\na Maven Installation, Tool Installation, Modify System Config]\n* https://wiki.jenkins.io/display/JENKINS/Add-a-new-label-to-agents-meeting-a-condition.html[Add\na new label to agents meeting a condition] \u2014 This script shows how to alter the\nagent nodes' label membership. In this case we create a new label if the\ne"
  },
  "3896": {
    "source_file": "script-console.txt",
    "text": "w label to agents meeting a condition] \u2014 This script shows how to alter the\nagent nodes' label membership. In this case we create a new label if the\nexisting label contains a string. It has been tested from the Jenkins command\nwindow.\n* https://wiki.jenkins.io/display/JENKINS/Add+notification+plugin+to+every+job[Add\nnotification plugin to every job] \u2014 This script will add the Notification\nPlugin t"
  },
  "3897": {
    "source_file": "script-console.txt",
    "text": "jenkins.io/display/JENKINS/Add+notification+plugin+to+every+job[Add\nnotification plugin to every job] \u2014 This script will add the Notification\nPlugin to every job.\n* https://wiki.jenkins.io/display/JENKINS/Allow+broken+build+claiming+on+every+jobs[Allow\nbroken build claiming on every jobs] \u2014 With the following simple script, you\ncan activate the option on every jobs of your server in just one go.\n*"
  },
  "3898": {
    "source_file": "script-console.txt",
    "text": "ow\nbroken build claiming on every jobs] \u2014 With the following simple script, you\ncan activate the option on every jobs of your server in just one go.\n* https://wiki.jenkins.io/display/JENKINS/Batch-Update+Mercurial+branch+that+is+checked+out[Batch-Update\nMercurial branch that is checked out] \u2014 Updates for multiple jobs which branch\nwill be checked out from Hg\n* https://wiki.jenkins.io/display/JENKI"
  },
  "3899": {
    "source_file": "script-console.txt",
    "text": "ate\nMercurial branch that is checked out] \u2014 Updates for multiple jobs which branch\nwill be checked out from Hg\n* https://wiki.jenkins.io/display/JENKINS/Bulk+rename+projects[Bulk\nrename projects]\n* https://wiki.jenkins.io/display/JENKINS/Change+JVM+Options+in+all+Maven+tasks+of+Freestyle+Jobs[Change\nJVM Options in all Maven tasks of Freestyle Jobs] \u2014 This script find all Maven\nTasks registered in "
  },
  "3900": {
    "source_file": "script-console.txt",
    "text": "ptions+in+all+Maven+tasks+of+Freestyle+Jobs[Change\nJVM Options in all Maven tasks of Freestyle Jobs] \u2014 This script find all Maven\nTasks registered in freestyle jobs and replace JVM Options by a new value.\n* https://wiki.jenkins.io/display/JENKINS/Change+publish+over+SSH+configuration[Change\npublish over SSH configuration]\n* https://wiki.jenkins.io/display/JENKINS/Change+SCMTrigger+for+each+project"
  },
  "3901": {
    "source_file": "script-console.txt",
    "text": "nge+publish+over+SSH+configuration[Change\npublish over SSH configuration]\n* https://wiki.jenkins.io/display/JENKINS/Change+SCMTrigger+for+each+project+to+disable+during+the+night+and+the+week-end[Change\nSCMTrigger for each project to disable during the night and the week-end] \u2014\nThis script lets you easily change all jobs running every minutes so that it\ngets disabled between 21:00 and 07:00 and on"
  },
  "3902": {
    "source_file": "script-console.txt",
    "text": "he night and the week-end] \u2014\nThis script lets you easily change all jobs running every minutes so that it\ngets disabled between 21:00 and 07:00 and on Saturday and Sunday.\n* https://wiki.jenkins.io/display/JENKINS/Change+Version-Number+in+SVN-path[Change\nVersion-Number in SVN-path]\n* https://wiki.jenkins.io/display/JENKINS/Clone+all+projects+in+a+View[Clone\nall projects in a View] \u2014 This script en"
  },
  "3903": {
    "source_file": "script-console.txt",
    "text": "ange\nVersion-Number in SVN-path]\n* https://wiki.jenkins.io/display/JENKINS/Clone+all+projects+in+a+View[Clone\nall projects in a View] \u2014 This script enumerates all projects belonging to a\nspecific view and clones them.\n* https://wiki.jenkins.io/display/JENKINS/Convert+standard+mail+notifications+to+use+the+Mail-Ext+Publisher+plugin[Convert\nstandard mail notifications to use the Mail-Ext Publisher p"
  },
  "3904": {
    "source_file": "script-console.txt",
    "text": "y/JENKINS/Convert+standard+mail+notifications+to+use+the+Mail-Ext+Publisher+plugin[Convert\nstandard mail notifications to use the Mail-Ext Publisher plugin] \u2014 This script\nreplace mail notifications in all projects by Mail-Ext publisher plugin and\nre-uses existing recipients.\n* https://wiki.jenkins.io/display/JENKINS/Delete+.tmp+files+left+in+workspace-files[Delete\ntmp files left in workspace-files"
  },
  "3905": {
    "source_file": "script-console.txt",
    "text": "uses existing recipients.\n* https://wiki.jenkins.io/display/JENKINS/Delete+.tmp+files+left+in+workspace-files[Delete\ntmp files left in workspace-files] \u2014 This scripts deletes all the tmp files\nleft in workspace-files directory after the build. On windows servers this\nseems pretty common.\n* https://wiki.jenkins.io/display/JENKINS/Delete+workspace+for+all+disabled+jobs[Delete\nworkspace for all disab"
  },
  "3906": {
    "source_file": "script-console.txt",
    "text": "dows servers this\nseems pretty common.\n* https://wiki.jenkins.io/display/JENKINS/Delete+workspace+for+all+disabled+jobs[Delete\nworkspace for all disabled jobs] \u2014 Deletes the workspace for all disabled jobs\nto save space\n* https://wiki.jenkins.io/display/JENKINS/Disable+all+jobs[Disable all\njobs] \u2014 This script disables all jobs in your Jenkins server\n* https://wiki.jenkins.io/display/JENKINS/Displa"
  },
  "3907": {
    "source_file": "script-console.txt",
    "text": "lay/JENKINS/Disable+all+jobs[Disable all\njobs] \u2014 This script disables all jobs in your Jenkins server\n* https://wiki.jenkins.io/display/JENKINS/Display+Information+About+Nodes[Display\nInformation About Nodes] \u2014 This scripts displays a bunch of information about\nall the agent nodes.\n* https://wiki.jenkins.io/display/JENKINS/Display+job+parameters[Display\njob parameters] \u2014 This scripts displays the "
  },
  "3908": {
    "source_file": "script-console.txt",
    "text": "ation about\nall the agent nodes.\n* https://wiki.jenkins.io/display/JENKINS/Display+job+parameters[Display\njob parameters] \u2014 This scripts displays the parameters for all the jobs along\nwith their default values (if applicable).\n* https://wiki.jenkins.io/display/JENKINS/Display+jobs+group+by+the+build+steps+they+use[Display\njobs group by the build steps they use]\n* https://wiki.jenkins.io/display/JE"
  },
  "3909": {
    "source_file": "script-console.txt",
    "text": "io/display/JENKINS/Display+jobs+group+by+the+build+steps+they+use[Display\njobs group by the build steps they use]\n* https://wiki.jenkins.io/display/JENKINS/Display-list-of-projects-that-were-built-more-than-1-day-ago..html[Display\nlist of projects that were built more than 1 day ago.] \u2014 This script to display\nlist of projects that were built more than 1 day ago.\n* https://wiki.jenkins.io/display/J"
  },
  "3910": {
    "source_file": "script-console.txt",
    "text": "at were built more than 1 day ago.] \u2014 This script to display\nlist of projects that were built more than 1 day ago.\n* https://wiki.jenkins.io/display/JENKINS/Display+mail+notifications+recipients[Display\nmail notifications recipients] \u2014 This script displays for all jobs the list of\nmail recipients used for notifications.\n* https://wiki.jenkins.io/display/JENKINS/Display+monitors+status[Display\nmoni"
  },
  "3911": {
    "source_file": "script-console.txt",
    "text": "splays for all jobs the list of\nmail recipients used for notifications.\n* https://wiki.jenkins.io/display/JENKINS/Display+monitors+status[Display\nmonitors status] \u2014 Jenkins uses monitors to validate various behaviors. If you\ndismiss one, Jenkins will never propose you to reactivate it. This script\nallows you to check the status of all monitors and to reactivate them.\n* https://wiki.jenkins.io/disp"
  },
  "3912": {
    "source_file": "script-console.txt",
    "text": " never propose you to reactivate it. This script\nallows you to check the status of all monitors and to reactivate them.\n* https://wiki.jenkins.io/display/JENKINS/138454178.html[Display\nthe number of jobs using SCM Polling from Freestyle, Pipeline and Maven]\n* https://wiki.jenkins.io/display/JENKINS/Display+timer+triggers[Display\ntimer triggers] \u2014 This scripts displays the timer triggers for all th"
  },
  "3913": {
    "source_file": "script-console.txt",
    "text": " Maven]\n* https://wiki.jenkins.io/display/JENKINS/Display+timer+triggers[Display\ntimer triggers] \u2014 This scripts displays the timer triggers for all the jobs in\norder to better arrange them.\n* https://wiki.jenkins.io/display/JENKINS/Display+Tools+Location+on+All+Nodes[Display\nTools Location on All Nodes] \u2014 This script can help to get Jenkins tools\nlocation on all your agents\n* https://wiki.jenkins."
  },
  "3914": {
    "source_file": "script-console.txt",
    "text": "tion+on+All+Nodes[Display\nTools Location on All Nodes] \u2014 This script can help to get Jenkins tools\nlocation on all your agents\n* https://wiki.jenkins.io/display/JENKINS/Enable+Timestamper+plugin+on+all+jobs[Enable\nTimestamper plugin on all jobs] \u2014 With the following simple script, you can\nactivate the option on every jobs of your server in just one go.\n* https://wiki.jenkins.io/display/JENKINS/Fai"
  },
  "3915": {
    "source_file": "script-console.txt",
    "text": "th the following simple script, you can\nactivate the option on every jobs of your server in just one go.\n* https://wiki.jenkins.io/display/JENKINS/Failed+Jobs[Failed Jobs] \u2014\nThis scripts displays a list of all failed jobs. Addon: restart them.\n* https://wiki.jenkins.io/display/JENKINS/Find+builds+currently+running+that+has+been+executing+for+more+than+N+seconds[Find\nbuilds currently running that h"
  },
  "3916": {
    "source_file": "script-console.txt",
    "text": "s://wiki.jenkins.io/display/JENKINS/Find+builds+currently+running+that+has+been+executing+for+more+than+N+seconds[Find\nbuilds currently running that has been executing for more than N seconds]\n* https://wiki.jenkins.io/display/JENKINS/Grant+Cancel+Permission+for+user+and+group+that+have+Build+permission[Grant\nCancel Permission for user and group that have Build permission] \u2014 This script\nwill go th"
  },
  "3917": {
    "source_file": "script-console.txt",
    "text": "rmission+for+user+and+group+that+have+Build+permission[Grant\nCancel Permission for user and group that have Build permission] \u2014 This script\nwill go through all groups and users in both Global security and per job\nsecurity settings.\n* https://wiki.jenkins.io/display/JENKINS/Invalidate+Jenkins+HTTP+sessions[Invalidate\nJenkins HTTP sessions] \u2014 This script can monitor and invalidate HTTP sessions\nif t"
  },
  "3918": {
    "source_file": "script-console.txt",
    "text": "kins.io/display/JENKINS/Invalidate+Jenkins+HTTP+sessions[Invalidate\nJenkins HTTP sessions] \u2014 This script can monitor and invalidate HTTP sessions\nif there are many open ones on your server.\n* https://wiki.jenkins.io/display/JENKINS/Manually+run+log+rotation+on+all+jobs[Manually\nrun log rotation on all jobs] \u2014 Runs log rotation on all jobs to free space\n* https://wiki.jenkins.io/display/JENKINS/Mon"
  },
  "3919": {
    "source_file": "script-console.txt",
    "text": "otation+on+all+jobs[Manually\nrun log rotation on all jobs] \u2014 Runs log rotation on all jobs to free space\n* https://wiki.jenkins.io/display/JENKINS/Monitor+and+Restart+Offline+Slaves[Monitor\nand Restart Offline Agents] \u2014 This script can monitor and restart offline nodes\nif they are not disconnected manually.\n* https://wiki.jenkins.io/display/JENKINS/Monitoring+Scripts[Monitoring\nScripts] \u2014 Several "
  },
  "3920": {
    "source_file": "script-console.txt",
    "text": "start offline nodes\nif they are not disconnected manually.\n* https://wiki.jenkins.io/display/JENKINS/Monitoring+Scripts[Monitoring\nScripts] \u2014 Several scripts to display data about http sessions, threads,\nmemory, JVM or MBeans, when using the Monitoring plugin.\n* https://wiki.jenkins.io/display/JENKINS/My+Test+Grovvy[My Test Grovvy]\n* https://wiki.jenkins.io/display/JENKINS/Parameterized+System+Gro"
  },
  "3921": {
    "source_file": "script-console.txt",
    "text": "ng plugin.\n* https://wiki.jenkins.io/display/JENKINS/My+Test+Grovvy[My Test Grovvy]\n* https://wiki.jenkins.io/display/JENKINS/Parameterized+System+Groovy+script[Parameterized\nSystem Groovy script] \u2014 This script will demonstrate how to get parameters in a\nsystem groovy script.\n* https://wiki.jenkins.io/display/JENKINS/Preselect+username+in+Maven+Release+Build[Preselect\nusername in Maven Release Bui"
  },
  "3922": {
    "source_file": "script-console.txt",
    "text": "in a\nsystem groovy script.\n* https://wiki.jenkins.io/display/JENKINS/Preselect+username+in+Maven+Release+Build[Preselect\nusername in Maven Release Build]\n* https://wiki.jenkins.io/display/JENKINS/Printing+a+list+of+credentials+and+their+IDs[Printing\na list of credentials and their IDs]\n* https://wiki.jenkins.io/display/JENKINS/Remove+all+disabled+modules+in+Maven+jobs[Remove\nall disabled modules i"
  },
  "3923": {
    "source_file": "script-console.txt",
    "text": "a list of credentials and their IDs]\n* https://wiki.jenkins.io/display/JENKINS/Remove+all+disabled+modules+in+Maven+jobs[Remove\nall disabled modules in Maven jobs] \u2014 To remove all disabled modules in Maven\njobs\n* https://wiki.jenkins.io/display/JENKINS/Remove+Deployed+Artifacts+Actions[Remove\nDeployed Artifacts Actions] \u2014 This script is used to remove the Deployed\nArtifacts list that is uselessly "
  },
  "3924": {
    "source_file": "script-console.txt",
    "text": "NS/Remove+Deployed+Artifacts+Actions[Remove\nDeployed Artifacts Actions] \u2014 This script is used to remove the Deployed\nArtifacts list that is uselessly stored for each build by the Artifact Deployer\nPlugin.\n* https://wiki.jenkins.io/display/JENKINS/Remove+Git+Plugin+BuildsByBranch+BuildData[Remove\nGit Plugin BuildsByBranch BuildData] \u2014 This script is used to remove the static\nlist of BuildsByBranch "
  },
  "3925": {
    "source_file": "script-console.txt",
    "text": "ove+Git+Plugin+BuildsByBranch+BuildData[Remove\nGit Plugin BuildsByBranch BuildData] \u2014 This script is used to remove the static\nlist of BuildsByBranch that is uselessly stored for each build by the Git\nPlugin.\n* https://wiki.jenkins.io/display/JENKINS/Set+GitBlitRepositoryBrowser+with+custum+settings+on+all+repos[Set\nGitBlitRepositoryBrowser with custom settings on all repos] \u2014 This scripts\nallows "
  },
  "3926": {
    "source_file": "script-console.txt",
    "text": "/Set+GitBlitRepositoryBrowser+with+custum+settings+on+all+repos[Set\nGitBlitRepositoryBrowser with custom settings on all repos] \u2014 This scripts\nallows to update the repo browser. Can be adapted to any other browser, not\nonly gitblit.\n* https://wiki.jenkins.io/display/JENKINS/Update+maven+jobs+to+use+the+post+build+task+to+deploy+artifacts[Update\nmaven jobs to use the post build task to deploy artif"
  },
  "3927": {
    "source_file": "script-console.txt",
    "text": "nkins.io/display/JENKINS/Update+maven+jobs+to+use+the+post+build+task+to+deploy+artifacts[Update\nmaven jobs to use the post build task to deploy artifacts] \u2014 This script\nupdates all maven jobs having a deploy goal by install and activate the post\nbuild step to deploy artifacts at the end of the build\n* https://wiki.jenkins.io/display/JENKINS/Update+SVN+Browser[Update SVN\nBrowser]\n* https://wiki.je"
  },
  "3928": {
    "source_file": "script-console.txt",
    "text": "ld step to deploy artifacts at the end of the build\n* https://wiki.jenkins.io/display/JENKINS/Update+SVN+Browser[Update SVN\nBrowser]\n* https://wiki.jenkins.io/display/JENKINS/Wipe+out+workspaces+of+all+jobs[Wipe\nout workspaces of all jobs] \u2014 This script wipes out the workspaces of all jobs\non your Jenkins server\n* https://wiki.jenkins.io/display/JENKINS/Wipe+workspaces+for+a+set+of+jobs+on+all+nod"
  },
  "3929": {
    "source_file": "script-console.txt",
    "text": "ipt wipes out the workspaces of all jobs\non your Jenkins server\n* https://wiki.jenkins.io/display/JENKINS/Wipe+workspaces+for+a+set+of+jobs+on+all+nodes[Wipe\nworkspaces for a set of jobs on all nodes] \u2014 The script wipes workspaces of\ncertain jobs on all nodes.\n\n-  Adds the ability to provide configuration files (i.e., settings.xml for\nmaven, XML, groovy, custom files, etc.) loaded through the Jenk"
  },
  "3930": {
    "source_file": "script-console.txt",
    "text": "all nodes.\n\n-  Adds the ability to provide configuration files (i.e., settings.xml for\nmaven, XML, groovy, custom files, etc.) loaded through the Jenkins UI which\nwill be copied to the job's workspace.\n\n-\n\u2014 Execute a global configured groovy script after each build of each job managed\nby the Jenkins.  This is typical for cases when you need to do something based\non a shared set of parameters, such"
  },
  "3931": {
    "source_file": "script-console.txt",
    "text": "fter each build of each job managed\nby the Jenkins.  This is typical for cases when you need to do something based\non a shared set of parameters, such as triggering downstream jobs managed by\nthe same Jenkins or remote ones based on the parameters been passed to the\nparameterized jobs.\n\n- https://plugins.jenkins.io/groovy[Groovy plugin]\n\n- https://plugins.jenkins.io/groovy-postbuild[Groovy Postbui"
  },
  "3932": {
    "source_file": "script-console.txt",
    "text": "en passed to the\nparameterized jobs.\n\n- https://plugins.jenkins.io/groovy[Groovy plugin]\n\n- https://plugins.jenkins.io/groovy-postbuild[Groovy Postbuild Plugin] \u2014 This\nplugin executes a groovy script in the Jenkins JVM. Typically, the script\nchecks some conditions and changes accordingly the build result, puts badges\nnext to the build in the build history and/or displays information on the build\ns"
  },
  "3933": {
    "source_file": "script-console.txt",
    "text": "ome conditions and changes accordingly the build result, puts badges\nnext to the build in the build history and/or displays information on the build\nsummary page.\n\n- https://plugins.jenkins.io/groovy-remote[Groovy Remote Control\nPlugin] \u2014 This plugin provides\nhttp://groovy.codehaus.org/modules/remote/[Groovy Remote Control]'s receiver,\nand allows to control external application from Jenkins.\n\n- ht"
  },
  "3934": {
    "source_file": "script-console.txt",
    "text": " provides\nhttp://groovy.codehaus.org/modules/remote/[Groovy Remote Control]'s receiver,\nand allows to control external application from Jenkins.\n\n- https://plugins.jenkins.io/matrix-groovy-execution-strategy[Matrix Groovy\nExecution Strategy Plugin] \u2014 A plugin to decide the execution order and valid\ncombinations of matrix projects.\n\n- https://plugins.jenkins.io/scriptler[Scriptler Plugin] \u2014 Scriptl"
  },
  "3935": {
    "source_file": "script-console.txt",
    "text": " A plugin to decide the execution order and valid\ncombinations of matrix projects.\n\n- https://plugins.jenkins.io/scriptler[Scriptler Plugin] \u2014 Scriptler allows you\nto store/edit groovy scripts and execute it on any of the nodes... no need to\ncopy/paste groovy code anymore."
  },
  "3936": {
    "source_file": "script-console.txt",
    "text": "te groovy code anymore."
  },
  "3937": {
    "source_file": "searchbox.txt",
    "text": "layout: section\ntitle: Command Palette\n\n\nJenkins now features a new search experience known as *Command Palette*.\nLocated in the upper-right corner of the page next to your name, the Command Palette enables you to search everything in Jenkins.\n\n[.boxshadow]\n\nFor example, enter \"git #23 console\" to display the results for the console output page of \"git job build #23\".\nThe Command Palette feature u"
  },
  "3938": {
    "source_file": "searchbox.txt",
    "text": "shadow]\n\nFor example, enter \"git #23 console\" to display the results for the console output page of \"git job build #23\".\nThe Command Palette feature utilizes auto-completion to help you find what you're looking for.\nResults can include additional search terms for narrowing results, Pipelines, Views, additional features installed within your Jenkins environment, such as the Design Library, and spec"
  },
  "3939": {
    "source_file": "searchbox.txt",
    "text": "rch terms for narrowing results, Pipelines, Views, additional features installed within your Jenkins environment, such as the Design Library, and specific pages within jobs based on your installed plugins, such as the plugin:warnings-ng[Warnings] plugin.\nSearch results also provide more clarity in the form of icons to help indicate Jenkins features and job statuses.\n\nThe Command Palette is also ac"
  },
  "3940": {
    "source_file": "searchbox.txt",
    "text": "gin.\nSearch results also provide more clarity in the form of icons to help indicate Jenkins features and job statuses.\n\nThe Command Palette is also accessible via keyboard commands for macOS (`CMD+k`) and Windows/Linux (`CTRL+K`).\n\n[.boxshadow]\n\n[[SearchBox-Caseinsensitivesearch]]\n\nNavigate to your profile preferences page (/jenkins/user/<your_profile>/preferences) and activate the case- insensiti"
  },
  "3941": {
    "source_file": "searchbox.txt",
    "text": "archBox-Caseinsensitivesearch]]\n\nNavigate to your profile preferences page (/jenkins/user/<your_profile>/preferences) and activate the case- insensitive search option, if desired.\n\n[.boxshadow]\n\nPlease note that case-insensitive search is not available for anonymous (not signed in) users.\n\n[[SearchBox-OpenSearchsupport]]\n\nThis search feature is also exposed to the browser through http://en.wikiped"
  },
  "3942": {
    "source_file": "searchbox.txt",
    "text": "le for anonymous (not signed in) users.\n\n[[SearchBox-OpenSearchsupport]]\n\nThis search feature is also exposed to the browser through http://en.wikipedia.org/wiki/OpenSearch[OpenSearch], so you can install this search and auto-completion feature in your browser search box, making it even easier to navigate Jenkins.\n\nFor example in Firefox, you can add the Jenkins search to your browser's search eng"
  },
  "3943": {
    "source_file": "searchbox.txt",
    "text": "ur browser search box, making it even easier to navigate Jenkins.\n\nFor example in Firefox, you can add the Jenkins search to your browser's search engines via the dropdown on the right of the address bar:\n\n[.boxshadow]\n\n[[SearchBox-Feedbackappreciated]]\n\nThere's always room for improvement in how Jenkins associates search terms with actual pages.\nYour feedback is appreciated."
  },
  "3944": {
    "source_file": "searchbox.txt",
    "text": "d]]\n\nThere's always room for improvement in how Jenkins associates search terms with actual pages.\nYour feedback is appreciated."
  },
  "3945": {
    "source_file": "secrets.txt",
    "text": "title: Storing Secrets\nlayout: developer\n\n\nPlugins commonly store user credentials and similar secrets, like API keys, access tokens, or just user names and passwords, to interface with other systems and services.\nPlugins that store such secrets need to be careful how they store them.\nWith simple `String` fields that get serialized to disk as plain text, a number of problems can occur:\n\n* On many "
  },
  "3946": {
    "source_file": "secrets.txt",
    "text": " to be careful how they store them.\nWith simple `String` fields that get serialized to disk as plain text, a number of problems can occur:\n\n* On many systems, large parts of the Jenkins home directory is accessible to other user accounts, allowing to retrieve credentials stored on disk as plain text.\n* Backups of Jenkins home can be compromised, disclosing secrets, even when excluding the +secrets"
  },
  "3947": {
    "source_file": "secrets.txt",
    "text": " retrieve credentials stored on disk as plain text.\n* Backups of Jenkins home can be compromised, disclosing secrets, even when excluding the +secrets/+ directory.\n* String fields are round-tripped in configuration forms as plain text even if the value is hidden in a password field, so can be accessed via the HTML page source code. This even applies to users who only have the plugin:extended-read-"
  },
  "3948": {
    "source_file": "secrets.txt",
    "text": "ue is hidden in a password field, so can be accessed via the HTML page source code. This even applies to users who only have the plugin:extended-read-permission[Extended Read] permission.\n\nThe easiest solution to all of the above is to store the password as a jenkinsdoc:Secret[Secret].\n\n* The key to decrypt secrets is stored in the `secrets/` directory which has the highest protection, and is reco"
  },
  "3949": {
    "source_file": "secrets.txt",
    "text": "word as a jenkinsdoc:Secret[Secret].\n\n* The key to decrypt secrets is stored in the `secrets/` directory which has the highest protection, and is recommended to be excluded from backups.\n* `Secret` fields are round-tripped in their encrypted form, so that their plain-text form cannot be retrieved by users later.\n  If a user only has the Extended Read permission, the secret is simply removed from o"
  },
  "3950": {
    "source_file": "secrets.txt",
    "text": " that their plain-text form cannot be retrieved by users later.\n  If a user only has the Extended Read permission, the secret is simply removed from output.\n\nA more advanced option is to integrate with plugin:credentials[Credentials Plugin]. See https://github.com/jenkinsci/credentials-plugin/tree/master/docs[its documentation] for more information.\n\n### Storing Secrets on Disk\n\nThe easiest way to"
  },
  "3951": {
    "source_file": "secrets.txt",
    "text": "s://github.com/jenkinsci/credentials-plugin/tree/master/docs[its documentation] for more information.\n\n### Storing Secrets on Disk\n\nThe easiest way to store secrets is to store them in a field of the type jenkinsdoc:Secret[], and access that field in your other code via a getter that returns the same type.\nJenkins will transparently handle the encryption and decryption for on-disk storage.\n\nAn exa"
  },
  "3952": {
    "source_file": "secrets.txt",
    "text": " your other code via a getter that returns the same type.\nJenkins will transparently handle the encryption and decryption for on-disk storage.\n\nAn example for how to use a `Secret` shared between all instances of a build step is below.\n\npublic class MyBuilder extends Builder implements SimpleBuildStep {\n\n    public void perform(Run<?,?> run, FilePath workspace, Launcher launcher, TaskListener list"
  },
  "3953": {
    "source_file": "secrets.txt",
    "text": "MyBuilder extends Builder implements SimpleBuildStep {\n\n    public void perform(Run<?,?> run, FilePath workspace, Launcher launcher, TaskListener listener) {\n        String password = ((MyBuilder.DescriptorImpl)getDescriptor()).getPassword().getPlainText(); //<1> // Perform work with the password here, like sending HTTP requests etc.\n        // Secret#toString will also obtain the plain text, but "
  },
  "3954": {
    "source_file": "secrets.txt",
    "text": "Text(); //<1> // Perform work with the password here, like sending HTTP requests etc.\n        // Secret#toString will also obtain the plain text, but it's deprecated and will log a warning.\n    }\n\n    @Extension\n    public static class DescriptorImpl extends BuildStepDescriptor<Builder> {\n        private Secret password; //<2> public void setPassword(Secret password) {\n            this.password = "
  },
  "3955": {
    "source_file": "secrets.txt",
    "text": " extends BuildStepDescriptor<Builder> {\n        private Secret password; //<2> public void setPassword(Secret password) {\n            this.password = password;\n        }\n\n        public Secret getPassword() { //<3> return password;\n        }\n\n        @Override\n        public boolean configure(StaplerRequest req, JSONObject json) throws FormException {\n            req.bindJSON(this, json);\n        "
  },
  "3956": {
    "source_file": "secrets.txt",
    "text": " @Override\n        public boolean configure(StaplerRequest req, JSONObject json) throws FormException {\n            req.bindJSON(this, json);\n            return true;\n        }\n\n        // more code\n    }\n\n    // more code\n}\n\n<1> To use the password, obtain the plain text.\n<2> `Secret` field will store the password encrypted on disk.\n<3> `Secret` getter, if used by the `f:password` form field (bel"
  },
  "3957": {
    "source_file": "secrets.txt",
    "text": " obtain the plain text.\n<2> `Secret` field will store the password encrypted on disk.\n<3> `Secret` getter, if used by the `f:password` form field (below), will round-trip the password on the UI in encrypted form and hide it from users without Configure permission.\n\n### Secrets and Configuration Forms\n\nIn the configuration form, display the secret itself (rather than the decrypted secret) hidden in"
  },
  "3958": {
    "source_file": "secrets.txt",
    "text": "re permission.\n\n### Secrets and Configuration Forms\n\nIn the configuration form, display the secret itself (rather than the decrypted secret) hidden in a `<f:password>` field.\nThis requires that the getter or public field used to populate the form element also is a jenkinsdoc:Secret[] (see above).\n\n  <f:entry title=\"${%Password}\" field=\"password\">\n    <f:password />\n  </f:entry>\n\nSecrets spanning m"
  },
  "3959": {
    "source_file": "secrets.txt",
    "text": "ment also is a jenkinsdoc:Secret[] (see above).\n\n  <f:entry title=\"${%Password}\" field=\"password\">\n    <f:password />\n  </f:entry>\n\nSecrets spanning multiple lines (such as certificates or SSH keys) should be masked from view by using the `<f:secretTextarea>` form element.\nIt is available from Jenkins 2.171.\nPlugins with older core baselines can add a dependency on the standalone library `io.jenki"
  },
  "3960": {
    "source_file": "secrets.txt",
    "text": "extarea>` form element.\nIt is available from Jenkins 2.171.\nPlugins with older core baselines can add a dependency on the standalone library `io.jenkins.temp.jelly:multiline-secrets-ui:1.0` (or newer) with the same form element.\nSee https://github.com/jenkinsci/lib-multiline-secrets-ui/blob/master/README.md[the documentation in its GitHub repository] for usage instructions and sample code.\n\n### En"
  },
  "3961": {
    "source_file": "secrets.txt",
    "text": "m/jenkinsci/lib-multiline-secrets-ui/blob/master/README.md[the documentation in its GitHub repository] for usage instructions and sample code.\n\n### Encryption of Secrets and Credentials\n\nJenkins uses AES to encrypt and protect secrets, credentials, and their respective encryption keys.\nThese encryption keys are stored in `$JENKINS_HOME/secrets/` along with the master key used to protect said keys."
  },
  "3962": {
    "source_file": "secrets.txt",
    "text": "nd their respective encryption keys.\nThese encryption keys are stored in `$JENKINS_HOME/secrets/` along with the master key used to protect said keys.\nThis directory should be configured so that only the operating system user the Jenkins controller is running as has read and write access to this directory (i.e., a `chmod` value of `0700` or using appropriate file attributes).\nThe master key (somet"
  },
  "3963": {
    "source_file": "secrets.txt",
    "text": "s running as has read and write access to this directory (i.e., a `chmod` value of `0700` or using appropriate file attributes).\nThe master key (sometimes referred to as a \"key encryption key\" in cryptojargon) is stored _unencrypted_ on the Jenkins controller filesystem in `$JENKINS_HOME/secrets/master.key` which does not protect against attackers with direct access to that file.\nMost users and de"
  },
  "3964": {
    "source_file": "secrets.txt",
    "text": "ontroller filesystem in `$JENKINS_HOME/secrets/master.key` which does not protect against attackers with direct access to that file.\nMost users and developers will use these encryption keys indirectly via either the jenkinsdoc:Secret[] API for encrypting generic secret data or through the credentials API.\nFor the cryptocurious, Jenkins uses AES in cipher block chaining (CBC) mode with PKCS#5 paddi"
  },
  "3965": {
    "source_file": "secrets.txt",
    "text": "ting generic secret data or through the credentials API.\nFor the cryptocurious, Jenkins uses AES in cipher block chaining (CBC) mode with PKCS#5 padding and random IVs to encrypt instances of jenkinsdoc:CryptoConfidentialKey[] which are stored in `$JENKINS_HOME/secrets/` with a filename corresponding to their `CryptoConfidentialKey` id.\nCommon key ids include:\n\n* `hudson.util.Secret`: used for gen"
  },
  "3966": {
    "source_file": "secrets.txt",
    "text": "ENKINS_HOME/secrets/` with a filename corresponding to their `CryptoConfidentialKey` id.\nCommon key ids include:\n\n* `hudson.util.Secret`: used for generic secrets;\n* `com.cloudbees.plugins.credentials.SecretBytes.KEY`: used for some credentials types;\n* `jenkins.model.Jenkins.crumbSalt`: used by the ; and\n* `org.jenkinsci.main.modules.instance_identity.InstanceIdentity.KEY`: used to identify the J"
  },
  "3967": {
    "source_file": "secrets.txt",
    "text": ";\n* `jenkins.model.Jenkins.crumbSalt`: used by the ; and\n* `org.jenkinsci.main.modules.instance_identity.InstanceIdentity.KEY`: used to identify the Jenkins controller."
  },
  "3968": {
    "source_file": "securing-builds.txt",
    "text": "title: Securing Builds\nlayout: section\n\n\nifdef::env-github[:imagesdir: ../resources]\nifndef::env-github[:imagesdir: ../../resources]\n\nBuilding software is the primary use case for Jenkins.\nTo accomplish that, Jenkins invokes build scripts containing user-specified code, and ensuring this is done in a safe manner must be a major concern for Jenkins administrators.\nThe following sections discuss pot"
  },
  "3969": {
    "source_file": "securing-builds.txt",
    "text": "user-specified code, and ensuring this is done in a safe manner must be a major concern for Jenkins administrators.\nThe following sections discuss potential issues and strategies to deal with them.\n\nAs discussed in , Jenkins should be set up for _distributed builds_ to ensure build scripts are not executing on the controller, where they could access the Jenkins home directory or otherwise interfer"
  },
  "3970": {
    "source_file": "securing-builds.txt",
    "text": "tributed builds_ to ensure build scripts are not executing on the controller, where they could access the Jenkins home directory or otherwise interfere with the operation of Jenkins.\n\nAn additional concern is that builds need to be isolated from each other:\nWhile simple Jenkins instances building a single project may be able to operate securely with a single static agent, administrators of more co"
  },
  "3971": {
    "source_file": "securing-builds.txt",
    "text": " other:\nWhile simple Jenkins instances building a single project may be able to operate securely with a single static agent, administrators of more complex instances need to consider whether builds need to be isolated from each other.\nSome examples:\n\n- Jenkins hosts multiple teams, which are not allowed to access each others' projects or source code.\n- Jenkins builds pull requests/merge requests s"
  },
  "3972": {
    "source_file": "securing-builds.txt",
    "text": "\n- Jenkins hosts multiple teams, which are not allowed to access each others' projects or source code.\n- Jenkins builds pull requests/merge requests submitted to public repositories, e.g., on GitHub.\n\nIn these scenarios, build scripts running on the same agents may be able to access data related to other, unrelated, projects, and potentially even manipulate their build results.\nEven not assuming m"
  },
  "3973": {
    "source_file": "securing-builds.txt",
    "text": "same agents may be able to access data related to other, unrelated, projects, and potentially even manipulate their build results.\nEven not assuming malicious intent, badly set up build scripts can accidentally delete unrelated data or cause resource exhaustion on the static agent, delaying builds.\n\nSolutions to this issue include the following:\n\n- Use https://plugins.jenkins.io/ui/search/?labels="
  },
  "3974": {
    "source_file": "securing-builds.txt",
    "text": " exhaustion on the static agent, delaying builds.\n\nSolutions to this issue include the following:\n\n- Use https://plugins.jenkins.io/ui/search/?labels=cloud[cloud providers] that create a new agent for every build.\n- Plugins such as plugin:job-restrictions[Job Restrictions Plugin] limit which jobs can be run on certain nodes.\n\nWhen using organization folders or https://plugins.jenkins.io/workflow-m"
  },
  "3975": {
    "source_file": "securing-builds.txt",
    "text": "tions[Job Restrictions Plugin] limit which jobs can be run on certain nodes.\n\nWhen using organization folders or https://plugins.jenkins.io/workflow-multibranch/[multibranch Pipelines], Jenkins automatically builds new pull requests by default.\nEspecially when a Jenkins instance builds projects from public repositories, this can open the door for abuse, such as:\n// General issue is tracked in http"
  },
  "3976": {
    "source_file": "securing-builds.txt",
    "text": "ially when a Jenkins instance builds projects from public repositories, this can open the door for abuse, such as:\n// General issue is tracked in https://issues.jenkins.io/browse/JENKINS-53752\n\n- Spam pull requests that trigger many new builds.\n- Malicious pull requests that modify build scripts, e.g., to mine cryptocurrency.\n\nStrategies for dealing with this include:\n\n- Use cloud providers and li"
  },
  "3977": {
    "source_file": "securing-builds.txt",
    "text": "icious pull requests that modify build scripts, e.g., to mine cryptocurrency.\n\nStrategies for dealing with this include:\n\n- Use cloud providers and limit how many agents can be launched in parallel. This is easy to implement, but can delay legitimate builds due to resource constraints.\n- Define https://plugins.jenkins.io/build-timeout[timeouts] in the Pipeline definition (typically `Jenkinsfile`),"
  },
  "3978": {
    "source_file": "securing-builds.txt",
    "text": " builds due to resource constraints.\n- Define https://plugins.jenkins.io/build-timeout[timeouts] in the Pipeline definition (typically `Jenkinsfile`), as it cannot be modified by users without commit access given appropriate Pipeline trust settings.\n- Do not automatically build new pull requests and instead require committers to opt into them, e.g., using plugins like https://plugins.jenkins.io/gi"
  },
  "3979": {
    "source_file": "securing-builds.txt",
    "text": "- Do not automatically build new pull requests and instead require committers to opt into them, e.g., using plugins like https://plugins.jenkins.io/github-label-filter/[GitHub Label Filter]\n// TODO: github-label-filter does not look like a plugin we should recommend here, are there better alternatives?\n\nBuild scripts and tools invoked during the build may change behavior depending on environment v"
  },
  "3980": {
    "source_file": "securing-builds.txt",
    "text": "should recommend here, are there better alternatives?\n\nBuild scripts and tools invoked during the build may change behavior depending on environment variables defined for the build.\nThese variables can come from various sources, such as build parameters, predefined agent environment variables, files read from the workspace and injected into the environment, etc.\n\n discusses this topic in detail, i"
  },
  "3981": {
    "source_file": "securing-builds.txt",
    "text": "ers, predefined agent environment variables, files read from the workspace and injected into the environment, etc.\n\n discusses this topic in detail, including solutions."
  },
  "3982": {
    "source_file": "securing-jenkins.txt",
    "text": "layout: section\nwip: true\n\n\nifdef::env-github[:imagesdir: ../resources]\nifndef::env-github[:imagesdir: ../../resources]\n\nSecuring Jenkins has two aspects to it.\n\n* Access control, which ensures users are authenticated when accessing Jenkins\n  and their activities are authorized.\n* Protecting Jenkins against external threats\n\nYou should lock down the access to Jenkins UI so that users are authentic"
  },
  "3983": {
    "source_file": "securing-jenkins.txt",
    "text": "ir activities are authorized.\n* Protecting Jenkins against external threats\n\nYou should lock down the access to Jenkins UI so that users are authenticated\nand appropriate set of permissions are given to them. This setting is\ncontrolled mainly by two axes:\n\n* *Security Realm*, which determines users and their passwords, as well as what\n  groups the users belong to.\n* *Authorization Strategy*, which"
  },
  "3984": {
    "source_file": "securing-jenkins.txt",
    "text": "axes:\n\n* *Security Realm*, which determines users and their passwords, as well as what\n  groups the users belong to.\n* *Authorization Strategy*, which determines who has access to what.\n\nThese two axes are orthogonal, and need to be individually configured. For\nexample, you might choose to use external LDAP or Active Directory as the\nsecurity realm, and you might choose \"everyone full access once "
  },
  "3985": {
    "source_file": "securing-jenkins.txt",
    "text": "igured. For\nexample, you might choose to use external LDAP or Active Directory as the\nsecurity realm, and you might choose \"everyone full access once logged in\" mode\nfor authorization strategy. Or you might choose to let Jenkins run its own user\ndatabase, and perform access control based on the permission/user matrix.\n\n* https://wiki.jenkins.io/display/JENKINS/Quick+and+Simple+Security[Quick and S"
  },
  "3986": {
    "source_file": "securing-jenkins.txt",
    "text": "base, and perform access control based on the permission/user matrix.\n\n* https://wiki.jenkins.io/display/JENKINS/Quick+and+Simple+Security[Quick and Simple Security] --- if you are running Jenkins like `java -jar jenkins.war` and only need a very simple setup\n* https://wiki.jenkins.io/display/JENKINS/Standard+Security+Setup[Standard Security Setup] --- discusses the most common setup of letting Je"
  },
  "3987": {
    "source_file": "securing-jenkins.txt",
    "text": "ple setup\n* https://wiki.jenkins.io/display/JENKINS/Standard+Security+Setup[Standard Security Setup] --- discusses the most common setup of letting Jenkins run its own user database and do finer-grained access control\n* https://wiki.jenkins.io/display/JENKINS/Apache+frontend+for+security[Apache frontend for security] --- run Jenkins behind Apache and perform access control in Apache instead of Jen"
  },
  "3988": {
    "source_file": "securing-jenkins.txt",
    "text": "y/JENKINS/Apache+frontend+for+security[Apache frontend for security] --- run Jenkins behind Apache and perform access control in Apache instead of Jenkins\n* https://wiki.jenkins.io/display/JENKINS/Authenticating+scripted+clients[Authenticating scripted clients] --- if you need to programmatically access security-enabled Jenkins web UI, use BASIC auth\n* https://wiki.jenkins.io/display/JENKINS/Matri"
  },
  "3989": {
    "source_file": "securing-jenkins.txt",
    "text": "ed clients] --- if you need to programmatically access security-enabled Jenkins web UI, use BASIC auth\n* https://wiki.jenkins.io/display/JENKINS/Matrix-based+security[Matrix-based security|Matrix-based security] --- Granting and denying finer-grained permissions\n\nIn addition to access control of users,  limits what builds can do, once started."
  },
  "3990": {
    "source_file": "securing-jenkins.txt",
    "text": " permissions\n\nIn addition to access control of users,  limits what builds can do, once started."
  },
  "3991": {
    "source_file": "securing-org-folders-and-multibranch-pipelines.txt",
    "text": "title: Securing SCM credentials for Organization Folders and Multibranch Pipelines\nlayout: section\n\n\nifdef::env-github[:imagesdir: ../resources]\nifndef::env-github[:imagesdir: ../../resources]\n\nOrganization Folders and Multibranch Pipelines are Jenkins project types that allow a single configuration item to automatically manage and build a potentially large number of Pipeline jobs for different re"
  },
  "3992": {
    "source_file": "securing-org-folders-and-multibranch-pipelines.txt",
    "text": "ns project types that allow a single configuration item to automatically manage and build a potentially large number of Pipeline jobs for different repositories or different branches of a single repository.\nThese projects interact with external SCM providers in various ways, which generally require credentials with SCM provider API access to be made available to Jenkins (\"scan credentials\").\nThe f"
  },
  "3993": {
    "source_file": "securing-org-folders-and-multibranch-pipelines.txt",
    "text": "roviders in various ways, which generally require credentials with SCM provider API access to be made available to Jenkins (\"scan credentials\").\nThe following sections discuss potential issues with visibility and accessibility of those credentials.\n\nFor many Branch Source configurations, such as those provided by GitHub Branch Source plugin and Bitbucket Branch Source plugin, the Jenkins user who "
  },
  "3994": {
    "source_file": "securing-org-folders-and-multibranch-pipelines.txt",
    "text": "For many Branch Source configurations, such as those provided by GitHub Branch Source plugin and Bitbucket Branch Source plugin, the Jenkins user who configures the project only needs to provide a single credential, which will be used in two ways:\n\n* By the controller, to perform plugin operations like Organization Folder scans, Multibranch Pipeline branch indexing, webhook modification, commit st"
  },
  "3995": {
    "source_file": "securing-org-folders-and-multibranch-pipelines.txt",
    "text": " By the controller, to perform plugin operations like Organization Folder scans, Multibranch Pipeline branch indexing, webhook modification, commit status updates, and more. These operations generally interact with SCM provider APIs that may require significant permissions beyond read/write access to the contents of a repository.\n* By nodes, to check out the repositories being built by the child P"
  },
  "3996": {
    "source_file": "securing-org-folders-and-multibranch-pipelines.txt",
    "text": "significant permissions beyond read/write access to the contents of a repository.\n* By nodes, to check out the repositories being built by the child Pipeline jobs.\n\nCredentials defined using the Global scope are available to all children of the object where they are defined.\nThis means that any credentials available to Organization Folders and Multibranch Pipelines will also be available to their "
  },
  "3997": {
    "source_file": "securing-org-folders-and-multibranch-pipelines.txt",
    "text": "t where they are defined.\nThis means that any credentials available to Organization Folders and Multibranch Pipelines will also be available to their child Pipeline jobs.\n\nAny user who has Job/Create permission in a location where a credential is available must be trusted to use that credential arbitrarily (and in many cases, Job/Configure is enough to use credentials arbitrarily).\nWhen using Jenk"
  },
  "3998": {
    "source_file": "securing-org-folders-and-multibranch-pipelines.txt",
    "text": "ilable must be trusted to use that credential arbitrarily (and in many cases, Job/Configure is enough to use credentials arbitrarily).\nWhen using Jenkins Pipeline, that trust is extended to any user who is able to modify `Jenkinsfile`, and have their changes used by Jenkins.\nWhich users are trusted to modify `Jenkinsfile` depends on the Branch Source configuration for the Pipeline, as they are abl"
  },
  "3999": {
    "source_file": "securing-org-folders-and-multibranch-pipelines.txt",
    "text": " changes used by Jenkins.\nWhich users are trusted to modify `Jenkinsfile` depends on the Branch Source configuration for the Pipeline, as they are able to modify `Jenkinsfile`.\nFor example, any user who can write to a branch in the repository is considered trusted by the GitHub Branch Source plugin.\n\nSCM credentials for Organization Folders and Multibranch Pipelines are available for arbitrary use"
  },
  "4000": {
    "source_file": "securing-org-folders-and-multibranch-pipelines.txt",
    "text": "idered trusted by the GitHub Branch Source plugin.\n\nSCM credentials for Organization Folders and Multibranch Pipelines are available for arbitrary use by anyone who is able to modify the `Jenkinsfile` of a repository being built by that Organization Folder or Multibranch Pipeline.\n\nMisuse of `withCredentials` around Pipeline steps that execute user-controlled code may allow untrusted users to capt"
  },
  "4001": {
    "source_file": "securing-org-folders-and-multibranch-pipelines.txt",
    "text": "Folder or Multibranch Pipeline.\n\nMisuse of `withCredentials` around Pipeline steps that execute user-controlled code may allow untrusted users to capture the credentials even if they do not have the ability to modify `Jenkinsfile`, but this is separate from the problems being discussed here.\nFor example, if a Multibranch Pipeline builds PRs from forks, and the Jenkinsfile binds a credential around"
  },
  "4002": {
    "source_file": "securing-org-folders-and-multibranch-pipelines.txt",
    "text": "te from the problems being discussed here.\nFor example, if a Multibranch Pipeline builds PRs from forks, and the Jenkinsfile binds a credential around a `sh` step that runs tests in the repository, a user can file a PR from a fork that modifies the tests to access the credential without having to modify `Jenkinsfile`.\n\nMany SCM plugins offer a configuration option to perform the actual source code"
  },
  "4003": {
    "source_file": "securing-org-folders-and-multibranch-pipelines.txt",
    "text": "ests to access the credential without having to modify `Jenkinsfile`.\n\nMany SCM plugins offer a configuration option to perform the actual source code checkout using SSH. These options do not prevent the scan credentials from being used in the Pipeline in other ways, for example by a `withCredentials` step.\n\nThis may be undesirable in two ways:\n\n* Write access to one repository can be used to obta"
  },
  "4004": {
    "source_file": "securing-org-folders-and-multibranch-pipelines.txt",
    "text": "ne in other ways, for example by a `withCredentials` step.\n\nThis may be undesirable in two ways:\n\n* Write access to one repository can be used to obtain credentials that have access to other repositories.\n* Write access to one repository can be used to obtain credentials with permissions beyond repository read/write access.\n\nThe above concerns may not matter to users with simple security models.\n\n"
  },
  "4005": {
    "source_file": "securing-org-folders-and-multibranch-pipelines.txt",
    "text": "to obtain credentials with permissions beyond repository read/write access.\n\nThe above concerns may not matter to users with simple security models.\n\nYou should consider the above implications carefully if:\n\n* You use a single organization folder in Jenkins to build multiple SCM repositories for which the users with SCM access to one repository must not have access to the other repositories being "
  },
  "4006": {
    "source_file": "securing-org-folders-and-multibranch-pipelines.txt",
    "text": "Jenkins to build multiple SCM repositories for which the users with SCM access to one repository must not have access to the other repositories being built.\n* Your SCM users must only have read/write access to repositories and no additional permissions.\n\nNote that if you allow untrusted users to create or configure jobs in locations where credentials are available, this issue does not matter, as t"
  },
  "4007": {
    "source_file": "securing-org-folders-and-multibranch-pipelines.txt",
    "text": "ns.\n\nNote that if you allow untrusted users to create or configure jobs in locations where credentials are available, this issue does not matter, as those users can use the credentials directly.\n\nAdditionally, these concerns only apply to users who do not have Job/Configure permission (or more powerful permissions) in Jenkins, but who do have the ability to edit Pipelines, for example because they"
  },
  "4008": {
    "source_file": "securing-org-folders-and-multibranch-pipelines.txt",
    "text": "o not have Job/Configure permission (or more powerful permissions) in Jenkins, but who do have the ability to edit Pipelines, for example because they have write access to repositories that contain Jenkinsfiles.\nIf untrusted users do not have the ability to edit Jenkinsfiles, for example because Multibranch Pipelines are configured to use a centralized Pipeline via a plugin such as plugin:inline-p"
  },
  "4009": {
    "source_file": "securing-org-folders-and-multibranch-pipelines.txt",
    "text": "lity to edit Jenkinsfiles, for example because Multibranch Pipelines are configured to use a centralized Pipeline via a plugin such as plugin:inline-pipeline[Multibranch Pipeline Inline Definition] or plugin:pipeline-multibranch-defaults[Pipeline: Multibranch with defaults], these issues do not matter.\n\nIf your primary concern is to prevent users with SCM read/write access to a repository from usi"
  },
  "4010": {
    "source_file": "securing-org-folders-and-multibranch-pipelines.txt",
    "text": "ltibranch with defaults], these issues do not matter.\n\nIf your primary concern is to prevent users with SCM read/write access to a repository from using the scan credentials to access other repositories being built by an Organization Folder, you have a few options:\n\n* Assuming that your SCM provider allows you to create credentials which may only access specific repositories (such as GitHub's fine"
  },
  "4011": {
    "source_file": "securing-org-folders-and-multibranch-pipelines.txt",
    "text": " a few options:\n\n* Assuming that your SCM provider allows you to create credentials which may only access specific repositories (such as GitHub's fine-grained personal access tokens), you can create multiple Organization Folders configured to build distinct subsets of the repositories in question, defining the restricted credentials directly on each Organization Folder in Jenkins.\n* Depending on y"
  },
  "4012": {
    "source_file": "securing-org-folders-and-multibranch-pipelines.txt",
    "text": "istinct subsets of the repositories in question, defining the restricted credentials directly on each Organization Folder in Jenkins.\n* Depending on your SCM provider's credential-related features, you may not be able to use Organization Folders securely, and would instead need to create one Multibranch Pipeline for each repository with a credential defined on it that only allows access to that sp"
  },
  "4013": {
    "source_file": "securing-org-folders-and-multibranch-pipelines.txt",
    "text": "rely, and would instead need to create one Multibranch Pipeline for each repository with a credential defined on it that only allows access to that specific repository.\n\nUnfortunately, if your primary concern is to prevent users with SCM read/write access to a repository from using the scan credentials to gain elevated permissions, there is no generic solution.\nIn some cases, you may be able to re"
  },
  "4014": {
    "source_file": "securing-org-folders-and-multibranch-pipelines.txt",
    "text": "ccess to a repository from using the scan credentials to gain elevated permissions, there is no generic solution.\nIn some cases, you may be able to remove permissions from the credential to make it less powerful.\nFor example, you may be able to remove webhook-related permissions from the credentials, which will prevent Jenkins from automatically managing webhooks, in favor of having an administrat"
  },
  "4015": {
    "source_file": "securing-org-folders-and-multibranch-pipelines.txt",
    "text": "e webhook-related permissions from the credentials, which will prevent Jenkins from automatically managing webhooks, in favor of having an administrator configure webhooks manually.\n\nIf you are using GitHub Branch Source Plugin with GitHub App Credentials, the plugin offers various features as of version 1844.v4a_9883d49126 that can be used to improve security.\nRefer to  for details."
  },
  "4016": {
    "source_file": "securing-org-folders-and-multibranch-pipelines.txt",
    "text": "tials, the plugin offers various features as of version 1844.v4a_9883d49126 that can be used to improve security.\nRefer to  for details."
  },
  "4017": {
    "source_file": "SECURITY-534.txt",
    "text": "title: Ensuring view rendering after SECURITY-534\nlayout: developersection\nreferences:\n- url: /security/advisory/2019-07-17/#SECURITY-534\n  title: SECURITY-534 security fix\n\n\nJenkins filters view dispatch using the `DispatchValidator` SPI in Stapler which implements some common default rules for distinguishing between views and fragments.\nFrom the Jenkins Jelly tag library `/lib/layout`, there is "
  },
  "4018": {
    "source_file": "SECURITY-534.txt",
    "text": "which implements some common default rules for distinguishing between views and fragments.\nFrom the Jenkins Jelly tag library `/lib/layout`, there is a Jelly tag, `<l:view>`, which is used as the basis for defining a top level view and some optional parameters.\nThis tag is used and implied by the common Jelly tags `<l:layout>` and `<l:ajax>` which are the typical root Jelly elements used when defi"
  },
  "4019": {
    "source_file": "SECURITY-534.txt",
    "text": "parameters.\nThis tag is used and implied by the common Jelly tags `<l:layout>` and `<l:ajax>` which are the typical root Jelly elements used when defining views.\nFor views that don't use `l:layout` or `l:ajax`, here's an example of how to declare that:\n\n<?jelly escape-by-default='true'?>\n<j:jelly xmlns:j=\"jelly:core\" xmlns:l=\"/lib/layout\">\n  <l:view contentType=\"text/html;charset=UTF-8\">\n    <html"
  },
  "4020": {
    "source_file": "SECURITY-534.txt",
    "text": "t:\n\n<?jelly escape-by-default='true'?>\n<j:jelly xmlns:j=\"jelly:core\" xmlns:l=\"/lib/layout\">\n  <l:view contentType=\"text/html;charset=UTF-8\">\n    <html>\n      <!-- fancy SPA -->\n    </html>\n  </l:view>\n</j:jelly>\n\nOr using Groovy:\n\ndef l = namespace('/lib/layout')\nl.view(contentType: 'text/html;charset=UTF-8') {\n  html {\n    // ...\n  }\n}\n\nAdditionally, views named `index` and views that set an HTTP"
  },
  "4021": {
    "source_file": "SECURITY-534.txt",
    "text": "/lib/layout')\nl.view(contentType: 'text/html;charset=UTF-8') {\n  html {\n    // ...\n  }\n}\n\nAdditionally, views named `index` and views that set an HTTP content type header via `<st:contentType>` are automatically considered views.\n\nSome views do not follow these established patterns for one reason or another.\nViews can be allowed or denied explicitly via the annotations `@StaplerViews` and `@Staple"
  },
  "4022": {
    "source_file": "SECURITY-534.txt",
    "text": "ollow these established patterns for one reason or another.\nViews can be allowed or denied explicitly via the annotations `@StaplerViews` and `@StaplerFragments` respectively.\nThese annotations are applied to the model class that dispatches the views and override the above dispatch filtering logic.\nFor example, suppose Jenkins defines an abstract class `BaseClass` which has views `index`, `configu"
  },
  "4023": {
    "source_file": "SECURITY-534.txt",
    "text": " and override the above dispatch filtering logic.\nFor example, suppose Jenkins defines an abstract class `BaseClass` which has views `index`, `configure`, `create`, and `delete`.\nImplementation classes are expected to provide their own fragment view `config` which gets included in `configure` and `create`.\nThis can be encoded explicitly in the model class:\n\n@StaplerViews({\"configure\", \"create\", \"d"
  },
  "4024": {
    "source_file": "SECURITY-534.txt",
    "text": "`config` which gets included in `configure` and `create`.\nThis can be encoded explicitly in the model class:\n\n@StaplerViews({\"configure\", \"create\", \"delete\"}) // index is implicit\n@StaplerFragments(\"config\")\npublic abstract class BaseClass {\n    ...\n}\n\nBy adding the annotations to Jenkins, implementation classes (typically from plugins) can be filtered explicitly via the parent annotations without"
  },
  "4025": {
    "source_file": "SECURITY-534.txt",
    "text": "}\n\nBy adding the annotations to Jenkins, implementation classes (typically from plugins) can be filtered explicitly via the parent annotations without updating the downstream code.\nImplementation classes may further define additional views or fragments.\nFor example, suppose `ExtendedClass` extends `BaseClass` and adds its own optional fragment view `advanced` which its implementation classes can i"
  },
  "4026": {
    "source_file": "SECURITY-534.txt",
    "text": "ts.\nFor example, suppose `ExtendedClass` extends `BaseClass` and adds its own optional fragment view `advanced` which its implementation classes can include.\n\n@StaplerFragments(\"advanced\")\npublic class ExtendedClass extends BaseClass {\n    ...\n}\n\nThese annotations are provided in a standalone annotation dependency and can be included in a plugin's dependencies:\n\n<dependency>\n  <groupId>io.jenkins."
  },
  "4027": {
    "source_file": "SECURITY-534.txt",
    "text": "se annotations are provided in a standalone annotation dependency and can be included in a plugin's dependencies:\n\n<dependency>\n  <groupId>io.jenkins.stapler</groupId>\n  <artifactId>jenkins-stapler-support</artifactId>\n  <version>1.1</version>\n</dependency>"
  },
  "4028": {
    "source_file": "SECURITY-534.txt",
    "text": "ndency>"
  },
  "4029": {
    "source_file": "security.txt",
    "text": "layout: redirect\nredirect_url: \"/doc/book/security/securing-jenkins/\""
  },
  "4030": {
    "source_file": "serialization-of-anonymous-classes.txt",
    "text": "title: How to serialize anonymous classes\nlayout: developer\n\n\nJenkins core and plugin code make use of two kinds of serialization of Java objects: to XML files like `+config.xml+` or\u00a0`+build.xml+` or global settings, via XStream; and using Java\u2019s built-in serialization mechanism, for Remoting calls. In either case you may see a warning from\u00a0() or () such as:\n\nAttempt to (de-)serialize anonymous cl"
  },
  "4031": {
    "source_file": "serialization-of-anonymous-classes.txt",
    "text": "lt-in serialization mechanism, for Remoting calls. In either case you may see a warning from\u00a0() or () such as:\n\nAttempt to (de-)serialize anonymous class org.jenkinsci.plugins.stuff.YourClass$3\nin file:/\u2026/plugins/stuff/WEB-INF/lib/stuff.jar;\nsee: https://jenkins.io/redirect/serialization-of-anonymous-classes/\n\nThere are less common variants for attempts to serialize lambdas or local classes.\nThe w"
  },
  "4032": {
    "source_file": "serialization-of-anonymous-classes.txt",
    "text": "ps://jenkins.io/redirect/serialization-of-anonymous-classes/\n\nThere are less common variants for attempts to serialize lambdas or local classes.\nThe warning will be logged by\u00a0`+org.jenkinsci.remoting.util.AnonymousClassWarnings+`.\nIf you see this warning, track down the location in source code:\n\njavap -classpath /\u2026/plugins/stuff/WEB-INF/lib/stuff.jar -l 'org.jenkinsci.plugins.stuff.YourClass$3'\n\nw"
  },
  "4033": {
    "source_file": "serialization-of-anonymous-classes.txt",
    "text": "ning, track down the location in source code:\n\njavap -classpath /\u2026/plugins/stuff/WEB-INF/lib/stuff.jar -l 'org.jenkinsci.plugins.stuff.YourClass$3'\n\nwill give you an overview of the class, and\u00a0`+LineNumberTable+` entries will show you which lines in\u00a0`+YourClass.java+` contain the class declaration.\n\n## Usages in Remoting\n\nThe main problem with sending anonymous classes over Remoting is that can al"
  },
  "4034": {
    "source_file": "serialization-of-anonymous-classes.txt",
    "text": "`+YourClass.java+` contain the class declaration.\n\n## Usages in Remoting\n\nThe main problem with sending anonymous classes over Remoting is that can all too easily \u201ccapture\u201d unexpected and unwanted fields in the callable, which may cause serious issues including those described in\u00a0(). Also you will get unusable listings from metrics collected as .\n\nTo fix code like this:\n\nint stuff(FilePath workspa"
  },
  "4035": {
    "source_file": "serialization-of-anonymous-classes.txt",
    "text": "s including those described in\u00a0(). Also you will get unusable listings from metrics collected as .\n\nTo fix code like this:\n\nint stuff(FilePath workspace, final String arg) throws IOException, InterruptedException {\n    return workspace.act(new MasterToSlaveFileCallable<Integer>() {\n        @Override\n        public Integer invoke(File f, VirtualChannel channel) throws IOException, InterruptedExcept"
  },
  "4036": {
    "source_file": "serialization-of-anonymous-classes.txt",
    "text": "ToSlaveFileCallable<Integer>() {\n        @Override\n        public Integer invoke(File f, VirtualChannel channel) throws IOException, InterruptedException {\n            return countThings(f, arg);\n        }\n    });\n}\n\njust use a \"convert anonymous to member\" refactoring in your IDE, or manually:\n\nprivate record ThingCounter(String arg) implements ControllerToAgentFileCallable<Integer> {\n    @Overri"
  },
  "4037": {
    "source_file": "serialization-of-anonymous-classes.txt",
    "text": "member\" refactoring in your IDE, or manually:\n\nprivate record ThingCounter(String arg) implements ControllerToAgentFileCallable<Integer> {\n    @Override\n    public Integer invoke(File f, VirtualChannel channel) throws IOException, InterruptedException {\n        return countThings(f, arg);\n    }\n}\nint stuff(FilePath workspace, String arg) throws IOException, InterruptedException {\n    return worksp"
  },
  "4038": {
    "source_file": "serialization-of-anonymous-classes.txt",
    "text": "n {\n        return countThings(f, arg);\n    }\n}\nint stuff(FilePath workspace, String arg) throws IOException, InterruptedException {\n    return workspace.act(new ThingCounter(arg));\n}\n\nor prior to Jenkins 2.485:\n\nprivate static final class ThingCounter extends MasterToSlaveFileCallable<Integer> {\n    private final String arg;\n    ThingCounter(String arg) {\n        this.arg = arg;\n    }\n    @Overri"
  },
  "4039": {
    "source_file": "serialization-of-anonymous-classes.txt",
    "text": "er extends MasterToSlaveFileCallable<Integer> {\n    private final String arg;\n    ThingCounter(String arg) {\n        this.arg = arg;\n    }\n    @Override\n    public Integer invoke(File f, VirtualChannel channel) throws IOException, InterruptedException {\n        return countThings(f, arg);\n    }\n}\nint stuff(FilePath workspace, String arg) throws IOException, InterruptedException {\n    return worksp"
  },
  "4040": {
    "source_file": "serialization-of-anonymous-classes.txt",
    "text": "n {\n        return countThings(f, arg);\n    }\n}\nint stuff(FilePath workspace, String arg) throws IOException, InterruptedException {\n    return workspace.act(new ThingCounter(arg));\n}\n\n## Usages in XStream\n\nIf you have accidentally used an anonymous inner class as a field in some object serialized via XStream, your XML files are going to be a mess. This is a worse problem than for Remoting since n"
  },
  "4041": {
    "source_file": "serialization-of-anonymous-classes.txt",
    "text": "inner class as a field in some object serialized via XStream, your XML files are going to be a mess. This is a worse problem than for Remoting since not only can you suffer from  security blocks, but the mistake has been persisted to disk so you need to take into account possible saved settings.\n\nIf the field was not really valuable, make it\u00a0`+transient+` (so it will not be saved), and\u00a0_also_ rena"
  },
  "4042": {
    "source_file": "serialization-of-anonymous-classes.txt",
    "text": " to take into account possible saved settings.\n\nIf the field was not really valuable, make it\u00a0`+transient+` (so it will not be saved), and\u00a0_also_ rename it so Jenkins will not even try to load existing values from disk.\n\nIf you can afford to discard old settings, fix its type and rename it.\n\nIf you really need to load existing settings, you are going to have to do some work to retain compatibility"
  },
  "4043": {
    "source_file": "serialization-of-anonymous-classes.txt",
    "text": "old settings, fix its type and rename it.\n\nIf you really need to load existing settings, you are going to have to do some work to retain compatibility. If\u00a0`+YourClass$3+` was saved to disk, originally from\n\nclass YourClass {\n    // \u2026dozens of unrelated lines\u2026\n    public SomeInterface thingThatGetsSaved(final String arg) {\n        return new SomeInterface() {\n            @Override\n            publi"
  },
  "4044": {
    "source_file": "serialization-of-anonymous-classes.txt",
    "text": "ed lines\u2026\n    public SomeInterface thingThatGetsSaved(final String arg) {\n        return new SomeInterface() {\n            @Override\n            public void someMethod() {\n                use(arg);\n            }\n        };\n    }\n}\n\nthen you can refactor this way:\n\nclass YourClass {\n    // right at the top of the file:\n    /** @deprecated unused */\n    private static final Object[] SOME_CLOSURES = "
  },
  "4045": {
    "source_file": "serialization-of-anonymous-classes.txt",
    "text": "tor this way:\n\nclass YourClass {\n    // right at the top of the file:\n    /** @deprecated unused */\n    private static final Object[] SOME_CLOSURES = {\n        new Object() {}, // YourClass$1\n        new Object() {}, // YourClass$2\n    };\n    /** @deprecated unused */\n    private SomeInterface thingThatGetsSaved(final String arg) {\n        return new SomeInterface() { // YourClass$3\n            @O"
  },
  "4046": {
    "source_file": "serialization-of-anonymous-classes.txt",
    "text": "precated unused */\n    private SomeInterface thingThatGetsSaved(final String arg) {\n        return new SomeInterface() { // YourClass$3\n            @Override\n            public void someMethod() {\n                use(arg);\n            }\n            private Object readResolve() {\n                return new ThingThatGetsSaved(arg);\n            }\n        };\n    }\n    // \u2026dozens of unrelated lines\u2026\n  "
  },
  "4047": {
    "source_file": "serialization-of-anonymous-classes.txt",
    "text": "rivate Object readResolve() {\n                return new ThingThatGetsSaved(arg);\n            }\n        };\n    }\n    // \u2026dozens of unrelated lines\u2026\n    public SomeInterface thingThatGetsSaved(String arg) {\n        return new ThingThatGetsSaved(arg);\n    }\n    private static final class ThingThatGetsSaved implements SomeInterface {\n        private final String arg;\n        ThingThatGetsSaved(String"
  },
  "4048": {
    "source_file": "serialization-of-anonymous-classes.txt",
    "text": "    }\n    private static final class ThingThatGetsSaved implements SomeInterface {\n        private final String arg;\n        ThingThatGetsSaved(String arg) {\n            this.arg = arg;\n        }\n        @Override\n        public void someMethod() {\n            use(arg);\n        }\n    }\n}"
  },
  "4049": {
    "source_file": "serialization-of-anonymous-classes.txt",
    "text": "           use(arg);\n        }\n    }\n}"
  },
  "4050": {
    "source_file": "services.txt",
    "text": "title: Exposed Services and Ports\nlayout: section\n\n\nJenkins is a fairly complex application and as such does more than just serve a web interface.\nThis section documents the services it frequently exposes on the network.\n\nNOTE: Plugins may expose further services on the network.\nOnly very commonly installed plugins are considered below.\n\nThe web UI served via HTTP (or HTTPS), by default on port 80"
  },
  "4051": {
    "source_file": "services.txt",
    "text": "ther services on the network.\nOnly very commonly installed plugins are considered below.\n\nThe web UI served via HTTP (or HTTPS), by default on port 8080.\nSometimes Jenkins is running behind a reverse proxy that may customize or filter requests and responses.\n\nFor an overview of the URLs accessible to users without any permissions in Jenkins, see .\n// TODO that should be moved here.\n\nJenkins can ex"
  },
  "4052": {
    "source_file": "services.txt",
    "text": "sponses.\n\nFor an overview of the URLs accessible to users without any permissions in Jenkins, see .\n// TODO that should be moved here.\n\nJenkins can expose a TCP port that allows inbound agents to connect to it.\nIt can be enabled, disabled, and configured in _Manage Jenkins \u00bb Security_.\n\n// TODO Screenshot\n\nThe two supported modes (while enabled) are:\n\n*Random*: The TCP port is chosen at random to "
  },
  "4053": {
    "source_file": "services.txt",
    "text": "ured in _Manage Jenkins \u00bb Security_.\n\n// TODO Screenshot\n\nThe two supported modes (while enabled) are:\n\n*Random*: The TCP port is chosen at random to avoid collisions on the Jenkins <<../glossary#controller,controller>>.\n  The downside to randomized ports is that they are chosen during the boot of the Jenkins controller, making it difficult to manage firewall rules allowing TCP traffic.\n*Fixed*: T"
  },
  "4054": {
    "source_file": "services.txt",
    "text": "ports is that they are chosen during the boot of the Jenkins controller, making it difficult to manage firewall rules allowing TCP traffic.\n*Fixed*: The port is chosen by the Jenkins administrator and is consistent across reboots of the Jenkins controller.\n  This makes it easier to manage firewall rules allowing TCP-based agents to connect to the controller.\n\nThis service is disabled by default in"
  },
  "4055": {
    "source_file": "services.txt",
    "text": "oller.\n  This makes it easier to manage firewall rules allowing TCP-based agents to connect to the controller.\n\nThis service is disabled by default in most packages, but the Docker images expose it at port 50000.\n\nHTTP requests at this port get a minimal plain text response with some diagnostic information.\nIt looks like the following:\n\nJenkins-Agent-Protocols: JNLP4-connect, Ping <1> Jenkins-Vers"
  },
  "4056": {
    "source_file": "services.txt",
    "text": "imal plain text response with some diagnostic information.\nIt looks like the following:\n\nJenkins-Agent-Protocols: JNLP4-connect, Ping <1> Jenkins-Version: 2.289 <2> Jenkins-Session: b4783dfa <3> Client: 172.17.0.1 <4> Server: 172.17.0.3 <5> Remoting-Minimum-Version: 3.14 <6> <1> List of currently enabled TCP inbound agent protocols.\n<2> The current version of Jenkins.\n<3> The session of the curren"
  },
  "4057": {
    "source_file": "services.txt",
    "text": "Minimum-Version: 3.14 <6> <1> List of currently enabled TCP inbound agent protocols.\n<2> The current version of Jenkins.\n<3> The session of the current Jenkins execution. This is unrelated to web session cookies. This is changed to a new value whenever Jenkins starts. It is used in various URLs to help implement caching of static resources, and can be used by clients to tell whether Jenkins restar"
  },
  "4058": {
    "source_file": "services.txt",
    "text": "er Jenkins starts. It is used in various URLs to help implement caching of static resources, and can be used by clients to tell whether Jenkins restarted.\n<4> The client IP address as seen from Jenkins.\n<5> The Jenkins controller's IP address.\n<6> The minimum required version of the https://github.com/jenkinsci/remoting/[Remoting] library for agents to connect to this Jenkins controller.\n\n// Since"
  },
  "4059": {
    "source_file": "services.txt",
    "text": "e minimum required version of the https://github.com/jenkinsci/remoting/[Remoting] library for agents to connect to this Jenkins controller.\n\n// Since 2.217\nInbound agents may instead be configured to use WebSocket transport to connect to Jenkins.\nIn this case no extra TCP port need be enabled and no special security configuration is needed.\n\nThe https://plugins.jenkins.io/sshd[SSH Server] Plugin "
  },
  "4060": {
    "source_file": "services.txt",
    "text": " this case no extra TCP port need be enabled and no special security configuration is needed.\n\nThe https://plugins.jenkins.io/sshd[SSH Server] Plugin can be configured to open an SSH port on the Jenkins controller.\n\n// TODO Remove this note once it's been a year or so.\nNOTE: This plugin's functionality was part of Jenkins (core) until Jenkins 2.281.\n\n// TODO screenshot\n\nAuthentication can be usern"
  },
  "4061": {
    "source_file": "services.txt",
    "text": " been a year or so.\nNOTE: This plugin's functionality was part of Jenkins (core) until Jenkins 2.281.\n\n// TODO screenshot\n\nAuthentication can be username/password or using public key authentication.\nFor the latter, the public keys can be stored in Jenkins users' profiles.\n\nThis SSH server does not provide a regular OS shell once logged in.\nInstead, it provides a shell-like interface for the .\n\nAdd"
  },
  "4062": {
    "source_file": "services.txt",
    "text": "nkins users' profiles.\n\nThis SSH server does not provide a regular OS shell once logged in.\nInstead, it provides a shell-like interface for the .\n\nAdditionally, some plugins may provide features that require the SSH server to be enabled, like the plugin:git-server[GIT server] Plugin.\n\nThis service is disabled by default.\n\nJenkins releases 2.219 and earlier included features that allowed users to d"
  },
  "4063": {
    "source_file": "services.txt",
    "text": "gin:git-server[GIT server] Plugin.\n\nThis service is disabled by default.\n\nJenkins releases 2.219 and earlier included features that allowed users to discover Jenkins on their network.\nThese features have been removed without replacement in Jenkins 2.220 for security reasons."
  },
  "4064": {
    "source_file": "services.txt",
    "text": "220 for security reasons."
  },
  "4065": {
    "source_file": "servlet-containers.txt",
    "text": "layout: section\ntitle: Other Servlet Containers\n\n\nifdef::env-github[:imagesdir: ../resources]\nifndef::env-github[:imagesdir: ../../resources]\n\nJenkins is typically run as a standalone application in its own process.\nThe Jenkins WAR file bundles ,\na  servlet container wrapper,\nand can be started on any operating system or platform with a version of Java supported by Jenkins.\nThis is the preferred w"
  },
  "4066": {
    "source_file": "servlet-containers.txt",
    "text": "servlet container wrapper,\nand can be started on any operating system or platform with a version of Java supported by Jenkins.\nThis is the preferred way to deploy Jenkins and is fully supported.\n\nTheoretically, Jenkins can also be run as a servlet in a traditional servlet container\nlike  or ,\nbut in practice this is largely untested and there are many caveats.\nIn particular, support for WebSocket "
  },
  "4067": {
    "source_file": "servlet-containers.txt",
    "text": " a traditional servlet container\nlike  or ,\nbut in practice this is largely untested and there are many caveats.\nIn particular, support for WebSocket agents is only implemented for the Jetty servlet container.\nSee the  page for details.\n\nWARNING: Support for traditional servlet containers may be discontinued in the future.\n\n* **Jenkins 2.492.3+ requires Servlet API 5.0 (Jakarta EE 9)**\n* Compatibl"
  },
  "4068": {
    "source_file": "servlet-containers.txt",
    "text": "port for traditional servlet containers may be discontinued in the future.\n\n* **Jenkins 2.492.3+ requires Servlet API 5.0 (Jakarta EE 9)**\n* Compatible containers:\n  * **Tomcat 10.1.x** (Tested with 10.1.40 - latest version)\n  * WildFly version needs verification (minimum 30+ recommended)\n* Requires JDK 17+ for full compatibility\n\n### Deployment\n\n# Download Tomcat 10.1.x\nwget https://archive.apach"
  },
  "4069": {
    "source_file": "servlet-containers.txt",
    "text": " verification (minimum 30+ recommended)\n* Requires JDK 17+ for full compatibility\n\n### Deployment\n\n# Download Tomcat 10.1.x\nwget https://archive.apache.org/dist/tomcat/tomcat-10/v10.1.40/bin/apache-tomcat-10.1.40.tar.gz\n\n# Extract and deploy\ntar xzf apache-tomcat-10.1.40.tar.gz\nexport CATALINA_HOME=$(pwd)/apache-tomcat-10.1.40\ncp jenkins.war $CATALINA_HOME/webapps/\n\n### Configuration\n**Set Jenkins"
  },
  "4070": {
    "source_file": "servlet-containers.txt",
    "text": "apache-tomcat-10.1.40.tar.gz\nexport CATALINA_HOME=$(pwd)/apache-tomcat-10.1.40\ncp jenkins.war $CATALINA_HOME/webapps/\n\n### Configuration\n**Set Jenkins home:**\n\nmkdir /var/lib/jenkins\necho \"export CATALINA_OPTS=-DJENKINS_HOME=/var/lib/jenkins\" > $CATALINA_HOME/bin/setenv.sh\nchmod +x $CATALINA_HOME/bin/setenv.sh\n\nNOTE: Running multiple Jenkins controllers within a single Java process is unsupported."
  },
  "4071": {
    "source_file": "servlet-containers.txt",
    "text": "LINA_HOME/bin/setenv.sh\nchmod +x $CATALINA_HOME/bin/setenv.sh\n\nNOTE: Running multiple Jenkins controllers within a single Java process is unsupported.\n\nScheme selection in redirect URLs is delegated to the servlet container,\nand Jetty handles the `X-Forwarded-For`, `X-Forwarded-By`, and `X-Forwarded-Proto` headers by default.\nWith Tomcat, one needs to add a\nto expose these headers to Jenkins via t"
  },
  "4072": {
    "source_file": "servlet-containers.txt",
    "text": "Forwarded-For`, `X-Forwarded-By`, and `X-Forwarded-Proto` headers by default.\nWith Tomcat, one needs to add a\nto expose these headers to Jenkins via the Servlet API.\nAdd the following to `+${CATALINA_HOME}/conf/server.xml+` within the `<Host>` section:\n\n<Valve className=\"org.apache.catalina.valves.RemoteIpValve\"\n       remoteIpHeader=\"X-Forwarded-For\"\n       proxiesHeader=\"X-Forwarded-By\"\n       p"
  },
  "4073": {
    "source_file": "servlet-containers.txt",
    "text": "n:\n\n<Valve className=\"org.apache.catalina.valves.RemoteIpValve\"\n       remoteIpHeader=\"X-Forwarded-For\"\n       proxiesHeader=\"X-Forwarded-By\"\n       protocolHeader=\"X-Forwarded-Proto\" />\n\n### Requirements\n* **WildFly 30+** required for Jenkins 2.492.3+ with JDK 17\n* Uses Servlet API 5.0 (Jakarta EE 9) with `jakarta.servlet` namespace\n* **Incompatible with WildFly 26 and earlier** (Servlet API 4.0)"
  },
  "4074": {
    "source_file": "servlet-containers.txt",
    "text": "3+ with JDK 17\n* Uses Servlet API 5.0 (Jakarta EE 9) with `jakarta.servlet` namespace\n* **Incompatible with WildFly 26 and earlier** (Servlet API 4.0)\n\n### Deployment\n\ncp jenkins.war $JBOSS_HOME/standalone/deployments/\n\n### Configuration\n\n# Add this to $JBOSS_HOME/bin/standalone.conf\nJAVA_OPTS=\"$JAVA_OPTS -DJENKINS_HOME=/var/lib/jenkins\"\n\nNOTE: Running multiple Jenkins controllers within a single "
  },
  "4075": {
    "source_file": "servlet-containers.txt",
    "text": "to $JBOSS_HOME/bin/standalone.conf\nJAVA_OPTS=\"$JAVA_OPTS -DJENKINS_HOME=/var/lib/jenkins\"\n\nNOTE: Running multiple Jenkins controllers within a single Java process is unsupported."
  },
  "4076": {
    "source_file": "shared-libraries.txt",
    "text": "layout: section\ntitle: Extending with Shared Libraries\n\n\nifdef::env-github[:imagesdir: ../resources]\nifndef::env-github[:imagesdir: ../../resources]\n\nAs Pipeline is adopted for more and more projects in an organization, common\npatterns are likely to emerge. Oftentimes it is useful to share parts of\nPipelines between various projects to reduce redundancies and keep code\n\"DRY\"\nfootnote:dry[https://e"
  },
  "4077": {
    "source_file": "shared-libraries.txt",
    "text": "emerge. Oftentimes it is useful to share parts of\nPipelines between various projects to reduce redundancies and keep code\n\"DRY\"\nfootnote:dry[https://en.wikipedia.org/wiki/Don\\'t_repeat_yourself].\n\nPipeline has support for creating \"Shared Libraries\" which can be defined in\nexternal source control repositories and loaded into existing Pipelines.\n\nvideo::Wj-weFEsTb0[youtube,width=800,height=420]\n\nA "
  },
  "4078": {
    "source_file": "shared-libraries.txt",
    "text": "which can be defined in\nexternal source control repositories and loaded into existing Pipelines.\n\nvideo::Wj-weFEsTb0[youtube,width=800,height=420]\n\nA Shared Library is defined with a name, a source code retrieval method such\nas by SCM, and optionally a default version.  The name should be a short\nidentifier as it will be used in scripts.\n\nThe version could be anything understood by that SCM; for e"
  },
  "4079": {
    "source_file": "shared-libraries.txt",
    "text": " a default version.  The name should be a short\nidentifier as it will be used in scripts.\n\nThe version could be anything understood by that SCM; for example, branches,\ntags, and commit hashes all work for Git.  You may also declare whether scripts\nneed to explicitly request that library (detailed below), or if it is present\nby default.  Furthermore, if you specify a version in Jenkins configuratio"
  },
  "4080": {
    "source_file": "shared-libraries.txt",
    "text": "ed to explicitly request that library (detailed below), or if it is present\nby default.  Furthermore, if you specify a version in Jenkins configuration,\nyou can block scripts from selecting a _different_ version.\n\nThe best way to specify the SCM is using an SCM plugin which has been\nspecifically updated to support a new API for checking out an arbitrary named\nversion (_Modern SCM_ option).  As of "
  },
  "4081": {
    "source_file": "shared-libraries.txt",
    "text": "sing an SCM plugin which has been\nspecifically updated to support a new API for checking out an arbitrary named\nversion (_Modern SCM_ option).  As of this writing, the latest versions of the\nGit and Subversion plugins support this mode; others should follow.\n\nIf your SCM plugin has not been integrated, you may select _Legacy SCM_ and\npick anything offered.  In this case, you need to include\n`${lib"
  },
  "4082": {
    "source_file": "shared-libraries.txt",
    "text": " follow.\n\nIf your SCM plugin has not been integrated, you may select _Legacy SCM_ and\npick anything offered.  In this case, you need to include\n`${library.yourLibName.version}` somewhere in the configuration of the SCM, so\nthat during checkout the plugin will expand this variable to select the desired\nversion.  For example, for Subversion, you can set the _Repository URL_ to\n`https://svnserver/pro"
  },
  "4083": {
    "source_file": "shared-libraries.txt",
    "text": "ugin will expand this variable to select the desired\nversion.  For example, for Subversion, you can set the _Repository URL_ to\n`https://svnserver/project/${library.yourLibName.version}` and then use\nversions such as `trunk` or `branches/dev` or `tags/1.0`.\n\nThe directory structure of a Shared Library repository is as follows:\n\n(root)\n- src                     # Groovy source files\n|   +- org\n|   "
  },
  "4084": {
    "source_file": "shared-libraries.txt",
    "text": "s/1.0`.\n\nThe directory structure of a Shared Library repository is as follows:\n\n(root)\n- src                     # Groovy source files\n|   +- org\n|       +- foo\n|           +- Bar.groovy  # for org.foo.Bar class\n- vars\n|   +- foo.groovy          # for global 'foo' variable\n|   +- foo.txt             # help for 'foo' variable\n- resources               # resource files (external libraries only)\n|   "
  },
  "4085": {
    "source_file": "shared-libraries.txt",
    "text": "r global 'foo' variable\n|   +- foo.txt             # help for 'foo' variable\n- resources               # resource files (external libraries only)\n|   +- org\n|       +- foo\n|           +- bar.json    # static helper data for org.foo.Bar\n\nThe `src` directory should look like standard Java source directory structure.\nThis directory is added to the classpath when executing Pipelines.\n\nThe `vars` direc"
  },
  "4086": {
    "source_file": "shared-libraries.txt",
    "text": "ectory should look like standard Java source directory structure.\nThis directory is added to the classpath when executing Pipelines.\n\nThe `vars` directory hosts script files that are exposed as a variable in Pipelines. The name of the file is the name of the variable in the Pipeline.\nSo if you had a file called `vars/log.groovy` with a function like `def info(message)...` in it, you can access thi"
  },
  "4087": {
    "source_file": "shared-libraries.txt",
    "text": "e of the variable in the Pipeline.\nSo if you had a file called `vars/log.groovy` with a function like `def info(message)...` in it, you can access this function like `log.info \"hello world\"` in the Pipeline. You can put as many functions as you like inside this file. Read on below for more examples and options.\n\nThe basename of each `.groovy` file should be a Groovy (~ Java) identifier, convention"
  },
  "4088": {
    "source_file": "shared-libraries.txt",
    "text": "inside this file. Read on below for more examples and options.\n\nThe basename of each `.groovy` file should be a Groovy (~ Java) identifier, conventionally `camelCased`.\nThe matching `.txt`, if present, can contain documentation, processed through the system\u2019s configured https://wiki.jenkins.io/display/JENKINS/Markup+formatting[markup formatter] (so may really be HTML, Markdown, etc., though the `."
  },
  "4089": {
    "source_file": "shared-libraries.txt",
    "text": " system\u2019s configured https://wiki.jenkins.io/display/JENKINS/Markup+formatting[markup formatter] (so may really be HTML, Markdown, etc., though the `.txt` extension is required). This documentation will only be visible on the  pages that are accessed from the navigation sidebar of Pipeline jobs that import the shared library. In addition, those jobs must run successfully once before the shared lib"
  },
  "4090": {
    "source_file": "shared-libraries.txt",
    "text": " from the navigation sidebar of Pipeline jobs that import the shared library. In addition, those jobs must run successfully once before the shared library documentation will be generated.\n\nThe Groovy source files in these directories get the same \u201cCPS transformation\u201d\nas in Scripted Pipeline.\n\nA `resources` directory allows the `libraryResource` step to be used from an external library to load asso"
  },
  "4091": {
    "source_file": "shared-libraries.txt",
    "text": "S transformation\u201d\nas in Scripted Pipeline.\n\nA `resources` directory allows the `libraryResource` step to be used from an external library to load associated non-Groovy files.\nCurrently this feature is not supported for internal libraries.\n\nOther directories under the root are reserved for future enhancements.\n\nThere are several places where Shared Libraries can be defined, depending on\nthe use-cas"
  },
  "4092": {
    "source_file": "shared-libraries.txt",
    "text": "ctories under the root are reserved for future enhancements.\n\nThere are several places where Shared Libraries can be defined, depending on\nthe use-case.\nNavigate to *_Manage Jenkins \u00bb System \u00bb Global Trusted Pipeline Libraries_* to configure as many libraries as necessary.\n\n{empty}\n\nSince these libraries will be globally usable, any Pipeline in the system can\nutilize functionality implemented in t"
  },
  "4093": {
    "source_file": "shared-libraries.txt",
    "text": "libraries as necessary.\n\n{empty}\n\nSince these libraries will be globally usable, any Pipeline in the system can\nutilize functionality implemented in these libraries.\n\nThese libraries may be marked \u201ctrusted\u201c, meaning they can run any methods in Java,\nGroovy, Jenkins internal APIs, Jenkins plugins, or third-party libraries.\nThis allows you to define libraries that encapsulate individually unsafe API"
  },
  "4094": {
    "source_file": "shared-libraries.txt",
    "text": "Groovy, Jenkins internal APIs, Jenkins plugins, or third-party libraries.\nThis allows you to define libraries that encapsulate individually unsafe APIs in a\nhigher-level wrapper that is safe for use from any pipeline.\nBeware that **anyone able to push commits to this SCM repository could obtain unlimited access to Jenkins**.\nYou need the _Overall/RunScripts_ permission to configure these libraries"
  },
  "4095": {
    "source_file": "shared-libraries.txt",
    "text": "h commits to this SCM repository could obtain unlimited access to Jenkins**.\nYou need the _Overall/RunScripts_ permission to configure these libraries (normally this will be granted to Jenkins administrators).\n\nIf you only have _Overall/Manage_ permission, you can still configure global libraries,\nbut only \u201cuntrusted\u201d ones that run in the Groovy sandbox just like typical Pipeline scripts.\n\nAny Fol"
  },
  "4096": {
    "source_file": "shared-libraries.txt",
    "text": "ssion, you can still configure global libraries,\nbut only \u201cuntrusted\u201d ones that run in the Groovy sandbox just like typical Pipeline scripts.\n\nAny Folder created can have Shared Libraries associated with it. This mechanism\nallows scoping of specific libraries to all the Pipelines inside of the folder\nor subfolder.\n\nFolder-scoped libraries are always \u201cuntrusted\u201d.\n\nOther plugins may add ways of defi"
  },
  "4097": {
    "source_file": "shared-libraries.txt",
    "text": "libraries to all the Pipelines inside of the folder\nor subfolder.\n\nFolder-scoped libraries are always \u201cuntrusted\u201d.\n\nOther plugins may add ways of defining libraries on the fly.  For example, the\nplugin:pipeline-github-lib[Pipeline: GitHub Groovy Libraries] plugin\nallows a script to use an untrusted library\nnamed like `github.com/someorg/somerepo` without any additional configuration.  In\nthis case"
  },
  "4098": {
    "source_file": "shared-libraries.txt",
    "text": "aries] plugin\nallows a script to use an untrusted library\nnamed like `github.com/someorg/somerepo` without any additional configuration.  In\nthis case, the specified GitHub repository would be loaded, from the `master`\nbranch, using an anonymous checkout.\n\nShared Libraries marked _Load implicitly_ allows Pipelines to immediately use\nclasses or global variables defined by any such libraries. To acc"
  },
  "4099": {
    "source_file": "shared-libraries.txt",
    "text": "kout.\n\nShared Libraries marked _Load implicitly_ allows Pipelines to immediately use\nclasses or global variables defined by any such libraries. To access other\nshared libraries, the `Jenkinsfile` needs to use the `@Library` annotation,\nspecifying the library's name:\n\n{empty}\n\n@Library('my-shared-library') _\n/* Using a version specifier, such as branch, tag, etc */\n@Library('my-shared-library@1.0')"
  },
  "4100": {
    "source_file": "shared-libraries.txt",
    "text": " library's name:\n\n{empty}\n\n@Library('my-shared-library') _\n/* Using a version specifier, such as branch, tag, etc */\n@Library('my-shared-library@1.0') _\n/* Accessing multiple libraries with one statement */\n@Library(['my-shared-library', 'otherlib@abc1234']) _\n\nThe annotation can be anywhere in the script where an annotation is permitted\nby Groovy.  When referring to class libraries (with `src/` d"
  },
  "4101": {
    "source_file": "shared-libraries.txt",
    "text": "c1234']) _\n\nThe annotation can be anywhere in the script where an annotation is permitted\nby Groovy.  When referring to class libraries (with `src/` directories),\nconventionally the annotation goes on an `import` statement:\n\n@Library('somelib')\nimport com.mycorp.pipeline.somelib.UsefulClass\n\n[TIP]\n\nFor Shared Libraries which only define Global Variables (`vars/`), or a\n`Jenkinsfile` which only nee"
  },
  "4102": {
    "source_file": "shared-libraries.txt",
    "text": "t com.mycorp.pipeline.somelib.UsefulClass\n\n[TIP]\n\nFor Shared Libraries which only define Global Variables (`vars/`), or a\n`Jenkinsfile` which only needs a Global Variable, the\n\npattern `@Library('my-shared-library') _` may be useful for keeping code\nconcise. In essence, instead of annotating an unnecessary `import` statement,\nthe symbol `_` is annotated.\n\nIt is not recommended to `import` a global"
  },
  "4103": {
    "source_file": "shared-libraries.txt",
    "text": "concise. In essence, instead of annotating an unnecessary `import` statement,\nthe symbol `_` is annotated.\n\nIt is not recommended to `import` a global variable/function,\nsince this will force the compiler to interpret fields and methods as `static`\neven if they were intended to be customized.\nThe Groovy compiler in this case can produce confusing error messages.\n\nLibraries are resolved and loaded "
  },
  "4104": {
    "source_file": "shared-libraries.txt",
    "text": "ven if they were intended to be customized.\nThe Groovy compiler in this case can produce confusing error messages.\n\nLibraries are resolved and loaded during _compilation_ of the script,\nbefore it starts executing.  This allows the Groovy compiler to understand the\nmeaning of symbols used in static type checking, and permits them to be used\nin type declarations in the script, for example:\n\n@Library"
  },
  "4105": {
    "source_file": "shared-libraries.txt",
    "text": "understand the\nmeaning of symbols used in static type checking, and permits them to be used\nin type declarations in the script, for example:\n\n@Library('somelib')\nimport com.mycorp.pipeline.somelib.Helper\n\nint useSomeLib(Helper helper) {\n    helper.prepare()\n    return helper.count()\n}\n\necho useSomeLib(new Helper('some text'))\n\nGlobal Variables however, are resolved at runtime.\n\nThis video reviews "
  },
  "4106": {
    "source_file": "shared-libraries.txt",
    "text": "epare()\n    return helper.count()\n}\n\necho useSomeLib(new Helper('some text'))\n\nGlobal Variables however, are resolved at runtime.\n\nThis video reviews using resource files from a Shared Library.\nA link to the example repository used is also provided in the .\n\nvideo::eV7roTXrEqg[youtube,width=800,height=420]\n\nAs of version 2.7 of the _Pipeline: Shared Groovy Libraries_ plugin,\nthere is a new option "
  },
  "4107": {
    "source_file": "shared-libraries.txt",
    "text": "n the .\n\nvideo::eV7roTXrEqg[youtube,width=800,height=420]\n\nAs of version 2.7 of the _Pipeline: Shared Groovy Libraries_ plugin,\nthere is a new option for loading (non-implicit) libraries in a script:\na `library` step that loads a library _dynamically_, at any time during the build.\n\nIf you are only interested in using global variables/functions (from the `vars/` directory),\nthe syntax is quite sim"
  },
  "4108": {
    "source_file": "shared-libraries.txt",
    "text": "_, at any time during the build.\n\nIf you are only interested in using global variables/functions (from the `vars/` directory),\nthe syntax is quite simple:\n\nlibrary 'my-shared-library'\n\nThereafter, any global variables from that library will be accessible to the script.\n\nUsing classes from the `src/` directory is also possible, but trickier.\nWhereas the `@Library` annotation prepares the \u201cclasspath"
  },
  "4109": {
    "source_file": "shared-libraries.txt",
    "text": "ible to the script.\n\nUsing classes from the `src/` directory is also possible, but trickier.\nWhereas the `@Library` annotation prepares the \u201cclasspath\u201d of the script prior to compilation,\nby the time a `library` step is encountered the script has already been compiled.\nTherefore you cannot `import` or otherwise \u201cstatically\u201d refer to types from the library.\n\nHowever you may use library classes dyna"
  },
  "4110": {
    "source_file": "shared-libraries.txt",
    "text": "eady been compiled.\nTherefore you cannot `import` or otherwise \u201cstatically\u201d refer to types from the library.\n\nHowever you may use library classes dynamically (without type checking),\naccessing them by fully-qualified name from the return value of the `library` step.\n`static` methods can be invoked using a Java-like syntax:\n\nlibrary('my-shared-library').com.mycorp.pipeline.Utils.someStaticMethod()\n"
  },
  "4111": {
    "source_file": "shared-libraries.txt",
    "text": " `library` step.\n`static` methods can be invoked using a Java-like syntax:\n\nlibrary('my-shared-library').com.mycorp.pipeline.Utils.someStaticMethod()\n\nYou can also access `static` fields, and call constructors as if they were `static` methods named `new`:\n\ndef useSomeLib(helper) { // dynamic: cannot declare as Helper\n    helper.prepare()\n    return helper.count()\n}\n\ndef lib = library('my-shared-li"
  },
  "4112": {
    "source_file": "shared-libraries.txt",
    "text": "new`:\n\ndef useSomeLib(helper) { // dynamic: cannot declare as Helper\n    helper.prepare()\n    return helper.count()\n}\n\ndef lib = library('my-shared-library').com.mycorp.pipeline // preselect the package\n\necho useSomeLib(lib.Helper.new(lib.Constants.SOME_TEXT))\n\nThe \"Default version\" for a configured Shared Library is used when \"Load\nimplicitly\" is checked, or if a Pipeline references the library o"
  },
  "4113": {
    "source_file": "shared-libraries.txt",
    "text": "OME_TEXT))\n\nThe \"Default version\" for a configured Shared Library is used when \"Load\nimplicitly\" is checked, or if a Pipeline references the library only by name,\nfor example `@Library('my-shared-library') _`. If a \"Default version\" is *not*\ndefined, the Pipeline must specify a version, for example\n`@Library('my-shared-library@master') _`.\n\nIf \"Allow default version to be overridden\" is enabled in"
  },
  "4114": {
    "source_file": "shared-libraries.txt",
    "text": " the Pipeline must specify a version, for example\n`@Library('my-shared-library@master') _`.\n\nIf \"Allow default version to be overridden\" is enabled in the Shared Library's\nconfiguration, a `@Library` annotation may also override a default version\ndefined for the library. This also allows a library with \"Load implicitly\" to\nbe loaded from a different version if necessary.\n\nWhen using the `library` "
  },
  "4115": {
    "source_file": "shared-libraries.txt",
    "text": "ined for the library. This also allows a library with \"Load implicitly\" to\nbe loaded from a different version if necessary.\n\nWhen using the `library` step you may also specify a version:\n\nlibrary 'my-shared-library@master'\n\nSince this is a regular step, that version could be _computed_\nrather than a constant as with the annotation; for example:\n\nlibrary \"my-shared-library@$BRANCH_NAME\"\n\nwould load"
  },
  "4116": {
    "source_file": "shared-libraries.txt",
    "text": "ep, that version could be _computed_\nrather than a constant as with the annotation; for example:\n\nlibrary \"my-shared-library@$BRANCH_NAME\"\n\nwould load a library using the same SCM branch as the multibranch `Jenkinsfile`.\nAs another example, you could pick a library by parameter:\n\nproperties([parameters([string(name: 'LIB_VERSION', defaultValue: 'master')])])\nlibrary \"my-shared-library@${params.LIB"
  },
  "4117": {
    "source_file": "shared-libraries.txt",
    "text": " pick a library by parameter:\n\nproperties([parameters([string(name: 'LIB_VERSION', defaultValue: 'master')])])\nlibrary \"my-shared-library@${params.LIB_VERSION}\"\n\nNote that the `library` step may not be used to override the version of an implicitly loaded library.\nIt is already loaded by the time the script starts, and a library of a given name may not be loaded twice.\n\nThe best way to specify the "
  },
  "4118": {
    "source_file": "shared-libraries.txt",
    "text": "aded library.\nIt is already loaded by the time the script starts, and a library of a given name may not be loaded twice.\n\nThe best way to specify the SCM is using an SCM plugin which has been\nspecifically updated to support a new API for checking out an arbitrary named\nversion (**Modern SCM** option). As of this writing, the latest versions of the\nGit and Subversion plugins support this mode.\n\n{em"
  },
  "4119": {
    "source_file": "shared-libraries.txt",
    "text": " an arbitrary named\nversion (**Modern SCM** option). As of this writing, the latest versions of the\nGit and Subversion plugins support this mode.\n\n{empty}\n\nSCM plugins which have not yet been updated to support the newer features\nrequired by Shared Libraries, may still be used via the **Legacy SCM** option.\nIn this case, include `${library.yourlibrarynamehere.version}` wherever a\nbranch/tag/ref ma"
  },
  "4120": {
    "source_file": "shared-libraries.txt",
    "text": "ibraries, may still be used via the **Legacy SCM** option.\nIn this case, include `${library.yourlibrarynamehere.version}` wherever a\nbranch/tag/ref may be configured for that particular SCM plugin.  This ensures\nthat during checkout of the library's source code, the SCM plugin will expand\nthis variable to checkout the appropriate version of the library.\n\n{empty}\n\nIf you only specify a library name"
  },
  "4121": {
    "source_file": "shared-libraries.txt",
    "text": "source code, the SCM plugin will expand\nthis variable to checkout the appropriate version of the library.\n\n{empty}\n\nIf you only specify a library name (optionally with version after `@`) in the `library` step,\nJenkins will look for a preconfigured library of that name.\n(Or in the case of a `github.com/owner/repo` automatic library it will load that.)\n\nBut you may also specify the retrieval method "
  },
  "4122": {
    "source_file": "shared-libraries.txt",
    "text": "brary of that name.\n(Or in the case of a `github.com/owner/repo` automatic library it will load that.)\n\nBut you may also specify the retrieval method dynamically,\nin which case there is no need for the library to have been predefined in Jenkins.\nHere is an example:\n\nlibrary identifier: 'custom-lib@master', retriever: modernSCM(\n  [$class: 'GitSCMSource',\n   remote: 'git@git.mycorp.com:my-jenkins-u"
  },
  "4123": {
    "source_file": "shared-libraries.txt",
    "text": " is an example:\n\nlibrary identifier: 'custom-lib@master', retriever: modernSCM(\n  [$class: 'GitSCMSource',\n   remote: 'git@git.mycorp.com:my-jenkins-utils.git',\n   credentialsId: 'my-private-key'])\n\nIt is best to refer to *Pipeline Syntax* for the precise syntax for your SCM.\n\nNote that the library version _must_ be specified in these cases.\n\nAt the base level, any valid\n\nis okay for use. Differen"
  },
  "4124": {
    "source_file": "shared-libraries.txt",
    "text": "ecise syntax for your SCM.\n\nNote that the library version _must_ be specified in these cases.\n\nAt the base level, any valid\n\nis okay for use. Different data structures, utility methods, etc, such as:\n\n// src/org/foo/Point.groovy\npackage org.foo\n\n// point in 3D space\nclass Point {\n  float x,y,z\n}\n\nLibrary classes cannot directly call steps such as `sh` or `git`.\nThey can however implement methods, "
  },
  "4125": {
    "source_file": "shared-libraries.txt",
    "text": "oint in 3D space\nclass Point {\n  float x,y,z\n}\n\nLibrary classes cannot directly call steps such as `sh` or `git`.\nThey can however implement methods, outside of the scope of an enclosing\nclass, which in turn invoke Pipeline steps, for example:\n\n// src/org/foo/Zot.groovy\npackage org.foo\n\ndef checkOutFrom(repo) {\n  git url: \"git@github.com:jenkinsci/${repo}\"\n}\n\nreturn this\n\nWhich can then be called "
  },
  "4126": {
    "source_file": "shared-libraries.txt",
    "text": "c/org/foo/Zot.groovy\npackage org.foo\n\ndef checkOutFrom(repo) {\n  git url: \"git@github.com:jenkinsci/${repo}\"\n}\n\nreturn this\n\nWhich can then be called from a Scripted Pipeline:\n\ndef z = new org.foo.Zot()\nz.checkOutFrom(repo)\n\nThis approach has limitations; for example, it prevents the declaration of a\nsuperclass.\n\nAlternately, a set of `steps` can be passed explicitly using `this` to a library clas"
  },
  "4127": {
    "source_file": "shared-libraries.txt",
    "text": "ions; for example, it prevents the declaration of a\nsuperclass.\n\nAlternately, a set of `steps` can be passed explicitly using `this` to a library class, in a\nconstructor, or just one method:\n\npackage org.foo\nclass Utilities implements Serializable {\n  def steps\n  Utilities(steps) {this.steps = steps}\n  def mvn(args) {\n    steps.sh \"${steps.tool 'Maven'}/bin/mvn -o ${args}\"\n  }\n}\n\nWhen saving state"
  },
  "4128": {
    "source_file": "shared-libraries.txt",
    "text": "  def steps\n  Utilities(steps) {this.steps = steps}\n  def mvn(args) {\n    steps.sh \"${steps.tool 'Maven'}/bin/mvn -o ${args}\"\n  }\n}\n\nWhen saving state on classes, such as above, the class *must* implement the\n`Serializable` interface. This ensures that a Pipeline using the class, as seen\nin the example below, can properly suspend and resume in Jenkins.\n\n@Library('utils') import org.foo.Utilities\nd"
  },
  "4129": {
    "source_file": "shared-libraries.txt",
    "text": "at a Pipeline using the class, as seen\nin the example below, can properly suspend and resume in Jenkins.\n\n@Library('utils') import org.foo.Utilities\ndef utils = new Utilities(this)\nnode {\n  utils.mvn 'clean package'\n}\n\nIf the library needs to access global variables, such as `env`, those should be\nexplicitly passed into the library classes, or methods, in a similar manner.\n\nInstead of passing nume"
  },
  "4130": {
    "source_file": "shared-libraries.txt",
    "text": "global variables, such as `env`, those should be\nexplicitly passed into the library classes, or methods, in a similar manner.\n\nInstead of passing numerous variables from the Scripted Pipeline into a library,\n\npackage org.foo\nclass Utilities {\n  static def mvn(script, args) {\n    script.sh \"${script.tool 'Maven'}/bin/mvn -s ${script.env.HOME}/jenkins.xml -o ${args}\"\n  }\n}\n\nThe above example shows t"
  },
  "4131": {
    "source_file": "shared-libraries.txt",
    "text": "c def mvn(script, args) {\n    script.sh \"${script.tool 'Maven'}/bin/mvn -s ${script.env.HOME}/jenkins.xml -o ${args}\"\n  }\n}\n\nThe above example shows the script being passed in to one `static` method,\ninvoked from a Scripted Pipeline as follows:\n\n@Library('utils') import static org.foo.Utilities.*\nnode {\n  mvn this, 'clean package'\n}\n\nInternally, scripts in the `vars` directory are instantiated on-"
  },
  "4132": {
    "source_file": "shared-libraries.txt",
    "text": "rary('utils') import static org.foo.Utilities.*\nnode {\n  mvn this, 'clean package'\n}\n\nInternally, scripts in the `vars` directory are instantiated on-demand  as\nsingletons. This allows multiple methods to be defined in a\nsingle `.groovy` file for convenience.  For example:\n\n.vars/log.groovy\n\ndef info(message) {\n    echo \"INFO: ${message}\"\n}\n\ndef warning(message) {\n    echo \"WARNING: ${message}\"\n}\n"
  },
  "4133": {
    "source_file": "shared-libraries.txt",
    "text": "venience.  For example:\n\n.vars/log.groovy\n\ndef info(message) {\n    echo \"INFO: ${message}\"\n}\n\ndef warning(message) {\n    echo \"WARNING: ${message}\"\n}\n\n.Jenkinsfile\n\n@Library('utils') _\n\nlog.info 'Starting'\nlog.warning 'Nothing to do!'\n\nDeclarative Pipeline does not allow method calls on objects outside \"script\" blocks.\n().\nThe method calls above would need to be put inside a `script` directive:\n\n."
  },
  "4134": {
    "source_file": "shared-libraries.txt",
    "text": "peline does not allow method calls on objects outside \"script\" blocks.\n().\nThe method calls above would need to be put inside a `script` directive:\n\n.Jenkinsfile\n\n@Library('utils') _\n\npipeline {\n    agent none\n    stages {\n        stage ('Example') {\n            steps {\n                // log.info 'Starting' // <1> script { // <2> log.info 'Starting'\n                    log.warning 'Nothing to do!"
  },
  "4135": {
    "source_file": "shared-libraries.txt",
    "text": "\n            steps {\n                // log.info 'Starting' // <1> script { // <2> log.info 'Starting'\n                    log.warning 'Nothing to do!'\n                }\n            }\n        }\n    }\n}\n\n<1> This method call would fail because it is outside a `script` directive.\n<2> `script` directive required to access global variables in Declarative Pipeline.\n\nA variable defined in a shared libra"
  },
  "4136": {
    "source_file": "shared-libraries.txt",
    "text": "utside a `script` directive.\n<2> `script` directive required to access global variables in Declarative Pipeline.\n\nA variable defined in a shared library will only show up in _Global Variables\nReference_ (under _Pipeline Syntax_) after Jenkins loads and uses that library\nas part of a successful Pipeline run.\n\n.Avoid preserving state in global variables\n[WARNING]\n\nAll global variables defined in a S"
  },
  "4137": {
    "source_file": "shared-libraries.txt",
    "text": "nd uses that library\nas part of a successful Pipeline run.\n\n.Avoid preserving state in global variables\n[WARNING]\n\nAll global variables defined in a Shared Library should be stateless, i.e. they should act as collections of functions.\nIf your pipeline tried to store some state in global variables, this state would be lost in case of Jenkins controller restart.\nUse a static class or instantiate a l"
  },
  "4138": {
    "source_file": "shared-libraries.txt",
    "text": "e tried to store some state in global variables, this state would be lost in case of Jenkins controller restart.\nUse a static class or instantiate a local variable of a class instead.\n\nThough using fields for global variables is discouraged as per above, it is possible to define fields and use them as read-only.\nTo define a field you need to use an annotation:\n\n@groovy.transform.Field\ndef yourFiel"
  },
  "4139": {
    "source_file": "shared-libraries.txt",
    "text": "ove, it is possible to define fields and use them as read-only.\nTo define a field you need to use an annotation:\n\n@groovy.transform.Field\ndef yourField = \"YourConstantValue\"\n\ndef yourFunction....\n\nShared Libraries can also define global variables which behave similarly to\nbuilt-in steps, such as `sh` or `git`. Global variables defined in Shared\nLibraries *must* be named with all lowercase or \"came"
  },
  "4140": {
    "source_file": "shared-libraries.txt",
    "text": "ch behave similarly to\nbuilt-in steps, such as `sh` or `git`. Global variables defined in Shared\nLibraries *must* be named with all lowercase or \"camelCased\" in order to be\nloaded properly by Pipeline.\nfootnote:[https://gist.github.com/rtyler/e5e57f075af381fce4ed3ae57aa1f0c2]\n\nFor example, to define `sayHello`, the file `vars/sayHello.groovy`\nshould be created and should implement a `call` method."
  },
  "4141": {
    "source_file": "shared-libraries.txt",
    "text": "75af381fce4ed3ae57aa1f0c2]\n\nFor example, to define `sayHello`, the file `vars/sayHello.groovy`\nshould be created and should implement a `call` method. The `call` method\nallows the global variable to be invoked in a manner similar to a step:\n\n// vars/sayHello.groovy\ndef call(String name = 'human') {\n    // Any valid steps can be called from this code, just like in other\n    // Scripted Pipeline\n   "
  },
  "4142": {
    "source_file": "shared-libraries.txt",
    "text": "sayHello.groovy\ndef call(String name = 'human') {\n    // Any valid steps can be called from this code, just like in other\n    // Scripted Pipeline\n    echo \"Hello, ${name}.\"\n}\n\nThe Pipeline would then be able to reference and invoke this variable:\n\nsayHello 'Joe'\nsayHello() /* invoke with default arguments */\n\nIf called with a block, the `call` method will receive a\nThe type should be defined expl"
  },
  "4143": {
    "source_file": "shared-libraries.txt",
    "text": "ayHello 'Joe'\nsayHello() /* invoke with default arguments */\n\nIf called with a block, the `call` method will receive a\nThe type should be defined explicitly to clarify the intent of the step, for\nexample:\n\n// vars/windows.groovy\ndef call(Closure body) {\n    node('windows') {\n        body()\n    }\n}\n\nThe Pipeline can then use this variable like any built-in step which\naccepts a block:\n\nwindows {\n   "
  },
  "4144": {
    "source_file": "shared-libraries.txt",
    "text": ") {\n    node('windows') {\n        body()\n    }\n}\n\nThe Pipeline can then use this variable like any built-in step which\naccepts a block:\n\nwindows {\n    bat \"cmd /?\"\n}\n\nIf you have a lot of Pipelines that are mostly similar, the global\nvariable mechanism provides a handy tool to build a higher-level DSL\nthat captures the similarity. For example, all Jenkins plugins are built and\ntested in the same w"
  },
  "4145": {
    "source_file": "shared-libraries.txt",
    "text": "sm provides a handy tool to build a higher-level DSL\nthat captures the similarity. For example, all Jenkins plugins are built and\ntested in the same way, so we might write a step named\n`buildPlugin`:\n\n// vars/buildPlugin.groovy\ndef call(Map config) {\n    node {\n        git url: \"https://github.com/jenkinsci/${config.name}-plugin.git\"\n        sh 'mvn install'\n        mail to: '...', subject: \"${con"
  },
  "4146": {
    "source_file": "shared-libraries.txt",
    "text": "\n    node {\n        git url: \"https://github.com/jenkinsci/${config.name}-plugin.git\"\n        sh 'mvn install'\n        mail to: '...', subject: \"${config.name} plugin build\", body: '...'\n    }\n}\n\nAssuming the script has either been loaded as a\n<<global-shared-libraries,Global Shared Library>> or as a\n<<folder-level-shared-libraries, Folder-level Shared Library>>\nthe resulting `Jenkinsfile` will be"
  },
  "4147": {
    "source_file": "shared-libraries.txt",
    "text": "al-shared-libraries,Global Shared Library>> or as a\n<<folder-level-shared-libraries, Folder-level Shared Library>>\nthe resulting `Jenkinsfile` will be dramatically simpler:\n\n[pipeline]\n\n// Script //\nbuildPlugin name: 'git'\n// Declarative not yet implemented //\n\nThere is also a \u201cbuilder pattern\u201d trick using Groovy\u2019s `Closure.DELEGATE_FIRST`,\nwhich permits `Jenkinsfile` to look slightly more like a "
  },
  "4148": {
    "source_file": "shared-libraries.txt",
    "text": "emented //\n\nThere is also a \u201cbuilder pattern\u201d trick using Groovy\u2019s `Closure.DELEGATE_FIRST`,\nwhich permits `Jenkinsfile` to look slightly more like a configuration file than a program,\nbut this is more complex and error-prone and is not recommended.\n\n[IMPORTANT]\n\nWhile possible, accessing third-party libraries using `@Grab` from trusted libraries has various issues and is not recommended.\nInstead "
  },
  "4149": {
    "source_file": "shared-libraries.txt",
    "text": "\n[IMPORTANT]\n\nWhile possible, accessing third-party libraries using `@Grab` from trusted libraries has various issues and is not recommended.\nInstead of using `@Grab`, the recommended approach is to create a standalone executable in the programming language of your choice (using whatever third-party libraries you desire), install it on the Jenkins agents that your Pipelines use, and then invoke th"
  },
  "4150": {
    "source_file": "shared-libraries.txt",
    "text": "anguage of your choice (using whatever third-party libraries you desire), install it on the Jenkins agents that your Pipelines use, and then invoke that executable in your Pipelines using the `bat` or `sh` step.\n\nIt is possible to use third-party Java libraries, typically found in\n,\nfrom *trusted* library code using the `@Grab` annotation.  Refer to the\n\nfor details, but simply put:\n\n@Grab('org.ap"
  },
  "4151": {
    "source_file": "shared-libraries.txt",
    "text": "a libraries, typically found in\n,\nfrom *trusted* library code using the `@Grab` annotation.  Refer to the\n\nfor details, but simply put:\n\n@Grab('org.apache.commons:commons-math3:3.4.1')\nimport org.apache.commons.math3.primes.Primes\nvoid parallelize(int count) {\n  if (!Primes.isPrime(count)) {\n    error \"${count} was not prime\"\n  }\n  // \u2026\n}\n\nThird-party libraries are cached by default in `~/.groovy/"
  },
  "4152": {
    "source_file": "shared-libraries.txt",
    "text": "t count) {\n  if (!Primes.isPrime(count)) {\n    error \"${count} was not prime\"\n  }\n  // \u2026\n}\n\nThird-party libraries are cached by default in `~/.groovy/grapes/` on the\nJenkins controller.\n\nExternal libraries may load adjunct files from a `resources/` directory using\nthe `libraryResource` step.  The argument is a relative pathname, akin to Java\nresource loading:\n\ndef request = libraryResource 'com/my"
  },
  "4153": {
    "source_file": "shared-libraries.txt",
    "text": "irectory using\nthe `libraryResource` step.  The argument is a relative pathname, akin to Java\nresource loading:\n\ndef request = libraryResource 'com/mycorp/pipeline/somelib/request.json'\n\nThe file is loaded as a string, suitable for passing to certain APIs or saving\nto a workspace using `writeFile`.\n\nIt is advisable to use an unique package structure so you do not accidentally\nconflict with another"
  },
  "4154": {
    "source_file": "shared-libraries.txt",
    "text": " APIs or saving\nto a workspace using `writeFile`.\n\nIt is advisable to use an unique package structure so you do not accidentally\nconflict with another library.\n\nIf you notice a mistake in a build using an untrusted library,\nsimply click the _Replay_ link to try editing one or more of its source files,\nand see if the resulting build behaves as expected.\nOnce you are satisfied with the result, follo"
  },
  "4155": {
    "source_file": "shared-libraries.txt",
    "text": "link to try editing one or more of its source files,\nand see if the resulting build behaves as expected.\nOnce you are satisfied with the result, follow the diff link from the build\u2019s status page,\nand apply the diff to the library repository and commit.\n\n(Even if the version requested for the library was a branch, rather than a fixed version like a tag,\nreplayed builds will use the exact same revis"
  },
  "4156": {
    "source_file": "shared-libraries.txt",
    "text": "t.\n\n(Even if the version requested for the library was a branch, rather than a fixed version like a tag,\nreplayed builds will use the exact same revision as the original build:\nlibrary sources will not be checked out again.)\n\n_Replay_ is not currently supported for trusted libraries.\nModifying resource files is also not currently supported during _Replay_.\n\nStarting with Declarative 1.2, released "
  },
  "4157": {
    "source_file": "shared-libraries.txt",
    "text": "y supported for trusted libraries.\nModifying resource files is also not currently supported during _Replay_.\n\nStarting with Declarative 1.2, released in late September, 2017, you can define\nDeclarative Pipelines in your shared libraries as well. Here's an example,\nwhich will execute a different Declarative Pipeline depending on whether the\nbuild number is odd or even:\n\n// vars/evenOrOdd.groovy\ndef"
  },
  "4158": {
    "source_file": "shared-libraries.txt",
    "text": "'s an example,\nwhich will execute a different Declarative Pipeline depending on whether the\nbuild number is odd or even:\n\n// vars/evenOrOdd.groovy\ndef call(int buildNumber) {\n  if (buildNumber % 2 == 0) {\n    pipeline {\n      agent any\n      stages {\n        stage('Even Stage') {\n          steps {\n            echo \"The build number is even\"\n          }\n        }\n      }\n    }\n  } else {\n    pipeli"
  },
  "4159": {
    "source_file": "shared-libraries.txt",
    "text": "\n        stage('Even Stage') {\n          steps {\n            echo \"The build number is even\"\n          }\n        }\n      }\n    }\n  } else {\n    pipeline {\n      agent any\n      stages {\n        stage('Odd Stage') {\n          steps {\n            echo \"The build number is odd\"\n          }\n        }\n      }\n    }\n  }\n}\n\n// Jenkinsfile\n@Library('my-shared-library') _\n\nevenOrOdd(currentBuild.getNumber("
  },
  "4160": {
    "source_file": "shared-libraries.txt",
    "text": "\"The build number is odd\"\n          }\n        }\n      }\n    }\n  }\n}\n\n// Jenkinsfile\n@Library('my-shared-library') _\n\nevenOrOdd(currentBuild.getNumber())\n\nOnly entire ``pipeline``s can be defined in shared libraries as of this time.\nThis can only be done in `vars/*.groovy`, and only in a `call` method. Only one\nDeclarative Pipeline can be executed in a single build, and if you attempt to\nexecute a "
  },
  "4161": {
    "source_file": "shared-libraries.txt",
    "text": "one in `vars/*.groovy`, and only in a `call` method. Only one\nDeclarative Pipeline can be executed in a single build, and if you attempt to\nexecute a second one, your build will fail as a result.\n\nBy adding `@Library('my-shared-library@pull/<your-pr-number>/head') _` at the top of a library consumer Jenkinsfile, you can test your pipeline library pull request changes __in situ__ if your pipeline l"
  },
  "4162": {
    "source_file": "shared-libraries.txt",
    "text": "number>/head') _` at the top of a library consumer Jenkinsfile, you can test your pipeline library pull request changes __in situ__ if your pipeline library is hosted on GitHub and the SCM configuration for the pipeline library uses GitHub. +\nRefer to the pull request or merge request branch naming convention for other providers like Assembla, Bitbucket, Gitea, GitLab, and Tuleap.\n\nTake, for examp"
  },
  "4163": {
    "source_file": "shared-libraries.txt",
    "text": "o the pull request or merge request branch naming convention for other providers like Assembla, Bitbucket, Gitea, GitLab, and Tuleap.\n\nTake, for example, a change to the global ci.jenkins.io shared pipeline, which has its source code stored at https://github.com/jenkins-infra/pipeline-library/.\n\nLet's say you're writing a new feature and opened a pull request on the pipeline library, number `123`."
  },
  "4164": {
    "source_file": "shared-libraries.txt",
    "text": "//github.com/jenkins-infra/pipeline-library/.\n\nLet's say you're writing a new feature and opened a pull request on the pipeline library, number `123`.\n\nBy opening a pull request on https://github.com/jenkinsci/jenkins-infra-test-plugin/[the dedicated `jenkins-infra-test-plugin` test repository] with the following content, you'll be able to check your changes on ci.jenkins.io:\n\n--- jenkins-infra-te"
  },
  "4165": {
    "source_file": "shared-libraries.txt",
    "text": " `jenkins-infra-test-plugin` test repository] with the following content, you'll be able to check your changes on ci.jenkins.io:\n\n--- jenkins-infra-test-plugin/Jenkinsfile\n++ jenkins-infra-test-plugin/Jenkinsfile\n@@ -1,3 +1,4 @@\n@Library('pipeline-library@pull/123/head') _\n  buildPlugin(\n    useContainerAgent: true,\n    configurations: [\n      [platform: 'linux', jdk: 21],\n      [platform: 'window"
  },
  "4166": {
    "source_file": "shared-libraries.txt",
    "text": "brary@pull/123/head') _\n  buildPlugin(\n    useContainerAgent: true,\n    configurations: [\n      [platform: 'linux', jdk: 21],\n      [platform: 'windows', jdk: 17],\n  ])"
  },
  "4167": {
    "source_file": "source-code-hosting.txt",
    "text": "title: Source Code Hosting\nlayout: developersection\n\n\nThe Jenkins project only publishes free and open source plugins distributed under an  or  license or dedicated to the public domain.\n\nThe canonical source code repository is in the `jenkinsci` GitHub organization to ensure source code access and project continuity in case previous maintainers move on.\nSome plugins we distribute are currently ma"
  },
  "4168": {
    "source_file": "source-code-hosting.txt",
    "text": "Hub organization to ensure source code access and project continuity in case previous maintainers move on.\nSome plugins we distribute are currently maintained outside the `jenkinsci` GitHub organization for historical reasons, but this is discouraged.\n lists all forked repositories in the `jenkinsci` GitHub organization and their source repositories.\n\nPlugin maintainers typically have repository a"
  },
  "4169": {
    "source_file": "source-code-hosting.txt",
    "text": ".\n lists all forked repositories in the `jenkinsci` GitHub organization and their source repositories.\n\nPlugin maintainers typically have repository admin permissions for plugins they maintain, but some features (like transfer and deletion of repos) are disabled.\n\nThis table shows the permissions currently granted to contributors in the `jenkinsci` GitHub repositories, excluding organization owner"
  },
  "4170": {
    "source_file": "source-code-hosting.txt",
    "text": "are disabled.\n\nThis table shows the permissions currently granted to contributors in the `jenkinsci` GitHub repositories, excluding organization owners with full permissions to every repository:\n\n+++\n    <style type=\"text/css\">\n    @import url(https://cdn.datatables.net/1.13.4/css/jquery.dataTables.min.css);\n    </style>\n    <script type=\"text/javascript\" src=\"https://cdn.datatables.net/1.13.4/js/"
  },
  "4171": {
    "source_file": "source-code-hosting.txt",
    "text": "//cdn.datatables.net/1.13.4/css/jquery.dataTables.min.css);\n    </style>\n    <script type=\"text/javascript\" src=\"https://cdn.datatables.net/1.13.4/js/jquery.dataTables.min.js\"></script>\n    <script type=\"text/javascript\">\n        $(document).ready(function() {\n            // Add a search input to each footer cell\n            $('#permissions tfoot th').each(function() {\n                var columnNa"
  },
  "4172": {
    "source_file": "source-code-hosting.txt",
    "text": "nction() {\n            // Add a search input to each footer cell\n            $('#permissions tfoot th').each(function() {\n                var columnName = $('#permissions thead th').eq($(this).index()).text();\n                $(this).html('<input type=\"text\" id=\"filter' + columnName + '\" placeholder=\"Filter ' + columnName + '\" title=\"Filter the table on ' + columnName + ' (support regular expressi"
  },
  "4173": {
    "source_file": "source-code-hosting.txt",
    "text": "e=\"text\" id=\"filter' + columnName + '\" placeholder=\"Filter ' + columnName + '\" title=\"Filter the table on ' + columnName + ' (support regular expressions)\" />');\n            });\n\n            $('#permissions').DataTable({\n                ajax: {\n                    url: 'https://reports.jenkins.io/github-jenkinsci-permissions-report.json',\n                    dataSrc: ''\n                },\n        "
  },
  "4174": {
    "source_file": "source-code-hosting.txt",
    "text": "               url: 'https://reports.jenkins.io/github-jenkinsci-permissions-report.json',\n                    dataSrc: ''\n                },\n                columns: [\n                    {\n                        title: \"Repository\",\n                        render: function(data, type, row, metadata) {\n                            return '<a href=\"https://github.com/jenkinsci/' + data + '\" target"
  },
  "4175": {
    "source_file": "source-code-hosting.txt",
    "text": "          render: function(data, type, row, metadata) {\n                            return '<a href=\"https://github.com/jenkinsci/' + data + '\" target=\"_blank\" rel=\"noreferrer noopener\">' + data + '</a>';\n                        }\n                    },\n                    {\n                        title: \"User\",\n                        render: function(data, type, row, metadata) {\n               "
  },
  "4176": {
    "source_file": "source-code-hosting.txt",
    "text": " },\n                    {\n                        title: \"User\",\n                        render: function(data, type, row, metadata) {\n                            return '<a href=\"https://github.com/' + data + '\" target=\"_blank\" rel=\"noreferrer noopener\">' + data + '</a>';\n                        }\n                    },\n                    { title: \"Access\" }\n                ]\n            }).colu"
  },
  "4177": {
    "source_file": "source-code-hosting.txt",
    "text": "ner\">' + data + '</a>';\n                        }\n                    },\n                    { title: \"Access\" }\n                ]\n            }).columns().every(function() {\n                var column = this;\n                // Regexp search in the column on every input\n                $('input', this.footer()).on('keyup change', function() {\n                    column.search(this.value, true).dr"
  },
  "4178": {
    "source_file": "source-code-hosting.txt",
    "text": "column on every input\n                $('input', this.footer()).on('keyup change', function() {\n                    column.search(this.value, true).draw();\n                });\n            });\n        });\n    </script>\n    <table id=\"permissions\" class=\"display\" cellspacing=\"0\" width=\"100%\">\n      <thead>\n        <tr>\n          <th>Repository</th>\n          <th>User</th>\n          <th>Access</th>\n "
  },
  "4179": {
    "source_file": "source-code-hosting.txt",
    "text": "s=\"display\" cellspacing=\"0\" width=\"100%\">\n      <thead>\n        <tr>\n          <th>Repository</th>\n          <th>User</th>\n          <th>Access</th>\n        </tr>\n      </thead>\n      <tfoot>\n        <tr>\n          <th>Repository</th>\n          <th>User</th>\n          <th>Access</th>\n          </tr>\n      </tfoot>\n    </table>\n\n+++"
  },
  "4180": {
    "source_file": "source-code-hosting.txt",
    "text": "ser</th>\n          <th>Access</th>\n          </tr>\n      </tfoot>\n    </table>\n\n+++"
  },
  "4181": {
    "source_file": "spawning-processes.txt",
    "text": "layout: section\n\n\nifdef::env-github[:imagesdir: ../resources]\nifndef::env-github[:imagesdir: ../../resources]\n\nIt is possible to spawn a process from a build and have that process live longer than the build itself.\nFor example, perhaps the build launches a new application server with the result of the build.\nIn older releases, the build often did not terminate.\nInstead, the specific step (such as "
  },
  "4182": {
    "source_file": "spawning-processes.txt",
    "text": "ches a new application server with the result of the build.\nIn older releases, the build often did not terminate.\nInstead, the specific step (such as the shell script, Ant, or Maven) terminates\nbut the build itself does not terminate.\n\nJenkins detects this situation and, instead of blocking indefinitely,  prints out a warning and terminates the build.\n\nThis happens because of how file descriptors "
  },
  "4183": {
    "source_file": "spawning-processes.txt",
    "text": "s this situation and, instead of blocking indefinitely,  prints out a warning and terminates the build.\n\nThis happens because of how file descriptors are used between processes in a build.\nJenkins and the child process are connected by three pipes (`stdin`, `stdout`, and `stderr`.)\nThis allows Jenkins to capture the output from the child process.\nThe child process may write a lot of data to the pi"
  },
  "4184": {
    "source_file": "spawning-processes.txt",
    "text": "stdin`, `stdout`, and `stderr`.)\nThis allows Jenkins to capture the output from the child process.\nThe child process may write a lot of data to the pipe and quit immediately after that, so Jenkins waits for end-of-file (EOF) to be sure that it has drained the pipes before it terminates the build.\n\nWhenever a process terminates, the operating system closes all the file descriptors it owned. So, eve"
  },
  "4185": {
    "source_file": "spawning-processes.txt",
    "text": "ained the pipes before it terminates the build.\n\nWhenever a process terminates, the operating system closes all the file descriptors it owned. So, even if the process did not close `stdout` and `stderr`, Jenkins gets end of file (EOF).\n\nThe complication happens when those file descriptors are inherited by other processes.\nLet's say the child process forks another process to the background.\nThe bac"
  },
  "4186": {
    "source_file": "spawning-processes.txt",
    "text": "ion happens when those file descriptors are inherited by other processes.\nLet's say the child process forks another process to the background.\nThe background process (which is actually a daemon) inherits all the file descriptors of the parent, including the writing side of the `stdout` ad `stderr` pipes that connect the child process and Jenkins.\nIf the daemon forgets to close them, Jenkins does n"
  },
  "4187": {
    "source_file": "spawning-processes.txt",
    "text": "ing the writing side of the `stdout` ad `stderr` pipes that connect the child process and Jenkins.\nIf the daemon forgets to close them, Jenkins does not get EOF for pipes even when the child process exits, because the daemon still has those descriptors open.\nThis is how this problem happens.\n\nA daemon should close all file descriptors to avoid such issues but some daemons do not follow the rule.\nY"
  },
  "4188": {
    "source_file": "spawning-processes.txt",
    "text": "rs open.\nThis is how this problem happens.\n\nA daemon should close all file descriptors to avoid such issues but some daemons do not follow the rule.\nYou can mitigate this problem with various workarounds.\n\nOn Unix, you can use a wrapper like http://www.clapper.org/software/daemonize/[this] to make the daemon behave.\nFor example:\n\ndaemonize -E BUILD_ID=dontKillMe /path/to/your/command\n\nIn a Jenkins"
  },
  "4189": {
    "source_file": "spawning-processes.txt",
    "text": "ww.clapper.org/software/daemonize/[this] to make the daemon behave.\nFor example:\n\ndaemonize -E BUILD_ID=dontKillMe /path/to/your/command\n\nIn a Jenkins Pipeline, use `+JENKINS_NODE_COOKIE+` instead of `+BUILD_ID+`.\n\nNote that this will set the BUILD_ID environment variable for the process being spawned to something other than the current BUILD_ID.\nOr you can start jenkins with `-Dhudson.util.Proces"
  },
  "4190": {
    "source_file": "spawning-processes.txt",
    "text": "D environment variable for the process being spawned to something other than the current BUILD_ID.\nOr you can start jenkins with `-Dhudson.util.ProcessTree.disable=true`.\n\nOn Windows, use the http://www.microsoft.com/resources/documentation/windows/xp/all/proddocs/en-us/ntcmds.mspx?mfr=true['at' command] to launch a process in the background.\nFor example:\n\n<scriptdef name=\"get-next-minute\" languag"
  },
  "4191": {
    "source_file": "spawning-processes.txt",
    "text": "p/all/proddocs/en-us/ntcmds.mspx?mfr=true['at' command] to launch a process in the background.\nFor example:\n\n<scriptdef name=\"get-next-minute\" language=\"beanshell\">\n  <attribute name=\"property\" />\n\n  date = new java.text.SimpleDateFormat(\"HH:mm\")\n    .format(new Date(System.currentTimeMillis() + 60000));\n  project.setProperty(attributes.get(\"property\"), date);\n</scriptdef>\n\n<get-next-minute proper"
  },
  "4192": {
    "source_file": "spawning-processes.txt",
    "text": " .format(new Date(System.currentTimeMillis() + 60000));\n  project.setProperty(attributes.get(\"property\"), date);\n</scriptdef>\n\n<get-next-minute property=\"next-minute\" />\n<exec executable=\"at\">\n  <arg value=\"${next-minute}\" />\n  <arg value=\"/interactive\" />\n  <arg value=\"${jboss.home}\\bin\\run.bat\" />\n</exec>\n\nAnother similar workaround on Windows is to use a wrapper script and launch your program t"
  },
  "4193": {
    "source_file": "spawning-processes.txt",
    "text": "ve\" />\n  <arg value=\"${jboss.home}\\bin\\run.bat\" />\n</exec>\n\nAnother similar workaround on Windows is to use a wrapper script and launch your program through it:\n\n// antRunAsync.js - Wrapper script to run an executable detached in the\n// background from Ant's <exec> task.  This works by running the executable\n// using the Windows Scripting Host WshShell.Run method which doesn't copy\n// the standard"
  },
  "4194": {
    "source_file": "spawning-processes.txt",
    "text": "om Ant's <exec> task.  This works by running the executable\n// using the Windows Scripting Host WshShell.Run method which doesn't copy\n// the standard filehandles stdin, stdout and stderr. Ant finds them closed\n// and doesn't wait for the program to exit.\n//\n// requirements:\n//   Windows Scripting Host 1.0 or better.  This is included with Windows\n//   98/Me/2000/XP.  Users of Windows 95 or Window"
  },
  "4195": {
    "source_file": "spawning-processes.txt",
    "text": "exit.\n//\n// requirements:\n//   Windows Scripting Host 1.0 or better.  This is included with Windows\n//   98/Me/2000/XP.  Users of Windows 95 or Windows NT 4.0 need to download\n//   and install WSH support from\n//   http://msdn.microsoft.com/scripting/.\n//\n// usage:\n// <exec executable=\"cscript.exe\">\n//   <env key=\"ANTRUN_TITLE\" value=\"Title for Window\" />  <!-- optional -->\n//   <env key=\"ANTRUN_O"
  },
  "4196": {
    "source_file": "spawning-processes.txt",
    "text": "/.\n//\n// usage:\n// <exec executable=\"cscript.exe\">\n//   <env key=\"ANTRUN_TITLE\" value=\"Title for Window\" />  <!-- optional -->\n//   <env key=\"ANTRUN_OUTPUT\" value=\"output.log\" />  <!-- optional -->\n//   <arg value=\"//NoLogo\" />\n//   <arg value=\"antRunAsync.js\" />  <!-- this script -->\n//   <arg value=\"real executable\" />\n// </exec>\n\nvar WshShell = WScript.CreateObject(\"WScript.Shell\");\nvar exeStr "
  },
  "4197": {
    "source_file": "spawning-processes.txt",
    "text": "nAsync.js\" />  <!-- this script -->\n//   <arg value=\"real executable\" />\n// </exec>\n\nvar WshShell = WScript.CreateObject(\"WScript.Shell\");\nvar exeStr = \"%comspec% /c\";\nvar arg = \"\";\nvar windowStyle = 1;\nvar WshProcessEnv = WshShell.Environment(\"PROCESS\");\nvar windowTitle = WshProcessEnv(\"ANTRUN_TITLE\");\nvar outputFile = WshProcessEnv(\"ANTRUN_OUTPUT\");\nvar OS = WshProcessEnv(\"OS\");\nvar isWindowsNT "
  },
  "4198": {
    "source_file": "spawning-processes.txt",
    "text": "SS\");\nvar windowTitle = WshProcessEnv(\"ANTRUN_TITLE\");\nvar outputFile = WshProcessEnv(\"ANTRUN_OUTPUT\");\nvar OS = WshProcessEnv(\"OS\");\nvar isWindowsNT = (OS == \"Windows_NT\");\n\n// On Windows NT/2000/XP, specify a title for the window.  If the environment\n// variable ANTRUN_TITLE is specified, that will be used instead of a default.\nif (isWindowsNT) {\n  if (windowTitle == \"\")\n     windowTitle = \"Ant "
  },
  "4199": {
    "source_file": "spawning-processes.txt",
    "text": "nt\n// variable ANTRUN_TITLE is specified, that will be used instead of a default.\nif (isWindowsNT) {\n  if (windowTitle == \"\")\n     windowTitle = \"Ant - \" + WScript.Arguments(i);\n  exeStr += \"title \" + windowTitle + \" &&\";\n}\n\n// Loop through arguments quoting ones with spaces\nfor (var i = 0; i < WScript.Arguments.count(); i++) {\n  arg = WScript.Arguments(i);\n  if (arg.indexOf(' ') > 0)\n    exeStr +"
  },
  "4200": {
    "source_file": "spawning-processes.txt",
    "text": " quoting ones with spaces\nfor (var i = 0; i < WScript.Arguments.count(); i++) {\n  arg = WScript.Arguments(i);\n  if (arg.indexOf(' ') > 0)\n    exeStr += \" \\\"\" + arg + \"\\\"\";\n  else\n    exeStr += \" \" + arg;\n}\n\n// If the environment variable ANTRUN_OUTPUT was specified, redirect\n// output to that file.\nif (outputFile != \"\") {\n  windowStyle = 7;  // new window is minimized\n  exeStr += \" > \\\"\" + outputF"
  },
  "4201": {
    "source_file": "spawning-processes.txt",
    "text": "T was specified, redirect\n// output to that file.\nif (outputFile != \"\") {\n  windowStyle = 7;  // new window is minimized\n  exeStr += \" > \\\"\" + outputFile + \"\\\"\";\n  if (isWindowsNT)\n    exeStr += \" 2>&1\";\n}\n\n// WScript.Echo(exeStr);\n// WshShell.Run(exeStr);\nWshShell.Run(exeStr, windowStyle, false);\n\nThis self-provided wrapper script can be called from Ant for example:\n\n<exec executable=\"cscript.exe"
  },
  "4202": {
    "source_file": "spawning-processes.txt",
    "text": "eStr);\nWshShell.Run(exeStr, windowStyle, false);\n\nThis self-provided wrapper script can be called from Ant for example:\n\n<exec executable=\"cscript.exe\">\n   <env key=\"ANTRUN_TITLE\" value=\"Title for Window\" />  <!-- optional -->\n   <env key=\"ANTRUN_OUTPUT\" value=\"output.log\" />  <!-- optional -->\n   <arg value=\"//NoLogo\" />\n   <arg value=\"antRunAsync.js\" />  <!-- this script -->\n   <arg value=\"real "
  },
  "4203": {
    "source_file": "spawning-processes.txt",
    "text": "PUT\" value=\"output.log\" />  <!-- optional -->\n   <arg value=\"//NoLogo\" />\n   <arg value=\"antRunAsync.js\" />  <!-- this script -->\n   <arg value=\"real executable\" />\n</exec>\n\nAnother workaround for Windows is to schedule a permanent task and force running it from the Ant script.\nFor example, run the command:\n\nC:\\>SCHTASKS /Create /RU SYSTEM /SC ONSTART /TN Tomcat /TR\n\"C:\\Program Files\\Apache Softwa"
  },
  "4204": {
    "source_file": "spawning-processes.txt",
    "text": "ning it from the Ant script.\nFor example, run the command:\n\nC:\\>SCHTASKS /Create /RU SYSTEM /SC ONSTART /TN Tomcat /TR\n\"C:\\Program Files\\Apache Software Foundation\\Tomcat 6.0\\bin\\startup.bat\"\n\nNote, that `ONSTART` can be replaced with `ONCE` if you do not want to keep Tomcat running.\nAdd the following code to your Ant script:\n\n<exec executable=\"SCHTASKS\">\n    <arg value=\"/Run\"/>\n    <arg value=\"/T"
  },
  "4205": {
    "source_file": "spawning-processes.txt",
    "text": "o not want to keep Tomcat running.\nAdd the following code to your Ant script:\n\n<exec executable=\"SCHTASKS\">\n    <arg value=\"/Run\"/>\n    <arg value=\"/TN\"/>\n    <arg value=\"Tomcat\"/>\n</exec>"
  },
  "4206": {
    "source_file": "split-plugin-from-core.txt",
    "text": "layout: developer\ntitle: Split plugin from core\n\n\nJenkins has a plugin architecture.\nFor historical reasons, some features were developed inside the Jenkins codebase itself (i.e., not as plugins).\n\nTo keep that core codebase more manageable, there is an ongoing effort to extract some of the existing features into dedicated plugins.\n\n.Walkthrough video\nvideo::vGJtbgghYO8[youtube, width=852, height="
  },
  "4207": {
    "source_file": "split-plugin-from-core.txt",
    "text": " an ongoing effort to extract some of the existing features into dedicated plugins.\n\n.Walkthrough video\nvideo::vGJtbgghYO8[youtube, width=852, height=480, start=480]\n\n* Locate everything that should be moved.\n** Do not forget to look in `core/src/main/resources/` for associated resources.\n*** (`Messages.properties` shared with other classes in the same package can be a headache: you need to create"
  },
  "4208": {
    "source_file": "split-plugin-from-core.txt",
    "text": "n/resources/` for associated resources.\n*** (`Messages.properties` shared with other classes in the same package can be a headache: you need to create a new `Messages` in a novel package.)\n** Look for relevant functional tests in `test/src/test/`.\n** Check for icons.\n** Double-check that you have really found everything relevant:\n*** `git ls-files | grep -F SOMETHING` for filenames and\n*** `git ls"
  },
  "4209": {
    "source_file": "split-plugin-from-core.txt",
    "text": " Check for icons.\n** Double-check that you have really found everything relevant:\n*** `git ls-files | grep -F SOMETHING` for filenames and\n*** `git ls-files | xargs grep -l SOMETHING` for contents.\n* Try temporarily deleting all the classes you propose to split, and do a clean build to verify that there are not unwanted usages from elsewhere in core.\nIf there are, you have some refactoring ahead o"
  },
  "4210": {
    "source_file": "split-plugin-from-core.txt",
    "text": "se to split, and do a clean build to verify that there are not unwanted usages from elsewhere in core.\nIf there are, you have some refactoring ahead of you, and this is where it gets hairy.\n* Split the code into a new repository with history intact.\n`git-filter-branch` can work, though it is not easy to use.\nIf possible, make sure translated commits mention the original commit hash.\n* Do a 1.0 rel"
  },
  "4211": {
    "source_file": "split-plugin-from-core.txt",
    "text": "`git-filter-branch` can work, though it is not easy to use.\nIf possible, make sure translated commits mention the original commit hash.\n* Do a 1.0 release of the new plugin, with the baseline set to the last weekly prior to your split.\nIdeally you would actually use the `-SNAPSHOT` version from the current core but Maven release rules will forbid this.\n* Create a core patch to:\n** delete the split"
  },
  "4212": {
    "source_file": "split-plugin-from-core.txt",
    "text": "uld actually use the `-SNAPSHOT` version from the current core but Maven release rules will forbid this.\n* Create a core patch to:\n** delete the split files\n** bundle in `war/pom.xml`\n** list in `ClassicPluginStrategy.DETACHED_LIST`\n* After a new weekly is produced using the above changes, update the baseline in the new plugin to that and cut a 1.1 (or 1.0.1).\nThis ensures it is only offered to us"
  },
  "4213": {
    "source_file": "split-plugin-from-core.txt",
    "text": "kly is produced using the above changes, update the baseline in the new plugin to that and cut a 1.1 (or 1.0.1).\nThis ensures it is only offered to users who do not still have that functionality in core, assuming the Update Center is configured properly.\n* Pat yourself on the back: Jenkins sources are a little more manageable than they were yesterday."
  },
  "4214": {
    "source_file": "split-plugin-from-core.txt",
    "text": "rly.\n* Pat yourself on the back: Jenkins sources are a little more manageable than they were yesterday."
  },
  "4215": {
    "source_file": "stapler-accessible-type.txt",
    "text": "title: Making Objects Accessible via Stapler\nlayout: developersection\nreferences:\n- url: /security/advisory/2018-12-05/#SECURITY-595\n  title: SECURITY-595 security fix\n\n\nBefore Jenkins 2.138.4 and 2.154, most objects in Jenkins were accessible through the basic Stapler routing rules discussed in .\nStarting in Jenkins 2.138.4 and 2.154, this is further restricted to address several security issues."
  },
  "4216": {
    "source_file": "stapler-accessible-type.txt",
    "text": "h the basic Stapler routing rules discussed in .\nStarting in Jenkins 2.138.4 and 2.154, this is further restricted to address several security issues.\n\nWhen the SECURITY-595 fix prevents access to a URL, a warning message is written to the Jenkins log that looks similar to the following:\n\nWARNING: New Stapler routing rules result in the URL \"/example\" no longer being allowed. If you consider it sa"
  },
  "4217": {
    "source_file": "stapler-accessible-type.txt",
    "text": "g that looks similar to the following:\n\nWARNING: New Stapler routing rules result in the URL \"/example\" no longer being allowed. If you consider it safe to use, add the following to the whitelist: \"method hudson.model.Hudson doExample\". Learn more: https://www.jenkins.io/redirect/stapler-routing\n\nAdministrators can follow the instructions to make the method or field work on their specific instance"
  },
  "4218": {
    "source_file": "stapler-accessible-type.txt",
    "text": "ttps://www.jenkins.io/redirect/stapler-routing\n\nAdministrators can follow the instructions to make the method or field work on their specific instance, but ideally the component is changed to prevent the problem in the first place.\n\nThe following code patterns are known to result in problems related to routing getters and fields:\n\n* Getters and fields declaring a generic type, such as `Object`. Je"
  },
  "4219": {
    "source_file": "stapler-accessible-type.txt",
    "text": "e patterns are known to result in problems related to routing getters and fields:\n\n* Getters and fields declaring a generic type, such as `Object`. Jenkins now looks at the declared (return) type to determine routability before invoking the method, and if the declared (return) type does not appear to be relevant, the getter or field will not be considered.\n* Getters and fields declaring a `Collect"
  },
  "4220": {
    "source_file": "stapler-accessible-type.txt",
    "text": "nd if the declared (return) type does not appear to be relevant, the getter or field will not be considered.\n* Getters and fields declaring a `Collection` type or any subclass from the Java collections framework.\n  While Stapler has support for indexed `List` and `Map` entry access, this does not apply to Jenkins releases with the SECURITY-595 fix.\n* Getters or fields declaring a (return) type tha"
  },
  "4221": {
    "source_file": "stapler-accessible-type.txt",
    "text": "ed `List` and `Map` entry access, this does not apply to Jenkins releases with the SECURITY-595 fix.\n* Getters or fields declaring a (return) type that itself does not appear to be routable, but has a getter or field declaring a (return) type that would be considered routable.\n  In a chain of getter/field accesses like `/foo/bar/baz/`, every element needs to appear relevant to Stapler.\n* Types tha"
  },
  "4222": {
    "source_file": "stapler-accessible-type.txt",
    "text": "uld be considered routable.\n  In a chain of getter/field accesses like `/foo/bar/baz/`, every element needs to appear relevant to Stapler.\n* Types that only provide Jelly/Groovy views, even `index.jelly`, but don't have methods or fields that appear routable.\n\nStarting from Jenkins 2.138.4 and 2.154, Jenkins recognizes the following annotations:\n\n* `@StaplerAccessibleType` on a class or interface "
  },
  "4223": {
    "source_file": "stapler-accessible-type.txt",
    "text": "routable.\n\nStarting from Jenkins 2.138.4 and 2.154, Jenkins recognizes the following annotations:\n\n* `@StaplerAccessibleType` on a class or interface will make getters and fields declaring this class, any subclass, or any implementing class as (return) type routable.\n  This is used on `ModelObject` in Jenkins core to make a great number of relevant types accessible via Stapler.\n* `@StaplerDispatch"
  },
  "4224": {
    "source_file": "stapler-accessible-type.txt",
    "text": "n) type routable.\n  This is used on `ModelObject` in Jenkins core to make a great number of relevant types accessible via Stapler.\n* `@StaplerDispatchable` on a method or field will make the annotated element routable, even if its signature or (return) type would otherwise prevent access.\n\nSpecific recommendations for known problems are listed below.\n\n* Do not declare an `Object` return type, or s"
  },
  "4225": {
    "source_file": "stapler-accessible-type.txt",
    "text": "n) type would otherwise prevent access.\n\nSpecific recommendations for known problems are listed below.\n\n* Do not declare an `Object` return type, or something similarly generic, but the specific `RoutableType` you're returning.\n* Return `RoutableType[]` instead of `List<RoutableType>`\n* If the return type is defined in your component, annotate it `@StaplerAccessibleType`.\n  You may need to add a d"
  },
  "4226": {
    "source_file": "stapler-accessible-type.txt",
    "text": "[]` instead of `List<RoutableType>`\n* If the return type is defined in your component, annotate it `@StaplerAccessibleType`.\n  You may need to add a dependency to the `io.jenkins.stapler:jenkins-stapler-support` library to make this annotation available.\n* If the return type is not defined in your component, annotate the method or field `@StaplerDispatchable`.\n  You may need to add a dependency to"
  },
  "4227": {
    "source_file": "stapler-accessible-type.txt",
    "text": "ble.\n* If the return type is not defined in your component, annotate the method or field `@StaplerDispatchable`.\n  You may need to add a dependency to the `io.jenkins.stapler:jenkins-stapler-support` library to make this annotation available."
  },
  "4228": {
    "source_file": "structured-form-submission.txt",
    "text": "title: Structured form submission\nlayout: developersection\n\n\nThe data model of HTML form submission is a map \u2014 each form field has a name, and when submitted, the server retrieves the values by names. This model has several problems.\n\nOne is the lack of structure; if you have a repeated structure in a form, which in turn contains a nested repeated structure, just giving it a name doesn't allow you"
  },
  "4229": {
    "source_file": "structured-form-submission.txt",
    "text": " of structure; if you have a repeated structure in a form, which in turn contains a nested repeated structure, just giving it a name doesn't allow you to distinguish the nesting structure.\nIOW, you can't tell `(A,B),(C,D)` from `(A,B,C),(D)` because the map just gives you a single list of 4 items.\nA similar related issue is when you put a checkbox in a repeated part of a form.\nIf some are checked "
  },
  "4230": {
    "source_file": "structured-form-submission.txt",
    "text": "the map just gives you a single list of 4 items.\nA similar related issue is when you put a checkbox in a repeated part of a form.\nIf some are checked by some are not, the server can never figure out which ones are checked because that information is lost when a form is submitted.\n\nAnother issue is the scope of the name. In HTML, all the form fields need to have unique names. This is akin to have a"
  },
  "4231": {
    "source_file": "structured-form-submission.txt",
    "text": "lost when a form is submitted.\n\nAnother issue is the scope of the name. In HTML, all the form fields need to have unique names. This is akin to have all your variables as global in a programming language, and in a modular extensible system like Jenkins, this is not preferable. Scoping of names also prevent a part of the form to be reused elsewhere in the same form.\n\nTo avoid these issues and furth"
  },
  "4232": {
    "source_file": "structured-form-submission.txt",
    "text": "ns, this is not preferable. Scoping of names also prevent a part of the form to be reused elsewhere in the same form.\n\nTo avoid these issues and further simplify the server side, in Jenkins the notion of the \"structured form submission\" is introduced.\n\nStructured form submission is a form submission where the data model is a JSON object tree, not a map. This is done by having a client compute the "
  },
  "4233": {
    "source_file": "structured-form-submission.txt",
    "text": ".\n\nStructured form submission is a form submission where the data model is a JSON object tree, not a map. This is done by having a client compute the JSON representation at the form submission time, and send that to the server as a hidden text field (along with all the other fields.)\n\nStructure is determined by several factors. First, the name of the form field becomes the JSON property name. For "
  },
  "4234": {
    "source_file": "structured-form-submission.txt",
    "text": "(along with all the other fields.)\n\nStructure is determined by several factors. First, the name of the form field becomes the JSON property name. For compatibility reasons, a name can have any \"abc.def.\" kind of prefix, and the prefix portion will be ignored. So for example, in the simplest case, the following form will produce the JSON result on the right.\n\n<form>\n  <input type=\"text\" name=\"my.na"
  },
  "4235": {
    "source_file": "structured-form-submission.txt",
    "text": " ignored. So for example, in the simplest case, the following form will produce the JSON result on the right.\n\n<form>\n  <input type=\"text\" name=\"my.name\"/>\n  <input type=\"checkbox\" name=\"my.option\"/> Send me e-mails\n</form>\n\n{ name: \"Kohsuke\", option: true }\n\nAny intermediate tag can have the 'name' attribute, and that would group the descendants into an intermediate object. Consider the following"
  },
  "4236": {
    "source_file": "structured-form-submission.txt",
    "text": ": true }\n\nAny intermediate tag can have the 'name' attribute, and that would group the descendants into an intermediate object. Consider the following example:\n\n<form>\n  <div name=\"first\">\n    <input type=\"text\" name=\"my.name\"/>\n    <input type=\"checkbox\" name=\"my.option\"/> Send me e-mails\n  </div>\n  <div name=\"second\">\n    <input type=\"text\" name=\"my.name\"/>\n    <input type=\"checkbox\" name=\"my.op"
  },
  "4237": {
    "source_file": "structured-form-submission.txt",
    "text": "kbox\" name=\"my.option\"/> Send me e-mails\n  </div>\n  <div name=\"second\">\n    <input type=\"text\" name=\"my.name\"/>\n    <input type=\"checkbox\" name=\"my.option\"/> Send me e-mails\n  </div>\n  ...\n  <div>\n    <input type=\"password\" name=\"my.password\" />\n  </div>\n</form>\n\n{\n  first: { name: \"Kohsuke\", option: true },\n  second: { name: \"Jesse\", option: false },\n  password: \"secret\"\n}\n\nIf there are multiple "
  },
  "4238": {
    "source_file": "structured-form-submission.txt",
    "text": "div>\n</form>\n\n{\n  first: { name: \"Kohsuke\", option: true },\n  second: { name: \"Jesse\", option: false },\n  password: \"secret\"\n}\n\nIf there are multiple elements with the same name, their values are aggregated into an array. Consider the following example:\n\n<form>\n  <div name=\"person\">\n    <input type=\"text\" name=\"my.name\"/>\n    <input type=\"checkbox\" name=\"my.option\"/> Send me e-mails\n  </div>\n  <di"
  },
  "4239": {
    "source_file": "structured-form-submission.txt",
    "text": "le:\n\n<form>\n  <div name=\"person\">\n    <input type=\"text\" name=\"my.name\"/>\n    <input type=\"checkbox\" name=\"my.option\"/> Send me e-mails\n  </div>\n  <div name=\"person\">\n    <input type=\"text\" name=\"my.name\"/>\n    <input type=\"checkbox\" name=\"my.option\"/> Send me e-mails\n  </div>\n  ...\n  <div>\n    <input type=\"password\" name=\"my.password\" />\n  </div>\n</form>\n\n{\n  person: [\n    { name: \"Kohsuke\", opti"
  },
  "4240": {
    "source_file": "structured-form-submission.txt",
    "text": "/> Send me e-mails\n  </div>\n  ...\n  <div>\n    <input type=\"password\" name=\"my.password\" />\n  </div>\n</form>\n\n{\n  person: [\n    { name: \"Kohsuke\", option: true },\n    { name: \"Jesse\", option: false }\n  ],\n  password:\"secret\"\n}\n\nThe nesting can be arbitrarily deep.\n\nFile uploads in the structured form are renamed to unique names, and the JSON tree will have the name of this unique form name. To rema"
  },
  "4241": {
    "source_file": "structured-form-submission.txt",
    "text": "trarily deep.\n\nFile uploads in the structured form are renamed to unique names, and the JSON tree will have the name of this unique form name. To remain backward compatible, this processing requires that the file INPUT element contains jsonAware=\"yes\" attribute:\n\n<form>\n  <div name=\"person\">\n    <input type=\"text\" name=\"my.name\"/>\n    <input type=\"file\" name=\"my.key\" jsonAware=\"yes\"/>\n  </div>\n  <"
  },
  "4242": {
    "source_file": "structured-form-submission.txt",
    "text": "\" attribute:\n\n<form>\n  <div name=\"person\">\n    <input type=\"text\" name=\"my.name\"/>\n    <input type=\"file\" name=\"my.key\" jsonAware=\"yes\"/>\n  </div>\n  <div name=\"person\">\n    <input type=\"text\" name=\"my.name\"/>\n    <input type=\"file\" name=\"my.key\" jsonAware=\"yes\"/>\n  </div>\n</form>\n\n{\n  person: [\n    { name: \"Kohsuke\", key: \"randomId1234567\" },\n    { name: \"Jesse\", key: \"randomIdabcdefg\" }\n  ]\n}\n\nst"
  },
  "4243": {
    "source_file": "structured-form-submission.txt",
    "text": "Aware=\"yes\"/>\n  </div>\n</form>\n\n{\n  person: [\n    { name: \"Kohsuke\", key: \"randomId1234567\" },\n    { name: \"Jesse\", key: \"randomIdabcdefg\" }\n  ]\n}\n\nstaplerRequest.getFileItem(\"randomId1234567\") would return the file uploaded for Kohsuke, and\nstaplerRequest.getFileItem(\"randomIdabcdefg\") would return the file uploaded for Jesse.\n\nSometimes, the mark up and the layout of the form makes it impossible"
  },
  "4244": {
    "source_file": "structured-form-submission.txt",
    "text": "equest.getFileItem(\"randomIdabcdefg\") would return the file uploaded for Jesse.\n\nSometimes, the mark up and the layout of the form makes it impossible for a grouped form fields to have a single common ancestor element (for example, grouped form elements are often spread across multiple table rows.) In such a case, you can put the `nameref` attribute to merge multiple tree of elements into one. Thi"
  },
  "4245": {
    "source_file": "structured-form-submission.txt",
    "text": "nts are often spread across multiple table rows.) In such a case, you can put the `nameref` attribute to merge multiple tree of elements into one. This mechanism is mostly used inside Jenkins form layout tags behind the scene, so it's not something plugin developers would need to worry about.\nConsider the following example:\n\n<form>\n  <table>\n    <tr name=\"cvs\" id=\"abc\"><td>\n      <input type=\"text"
  },
  "4246": {
    "source_file": "structured-form-submission.txt",
    "text": "lugin developers would need to worry about.\nConsider the following example:\n\n<form>\n  <table>\n    <tr name=\"cvs\" id=\"abc\"><td>\n      <input type=\"text\" name=\"CVSROOT\" />\n    </td></tr>\n    <tr nameref=\"abc\"><td>\n      <input type=\"text\" name=\"module\" />\n    </td></tr>\n    <tr name=\"svn\" id=\"def\"><td>\n      <input type=\"text\" name=\"URL\" />\n    </td></tr>\n    <tr nameref=\"def\"><td>\n      <input type"
  },
  "4247": {
    "source_file": "structured-form-submission.txt",
    "text": " />\n    </td></tr>\n    <tr name=\"svn\" id=\"def\"><td>\n      <input type=\"text\" name=\"URL\" />\n    </td></tr>\n    <tr nameref=\"def\"><td>\n      <input type=\"text\" name=\"module\" />\n    </td></tr>\n  </table>\n</form>\n\n{\n  cvs: { CVSROOT:\"...\", module:\"...\" },\n  svn: { URL:\"...\", module:\"...\" }\n}\n\nIf the `nameref` attribute points to a check box or a radio button INPUT element, the subordinate structure is"
  },
  "4248": {
    "source_file": "structured-form-submission.txt",
    "text": ",\n  svn: { URL:\"...\", module:\"...\" }\n}\n\nIf the `nameref` attribute points to a check box or a radio button INPUT element, the subordinate structure is only submitted when the INPUT element is selected/checked. This is convenient when such an INPUT element is used to control the visibility of nested form parts.\n\nYou can access the entire JSON tree by calling `StructuredForm.get(request)`, but such "
  },
  "4249": {
    "source_file": "structured-form-submission.txt",
    "text": "ement is used to control the visibility of nested form parts.\n\nYou can access the entire JSON tree by calling `StructuredForm.get(request)`, but such code is generally only necessary when you are in charge of the entire form submission. `Descriptor.configure()` and `Descriptor.newInstance()` take JSONObject, which corresponds to the form fragment that you contributed via `config.jelly`/`global.jel"
  },
  "4250": {
    "source_file": "structured-form-submission.txt",
    "text": "onfigure()` and `Descriptor.newInstance()` take JSONObject, which corresponds to the form fragment that you contributed via `config.jelly`/`global.jelly`.\n\nSee some of the Descriptor implementations in Jenkins core as an example.\n\nStaplerRequest provides several data-binding methods from JSONObject, which greatly simplifies the object instantiation from form data. See the javadoc of the `StaplerRe"
  },
  "4251": {
    "source_file": "structured-form-submission.txt",
    "text": "ides several data-binding methods from JSONObject, which greatly simplifies the object instantiation from form data. See the javadoc of the `StaplerRequest.bindJSONXXX` methods for details.\n\nNormally you don't need to implement anything on the server side if you are using the .\n\nYou may override the configure method of your `GlobalConfiguration` to bind all the fields at once and save it.\n\n@Overri"
  },
  "4252": {
    "source_file": "structured-form-submission.txt",
    "text": " side if you are using the .\n\nYou may override the configure method of your `GlobalConfiguration` to bind all the fields at once and save it.\n\n@Override\npublic boolean configure(StaplerRequest req, JSONObject json) {\n    req.bindJSON(this, json);\n    save();\n    return true;\n}\n\nAlternatively you can call the save method in each setter that you have:\n\n@DataBoundSetter\npublic void setCredentialID(St"
  },
  "4253": {
    "source_file": "structured-form-submission.txt",
    "text": " save();\n    return true;\n}\n\nAlternatively you can call the save method in each setter that you have:\n\n@DataBoundSetter\npublic void setCredentialID(String credentialID) {\n    this.credentialID = credentialID;\n    save();\n}"
  },
  "4254": {
    "source_file": "style-guides.txt",
    "text": "title: Style Guides\nlayout: developersection\n\n\nNOTE: Not all existing plugins may follow these rules, as those were established or enforced later.\n\nA plugin's artifact ID is used as the file base name and to uniquely identify the plugin in Jenkins and on update sites.\nIt needs to follow some conventions to be published:\n\n* Use a lowercase ID, and separate terms with hyphens as needed.\n* Include ne"
  },
  "4255": {
    "source_file": "style-guides.txt",
    "text": "d on update sites.\nIt needs to follow some conventions to be published:\n\n* Use a lowercase ID, and separate terms with hyphens as needed.\n* Include neither `jenkins` or `plugin` in the ID unless necessary for the name to make any sense at all.\n\nFor example, use `snapchat-notification` instead of `JenkinsSnapchatNotificationPlugin` or `notification-plugin-for-snapchat`.\n\nThe ID cannot be changed af"
  },
  "4256": {
    "source_file": "style-guides.txt",
    "text": "xample, use `snapchat-notification` instead of `JenkinsSnapchatNotificationPlugin` or `notification-plugin-for-snapchat`.\n\nThe ID cannot be changed after the first release; Jenkins would consider it a different plugin.\n\nA plugin's name is shown to users on the Jenkins UI and elsewhere, such as the plugin site.\nIf is recommended to use a short and descriptive name, like _Subversion_.\n\nIncluding _Je"
  },
  "4257": {
    "source_file": "style-guides.txt",
    "text": "ers on the Jenkins UI and elsewhere, such as the plugin site.\nIf is recommended to use a short and descriptive name, like _Subversion_.\n\nIncluding _Jenkins_ or _Plugin_ in the name to indicate that it is a plugin for Jenkins is redundant and discouraged, and these terms may be stripped from the name in some cases to ensure consistency in lists, and to shorten the name.\n\nAll new hosting requests ar"
  },
  "4258": {
    "source_file": "style-guides.txt",
    "text": "ged, and these terms may be stripped from the name in some cases to ensure consistency in lists, and to shorten the name.\n\nAll new hosting requests are instructed to use `io.jenkins.plugins` as group ID. +\nWe do not strictly prohibit other group IDs unless they're in bad faith (e.g. referencing an organization you have no relationship with), but we strongly recommend using `io.jenkins.plugins` to "
  },
  "4259": {
    "source_file": "style-guides.txt",
    "text": "unless they're in bad faith (e.g. referencing an organization you have no relationship with), but we strongly recommend using `io.jenkins.plugins` to avoid confusion and use a standardized pattern.\n\nThe Jenkins project generally follows the  but it's not well enforced even in core components.\nIndividual plugin maintainers sometimes choose to use different style guides for their plugins.\n\nGit commi"
  },
  "4260": {
    "source_file": "style-guides.txt",
    "text": " not well enforced even in core components.\nIndividual plugin maintainers sometimes choose to use different style guides for their plugins.\n\nGit commit messages should start with a reference to the Jira issue they're related to, if applicable, followed by a short summary on the first line, and more details on subsequent lines.\nExample:\n\n[JENKINS-00000] Frobnicate the widget\n\nIf a given commit _fix"
  },
  "4261": {
    "source_file": "style-guides.txt",
    "text": "ed by a short summary on the first line, and more details on subsequent lines.\nExample:\n\n[JENKINS-00000] Frobnicate the widget\n\nIf a given commit _fixes_ the specified issue, use of one of the following prefixes will make an automated infra process resolve the related Jira issue.\n\n[FIX JENKINS-00000] Frobnicate the widget\n[FIXED JENKINS-00000] Frobnicate the widget\n[FIXES JENKINS-00000] Frobnicate"
  },
  "4262": {
    "source_file": "style-guides.txt",
    "text": "esolve the related Jira issue.\n\n[FIX JENKINS-00000] Frobnicate the widget\n[FIXED JENKINS-00000] Frobnicate the widget\n[FIXES JENKINS-00000] Frobnicate the widget"
  },
  "4263": {
    "source_file": "support-policy-java.txt",
    "text": "layout: subsection\ntitle:  Java Support Policy\n\n\nThere are separate runtime and job execution requirements for Jenkins installations.\n\n## Running Jenkins system\n\nThe following Java versions are required to run Jenkins:\n\n|===\n|Supported Java versions|Long term support (LTS) release|Weekly release\n|Java 17, Java 21, or Java 25 |N/A |2.534 (October 2025)\n|Java 17 or Java 21|2.479.1 (October 2024) |2."
  },
  "4264": {
    "source_file": "support-policy-java.txt",
    "text": "Long term support (LTS) release|Weekly release\n|Java 17, Java 21, or Java 25 |N/A |2.534 (October 2025)\n|Java 17 or Java 21|2.479.1 (October 2024) |2.463 (June 2024)\n|Java 11, Java 17, or Java 21|2.426.1 (November 2023) |2.419 (August 2023)\n|Java 11 or Java 17|2.361.1 (September 2022)|2.357 (June 2022)\n|Java 8, Java 11, or Java 17|2.346.1 (June 2022)|2.340 (March 2022)\n|Java 8 or Java 11|2.164.1 ("
  },
  "4265": {
    "source_file": "support-policy-java.txt",
    "text": "or Java 17|2.361.1 (September 2022)|2.357 (June 2022)\n|Java 8, Java 11, or Java 17|2.346.1 (June 2022)|2.340 (March 2022)\n|Java 8 or Java 11|2.164.1 (March 2019)|2.164 (February 2019)\n|Java 8|2.60.1 (June 2017)|2.54 (April 2017)\n|Java 7|1.625.1 (October 2015)|1.612 (May 2015)\n|===\n\n[IMPORTANT]\n.Supported Java versions\n\nIf you install an unsupported Java version, your Jenkins controller will not ru"
  },
  "4266": {
    "source_file": "support-policy-java.txt",
    "text": "ber 2015)|1.612 (May 2015)\n|===\n\n[IMPORTANT]\n.Supported Java versions\n\nIf you install an unsupported Java version, your Jenkins controller will not run.\n\nThese requirements apply to all components of the Jenkins system, including the Jenkins controller, all types of agents, CLI clients, and other components.\nYou do _not_ need to build your application with the same version of Java used to run Jenk"
  },
  "4267": {
    "source_file": "support-policy-java.txt",
    "text": "er, all types of agents, CLI clients, and other components.\nYou do _not_ need to build your application with the same version of Java used to run Jenkins itself;\nsee the \"Running Java-based tools and builds on Jenkins\" section below.\n\nUpgrading an existing Jenkins setup to a newer version of Java?\nRefer to the  and the .\n\nDocker installation instructions are included in .\n\nThe Jenkins project perf"
  },
  "4268": {
    "source_file": "support-policy-java.txt",
    "text": "isting Jenkins setup to a newer version of Java?\nRefer to the  and the .\n\nDocker installation instructions are included in .\n\nThe Jenkins project performs a full test flow with the following JDK/JREs:\n\n* OpenJDK JDK / JRE 17 - 64 bits\n* OpenJDK JDK / JRE 21 - 64 bits\n\nJRE/JDKs from other vendors are supported and may be used.\nRefer to  for known Java compatibility issues.\nJenkins maintainers activ"
  },
  "4269": {
    "source_file": "support-policy-java.txt",
    "text": " JRE 21 - 64 bits\n\nJRE/JDKs from other vendors are supported and may be used.\nRefer to  for known Java compatibility issues.\nJenkins maintainers actively test  like those from OpenJDK, Eclipse Temurin, and Amazon Corretto.\nJenkins maintainers do not test .\nThe  does not actively work on OpenJ9 based Java virtual machines.\n\n## Running Java-based tools and builds on Jenkins\n\nThe JDK versions used to"
  },
  "4270": {
    "source_file": "support-policy-java.txt",
    "text": "test .\nThe  does not actively work on OpenJ9 based Java virtual machines.\n\n## Running Java-based tools and builds on Jenkins\n\nThe JDK versions used to build Java-based projects or run Java-based tools are independent from the version of Java used to run the Jenkins controller and agent processes.\nDuring builds, any JRE or JDK version compatible with the host system can be launched.\nThis includes:\n"
  },
  "4271": {
    "source_file": "support-policy-java.txt",
    "text": "run the Jenkins controller and agent processes.\nDuring builds, any JRE or JDK version compatible with the host system can be launched.\nThis includes:\n\n* Execution of `java` or `javac` from shell build steps and similar.\n* Execution of Maven/Ant/\u2026 build steps using a JDK managed by a JDK .\n\nSome plugins have more strict requirements, and may require a build to execute the same Java version used to "
  },
  "4272": {
    "source_file": "support-policy-java.txt",
    "text": "ld steps using a JDK managed by a JDK .\n\nSome plugins have more strict requirements, and may require a build to execute the same Java version used to run the Jenkins controller and agents.\nA notable plugin example is the plugin:maven-plugin[Maven Integration Plugin]. It requires the JDK version used for Maven builds to be at least the same Java version used in the Jenkins controller.\nThese cases a"
  },
  "4273": {
    "source_file": "support-policy-java.txt",
    "text": "egration Plugin]. It requires the JDK version used for Maven builds to be at least the same Java version used in the Jenkins controller.\nThese cases are generally documented in the plugin documentation.\n// This used to list Swarm Plugin Clients, but since they are agent processes that's kind of redundant.\n// TODO This used to list docker-workflow, but it's unclear why.\n\n## Monitoring Java versions"
  },
  "4274": {
    "source_file": "support-policy-java.txt",
    "text": "since they are agent processes that's kind of redundant.\n// TODO This used to list docker-workflow, but it's unclear why.\n\n## Monitoring Java versions\n\nModern Jenkins controllers and Jenkins agents verify Java requirements\nand notify users when they are launched with an unsupported version.\n\nThe plugin:versioncolumn[Versions Node Monitors plugin] provides detailed Java version monitoring.\n\n## JDKs"
  },
  "4275": {
    "source_file": "support-policy-java.txt",
    "text": "are launched with an unsupported version.\n\nThe plugin:versioncolumn[Versions Node Monitors plugin] provides detailed Java version monitoring.\n\n## JDKs used in Jenkins\n\nThe Jenkins project uses  as its primary JDK for building and testing Java based applications.\nThis includes:\n\n* Container Images\n* Jenkins core release builds\n*\n*\n* Testing Infrastructure\n\nSome of the reasons for choosing Temurin a"
  },
  "4276": {
    "source_file": "support-policy-java.txt",
    "text": "pplications.\nThis includes:\n\n* Container Images\n* Jenkins core release builds\n*\n*\n* Testing Infrastructure\n\nSome of the reasons for choosing Temurin are:\n\n* Availability over many different Java SE versions and across a wide range of platforms, including different operating systems and architectures.\n* Regular maintenance and long term support provided by the Eclipse Foundation."
  },
  "4277": {
    "source_file": "support-policy-java.txt",
    "text": "ding different operating systems and architectures.\n* Regular maintenance and long term support provided by the Eclipse Foundation."
  },
  "4278": {
    "source_file": "support-policy-linux.txt",
    "text": "layout: subsection\ntitle:  Linux Support Policy\n\n\nThis page documents the Linux support policy for the Jenkins controller and agents.\n\nIndividual Jenkins plugins may set additional requirements for Linux versions on controllers and/or agents.\nThis page does not document such requirements.\nRefer to  for additional requirements.\n\nTheoretically, Jenkins can run everywhere where you can run a supporte"
  },
  "4279": {
    "source_file": "support-policy-linux.txt",
    "text": "ge does not document such requirements.\nRefer to  for additional requirements.\n\nTheoretically, Jenkins can run everywhere where you can run a supported Java version,\nbut there are some limitations in practice.\nJenkins core and some plugins include native code or depend on Linux API and subsystems,\nwhich make them dependent on specific Linux versions.\nJenkins platform specific installation packages"
  },
  "4280": {
    "source_file": "support-policy-linux.txt",
    "text": "tive code or depend on Linux API and subsystems,\nwhich make them dependent on specific Linux versions.\nJenkins platform specific installation packages rely on specific Linux versions.\n\nWe define multiple support levels for Linux platforms.\n\n[width=\"100%\",cols=\"20%,35%,45%\",options=\"header\",]\n|===\n|Support level |Description |Platforms\n\n| **Level 1** - Supported\n| We run automated package manager i"
  },
  "4281": {
    "source_file": "support-policy-linux.txt",
    "text": "00%\",cols=\"20%,35%,45%\",options=\"header\",]\n|===\n|Support level |Description |Platforms\n\n| **Level 1** - Supported\n| We run automated package manager installation testing for these platforms, and we intend to fix reported issues in a timely manner.\n  We recommend either package manager based installations or container based installations for Linux.\n  Installations may also use `jenkins.war` without"
  },
  "4282": {
    "source_file": "support-policy-linux.txt",
    "text": "We recommend either package manager based installations or container based installations for Linux.\n  Installations may also use `jenkins.war` without a package manager, though our automated testing focuses on package manager and container installations.\na|\n  * 64-bit (amd64) Linux versions that use the Debian packaging format as\n  * 64-bit (amd64) Linux versions that use the Red Hat rpm packaging"
  },
  "4283": {
    "source_file": "support-policy-linux.txt",
    "text": "ons.\na|\n  * 64-bit (amd64) Linux versions that use the Debian packaging format as\n  * 64-bit (amd64) Linux versions that use the Red Hat rpm packaging format as\n  * 64-bit (amd64) Linux versions that use the OpenSUSE rpm packaging format as\n  * 64-bit (arm64, s390x) Linux versions that use the Debian packaging format as\n  * 64-bit (arm64, s390x) Linux versions that use the rpm packaging format as\n"
  },
  "4284": {
    "source_file": "support-policy-linux.txt",
    "text": "t (arm64, s390x) Linux versions that use the Debian packaging format as\n  * 64-bit (arm64, s390x) Linux versions that use the rpm packaging format as\n  * Linux container images (amd64, arm64, s390x) as published for the  and various agents\n\n| **Level 2** - Patches considered\n| Support may have limitations and extra requirements.\n  We do not test compatibility, and we may drop support at any time.\n"
  },
  "4285": {
    "source_file": "support-policy-linux.txt",
    "text": " 2** - Patches considered\n| Support may have limitations and extra requirements.\n  We do not test compatibility, and we may drop support at any time.\n  We consider patches that do not put level 1 support at risk and do not create maintenance overhead.\na|\n  * 32-bit (x86, arm) Linux versions\n  * RISC-V and other architectures not included in level 1 support\n  * Preview releases\n\n| **Level 3** - Uns"
  },
  "4286": {
    "source_file": "support-policy-linux.txt",
    "text": ".\na|\n  * 32-bit (x86, arm) Linux versions\n  * RISC-V and other architectures not included in level 1 support\n  * Preview releases\n\n| **Level 3** - Unsupported\n| These versions are known to be incompatible or to have severe limitations.\n  We do not support the listed platforms, and we do not accept patches.\na|\n  * Linux versions no longer supported by operating system providers\n|===\n\n*\n*\n*\n*\n\nYou a"
  },
  "4287": {
    "source_file": "support-policy-linux.txt",
    "text": "pport the listed platforms, and we do not accept patches.\na|\n  * Linux versions no longer supported by operating system providers\n|===\n\n*\n*\n*\n*\n\nYou are welcome to propose PRs that add support for other Linux platforms or to share feedback;\nwe honestly appreciate your contributions!\nLinux support in Jenkins is\nwhich has a , a ., and .\nYou are welcome to join these channels.\n\n* March 2022 - First v"
  },
  "4288": {
    "source_file": "support-policy-linux.txt",
    "text": "ly appreciate your contributions!\nLinux support in Jenkins is\nwhich has a , a ., and .\nYou are welcome to join these channels.\n\n* March 2022 - First version\n  (,\n   )"
  },
  "4289": {
    "source_file": "support-policy-servlet-containers.txt",
    "text": "layout: subsection\ntitle: Servlet Container Support Policy\n\n\nThis page documents the servlet container support policy for the Jenkins controller.\n\nJenkins typically runs as a standalone application in its own process.\nThe Jenkins WAR file bundles ,\na  servlet container wrapper,\nand can be started on any operating system or platform with a version of Java supported by Jenkins.\nThis is the preferred"
  },
  "4290": {
    "source_file": "support-policy-servlet-containers.txt",
    "text": "  servlet container wrapper,\nand can be started on any operating system or platform with a version of Java supported by Jenkins.\nThis is the preferred way to deploy Jenkins and is fully supported.\n\nTheoretically, Jenkins can also be run as a servlet in a traditional servlet container\nlike  or .\nHowever, in practice, this is largely untested, and there are many caveats.\nIn particular, support for W"
  },
  "4291": {
    "source_file": "support-policy-servlet-containers.txt",
    "text": "in a traditional servlet container\nlike  or .\nHowever, in practice, this is largely untested, and there are many caveats.\nIn particular, support for WebSocket agents is only implemented for the Jetty servlet container.\n\nWARNING: Support for traditional servlet containers may be discontinued in the future.\n\nWe define multiple support levels for servlet containers.\n\n[width=\"100%\",cols=\"20%,35%,45%\","
  },
  "4292": {
    "source_file": "support-policy-servlet-containers.txt",
    "text": "al servlet containers may be discontinued in the future.\n\nWe define multiple support levels for servlet containers.\n\n[width=\"100%\",cols=\"20%,35%,45%\",options=\"header\",]\n|===\n|Support level |Description |Servlet containers\n\n| **Level 1:** Supported\n| We run automated testing for these servlet containers, and we intend to fix reported issues in a timely manner.\na|The versions of Winstone and Jetty b"
  },
  "4293": {
    "source_file": "support-policy-servlet-containers.txt",
    "text": "We run automated testing for these servlet containers, and we intend to fix reported issues in a timely manner.\na|The versions of Winstone and Jetty bundled in the Jenkins .\n\n| **Level 2:** Patches considered\n| Support may have limitations and extra requirements.\n  We do not regularly test compatibility, and we may drop support at any time.\n  We consider patches that do not put Level 1 support at "
  },
  "4294": {
    "source_file": "support-policy-servlet-containers.txt",
    "text": "requirements.\n  We do not regularly test compatibility, and we may drop support at any time.\n  We consider patches that do not put Level 1 support at risk and do not create maintenance overhead.\na|\n  * Tomcat 9, based on Servlet API 4.0 (Jakarta EE 8) with `javax.servlet` imports. (*Weekly 2.474, LTS 2.462.3, and older*)\n  * WildFly 26, based on Servlet API 4.0 (Jakarta EE 8) with `javax.servlet` "
  },
  "4295": {
    "source_file": "support-policy-servlet-containers.txt",
    "text": ") with `javax.servlet` imports. (*Weekly 2.474, LTS 2.462.3, and older*)\n  * WildFly 26, based on Servlet API 4.0 (Jakarta EE 8) with `javax.servlet` imports. (*Weekly 2.474, LTS 2.462.3, and older*)\n  * Other servlet containers that are based on Servlet API 4.0 (Jakarta EE 8) with `javax.servlet` imports. (*Weekly 2.474, LTS 2.462.3, and older*)\n  * Jetty 11 or later, based on Servlet API 5.0 (Ja"
  },
  "4296": {
    "source_file": "support-policy-servlet-containers.txt",
    "text": "vlet API 4.0 (Jakarta EE 8) with `javax.servlet` imports. (*Weekly 2.474, LTS 2.462.3, and older*)\n  * Jetty 11 or later, based on Servlet API 5.0 (Jakarta EE 9) or later with `jakarta.servlet` imports. (*Weekly 2.475, LTS 2.479.1, and newer*)\n  * Tomcat 10 or later, based on Servlet API 5.0 (Jakarta EE 9) or later with `jakarta.servlet` imports. (*Weekly 2.475, LTS 2.479.1, and newer*)\n  * WildFl"
  },
  "4297": {
    "source_file": "support-policy-servlet-containers.txt",
    "text": "mcat 10 or later, based on Servlet API 5.0 (Jakarta EE 9) or later with `jakarta.servlet` imports. (*Weekly 2.475, LTS 2.479.1, and newer*)\n  * WildFly 27 or later, based on Servlet API 5.0 (Jakarta EE 9) or later with `jakarta.servlet` imports. (*Weekly 2.475, LTS 2.479.1, and newer*)\n  * Other servlet containers that are based on Servlet API 5.0 (Jakarta EE 9) or later with `jakarta.servlet` imp"
  },
  "4298": {
    "source_file": "support-policy-servlet-containers.txt",
    "text": "ekly 2.475, LTS 2.479.1, and newer*)\n  * Other servlet containers that are based on Servlet API 5.0 (Jakarta EE 9) or later with `jakarta.servlet` imports. (*Weekly 2.475, LTS 2.479.1, and newer*)\n\n| **Level 3:** Unsupported\n| These versions are known to be incompatible or to have severe limitations.\n  We do not support the listed servlet containers.\na|\n  * Jetty 11 or later, based on Servlet API "
  },
  "4299": {
    "source_file": "support-policy-servlet-containers.txt",
    "text": "n to be incompatible or to have severe limitations.\n  We do not support the listed servlet containers.\na|\n  * Jetty 11 or later, based on Servlet API 5.0 (Jakarta EE 9) or later with `jakarta.servlet` imports. (*Weekly 2.474, LTS 2.462.3, and older*)\n  * Tomcat 10 or later, based on Servlet API 5.0 (Jakarta EE 9) or later with `jakarta.servlet` imports. (*Weekly 2.474, LTS 2.462.3, and older*)\n  *"
  },
  "4300": {
    "source_file": "support-policy-servlet-containers.txt",
    "text": "\n  * Tomcat 10 or later, based on Servlet API 5.0 (Jakarta EE 9) or later with `jakarta.servlet` imports. (*Weekly 2.474, LTS 2.462.3, and older*)\n  * WildFly 27 or later, based on Servlet API 5.0 (Jakarta EE 9) or later with `jakarta.servlet` imports. (*Weekly 2.474, LTS 2.462.3, and older*)\n  * Other servlet containers that are based on Servlet API 5.0 (Jakarta EE 9) or later with `jakarta.servl"
  },
  "4301": {
    "source_file": "support-policy-servlet-containers.txt",
    "text": "s. (*Weekly 2.474, LTS 2.462.3, and older*)\n  * Other servlet containers that are based on Servlet API 5.0 (Jakarta EE 9) or later with `jakarta.servlet` imports. (*Weekly 2.474, LTS 2.462.3, and older*)\n\n|===\n\nWARNING: Support for Jakarta EE 8 is planned to end with the October LTS release.\n\n*\n*\n*\n*\n\nYou are welcome to propose PRs that add support or documentation for other servlet containers or "
  },
  "4302": {
    "source_file": "support-policy-servlet-containers.txt",
    "text": "anned to end with the October LTS release.\n\n*\n*\n*\n*\n\nYou are welcome to propose PRs that add support or documentation for other servlet containers or to share feedback;\nwe will appreciate your contributions!\nServlet container support in Jenkins falls under the\nwhich has a , a ., and .\nYou are welcome to join these channels."
  },
  "4303": {
    "source_file": "support-policy-servlet-containers.txt",
    "text": " under the\nwhich has a , a ., and .\nYou are welcome to join these channels."
  },
  "4304": {
    "source_file": "support-policy-web-browsers.txt",
    "text": "layout: subsection\ntitle:  Browser compatibility\n\n\nThis page documents the browser support policy for Jenkins controllers.\nNOTE: Content here does not apply to the Jenkins website or other services hosted by the Jenkins project.\n\nJenkins web browser support falls into one of three levels:\n\nLevel 1: Aim to proactively support these browsers and provide an equal\nUX across all.\nLevel 2: Accept patche"
  },
  "4305": {
    "source_file": "support-policy-web-browsers.txt",
    "text": "support falls into one of three levels:\n\nLevel 1: Aim to proactively support these browsers and provide an equal\nUX across all.\nLevel 2: Accept patches to fix issues and make the best effort to\nensure there is at least one way to do any action.\nLevel 3: No guarantees. We will accept patches, but only if they are\nlow risk. *This is the default unless a browser/version is listed\nbelow*.\n\nWe do not c"
  },
  "4306": {
    "source_file": "support-policy-web-browsers.txt",
    "text": " 3: No guarantees. We will accept patches, but only if they are\nlow risk. *This is the default unless a browser/version is listed\nbelow*.\n\nWe do not claim any compatibility with or accept bug reports and\npatches for pre-release (e.g., alpha, beta, or canary) versions of\nbrowsers.\n\n[width=\"100%\",cols=\"25%,25%,25%,25%\",options=\"header\",]\n|===\n|Browser |Level 1 |Level 2 |Level 3\n\n|Google Chrome\n|Late"
  },
  "4307": {
    "source_file": "support-policy-web-browsers.txt",
    "text": " canary) versions of\nbrowsers.\n\n[width=\"100%\",cols=\"25%,25%,25%,25%\",options=\"header\",]\n|===\n|Browser |Level 1 |Level 2 |Level 3\n\n|Google Chrome\n|Latest regular release/patch\n|Version N-1, latest patch\n|Other versions\n\n|Mozilla Firefox\n|Latest regular release/patch\n|Version N-1, latest patch;\nLatest https://www.mozilla.org/en-US/firefox/organizations/[ESR]\u00a0release\n|Other versions\u00a0\n\n|Microsoft Edge"
  },
  "4308": {
    "source_file": "support-policy-web-browsers.txt",
    "text": "r release/patch\n|Version N-1, latest patch;\nLatest https://www.mozilla.org/en-US/firefox/organizations/[ESR]\u00a0release\n|Other versions\u00a0\n\n|Microsoft Edge\n|Latest regular release/patch\n|Version N-1, latest patch\n|Other versions\n\n|Apple Safari\n|Latest regular release/patch\n|Version N-1, latest patch\n|Other versions\n|===\n\nSupport for mobile browsers (e.g. iOS Safari) has not yet been determined.\n\n* 2025"
  },
  "4309": {
    "source_file": "support-policy-web-browsers.txt",
    "text": "ular release/patch\n|Version N-1, latest patch\n|Other versions\n|===\n\nSupport for mobile browsers (e.g. iOS Safari) has not yet been determined.\n\n* 2025-06-16 - Move Firefox ESR to level 2 from level 1 ()\n* 2022-02-01 - Remove support for Internet Explorer, Add Edge ()\n* 2019-11-19 - Policy update ()\n* 2014-09-03 - Original policy for Jenkins 1.579 (http://meetings.jenkins-ci.org/jenkins/2014/jenkin"
  },
  "4310": {
    "source_file": "support-policy-web-browsers.txt",
    "text": "orer, Add Edge ()\n* 2019-11-19 - Policy update ()\n* 2014-09-03 - Original policy for Jenkins 1.579 (http://meetings.jenkins-ci.org/jenkins/2014/jenkins.2014-09-03-18.01.html[governance meeting notes])"
  },
  "4311": {
    "source_file": "support-policy-windows.txt",
    "text": "layout: subsection\ntitle:  Windows Support Policy\n\n\nThis page documents the Windows support policy for the Jenkins controller and agents.\n\nJenkins plugins may set additional requirements to Windows versions on controllers and/or agents.\nThis page does not document such requirements.\nPlease refer to plugin documentation.\n\nTheoretically, Jenkins can run everywhere where you can run a supported Java "
  },
  "4312": {
    "source_file": "support-policy-windows.txt",
    "text": "s not document such requirements.\nPlease refer to plugin documentation.\n\nTheoretically, Jenkins can run everywhere where you can run a supported Java version,\nbut there are some limitations in practice.\nJenkins core and some plugins include native code or depend on Windows API and subsystems,\nand hence they rely on specific Windows platforms and versions.\nIn Windows services, we also use , which r"
  },
  "4313": {
    "source_file": "support-policy-windows.txt",
    "text": "de or depend on Windows API and subsystems,\nand hence they rely on specific Windows platforms and versions.\nIn Windows services, we also use , which requires .NET Framework.\n\nWe define multiple support levels for Windows platforms.\n\n[width=\"100%\",cols=\"20%,35%,45%\",options=\"header\",]\n|===\n|Support level |Description |Platforms\n\n| **Level 1** - Full support\n| We run automated testing for these plat"
  },
  "4314": {
    "source_file": "support-policy-windows.txt",
    "text": "s=\"20%,35%,45%\",options=\"header\",]\n|===\n|Support level |Description |Platforms\n\n| **Level 1** - Full support\n| We run automated testing for these platforms, and we intend to fix reported issues timely.\na|\n  * 64-bit (amd-64) Windows Server versions, with the latest GA update pack\n  * Windows versions used in the official Docker images\n\n| **Level 2** - Supported\n| We do not actively test these plat"
  },
  "4315": {
    "source_file": "support-policy-windows.txt",
    "text": "with the latest GA update pack\n  * Windows versions used in the official Docker images\n\n| **Level 2** - Supported\n| We do not actively test these platforms, but we intend to keep compatibility.\n  We are happy to accept patches.\na|\n  * 64-bit (amd-64) Windows Server versions generally supported by Microsoft\n  * 64-bit (amd-64) Windows 10 and 11 versions generally supported by Microsoft\n\n| **Level 3"
  },
  "4316": {
    "source_file": "support-policy-windows.txt",
    "text": " Windows Server versions generally supported by Microsoft\n  * 64-bit (amd-64) Windows 10 and 11 versions generally supported by Microsoft\n\n| **Level 3** - Patches considered\n| Support may have limitations and extra requirements.\n  We do not test compatibility, and we may drop support if there is a need.\n  We will consider patches if they do not put Levels 1 or 2 support at risk and do not create m"
  },
  "4317": {
    "source_file": "support-policy-windows.txt",
    "text": "atibility, and we may drop support if there is a need.\n  We will consider patches if they do not put Levels 1 or 2 support at risk and do not create maintenance overhead.\na|\n  * x86 and other non-amd64 architectures\n  * Non-mainstream versions, e.g., Windows Embedded\n  * Preview releases\n  * Windows API emulation engines, e.g., Wine or ReactOS\n\n| **Level 4** - Unsupported\n| These versions are know"
  },
  "4318": {
    "source_file": "support-policy-windows.txt",
    "text": " Windows Embedded\n  * Preview releases\n  * Windows API emulation engines, e.g., Wine or ReactOS\n\n| **Level 4** - Unsupported\n| These versions are known to be incompatible or to have severe limitations.\n  We do not support the listed platforms, and we will not accept patches.\na|\n  * Windows versions no longer supported by Microsoft\n  * Windows XP older than SP3\n  * Windows Phone\n  * Other Windows p"
  },
  "4319": {
    "source_file": "support-policy-windows.txt",
    "text": " will not accept patches.\na|\n  * Windows versions no longer supported by Microsoft\n  * Windows XP older than SP3\n  * Windows Phone\n  * Other Windows platforms released before 2008\n|===\n\n* Starting from `Jenkins 2.238`,\n  .NET Framework 4.0 or above is required for all Windows service installations and built-in Windows service management logic.\n* Before `Jenkins 2.238`, .NET Framework 2.0 was suppo"
  },
  "4320": {
    "source_file": "support-policy-windows.txt",
    "text": "s required for all Windows service installations and built-in Windows service management logic.\n* Before `Jenkins 2.238`, .NET Framework 2.0 was supported\n* For platforms that do not support these versions,\n  consider using Native executables provided by the  project.\n\n*\n*\n\nIf you would like to add support for more Windows platforms or to share feedback,\nwe honestly appreciate your contributions!\n"
  },
  "4321": {
    "source_file": "support-policy-windows.txt",
    "text": "d by the  project.\n\n*\n*\n\nIf you would like to add support for more Windows platforms or to share feedback,\nwe honestly appreciate your contributions!\nWindows support in Jenkins is\nwhich has a chat, a mailing list, and regular meetings.\nYou are welcome to join these channels.\n\n* Jun 03, 2020 - First version\n  (,\n   )"
  },
  "4322": {
    "source_file": "support-policy-windows.txt",
    "text": "e to join these channels.\n\n* Jun 03, 2020 - First version\n  (,\n   )"
  },
  "4323": {
    "source_file": "symbols.txt",
    "text": "title: Symbols\nlayout: developer\n\n\n[.docs__version]#Available since Jenkins 2.335.#\n\n[.text-right]\nView the complete list of symbols available to use on\n\n{nbsp}\n\n[.lead]\nJenkins Symbols are an extensive and consistent collection of icons for use in Jenkins and plugins.\nSymbols are intended to be used everywhere a traditional icon would be used, such as in the sidebar,\nin buttons and in tables. Sym"
  },
  "4324": {
    "source_file": "symbols.txt",
    "text": "enkins and plugins.\nSymbols are intended to be used everywhere a traditional icon would be used, such as in the sidebar,\nin buttons and in tables. Symbols are scalable, support different weights and adapt to the user's theme.\n\n{nbsp}\n\n\n\nRead more about symbols and how to use them in your plugin on the  page."
  },
  "4325": {
    "source_file": "symbols.txt",
    "text": "ut symbols and how to use them in your plugin on the  page."
  },
  "4326": {
    "source_file": "syntax.txt",
    "text": "layout: section\ntitle: Pipeline Syntax\n\n\nifdef::env-github[:imagesdir: ../resources]\nifndef::env-github[:imagesdir: ../../resources]\n\nThis section builds on the information introduced in  and should be treated solely as a reference. For more information on how to use Pipeline syntax in practical examples, refer to:\n\n*\n*\n\nAs of version 2.5 of the Pipeline plugin, Pipeline supports two discrete <<de"
  },
  "4327": {
    "source_file": "syntax.txt",
    "text": "ion on how to use Pipeline syntax in practical examples, refer to:\n\n*\n*\n\nAs of version 2.5 of the Pipeline plugin, Pipeline supports two discrete <<declarative-pipeline, syntaxes>> - Declarative and Scripted. For the pros and cons of each, refer to the <<compare, comparison>>.\n\nAs discussed at the , the most fundamental part of a Pipeline is the <<steps, \"step\">>. Basically, steps tell Jenkins _wh"
  },
  "4328": {
    "source_file": "syntax.txt",
    "text": "he <<compare, comparison>>.\n\nAs discussed at the , the most fundamental part of a Pipeline is the <<steps, \"step\">>. Basically, steps tell Jenkins _what_ to do and serve as the basic building block for both Declarative and Scripted Pipeline syntax.\n\nFor an overview of available steps, please refer to the  which contains a comprehensive list of steps built into Pipeline as well as steps provided by"
  },
  "4329": {
    "source_file": "syntax.txt",
    "text": "For an overview of available steps, please refer to the  which contains a comprehensive list of steps built into Pipeline as well as steps provided by plugins.\n\n[[declarative-pipeline]]\n\nDeclarative Pipeline presents a more simplified and opinionated syntax on top of the Pipeline sub-systems.\nIn order to use them, install the plugin:pipeline-model-definition[Pipeline: Declarative Plugin].\n\nAll val"
  },
  "4330": {
    "source_file": "syntax.txt",
    "text": " syntax on top of the Pipeline sub-systems.\nIn order to use them, install the plugin:pipeline-model-definition[Pipeline: Declarative Plugin].\n\nAll valid Declarative Pipelines must be enclosed within a `pipeline` block, for example:\n\n[.width-min]\n\npipeline {\n    /* insert Declarative Pipeline here */\n}\n\nThe basic statements and expressions which are valid in Declarative Pipeline follow the same rul"
  },
  "4331": {
    "source_file": "syntax.txt",
    "text": "eline {\n    /* insert Declarative Pipeline here */\n}\n\nThe basic statements and expressions which are valid in Declarative Pipeline follow the same rules as  with the following exceptions:\n\n* The top-level of the Pipeline must be a _block_, specifically: `pipeline { }`.\n* No semicolons as statement separators.\nEach statement has to be on its own line.\n* Blocks must only consist of <<declarative-sec"
  },
  "4332": {
    "source_file": "syntax.txt",
    "text": "ly: `pipeline { }`.\n* No semicolons as statement separators.\nEach statement has to be on its own line.\n* Blocks must only consist of <<declarative-sections>>, <<declarative-directives>>, <<declarative-steps>>, or assignment statements.\n* A property reference statement is treated as a no-argument method invocation.\nSo, for example, `input` is treated as `input()`.\n\nYou can use the  to help you get "
  },
  "4333": {
    "source_file": "syntax.txt",
    "text": "eference statement is treated as a no-argument method invocation.\nSo, for example, `input` is treated as `input()`.\n\nYou can use the  to help you get started with configuring the directives and sections in your Declarative Pipeline.\n\nThere is currently an   which limits the maximum size of the code within the `pipeline{}` block.\nThis limitation does not apply to Scripted Pipelines.\n\n[[declarative-"
  },
  "4334": {
    "source_file": "syntax.txt",
    "text": "ly an   which limits the maximum size of the code within the `pipeline{}` block.\nThis limitation does not apply to Scripted Pipelines.\n\n[[declarative-sections]]\n\nSections in Declarative Pipeline typically contain one or more <<declarative-directives>> or <<declarative-steps>>.\n\nThe `agent` section specifies where the entire Pipeline, or a specific stage, will execute in the Jenkins environment dep"
  },
  "4335": {
    "source_file": "syntax.txt",
    "text": "> or <<declarative-steps>>.\n\nThe `agent` section specifies where the entire Pipeline, or a specific stage, will execute in the Jenkins environment depending on where the `agent` section is placed.\nThe section must be defined at the top-level inside the `pipeline` block, but stage-level usage is optional.\n\n[cols=\"^10h,>90a\",role=syntax]\n|===\n| Required\n| Yes\n\n| Parameters\n| <<agent-parameters, Desc"
  },
  "4336": {
    "source_file": "syntax.txt",
    "text": "he `pipeline` block, but stage-level usage is optional.\n\n[cols=\"^10h,>90a\",role=syntax]\n|===\n| Required\n| Yes\n\n| Parameters\n| <<agent-parameters, Described below>>\n\n| Allowed\n| In the top-level `pipeline` block and each `stage` block.\n|===\n\n[[differences-between-top-and-stage-level]]\n\nThere are some nuances when adding an agent to the top level or a stage level when the `options` directive is appl"
  },
  "4337": {
    "source_file": "syntax.txt",
    "text": "nces-between-top-and-stage-level]]\n\nThere are some nuances when adding an agent to the top level or a stage level when the `options` directive is applied.\nCheck the section  for more information.\n\n[[top-level-agents]]\n\nIn `agents` declared at the top level of a Pipeline, an agent is allocated and then the `timeout` option is applied.\nThe time to allocate the agent *is not included* in the limit se"
  },
  "4338": {
    "source_file": "syntax.txt",
    "text": " level of a Pipeline, an agent is allocated and then the `timeout` option is applied.\nThe time to allocate the agent *is not included* in the limit set by the `timeout` option.\n\npipeline {\n    agent any\n    options {\n        // Timeout counter starts AFTER agent is allocated\n        timeout(time: 1, unit: 'SECONDS')\n    }\n    stages {\n        stage('Example') {\n            steps {\n                "
  },
  "4339": {
    "source_file": "syntax.txt",
    "text": " AFTER agent is allocated\n        timeout(time: 1, unit: 'SECONDS')\n    }\n    stages {\n        stage('Example') {\n            steps {\n                echo 'Hello World'\n            }\n        }\n    }\n}\n\n[[stage-level-agents]]\n\nIn `agents` declared within a stage, the options are invoked *before* allocating the `agent` and *before* checking any `when` conditions.\nIn this case, when using `timeout`, "
  },
  "4340": {
    "source_file": "syntax.txt",
    "text": "hin a stage, the options are invoked *before* allocating the `agent` and *before* checking any `when` conditions.\nIn this case, when using `timeout`, it is applied *before* the `agent` is allocated.\nThe time to allocate the agent *is included* in the limit set by the `timeout` option.\n\npipeline {\n    agent none\n    stages {\n        stage('Example') {\n            agent any\n            options {\n   "
  },
  "4341": {
    "source_file": "syntax.txt",
    "text": " limit set by the `timeout` option.\n\npipeline {\n    agent none\n    stages {\n        stage('Example') {\n            agent any\n            options {\n                // Timeout counter starts BEFORE agent is allocated\n                timeout(time: 1, unit: 'SECONDS')\n            }\n            steps {\n                echo 'Hello World'\n            }\n        }\n    }\n}\n\nThis timeout will include the age"
  },
  "4342": {
    "source_file": "syntax.txt",
    "text": "it: 'SECONDS')\n            }\n            steps {\n                echo 'Hello World'\n            }\n        }\n    }\n}\n\nThis timeout will include the agent provisioning time.\nBecause the timeout includes the agent provisioning time, the Pipeline may fail in cases where agent allocation is delayed.\n\n[[agent-parameters]]\n\nIn order to support the wide variety of use-cases Pipeline authors may have, the "
  },
  "4343": {
    "source_file": "syntax.txt",
    "text": "l in cases where agent allocation is delayed.\n\n[[agent-parameters]]\n\nIn order to support the wide variety of use-cases Pipeline authors may have, the `agent` section supports a few different types of parameters.\nThese parameters can be applied at the top-level of the `pipeline` block, or within each `stage` directive.\n\nany:: Execute the Pipeline, or stage, on any available agent.\nFor example: `age"
  },
  "4344": {
    "source_file": "syntax.txt",
    "text": " top-level of the `pipeline` block, or within each `stage` directive.\n\nany:: Execute the Pipeline, or stage, on any available agent.\nFor example: `agent any`\n\nnone:: When applied at the top-level of the `pipeline` block no global agent will be allocated for the entire Pipeline run and each `stage` section will need to contain its own `agent` section.\nFor example: `agent none`\n\nlabel:: Execute the "
  },
  "4345": {
    "source_file": "syntax.txt",
    "text": "ted for the entire Pipeline run and each `stage` section will need to contain its own `agent` section.\nFor example: `agent none`\n\nlabel:: Execute the Pipeline, or stage, on an agent available in the Jenkins environment with the provided label.\nFor example: `agent { label 'my-defined-label' }`\nLabel conditions can also be used:\nFor example: `agent { label 'my-label1 && my-label2' }` or `agent { lab"
  },
  "4346": {
    "source_file": "syntax.txt",
    "text": "ample: `agent { label 'my-defined-label' }`\nLabel conditions can also be used:\nFor example: `agent { label 'my-label1 && my-label2' }` or `agent { label 'my-label1 || my-label2' }`\n\nnode:: `agent { node { label 'labelName' } }` behaves the same as `agent { label 'labelName' }`, but `node` allows for additional options (such as `customWorkspace`).\n\ndocker:: Execute the Pipeline, or stage, with the "
  },
  "4347": {
    "source_file": "syntax.txt",
    "text": "gent { label 'labelName' }`, but `node` allows for additional options (such as `customWorkspace`).\n\ndocker:: Execute the Pipeline, or stage, with the given container which will be dynamically provisioned on a <<../glossary#node, node>> pre-configured to accept Docker-based Pipelines, or on a node matching the optionally defined `label` parameter.\n`docker` also optionally accepts an `args` paramete"
  },
  "4348": {
    "source_file": "syntax.txt",
    "text": " to accept Docker-based Pipelines, or on a node matching the optionally defined `label` parameter.\n`docker` also optionally accepts an `args` parameter which may contain arguments to pass directly to a `docker run` invocation, and an `alwaysPull` option, which will force a `docker pull` even if the image name is already present.\nFor example: `agent { docker 'maven:3.9.3-eclipse-temurin-17' }` or\na"
  },
  "4349": {
    "source_file": "syntax.txt",
    "text": "ion, which will force a `docker pull` even if the image name is already present.\nFor example: `agent { docker 'maven:3.9.3-eclipse-temurin-17' }` or\nagent {\n    docker {\n        image 'maven:3.9.3-eclipse-temurin-17'\n        label 'my-defined-label'\n        args  '-v /tmp:/tmp'\n    }\n}\n\n`docker` also optionally accepts a `registryUrl` and `registryCredentialsId` parameters which will help to speci"
  },
  "4350": {
    "source_file": "syntax.txt",
    "text": "        args  '-v /tmp:/tmp'\n    }\n}\n\n`docker` also optionally accepts a `registryUrl` and `registryCredentialsId` parameters which will help to specify the Docker Registry to use and its credentials.\nThe parameter `registryCredentialsId` could be used alone for private repositories within the docker hub.\nFor example:\nagent {\n    docker {\n        image 'myregistry.com/node'\n        label 'my-defin"
  },
  "4351": {
    "source_file": "syntax.txt",
    "text": "ed alone for private repositories within the docker hub.\nFor example:\nagent {\n    docker {\n        image 'myregistry.com/node'\n        label 'my-defined-label'\n        registryUrl 'https://myregistry.com/'\n        registryCredentialsId 'myPredefinedCredentialsInJenkins'\n    }\n}\n\ndockerfile:: Execute the Pipeline, or stage, with a container built from a `Dockerfile` contained in the source reposito"
  },
  "4352": {
    "source_file": "syntax.txt",
    "text": "redentialsInJenkins'\n    }\n}\n\ndockerfile:: Execute the Pipeline, or stage, with a container built from a `Dockerfile` contained in the source repository.\nIn order to use this option, the `Jenkinsfile` must be loaded from either a *Multibranch Pipeline* or a *Pipeline from SCM*.\nConventionally this is the `Dockerfile` in the root of the source repository: `agent { dockerfile true }`.\nIf building a "
  },
  "4353": {
    "source_file": "syntax.txt",
    "text": "e* or a *Pipeline from SCM*.\nConventionally this is the `Dockerfile` in the root of the source repository: `agent { dockerfile true }`.\nIf building a `Dockerfile` in another directory, use the `dir` option: `agent { dockerfile { dir 'someSubDir' } }`.\nIf your `Dockerfile` has another name, you can specify the file name with the `filename` option. You can pass additional arguments to the `docker bu"
  },
  "4354": {
    "source_file": "syntax.txt",
    "text": ".\nIf your `Dockerfile` has another name, you can specify the file name with the `filename` option. You can pass additional arguments to the `docker build ...` command with the `additionalBuildArgs` option, like `agent { dockerfile { additionalBuildArgs '--build-arg foo=bar' } }`.\nFor example, a repository with the file `build/Dockerfile.build`, expecting a build argument `version`:\nagent {\n    // "
  },
  "4355": {
    "source_file": "syntax.txt",
    "text": "gs '--build-arg foo=bar' } }`.\nFor example, a repository with the file `build/Dockerfile.build`, expecting a build argument `version`:\nagent {\n    // Equivalent to \"docker build -f Dockerfile.build --build-arg version=1.0.2 ./build/\n    dockerfile {\n        filename 'Dockerfile.build'\n        dir 'build'\n        label 'my-defined-label'\n        additionalBuildArgs  '--build-arg version=1.0.2'\n    "
  },
  "4356": {
    "source_file": "syntax.txt",
    "text": "        filename 'Dockerfile.build'\n        dir 'build'\n        label 'my-defined-label'\n        additionalBuildArgs  '--build-arg version=1.0.2'\n        args '-v /tmp:/tmp'\n    }\n}\n\n`dockerfile` also optionally accepts a `registryUrl` and `registryCredentialsId` parameters which will help to specify the Docker Registry to use and its credentials.\nFor example:\nagent {\n    dockerfile {\n        file"
  },
  "4357": {
    "source_file": "syntax.txt",
    "text": "redentialsId` parameters which will help to specify the Docker Registry to use and its credentials.\nFor example:\nagent {\n    dockerfile {\n        filename 'Dockerfile.build'\n        dir 'build'\n        label 'my-defined-label'\n        registryUrl 'https://myregistry.com/'\n        registryCredentialsId 'myPredefinedCredentialsInJenkins'\n    }\n}\n\nkubernetes:: Execute the Pipeline, or stage, inside a"
  },
  "4358": {
    "source_file": "syntax.txt",
    "text": "tps://myregistry.com/'\n        registryCredentialsId 'myPredefinedCredentialsInJenkins'\n    }\n}\n\nkubernetes:: Execute the Pipeline, or stage, inside a pod deployed on a Kubernetes cluster.\nIn order to use this option, the `Jenkinsfile` must be loaded from either a *Multibranch Pipeline* or a *Pipeline from SCM*.\nThe Pod template is defined inside the kubernetes { } block.\nFor example, if you want "
  },
  "4359": {
    "source_file": "syntax.txt",
    "text": " from either a *Multibranch Pipeline* or a *Pipeline from SCM*.\nThe Pod template is defined inside the kubernetes { } block.\nFor example, if you want a pod with a Kaniko container inside it, you would define it as follows:\nagent {\n    kubernetes {\n        defaultContainer 'kaniko'\n        yaml '''\nkind: Pod\nspec:\n  containers:\n  - name: kaniko\n    image: gcr.io/kaniko-project/executor:debug\n    im"
  },
  "4360": {
    "source_file": "syntax.txt",
    "text": "      defaultContainer 'kaniko'\n        yaml '''\nkind: Pod\nspec:\n  containers:\n  - name: kaniko\n    image: gcr.io/kaniko-project/executor:debug\n    imagePullPolicy: Always\n    command:\n    - sleep\n    args:\n    - 99d\n    volumeMounts:\n      - name: aws-secret\n        mountPath: /root/.aws/\n      - name: docker-registry-config\n        mountPath: /kaniko/.docker\n  volumes:\n    - name: aws-secret\n   "
  },
  "4361": {
    "source_file": "syntax.txt",
    "text": "ws-secret\n        mountPath: /root/.aws/\n      - name: docker-registry-config\n        mountPath: /kaniko/.docker\n  volumes:\n    - name: aws-secret\n      secret:\n        secretName: aws-secret\n    - name: docker-registry-config\n      configMap:\n        name: docker-registry-config\n'''\n   }\n\nYou will need to create a secret `aws-secret` for Kaniko to be able to authenticate with ECR.\nThis secret sho"
  },
  "4362": {
    "source_file": "syntax.txt",
    "text": "  name: docker-registry-config\n'''\n   }\n\nYou will need to create a secret `aws-secret` for Kaniko to be able to authenticate with ECR.\nThis secret should contain the contents of `~/.aws/credentials`.\nThe other volume is a ConfigMap which should contain the endpoint of your ECR registry.\nFor example:\n{\n      \"credHelpers\": {\n        \"<your-aws-account-id>.dkr.ecr.eu-central-1.amazonaws.com\": \"ecr-l"
  },
  "4363": {
    "source_file": "syntax.txt",
    "text": "in the endpoint of your ECR registry.\nFor example:\n{\n      \"credHelpers\": {\n        \"<your-aws-account-id>.dkr.ecr.eu-central-1.amazonaws.com\": \"ecr-login\"\n      }\n}\n\nRefer to the following example for reference: https://github.com/jenkinsci/kubernetes-plugin/blob/master/examples/kaniko.groovy\n\nThese are a few options that can be applied to two or more `agent` implementations.\nThey are not require"
  },
  "4364": {
    "source_file": "syntax.txt",
    "text": "es-plugin/blob/master/examples/kaniko.groovy\n\nThese are a few options that can be applied to two or more `agent` implementations.\nThey are not required unless explicitly stated.\n\nlabel:: A string.\nThe label or label condition on which to run the Pipeline or individual `stage`.\nThis option is valid for `node`, `docker`, and `dockerfile`, and is required for `node`.\n\ncustomWorkspace:: A string.\nRun "
  },
  "4365": {
    "source_file": "syntax.txt",
    "text": "line or individual `stage`.\nThis option is valid for `node`, `docker`, and `dockerfile`, and is required for `node`.\n\ncustomWorkspace:: A string.\nRun the Pipeline or individual `stage` this `agent` is applied to within this custom workspace, rather than the default.\nIt can be either a relative path, in which case the custom workspace will be under the workspace root on the node, or an absolute pat"
  },
  "4366": {
    "source_file": "syntax.txt",
    "text": "han the default.\nIt can be either a relative path, in which case the custom workspace will be under the workspace root on the node, or an absolute path.\nFor example:\nagent {\n    node {\n        label 'my-defined-label'\n        customWorkspace '/some/other/path'\n    }\n}\n\nThis option is valid for `node`, `docker`, and `dockerfile`.\n\nreuseNode:: A boolean, false by default.\nIf true, run the container "
  },
  "4367": {
    "source_file": "syntax.txt",
    "text": "ther/path'\n    }\n}\n\nThis option is valid for `node`, `docker`, and `dockerfile`.\n\nreuseNode:: A boolean, false by default.\nIf true, run the container on the node specified at the top-level of the Pipeline, in the same workspace, rather than on a new node entirely.\nThis option is valid for `docker` and `dockerfile`, and only has an effect when used on an `agent` for an individual `stage`.\n\nargs:: A"
  },
  "4368": {
    "source_file": "syntax.txt",
    "text": "node entirely.\nThis option is valid for `docker` and `dockerfile`, and only has an effect when used on an `agent` for an individual `stage`.\n\nargs:: A string.\nRuntime arguments to pass to `docker run`.\nThis option is valid for `docker` and `dockerfile`.\n\n[[agent-example]]\n.Docker Agent, Declarative Pipeline\n=====\n\npipeline {\n    agent { docker 'maven:3.9.3-eclipse-temurin-17' } // <1> stages {\n   "
  },
  "4369": {
    "source_file": "syntax.txt",
    "text": "e`.\n\n[[agent-example]]\n.Docker Agent, Declarative Pipeline\n=====\n\npipeline {\n    agent { docker 'maven:3.9.3-eclipse-temurin-17' } // <1> stages {\n        stage('Example Build') {\n            steps {\n                sh 'mvn -B clean verify'\n            }\n        }\n    }\n}\n\n<1> Execute all the steps defined in this Pipeline within a newly created container of the given name and tag (`maven:3.9.3-ec"
  },
  "4370": {
    "source_file": "syntax.txt",
    "text": "   }\n        }\n    }\n}\n\n<1> Execute all the steps defined in this Pipeline within a newly created container of the given name and tag (`maven:3.9.3-eclipse-temurin-17`).\n=====\n\n.Stage-level Agent Section\n=====\n\npipeline {\n    agent none // <1> stages {\n        stage('Example Build') {\n            agent { docker 'maven:3.9.9-eclipse-temurin-21' } // <2> steps {\n                echo 'Hello, Maven'\n "
  },
  "4371": {
    "source_file": "syntax.txt",
    "text": " {\n        stage('Example Build') {\n            agent { docker 'maven:3.9.9-eclipse-temurin-21' } // <2> steps {\n                echo 'Hello, Maven'\n                sh 'mvn --version'\n            }\n        }\n        stage('Example Test') {\n            agent { docker 'openjdk:21-jre' } // <3> steps {\n                echo 'Hello, JDK'\n                sh 'java -version'\n            }\n        }\n    }\n"
  },
  "4372": {
    "source_file": "syntax.txt",
    "text": "  agent { docker 'openjdk:21-jre' } // <3> steps {\n                echo 'Hello, JDK'\n                sh 'java -version'\n            }\n        }\n    }\n}\n\n<1> Defining `agent none` at the top-level of the Pipeline ensures that <<../glossary#executor, an Executor>> will not be assigned unnecessarily.\nUsing `agent none` also forces each `stage` section to contain its own `agent` section.\n<2> Execute t"
  },
  "4373": {
    "source_file": "syntax.txt",
    "text": "n Executor>> will not be assigned unnecessarily.\nUsing `agent none` also forces each `stage` section to contain its own `agent` section.\n<2> Execute the steps in this stage in a newly created container using this image.\n<3> Execute the steps in this stage in a newly created container using a different image from the previous stage.\n=====\n\nThe `post` section defines one or more additional <<declara"
  },
  "4374": {
    "source_file": "syntax.txt",
    "text": "stage in a newly created container using a different image from the previous stage.\n=====\n\nThe `post` section defines one or more additional <<declarative-steps,steps>> that are run upon the completion of a Pipeline's or stage's run (depending on the location of the `post` section within the Pipeline). `post` can support any of the following <<post-conditions, post-condition>> blocks: `always`, `c"
  },
  "4375": {
    "source_file": "syntax.txt",
    "text": " location of the `post` section within the Pipeline). `post` can support any of the following <<post-conditions, post-condition>> blocks: `always`, `changed`, `fixed`, `regression`, `aborted`, `failure`, `success`, `unstable`, `unsuccessful`, and `cleanup`.\nThese condition blocks allow the execution of steps inside each condition depending on the completion status of the Pipeline or stage.\nThe con"
  },
  "4376": {
    "source_file": "syntax.txt",
    "text": "eanup`.\nThese condition blocks allow the execution of steps inside each condition depending on the completion status of the Pipeline or stage.\nThe condition blocks are executed in the order shown below.\n\n[cols=\"^10h,>90a\",role=syntax]\n|===\n| Required\n| No\n\n| Parameters\n| _None_\n\n| Allowed\n| In the top-level `pipeline` block and each `stage` block.\n|===\n\n[[post-conditions]]\n\n`always`:: Run the step"
  },
  "4377": {
    "source_file": "syntax.txt",
    "text": "\n| No\n\n| Parameters\n| _None_\n\n| Allowed\n| In the top-level `pipeline` block and each `stage` block.\n|===\n\n[[post-conditions]]\n\n`always`:: Run the steps in the `post` section regardless of the completion status of the Pipeline's or stage's run.\n`changed`:: Only run the steps in `post` if the current Pipeline's run has a different completion status from its previous run.\n`fixed`:: Only run the steps"
  },
  "4378": {
    "source_file": "syntax.txt",
    "text": "ed`:: Only run the steps in `post` if the current Pipeline's run has a different completion status from its previous run.\n`fixed`:: Only run the steps in `post` if the current Pipeline's run is successful and the previous run failed or was unstable.\n`regression`:: Only run the steps in `post` if the current Pipeline's or status is failure, unstable, or aborted and the previous run was successful.\n"
  },
  "4379": {
    "source_file": "syntax.txt",
    "text": "`regression`:: Only run the steps in `post` if the current Pipeline's or status is failure, unstable, or aborted and the previous run was successful.\n`aborted`:: Only run the steps in `post` if the current Pipeline's run has an \"aborted\" status, usually due to the Pipeline being manually aborted.\nThis is typically denoted by gray in the web UI.\n`failure`:: Only run the steps in `post` if the curre"
  },
  "4380": {
    "source_file": "syntax.txt",
    "text": "lly due to the Pipeline being manually aborted.\nThis is typically denoted by gray in the web UI.\n`failure`:: Only run the steps in `post` if the current Pipeline's or stage's run has a \"failed\" status, typically denoted by red in the web UI.\n`success`:: Only run the steps in `post` if the current Pipeline's or stage's run has a \"success\" status, typically denoted by blue or green in the web UI.\n`u"
  },
  "4381": {
    "source_file": "syntax.txt",
    "text": "`:: Only run the steps in `post` if the current Pipeline's or stage's run has a \"success\" status, typically denoted by blue or green in the web UI.\n`unstable`:: Only run the steps in `post` if the current Pipeline's run has an \"unstable\" status, usually caused by test failures, code violations, etc.\nThis is typically denoted by yellow in the web UI.\n`unsuccessful`:: Only run the steps in `post` if"
  },
  "4382": {
    "source_file": "syntax.txt",
    "text": "lly caused by test failures, code violations, etc.\nThis is typically denoted by yellow in the web UI.\n`unsuccessful`:: Only run the steps in `post` if the current Pipeline's or stage's run has not a \"success\" status.\nThis is typically denoted in the web UI depending on the status previously mentioned (for stages this may fire if the build itself is unstable).\n`cleanup`:: Run the steps in this `pos"
  },
  "4383": {
    "source_file": "syntax.txt",
    "text": "web UI depending on the status previously mentioned (for stages this may fire if the build itself is unstable).\n`cleanup`:: Run the steps in this `post` condition after every other `post` condition has been evaluated, regardless of the Pipeline or stage's status.\n\n[[post-example]]\n.Post Section, Declarative Pipeline\n=====\n\npipeline {\n    agent any\n    stages {\n        stage('Example') {\n          "
  },
  "4384": {
    "source_file": "syntax.txt",
    "text": "age's status.\n\n[[post-example]]\n.Post Section, Declarative Pipeline\n=====\n\npipeline {\n    agent any\n    stages {\n        stage('Example') {\n            steps {\n                echo 'Hello World'\n            }\n        }\n    }\n    post { // <1> always { // <2> echo 'I will always say Hello again!'\n        }\n    }\n}\n\n<1> Conventionally, the `post` section should be placed at the end of the Pipeline.\n"
  },
  "4385": {
    "source_file": "syntax.txt",
    "text": "{ // <2> echo 'I will always say Hello again!'\n        }\n    }\n}\n\n<1> Conventionally, the `post` section should be placed at the end of the Pipeline.\n<2> <<post-conditions, Post-condition>> blocks contain <<declarative-steps, steps>> the same as the <<steps>> section.\n=====\n\nContaining a sequence of one or more <<stage>> directives, the `stages` section is where the bulk of the \"work\" described by"
  },
  "4386": {
    "source_file": "syntax.txt",
    "text": "<<steps>> section.\n=====\n\nContaining a sequence of one or more <<stage>> directives, the `stages` section is where the bulk of the \"work\" described by a Pipeline will be located.\nAt a minimum, it is recommended that `stages` contain at least one <<stage>> directive for each discrete part of the continuous delivery process, such as Build, Test, and Deploy.\n\n[cols=\"^10h,>90a\",role=syntax]\n|===\n| Req"
  },
  "4387": {
    "source_file": "syntax.txt",
    "text": "age>> directive for each discrete part of the continuous delivery process, such as Build, Test, and Deploy.\n\n[cols=\"^10h,>90a\",role=syntax]\n|===\n| Required\n| Yes\n\n| Parameters\n| _None_\n\n| Allowed\n| Inside the `pipeline` block, or within a `stage`.\n|===\n\n[[stages-example]]\n.Stages, Declarative Pipeline\n=====\n\npipeline {\n    agent any\n    stages { // <1> stage('Example') {\n            steps {\n      "
  },
  "4388": {
    "source_file": "syntax.txt",
    "text": "==\n\n[[stages-example]]\n.Stages, Declarative Pipeline\n=====\n\npipeline {\n    agent any\n    stages { // <1> stage('Example') {\n            steps {\n                echo 'Hello World'\n            }\n        }\n    }\n}\n\n=====\n<1> The `stages` section will typically follow the directives such as `agent`, `options`, etc.\n\nThe `steps` section defines a series of one or more <<declarative-steps, steps>> to be"
  },
  "4389": {
    "source_file": "syntax.txt",
    "text": "pically follow the directives such as `agent`, `options`, etc.\n\nThe `steps` section defines a series of one or more <<declarative-steps, steps>> to be executed in a given `stage` directive.\n\n[cols=\"^10h,>90a\",role=syntax]\n|===\n| Required\n| Yes\n\n| Parameters\n| _None_\n\n| Allowed\n| Inside each `stage` block.\n|===\n\n[[steps-example]]\n.Single Step, Declarative Pipeline\n=====\n\npipeline {\n    agent any\n  "
  },
  "4390": {
    "source_file": "syntax.txt",
    "text": "ameters\n| _None_\n\n| Allowed\n| Inside each `stage` block.\n|===\n\n[[steps-example]]\n.Single Step, Declarative Pipeline\n=====\n\npipeline {\n    agent any\n    stages {\n        stage('Example') {\n            steps { // <1> echo 'Hello World'\n            }\n        }\n    }\n}\n\n<1> The `steps` section must contain one or more steps.\n=====\n\n[[declarative-directives]]\n\nThe `environment` directive specifies a se"
  },
  "4391": {
    "source_file": "syntax.txt",
    "text": "      }\n    }\n}\n\n<1> The `steps` section must contain one or more steps.\n=====\n\n[[declarative-directives]]\n\nThe `environment` directive specifies a sequence of key-value pairs which will be defined as environment variables for all steps, or stage-specific steps, depending on where the `environment` directive is located within the Pipeline.\n\nThis directive supports a special helper method `credenti"
  },
  "4392": {
    "source_file": "syntax.txt",
    "text": "cific steps, depending on where the `environment` directive is located within the Pipeline.\n\nThis directive supports a special helper method `credentials()` which can be used to access pre-defined Credentials by their identifier in the Jenkins environment.\n\n[cols=\"^10h,>90a\",role=syntax]\n|===\n| Required\n| No\n\n| Parameters\n| _None_\n\n| Allowed\n| Inside the `pipeline` block, or within `stage` directi"
  },
  "4393": {
    "source_file": "syntax.txt",
    "text": "nment.\n\n[cols=\"^10h,>90a\",role=syntax]\n|===\n| Required\n| No\n\n| Parameters\n| _None_\n\n| Allowed\n| Inside the `pipeline` block, or within `stage` directives.\n|===\n\nSecret Text::\nThe environment variable specified will be set to the Secret Text content.\nSecret File::\nThe environment variable specified will be set to the location of the File file that is temporarily created.\nUsername and password::\nThe"
  },
  "4394": {
    "source_file": "syntax.txt",
    "text": "Secret File::\nThe environment variable specified will be set to the location of the File file that is temporarily created.\nUsername and password::\nThe environment variable specified will be set to `username:password` and two additional environment variables will be automatically defined: `MYVARNAME_USR` and `MYVARNAME_PSW` respectively.\nSSH with Private Key::\nThe environment variable specified wil"
  },
  "4395": {
    "source_file": "syntax.txt",
    "text": "riables will be automatically defined: `MYVARNAME_USR` and `MYVARNAME_PSW` respectively.\nSSH with Private Key::\nThe environment variable specified will be set to the location of the SSH key file that is temporarily created and two additional environment variables will be automatically defined: `MYVARNAME_USR` and `MYVARNAME_PSW` (holding the passphrase).\n\nUnsupported credentials type causes the pi"
  },
  "4396": {
    "source_file": "syntax.txt",
    "text": "ent variables will be automatically defined: `MYVARNAME_USR` and `MYVARNAME_PSW` (holding the passphrase).\n\nUnsupported credentials type causes the pipeline to fail with the message: `org.jenkinsci.plugins.credentialsbinding.impl.CredentialNotFoundException: No suitable binding handler could be found for type <unsupportedType>.`\n\n[[environment-example]]\n.Secret Text Credentials, Declarative Pipeli"
  },
  "4397": {
    "source_file": "syntax.txt",
    "text": "ception: No suitable binding handler could be found for type <unsupportedType>.`\n\n[[environment-example]]\n.Secret Text Credentials, Declarative Pipeline\n=====\n\npipeline {\n    agent any\n    environment { // <1> CC = 'clang'\n    }\n    stages {\n        stage('Example') {\n            environment { // <2> AN_ACCESS_KEY = credentials('my-predefined-secret-text') // <3> }\n            steps {\n            "
  },
  "4398": {
    "source_file": "syntax.txt",
    "text": "stage('Example') {\n            environment { // <2> AN_ACCESS_KEY = credentials('my-predefined-secret-text') // <3> }\n            steps {\n                sh 'printenv'\n            }\n        }\n    }\n}\n\n<1> An `environment` directive used in the top-level `pipeline` block will apply to all steps within the Pipeline.\n<2> An `environment` directive defined within a `stage` will only apply the given en"
  },
  "4399": {
    "source_file": "syntax.txt",
    "text": "vel `pipeline` block will apply to all steps within the Pipeline.\n<2> An `environment` directive defined within a `stage` will only apply the given environment variables to steps within the `stage`.\n<3> The `environment` block has a helper method `credentials()` defined which can be used to access pre-defined Credentials by their identifier in the Jenkins environment.\n=====\n\n.Username and Password"
  },
  "4400": {
    "source_file": "syntax.txt",
    "text": "edentials()` defined which can be used to access pre-defined Credentials by their identifier in the Jenkins environment.\n=====\n\n.Username and Password Credentials\n=====\n\npipeline {\n    agent any\n    stages {\n        stage('Example Username/Password') {\n            environment {\n                SERVICE_CREDS = credentials('my-predefined-username-password')\n            }\n            steps {\n        "
  },
  "4401": {
    "source_file": "syntax.txt",
    "text": " {\n            environment {\n                SERVICE_CREDS = credentials('my-predefined-username-password')\n            }\n            steps {\n                sh 'echo \"Service user is $SERVICE_CREDS_USR\"'\n                sh 'echo \"Service password is $SERVICE_CREDS_PSW\"'\n                sh 'curl -u $SERVICE_CREDS https://myservice.example.com'\n            }\n        }\n        stage('Example SSH Use"
  },
  "4402": {
    "source_file": "syntax.txt",
    "text": " $SERVICE_CREDS_PSW\"'\n                sh 'curl -u $SERVICE_CREDS https://myservice.example.com'\n            }\n        }\n        stage('Example SSH Username with private key') {\n            environment {\n                SSH_CREDS = credentials('my-predefined-ssh-creds')\n            }\n            steps {\n                sh 'echo \"SSH private key is located at $SSH_CREDS\"'\n                sh 'echo \"S"
  },
  "4403": {
    "source_file": "syntax.txt",
    "text": "defined-ssh-creds')\n            }\n            steps {\n                sh 'echo \"SSH private key is located at $SSH_CREDS\"'\n                sh 'echo \"SSH user is $SSH_CREDS_USR\"'\n                sh 'echo \"SSH passphrase is $SSH_CREDS_PSW\"'\n            }\n        }\n    }\n}\n\n=====\n\nThe `options` directive allows configuring Pipeline-specific options from within the Pipeline itself.\nPipeline provides a"
  },
  "4404": {
    "source_file": "syntax.txt",
    "text": " }\n        }\n    }\n}\n\n=====\n\nThe `options` directive allows configuring Pipeline-specific options from within the Pipeline itself.\nPipeline provides a number of these options, such as `buildDiscarder`, but they may also be provided by plugins, such as `timestamps`.\n\n[cols=\"^10h,>90a\",role=syntax]\n|===\n| Required\n| No\n\n| Parameters\n| _None_\n\n| Allowed\n| Inside the `pipeline` block, or (with certain"
  },
  "4405": {
    "source_file": "syntax.txt",
    "text": "s `timestamps`.\n\n[cols=\"^10h,>90a\",role=syntax]\n|===\n| Required\n| No\n\n| Parameters\n| _None_\n\n| Allowed\n| Inside the `pipeline` block, or (with certain limitations) within `stage` directives.\n|===\n\nbuildDiscarder:: Persist artifacts and console output for the specific number of recent Pipeline runs.\nFor example: `options { buildDiscarder(logRotator(numToKeepStr: '1')) }`\n\ncheckoutToSubdirectory:: P"
  },
  "4406": {
    "source_file": "syntax.txt",
    "text": " for the specific number of recent Pipeline runs.\nFor example: `options { buildDiscarder(logRotator(numToKeepStr: '1')) }`\n\ncheckoutToSubdirectory:: Perform the automatic source control checkout in a subdirectory of the workspace.\nFor example: `options { checkoutToSubdirectory('foo') }`\n\ndisableConcurrentBuilds:: Disallow concurrent executions of the Pipeline.\nCan be useful for preventing simultan"
  },
  "4407": {
    "source_file": "syntax.txt",
    "text": "ns { checkoutToSubdirectory('foo') }`\n\ndisableConcurrentBuilds:: Disallow concurrent executions of the Pipeline.\nCan be useful for preventing simultaneous accesses to shared resources, etc.\nFor example: `options { disableConcurrentBuilds() }` to queue a build when there's already an executing build of the Pipeline, or `options { disableConcurrentBuilds(abortPrevious: true) }` to abort the running "
  },
  "4408": {
    "source_file": "syntax.txt",
    "text": "e a build when there's already an executing build of the Pipeline, or `options { disableConcurrentBuilds(abortPrevious: true) }` to abort the running one and start the new build.\n\ndisableResume:: Do not allow the pipeline to resume if the controller restarts.\nFor example: `options { disableResume() }`\n\nnewContainerPerStage:: Used with `docker` or `dockerfile` top-level agent.\nWhen specified, each "
  },
  "4409": {
    "source_file": "syntax.txt",
    "text": "restarts.\nFor example: `options { disableResume() }`\n\nnewContainerPerStage:: Used with `docker` or `dockerfile` top-level agent.\nWhen specified, each stage will run in a new container deployed on the same node, rather than all stages running in the same container deployment.\n\noverrideIndexTriggers:: Allows overriding default treatment of branch indexing triggers.\nIf branch indexing triggers are di"
  },
  "4410": {
    "source_file": "syntax.txt",
    "text": "ame container deployment.\n\noverrideIndexTriggers:: Allows overriding default treatment of branch indexing triggers.\nIf branch indexing triggers are disabled at the multibranch or organization label, `options { overrideIndexTriggers(true) }` will enable them for this job only.\nOtherwise, `options { overrideIndexTriggers(false) }` will disable branch indexing triggers for this job only.\n\npreserveSta"
  },
  "4411": {
    "source_file": "syntax.txt",
    "text": "le them for this job only.\nOtherwise, `options { overrideIndexTriggers(false) }` will disable branch indexing triggers for this job only.\n\npreserveStashes:: Preserve stashes from completed builds, for use with stage restarting.\nFor example: `options { preserveStashes() }` to preserve the stashes from the most recent completed build, or `options { preserveStashes(buildCount: 5) }` to preserve the s"
  },
  "4412": {
    "source_file": "syntax.txt",
    "text": "{ preserveStashes() }` to preserve the stashes from the most recent completed build, or `options { preserveStashes(buildCount: 5) }` to preserve the stashes from the five most recent completed builds.\n\nquietPeriod:: Set the quiet period, in seconds, for the Pipeline, overriding the global default.\nFor example: `options { quietPeriod(30) }`\n\nretry:: On failure, retry the entire Pipeline the specifi"
  },
  "4413": {
    "source_file": "syntax.txt",
    "text": "for the Pipeline, overriding the global default.\nFor example: `options { quietPeriod(30) }`\n\nretry:: On failure, retry the entire Pipeline the specified number of times.\nFor example: `options { retry(3) }`\n\nskipDefaultCheckout:: Skip checking out code from source control by default in the `agent` directive.\nFor example: `options { skipDefaultCheckout() }`\n\nskipStagesAfterUnstable:: Skip stages onc"
  },
  "4414": {
    "source_file": "syntax.txt",
    "text": "e from source control by default in the `agent` directive.\nFor example: `options { skipDefaultCheckout() }`\n\nskipStagesAfterUnstable:: Skip stages once the build status has gone to UNSTABLE.\nFor example: `options { skipStagesAfterUnstable() }`\n\ntimeout:: Set a timeout period for the Pipeline run, after which Jenkins should abort the Pipeline.\nFor example: `options { timeout(time: 1, unit: 'HOURS')"
  },
  "4415": {
    "source_file": "syntax.txt",
    "text": "ut:: Set a timeout period for the Pipeline run, after which Jenkins should abort the Pipeline.\nFor example: `options { timeout(time: 1, unit: 'HOURS') }`\n\n[[options-example]]\n.Global Timeout, Declarative Pipeline\n\npipeline {\n    agent any\n    options {\n        timeout(time: 1, unit: 'HOURS') // <1> }\n    stages {\n        stage('Example') {\n            steps {\n                echo 'Hello World'\n   "
  },
  "4416": {
    "source_file": "syntax.txt",
    "text": " {\n        timeout(time: 1, unit: 'HOURS') // <1> }\n    stages {\n        stage('Example') {\n            steps {\n                echo 'Hello World'\n            }\n        }\n    }\n}\n\n<1> Specifying a global execution timeout of one hour, after which Jenkins will abort the Pipeline run.\n=====\n\ntimestamps:: Prepend all console output generated by the Pipeline run with the time at which the line was emi"
  },
  "4417": {
    "source_file": "syntax.txt",
    "text": "kins will abort the Pipeline run.\n=====\n\ntimestamps:: Prepend all console output generated by the Pipeline run with the time at which the line was emitted.\nFor example: `options { timestamps() }`\n\nparallelsAlwaysFailFast:: Set failfast true for all subsequent parallel stages in the pipeline.\nFor example: `options { parallelsAlwaysFailFast() }`\n\ndisableRestartFromStage:: Completely disable option \""
  },
  "4418": {
    "source_file": "syntax.txt",
    "text": "ubsequent parallel stages in the pipeline.\nFor example: `options { parallelsAlwaysFailFast() }`\n\ndisableRestartFromStage:: Completely disable option \"Restart From Stage\" visible in classic Jenkins UI and Blue Ocean as well.\nFor example: `options { disableRestartFromStage() }`.\nThis option can not be used inside of the stage.\n\nA comprehensive list of available options is pending the completion of ."
  },
  "4419": {
    "source_file": "syntax.txt",
    "text": "sableRestartFromStage() }`.\nThis option can not be used inside of the stage.\n\nA comprehensive list of available options is pending the completion of .\n\nThe `options` directive for a `stage` is similar to the `options` directive at the root of the Pipeline.\nHowever, the `stage`-level `options` can only contain steps like `retry`, `timeout`, or `timestamps`, or Declarative options that are relevant "
  },
  "4420": {
    "source_file": "syntax.txt",
    "text": "eline.\nHowever, the `stage`-level `options` can only contain steps like `retry`, `timeout`, or `timestamps`, or Declarative options that are relevant to a `stage`, like `skipDefaultCheckout`.\n\nInside a `stage`, the steps in the `options` directive are invoked before entering the `agent` or checking any `when` conditions.\n\nskipDefaultCheckout:: Skip checking out code from source control by default "
  },
  "4421": {
    "source_file": "syntax.txt",
    "text": "e invoked before entering the `agent` or checking any `when` conditions.\n\nskipDefaultCheckout:: Skip checking out code from source control by default in the `agent` directive.\nFor example: `options { skipDefaultCheckout() }`\n\ntimeout:: Set a timeout period for this stage, after which Jenkins should abort the stage.\nFor example: `options { timeout(time: 1, unit: 'HOURS') }`\n\n[[stage-options-example"
  },
  "4422": {
    "source_file": "syntax.txt",
    "text": "period for this stage, after which Jenkins should abort the stage.\nFor example: `options { timeout(time: 1, unit: 'HOURS') }`\n\n[[stage-options-example]]\n.Stage Timeout, Declarative Pipeline\n=====\n\npipeline {\n    agent any\n    stages {\n        stage('Example') {\n            options {\n                timeout(time: 1, unit: 'HOURS') // <1> }\n            steps {\n                echo 'Hello World'\n    "
  },
  "4423": {
    "source_file": "syntax.txt",
    "text": "Example') {\n            options {\n                timeout(time: 1, unit: 'HOURS') // <1> }\n            steps {\n                echo 'Hello World'\n            }\n        }\n    }\n}\n\n<1> Specifying an execution timeout of one hour for the `Example` stage, after which Jenkins will abort the Pipeline run.\n=====\n\nretry:: On failure, retry this stage the specified number of times.\nFor example: `options { "
  },
  "4424": {
    "source_file": "syntax.txt",
    "text": ", after which Jenkins will abort the Pipeline run.\n=====\n\nretry:: On failure, retry this stage the specified number of times.\nFor example: `options { retry(3) }`\n\ntimestamps:: Prepend all console output generated during this stage with the time at which the line was emitted.\nFor example: `options { timestamps() }`\n\nThe `parameters` directive provides a list of parameters that a user should provide"
  },
  "4425": {
    "source_file": "syntax.txt",
    "text": "ich the line was emitted.\nFor example: `options { timestamps() }`\n\nThe `parameters` directive provides a list of parameters that a user should provide when triggering the Pipeline.\nThe values for these user-specified parameters are made available to Pipeline steps via the `params` object, refer to the <<parameters-example>> for its specific usage.\n\nEach parameter has a _Name_ and _Value_, dependin"
  },
  "4426": {
    "source_file": "syntax.txt",
    "text": "Pipeline steps via the `params` object, refer to the <<parameters-example>> for its specific usage.\n\nEach parameter has a _Name_ and _Value_, depending on the parameter type.\nThis information is exported as environment variables when the build starts, allowing subsequent parts of the build configuration to access those values.\nFor example, use the `+${PARAMETER_NAME}+` syntax with POSIX shells lik"
  },
  "4427": {
    "source_file": "syntax.txt",
    "text": ", allowing subsequent parts of the build configuration to access those values.\nFor example, use the `+${PARAMETER_NAME}+` syntax with POSIX shells like `bash` and `ksh`, the `+${Env:PARAMETER_NAME}+` syntax with PowerShell, or the `%PARAMETER_NAME%` syntax with Windows `cmd.exe`.\n\n[cols=\"^10h,>90a\",role=syntax]\n|===\n| Required\n| No\n\n| Parameters\n| _None_\n\n| Allowed\n| Only once, inside the `pipelin"
  },
  "4428": {
    "source_file": "syntax.txt",
    "text": "syntax with Windows `cmd.exe`.\n\n[cols=\"^10h,>90a\",role=syntax]\n|===\n| Required\n| No\n\n| Parameters\n| _None_\n\n| Allowed\n| Only once, inside the `pipeline` block.\n|===\n\nstring:: A parameter of a string type, for example: `parameters { string(name: 'DEPLOY_ENV', defaultValue: 'staging', description: '') }`.\n\ntext:: A text parameter, which can contain multiple lines, for example: `parameters { text(nam"
  },
  "4429": {
    "source_file": "syntax.txt",
    "text": "OY_ENV', defaultValue: 'staging', description: '') }`.\n\ntext:: A text parameter, which can contain multiple lines, for example: `parameters { text(name: 'DEPLOY_TEXT', defaultValue: 'One\\nTwo\\nThree\\n', description: '') }`.\n\nbooleanParam:: A boolean parameter, for example: `parameters { booleanParam(name: 'DEBUG_BUILD', defaultValue: true, description: '') }`.\n\nchoice:: A choice parameter, for exa"
  },
  "4430": {
    "source_file": "syntax.txt",
    "text": "parameter, for example: `parameters { booleanParam(name: 'DEBUG_BUILD', defaultValue: true, description: '') }`.\n\nchoice:: A choice parameter, for example: `parameters { choice(name: 'CHOICES', choices: ['one', 'two', 'three'], description: '') }`.\nThe first value is the default.\n\npassword:: A password parameter, for example: `parameters { password(name: 'PASSWORD', defaultValue: 'SECRET', descrip"
  },
  "4431": {
    "source_file": "syntax.txt",
    "text": "he first value is the default.\n\npassword:: A password parameter, for example: `parameters { password(name: 'PASSWORD', defaultValue: 'SECRET', description: 'A secret password') }`.\n\n[[parameters-example]]\n.Parameters, Declarative Pipeline\n=====\n\npipeline {\n    agent any\n    parameters {\n        string(name: 'PERSON', defaultValue: 'Mr Jenkins', description: 'Who should I say hello to?')\n\n        t"
  },
  "4432": {
    "source_file": "syntax.txt",
    "text": "line {\n    agent any\n    parameters {\n        string(name: 'PERSON', defaultValue: 'Mr Jenkins', description: 'Who should I say hello to?')\n\n        text(name: 'BIOGRAPHY', defaultValue: '', description: 'Enter some information about the person')\n\n        booleanParam(name: 'TOGGLE', defaultValue: true, description: 'Toggle this value')\n\n        choice(name: 'CHOICE', choices: ['One', 'Two', 'Thre"
  },
  "4433": {
    "source_file": "syntax.txt",
    "text": "      booleanParam(name: 'TOGGLE', defaultValue: true, description: 'Toggle this value')\n\n        choice(name: 'CHOICE', choices: ['One', 'Two', 'Three'], description: 'Pick something')\n\n        password(name: 'PASSWORD', defaultValue: 'SECRET', description: 'Enter a password')\n    }\n    stages {\n        stage('Example') {\n            steps {\n                echo \"Hello ${params.PERSON}\"\n\n        "
  },
  "4434": {
    "source_file": "syntax.txt",
    "text": "ription: 'Enter a password')\n    }\n    stages {\n        stage('Example') {\n            steps {\n                echo \"Hello ${params.PERSON}\"\n\n                echo \"Biography: ${params.BIOGRAPHY}\"\n\n                echo \"Toggle: ${params.TOGGLE}\"\n\n                echo \"Choice: ${params.CHOICE}\"\n\n                echo \"Password: ${params.PASSWORD}\"\n            }\n        }\n    }\n}\n\n=====\n\nA comprehensi"
  },
  "4435": {
    "source_file": "syntax.txt",
    "text": "            echo \"Choice: ${params.CHOICE}\"\n\n                echo \"Password: ${params.PASSWORD}\"\n            }\n        }\n    }\n}\n\n=====\n\nA comprehensive list of available parameters is pending the completion of .\n\nThe `triggers` directive defines the automated ways in which the Pipeline should be re-triggered.\nFor Pipelines which are integrated with a source such as GitHub or BitBucket, `triggers`"
  },
  "4436": {
    "source_file": "syntax.txt",
    "text": " automated ways in which the Pipeline should be re-triggered.\nFor Pipelines which are integrated with a source such as GitHub or BitBucket, `triggers` may not be necessary as webhooks-based integration will likely already be present.\nThe triggers currently available are `cron`, `pollSCM` and `upstream`.\n\n[cols=\"^10h,>90a\",role=syntax]\n|===\n| Required\n| No\n\n| Parameters\n| _None_\n\n| Allowed\n| Only o"
  },
  "4437": {
    "source_file": "syntax.txt",
    "text": "rently available are `cron`, `pollSCM` and `upstream`.\n\n[cols=\"^10h,>90a\",role=syntax]\n|===\n| Required\n| No\n\n| Parameters\n| _None_\n\n| Allowed\n| Only once, inside the `pipeline` block.\n|===\n\ncron:: Accepts a cron-style string to define a regular interval at which the Pipeline should be re-triggered, for example: `triggers { cron('H */4 * * 1-5') }`.\npollSCM:: Accepts a cron-style string to define a"
  },
  "4438": {
    "source_file": "syntax.txt",
    "text": "val at which the Pipeline should be re-triggered, for example: `triggers { cron('H */4 * * 1-5') }`.\npollSCM:: Accepts a cron-style string to define a regular interval at which Jenkins should check for new source changes.\nIf new changes exist, the Pipeline will be re-triggered.\nFor example: `triggers { pollSCM('H */4 * * 1-5') }`\nupstream:: Accepts a comma-separated string of jobs and a threshold."
  },
  "4439": {
    "source_file": "syntax.txt",
    "text": "peline will be re-triggered.\nFor example: `triggers { pollSCM('H */4 * * 1-5') }`\nupstream:: Accepts a comma-separated string of jobs and a threshold.\nWhen any job in the string finishes with the minimum threshold, the Pipeline will be re-triggered.\nFor example: `triggers { upstream(upstreamProjects: 'job1,job2', threshold: hudson.model.Result.SUCCESS) }`\n\nThe `pollSCM` trigger is only available i"
  },
  "4440": {
    "source_file": "syntax.txt",
    "text": "For example: `triggers { upstream(upstreamProjects: 'job1,job2', threshold: hudson.model.Result.SUCCESS) }`\n\nThe `pollSCM` trigger is only available in Jenkins 2.22 or later.\n\n[[triggers-example]]\n.Triggers, Declarative Pipeline\n=====\n\n// Declarative //\npipeline {\n    agent any\n    triggers {\n        cron('H */4 * * 1-5')\n    }\n    stages {\n        stage('Example') {\n            steps {\n          "
  },
  "4441": {
    "source_file": "syntax.txt",
    "text": " //\npipeline {\n    agent any\n    triggers {\n        cron('H */4 * * 1-5')\n    }\n    stages {\n        stage('Example') {\n            steps {\n                echo 'Hello World'\n            }\n        }\n    }\n}\n\n=====\n\n[[cron-syntax]]\n\nThe Jenkins cron syntax follows the syntax of the  (with minor differences).\nSpecifically, each line consists of 5 fields separated by TAB or whitespace:\n\n[%header,cols"
  },
  "4442": {
    "source_file": "syntax.txt",
    "text": "yntax follows the syntax of the  (with minor differences).\nSpecifically, each line consists of 5 fields separated by TAB or whitespace:\n\n[%header,cols=5*]\n|===\n|MINUTE\n|HOUR\n|DOM\n|MONTH\n|DOW\n\n|Minutes within the hour (0\u201359)\n|The hour of the day (0\u201323)\n|The day of the month (1\u201331)\n|The month (1\u201312)\n|The day of the week (0\u20137) where 0 and 7 are Sunday.\n|===\n\nTo specify multiple values for one field, "
  },
  "4443": {
    "source_file": "syntax.txt",
    "text": ")\n|The day of the month (1\u201331)\n|The month (1\u201312)\n|The day of the week (0\u20137) where 0 and 7 are Sunday.\n|===\n\nTo specify multiple values for one field, the following operators are available.\nIn the order of precedence,\n\n* `*` specifies all valid values\n* `M-N` specifies a range of values\n* `M-N/X` or `*/X` steps by intervals of `X` through the specified range or whole valid range\n* `A,B,...,Z` enume"
  },
  "4444": {
    "source_file": "syntax.txt",
    "text": "\n* `M-N` specifies a range of values\n* `M-N/X` or `*/X` steps by intervals of `X` through the specified range or whole valid range\n* `A,B,...,Z` enumerates multiple values\n\nTo allow periodically scheduled tasks to produce even load on the system, the symbol `H` (for \u201chash\u201d) should be used wherever possible.\nFor example, using `0 0 * * *` for a dozen daily jobs will cause a large spike at midnight."
  },
  "4445": {
    "source_file": "syntax.txt",
    "text": " symbol `H` (for \u201chash\u201d) should be used wherever possible.\nFor example, using `0 0 * * *` for a dozen daily jobs will cause a large spike at midnight.\nIn contrast, using `H H * * *` would still execute each job once a day, but not all at the same time, better using limited resources.\n\nThe `H` symbol can be used with a range.\nFor example, `H H(0-7) * * *` means some time between 12:00 AM (midnight)"
  },
  "4446": {
    "source_file": "syntax.txt",
    "text": "e, better using limited resources.\n\nThe `H` symbol can be used with a range.\nFor example, `H H(0-7) * * *` means some time between 12:00 AM (midnight) to 7:59 AM.\nYou can also use step intervals with `H`, with or without ranges.\n\nThe `H` symbol can be thought of as a random value over a range, but it actually is a hash of the job name, not a random function, so that the value remains stable for an"
  },
  "4447": {
    "source_file": "syntax.txt",
    "text": "e thought of as a random value over a range, but it actually is a hash of the job name, not a random function, so that the value remains stable for any given project.\n\nBeware that for the day of month field, short cycles such as `\\*/3` or `H/3` will not work consistently near the end of most months, due to variable month lengths.\nFor example, `*/3` will run on the 1st, 4th, \u202631st days of a long mo"
  },
  "4448": {
    "source_file": "syntax.txt",
    "text": "not work consistently near the end of most months, due to variable month lengths.\nFor example, `*/3` will run on the 1st, 4th, \u202631st days of a long month, then again the next day of the next month.\nHashes are always chosen in the 1-28 range, so `H/3` will produce a gap between runs of between 3 and 6 days at the end of a month.\nLonger cycles will also have inconsistent lengths, but the effect may "
  },
  "4449": {
    "source_file": "syntax.txt",
    "text": " will produce a gap between runs of between 3 and 6 days at the end of a month.\nLonger cycles will also have inconsistent lengths, but the effect may be relatively less noticeable.\n\nEmpty lines and lines that start with `#` will be ignored as comments.\n\nIn addition, `@yearly`, `@annually`, `@monthly`, `@weekly`, `@daily`, `@midnight`, and `@hourly` are supported as convenient aliases.\nThese use th"
  },
  "4450": {
    "source_file": "syntax.txt",
    "text": "s.\n\nIn addition, `@yearly`, `@annually`, `@monthly`, `@weekly`, `@daily`, `@midnight`, and `@hourly` are supported as convenient aliases.\nThese use the hash system for automatic balancing.\nFor example, `@hourly` is the same as `H * * * *` and could mean at any time during the hour.\n`@midnight` actually means some time between 12:00 AM and 2:59 AM.\n\n[[cron-syntax-examples]]\n.Jenkins cron syntax exa"
  },
  "4451": {
    "source_file": "syntax.txt",
    "text": "ean at any time during the hour.\n`@midnight` actually means some time between 12:00 AM and 2:59 AM.\n\n[[cron-syntax-examples]]\n.Jenkins cron syntax examples\n[cols=1]\n|===\n|every fifteen minutes (perhaps at :07, :22, :37, :52)\n|`triggers{ cron('H/15 * * * *') }`\n|every ten minutes in the first half of every hour (three times, perhaps at :04, :14, :24)\n|`triggers{ cron('H(0-29)/10 * * * *') }`\n|once "
  },
  "4452": {
    "source_file": "syntax.txt",
    "text": "* * *') }`\n|every ten minutes in the first half of every hour (three times, perhaps at :04, :14, :24)\n|`triggers{ cron('H(0-29)/10 * * * *') }`\n|once every two hours at 45 minutes past the hour starting at 9:45 AM and finishing at 3:45 PM every weekday.\n|`triggers{ cron('45 9-16/2 * * 1-5') }`\n|once in every two hours slot between 9 AM and 5 PM every weekday (perhaps at 10:38 AM, 12:38 PM, 2:38 PM"
  },
  "4453": {
    "source_file": "syntax.txt",
    "text": "ay.\n|`triggers{ cron('45 9-16/2 * * 1-5') }`\n|once in every two hours slot between 9 AM and 5 PM every weekday (perhaps at 10:38 AM, 12:38 PM, 2:38 PM, 4:38 PM)\n|`triggers{ cron('H H(9-16)/2 * * 1-5') }`\n|once a day on the 1st and 15th of every month except December\n|`triggers{ cron('H H 1,15 1-11 *') }`\n|===\n\nThe `stage` directive goes in the `stages` section and should contain a <<steps>> sectio"
  },
  "4454": {
    "source_file": "syntax.txt",
    "text": " except December\n|`triggers{ cron('H H 1,15 1-11 *') }`\n|===\n\nThe `stage` directive goes in the `stages` section and should contain a <<steps>> section, an optional `agent` section, or other stage-specific directives.\nPractically speaking, all of the real work done by a Pipeline will be wrapped in one or more `stage` directives.\n\n[cols=\"^10h,>90a\",role=syntax]\n|===\n| Required\n| At least one\n\n| Par"
  },
  "4455": {
    "source_file": "syntax.txt",
    "text": " real work done by a Pipeline will be wrapped in one or more `stage` directives.\n\n[cols=\"^10h,>90a\",role=syntax]\n|===\n| Required\n| At least one\n\n| Parameters\n| One mandatory parameter, a string for the name of the stage.\n\n| Allowed\n| Inside the `stages` section.\n|===\n\n[[stage-example]]\n.Stage, Declarative Pipeline\n=====\n\n// Declarative //\npipeline {\n    agent any\n    stages {\n        stage('Exampl"
  },
  "4456": {
    "source_file": "syntax.txt",
    "text": "es` section.\n|===\n\n[[stage-example]]\n.Stage, Declarative Pipeline\n=====\n\n// Declarative //\npipeline {\n    agent any\n    stages {\n        stage('Example') {\n            steps {\n                echo 'Hello World'\n            }\n        }\n    }\n}\n\n=====\n\nA section defining tools to auto-install and put on the `PATH`.\nThis is ignored if `agent none` is specified.\n\n[cols=\"^10h,>90a\",role=syntax]\n|===\n| "
  },
  "4457": {
    "source_file": "syntax.txt",
    "text": "\nA section defining tools to auto-install and put on the `PATH`.\nThis is ignored if `agent none` is specified.\n\n[cols=\"^10h,>90a\",role=syntax]\n|===\n| Required\n| No\n\n| Parameters\n| _None_\n\n| Allowed\n| Inside the `pipeline` block or a `stage` block.\n|===\n\nmaven::\njdk::\ngradle::\n\n[[tools-example]]\n.Tools, Declarative Pipeline\n=====\n\npipeline {\n    agent any\n    tools {\n        maven 'apache-maven-3.0"
  },
  "4458": {
    "source_file": "syntax.txt",
    "text": "==\n\nmaven::\njdk::\ngradle::\n\n[[tools-example]]\n.Tools, Declarative Pipeline\n=====\n\npipeline {\n    agent any\n    tools {\n        maven 'apache-maven-3.0.1' // <1> }\n    stages {\n        stage('Example') {\n            steps {\n                sh 'mvn --version'\n            }\n        }\n    }\n}\n\n<1> The tool name must be pre-configured in Jenkins under *Manage Jenkins* -> *Tools*.\n=====\n\nThe `input` dir"
  },
  "4459": {
    "source_file": "syntax.txt",
    "text": "ersion'\n            }\n        }\n    }\n}\n\n<1> The tool name must be pre-configured in Jenkins under *Manage Jenkins* -> *Tools*.\n=====\n\nThe `input` directive on a `stage` allows you to prompt for input, using the .\nThe `stage` will pause after any `options` have been applied, and before entering the `agent` block for that `stage` or evaluating the `when` condition of the `stage`.\nIf the `input` is "
  },
  "4460": {
    "source_file": "syntax.txt",
    "text": "tions` have been applied, and before entering the `agent` block for that `stage` or evaluating the `when` condition of the `stage`.\nIf the `input` is approved, the `stage` will then continue.\nAny parameters provided as part of the `input` submission will be available in the environment for the rest of the `stage`.\n\nmessage:: Required.\nThis will be presented to the user when they go to submit the `"
  },
  "4461": {
    "source_file": "syntax.txt",
    "text": "will be available in the environment for the rest of the `stage`.\n\nmessage:: Required.\nThis will be presented to the user when they go to submit the `input`.\n\nid:: An optional identifier for this `input`.\nThe default value is based on the `stage` name.\n\nok:: Optional text for the \"ok\" button on the `input` form.\n\nsubmitter:: An optional comma-separated list of users or external group names who are"
  },
  "4462": {
    "source_file": "syntax.txt",
    "text": "e.\n\nok:: Optional text for the \"ok\" button on the `input` form.\n\nsubmitter:: An optional comma-separated list of users or external group names who are allowed to submit this `input`.\nDefaults to allowing any user.\n\nsubmitterParameter:: An optional name of an environment variable to set with the `submitter` name, if present.\n\nparameters:: An optional list of parameters to prompt the submitter to pr"
  },
  "4463": {
    "source_file": "syntax.txt",
    "text": "me of an environment variable to set with the `submitter` name, if present.\n\nparameters:: An optional list of parameters to prompt the submitter to provide.\nRefer to <<parameters>> for more information.\n\n[[input-example]]\n.Input Step, Declarative Pipeline\n=====\n\npipeline {\n    agent any\n    stages {\n        stage('Example') {\n            input {\n                message \"Should we continue?\"\n      "
  },
  "4464": {
    "source_file": "syntax.txt",
    "text": "eline\n=====\n\npipeline {\n    agent any\n    stages {\n        stage('Example') {\n            input {\n                message \"Should we continue?\"\n                ok \"Yes, we should.\"\n                submitter \"alice,bob\"\n                parameters {\n                    string(name: 'PERSON', defaultValue: 'Mr Jenkins', description: 'Who should I say hello to?')\n                }\n            }\n      "
  },
  "4465": {
    "source_file": "syntax.txt",
    "text": "                  string(name: 'PERSON', defaultValue: 'Mr Jenkins', description: 'Who should I say hello to?')\n                }\n            }\n            steps {\n                echo \"Hello, ${PERSON}, nice to meet you.\"\n            }\n        }\n    }\n}\n\n=====\n\nThe `when` directive allows the Pipeline to determine whether the stage should be executed depending on the given condition.\nThe `when` d"
  },
  "4466": {
    "source_file": "syntax.txt",
    "text": " }\n}\n\n=====\n\nThe `when` directive allows the Pipeline to determine whether the stage should be executed depending on the given condition.\nThe `when` directive must contain at least one condition.\nIf the `when` directive contains more than one condition, all the child conditions must return true for the stage to execute.\nThis is the same as if the child conditions were nested in an `allOf` conditio"
  },
  "4467": {
    "source_file": "syntax.txt",
    "text": "on, all the child conditions must return true for the stage to execute.\nThis is the same as if the child conditions were nested in an `allOf` condition (refer to the <<when-example, examples>> below).\nIf an `anyOf` condition is used, note that the condition skips remaining tests as soon as the first \"true\" condition is found.\n\nMore complex conditional structures can be built using the nesting cond"
  },
  "4468": {
    "source_file": "syntax.txt",
    "text": "ndition skips remaining tests as soon as the first \"true\" condition is found.\n\nMore complex conditional structures can be built using the nesting conditions: `not`, `allOf`, or `anyOf`.\nNesting conditions may be nested to any arbitrary depth.\n\n[cols=\"^10h,>90a\",role=syntax]\n|===\n| Required\n| No\n\n| Parameters\n| _None_\n\n| Allowed\n| Inside a `stage` directive\n|===\n\nbranch:: Execute the stage when the"
  },
  "4469": {
    "source_file": "syntax.txt",
    "text": "\"^10h,>90a\",role=syntax]\n|===\n| Required\n| No\n\n| Parameters\n| _None_\n\n| Allowed\n| Inside a `stage` directive\n|===\n\nbranch:: Execute the stage when the branch being built matches the branch pattern (ANT style path glob) given, for example: `when { branch 'master' }`. Note that this only works on a multibranch Pipeline.\nThe optional parameter `comparator` may be added after an attribute to specify h"
  },
  "4470": {
    "source_file": "syntax.txt",
    "text": "nch 'master' }`. Note that this only works on a multibranch Pipeline.\nThe optional parameter `comparator` may be added after an attribute to specify how any patterns are evaluated for a match:\n\n* `EQUALS` for a simple string comparison\n* `GLOB` (the default) for an ANT style path glob (same as for example `changeset`)\n* `REGEXP` for regular expression matching\n\nFor example: `when { branch pattern:"
  },
  "4471": {
    "source_file": "syntax.txt",
    "text": "default) for an ANT style path glob (same as for example `changeset`)\n* `REGEXP` for regular expression matching\n\nFor example: `when { branch pattern: \"release-\\\\d+\", comparator: \"REGEXP\"}`\n\nbuildingTag:: Execute the stage when the build is building a tag.\nFor example: `when { buildingTag() }`\n\nchangelog:: Execute the stage if the build's SCM changelog contains a given regular expression pattern, "
  },
  "4472": {
    "source_file": "syntax.txt",
    "text": "a tag.\nFor example: `when { buildingTag() }`\n\nchangelog:: Execute the stage if the build's SCM changelog contains a given regular expression pattern, for example: `when { changelog '.*^\\\\[DEPENDENCY\\\\] .+$' }`.\n\nchangeset:: Execute the stage if the build's SCM changeset contains one or more files matching the given pattern.\nExample: `+when { changeset \"**/*.js\" }+`\nThe optional parameter `comparat"
  },
  "4473": {
    "source_file": "syntax.txt",
    "text": "uild's SCM changeset contains one or more files matching the given pattern.\nExample: `+when { changeset \"**/*.js\" }+`\nThe optional parameter `comparator` may be added after an attribute to specify how any patterns are evaluated for a match:\n\n* `EQUALS` for a simple string comparison\n* `GLOB` (the default) for an ANT style path glob case insensitive (this can be turned off with the `caseSensitive` "
  },
  "4474": {
    "source_file": "syntax.txt",
    "text": "S` for a simple string comparison\n* `GLOB` (the default) for an ANT style path glob case insensitive (this can be turned off with the `caseSensitive` parameter).\n* `REGEXP` for regular expression matching\n\nFor example: `when { changeset pattern: \".*TEST\\\\.java\", comparator: \"REGEXP\" }` or `when { changeset pattern: \"**/*TEST.java\", caseSensitive: true }`\n\nchangeRequest:: Executes the stage if the "
  },
  "4475": {
    "source_file": "syntax.txt",
    "text": "EST\\\\.java\", comparator: \"REGEXP\" }` or `when { changeset pattern: \"**/*TEST.java\", caseSensitive: true }`\n\nchangeRequest:: Executes the stage if the current build is for a \"change request\" (a.k.a. Pull Request on GitHub and Bitbucket, Merge Request on GitLab, Change in Gerrit, etc.).\nWhen no parameters are passed the stage runs on every change request, for example: `when { changeRequest() }`.\nBy "
  },
  "4476": {
    "source_file": "syntax.txt",
    "text": "on GitLab, Change in Gerrit, etc.).\nWhen no parameters are passed the stage runs on every change request, for example: `when { changeRequest() }`.\nBy adding a filter attribute with parameter to the change request, the stage can be made to run only on matching change requests.\nPossible attributes are `id`, `target`, `branch`, `fork`, `url`, `title`, `author`, `authorDisplayName`, and `authorEmail`."
  },
  "4477": {
    "source_file": "syntax.txt",
    "text": " matching change requests.\nPossible attributes are `id`, `target`, `branch`, `fork`, `url`, `title`, `author`, `authorDisplayName`, and `authorEmail`.\nEach of these corresponds to a `CHANGE_*` environment variable, for example: `when { changeRequest target: 'master' }`.\nThe optional parameter `comparator` may be added after an attribute to specify how any patterns are evaluated for a match:\n\n* `EQ"
  },
  "4478": {
    "source_file": "syntax.txt",
    "text": "target: 'master' }`.\nThe optional parameter `comparator` may be added after an attribute to specify how any patterns are evaluated for a match:\n\n* `EQUALS` for a simple string comparison (the default)\n* `GLOB` for an ANT style path glob (same as for example `changeset`)\n* `REGEXP` for regular expression matching\n\nExample: `when { changeRequest authorEmail: \"[\\\\w_-.]+@example.com\", comparator: 'REG"
  },
  "4479": {
    "source_file": "syntax.txt",
    "text": "example `changeset`)\n* `REGEXP` for regular expression matching\n\nExample: `when { changeRequest authorEmail: \"[\\\\w_-.]+@example.com\", comparator: 'REGEXP' }`\n\nenvironment:: Execute the stage when the specified environment variable is set to the given value, for example: `when { environment name: 'DEPLOY_TO', value: 'production' }`.\n\nequals:: Execute the stage when the expected value is equal to th"
  },
  "4480": {
    "source_file": "syntax.txt",
    "text": " value, for example: `when { environment name: 'DEPLOY_TO', value: 'production' }`.\n\nequals:: Execute the stage when the expected value is equal to the actual value, for example: `when { equals expected: 2, actual: currentBuild.number }`.\n\nexpression:: Execute the stage when the specified Groovy expression evaluates to true, for example: `when { expression { return params.DEBUG_BUILD } }`.\n\nNOTE: "
  },
  "4481": {
    "source_file": "syntax.txt",
    "text": ":: Execute the stage when the specified Groovy expression evaluates to true, for example: `when { expression { return params.DEBUG_BUILD } }`.\n\nNOTE: When returning strings from your expressions they must be converted to booleans or return `null` to evaluate to false. Simply returning \"0\" or \"false\" will still evaluate to \"true\".\n\ntag:: Execute the stage if the `TAG_NAME` variable matches the give"
  },
  "4482": {
    "source_file": "syntax.txt",
    "text": "evaluate to false. Simply returning \"0\" or \"false\" will still evaluate to \"true\".\n\ntag:: Execute the stage if the `TAG_NAME` variable matches the given pattern.\nFor example: `when { tag \"release-*\" }`\nIf an empty pattern is provided the stage will execute if the `TAG_NAME` variable exists (same as `buildingTag()`).\nThe optional parameter `comparator` may be added after an attribute to specify how "
  },
  "4483": {
    "source_file": "syntax.txt",
    "text": "ecute if the `TAG_NAME` variable exists (same as `buildingTag()`).\nThe optional parameter `comparator` may be added after an attribute to specify how any patterns are evaluated for a match:\n\n* `EQUALS` for a simple string comparison,\n* `GLOB` (the default) for an ANT style path glob (same as for example `changeset`), or\n* `REGEXP` for regular expression matching.\n\nFor example: `when { tag pattern:"
  },
  "4484": {
    "source_file": "syntax.txt",
    "text": "fault) for an ANT style path glob (same as for example `changeset`), or\n* `REGEXP` for regular expression matching.\n\nFor example: `when { tag pattern: \"release-\\\\d+\", comparator: \"REGEXP\"}`\n\nnot:: Execute the stage when the nested condition is false.\nMust contain one condition.\nFor example: `when { not { branch 'master' } }`\n\nallOf:: Execute the stage when all of the nested conditions are true.\nMu"
  },
  "4485": {
    "source_file": "syntax.txt",
    "text": "\nMust contain one condition.\nFor example: `when { not { branch 'master' } }`\n\nallOf:: Execute the stage when all of the nested conditions are true.\nMust contain at least one condition.\nFor example: `when { allOf { branch 'master'; environment name: 'DEPLOY_TO', value: 'production' } }`\n\nanyOf:: Execute the stage when at least one of the nested conditions is true.\nMust contain at least one conditio"
  },
  "4486": {
    "source_file": "syntax.txt",
    "text": "DEPLOY_TO', value: 'production' } }`\n\nanyOf:: Execute the stage when at least one of the nested conditions is true.\nMust contain at least one condition.\nFor example: `when { anyOf { branch 'master'; branch 'staging' } }`\n\ntriggeredBy:: Execute the stage when the current build has been triggered by the param given.\nFor example:\n\n* `when { triggeredBy 'SCMTrigger' }`\n* `when { triggeredBy 'TimerTrig"
  },
  "4487": {
    "source_file": "syntax.txt",
    "text": "age when the current build has been triggered by the param given.\nFor example:\n\n* `when { triggeredBy 'SCMTrigger' }`\n* `when { triggeredBy 'TimerTrigger' }`\n* `when { triggeredBy 'BuildUpstreamCause' }`\n* `when { triggeredBy  cause: \"UserIdCause\", detail: \"vlinde\" }`\n\nBy default, the `when` condition for a `stage` will be evaluated after entering the `agent` for that `stage`, if one is defined.\nH"
  },
  "4488": {
    "source_file": "syntax.txt",
    "text": "etail: \"vlinde\" }`\n\nBy default, the `when` condition for a `stage` will be evaluated after entering the `agent` for that `stage`, if one is defined.\nHowever, this can be changed by specifying the `beforeAgent` option within the `when` block.\nIf `beforeAgent` is set to `true`, the `when` condition will be evaluated first, and the `agent` will only be entered if the `when` condition evaluates to tru"
  },
  "4489": {
    "source_file": "syntax.txt",
    "text": "reAgent` is set to `true`, the `when` condition will be evaluated first, and the `agent` will only be entered if the `when` condition evaluates to true.\n\nBy default, the when condition for a stage will not be evaluated before the input, if one is defined.\nHowever, this can be changed by specifying the `beforeInput` option within the when block.\nIf `beforeInput` is set to true, the when condition w"
  },
  "4490": {
    "source_file": "syntax.txt",
    "text": "ined.\nHowever, this can be changed by specifying the `beforeInput` option within the when block.\nIf `beforeInput` is set to true, the when condition will be evaluated first, and the input will only be entered if the when condition evaluates to true.\n\n`beforeInput true` takes precedence over `beforeAgent true`.\n\nBy default, the `when` condition for a `stage` will be evaluated after entering the `op"
  },
  "4491": {
    "source_file": "syntax.txt",
    "text": "\n`beforeInput true` takes precedence over `beforeAgent true`.\n\nBy default, the `when` condition for a `stage` will be evaluated after entering the `options` for that `stage`, if any are defined.\nHowever, this can be changed by specifying the `beforeOptions` option within the `when` block.\nIf `beforeOptions` is set to `true`, the `when` condition will be evaluated first, and the `options` will only"
  },
  "4492": {
    "source_file": "syntax.txt",
    "text": "ptions` option within the `when` block.\nIf `beforeOptions` is set to `true`, the `when` condition will be evaluated first, and the `options` will only be entered if the `when` condition evaluates to true.\n\n`beforeOptions true` takes precedence over `beforeInput true` and `beforeAgent true`.\n\n[[when-example]]\n.Single Condition, Declarative Pipeline\n=====\n\npipeline {\n    agent any\n    stages {\n     "
  },
  "4493": {
    "source_file": "syntax.txt",
    "text": "beforeInput true` and `beforeAgent true`.\n\n[[when-example]]\n.Single Condition, Declarative Pipeline\n=====\n\npipeline {\n    agent any\n    stages {\n        stage('Example Build') {\n            steps {\n                echo 'Hello World'\n            }\n        }\n        stage('Example Deploy') {\n            when {\n                branch 'production'\n            }\n            steps {\n                echo"
  },
  "4494": {
    "source_file": "syntax.txt",
    "text": "     }\n        stage('Example Deploy') {\n            when {\n                branch 'production'\n            }\n            steps {\n                echo 'Deploying'\n            }\n        }\n    }\n}\n\n=====\n\n.Multiple Condition, Declarative Pipeline\n=====\n\npipeline {\n    agent any\n    stages {\n        stage('Example Build') {\n            steps {\n                echo 'Hello World'\n            }\n        "
  },
  "4495": {
    "source_file": "syntax.txt",
    "text": "\n\npipeline {\n    agent any\n    stages {\n        stage('Example Build') {\n            steps {\n                echo 'Hello World'\n            }\n        }\n        stage('Example Deploy') {\n            when {\n                branch 'production'\n                environment name: 'DEPLOY_TO', value: 'production'\n            }\n            steps {\n                echo 'Deploying'\n            }\n        }\n "
  },
  "4496": {
    "source_file": "syntax.txt",
    "text": "       environment name: 'DEPLOY_TO', value: 'production'\n            }\n            steps {\n                echo 'Deploying'\n            }\n        }\n    }\n}\n\n=====\n\n.Nested condition (same behavior as previous example)\n=====\n\npipeline {\n    agent any\n    stages {\n        stage('Example Build') {\n            steps {\n                echo 'Hello World'\n            }\n        }\n        stage('Example D"
  },
  "4497": {
    "source_file": "syntax.txt",
    "text": "\n    stages {\n        stage('Example Build') {\n            steps {\n                echo 'Hello World'\n            }\n        }\n        stage('Example Deploy') {\n            when {\n                allOf {\n                    branch 'production'\n                    environment name: 'DEPLOY_TO', value: 'production'\n                }\n            }\n            steps {\n                echo 'Deploying'\n "
  },
  "4498": {
    "source_file": "syntax.txt",
    "text": "             environment name: 'DEPLOY_TO', value: 'production'\n                }\n            }\n            steps {\n                echo 'Deploying'\n            }\n        }\n    }\n}\n\n=====\n\n.Multiple condition and nested condition\n=====\n\npipeline {\n    agent any\n    stages {\n        stage('Example Build') {\n            steps {\n                echo 'Hello World'\n            }\n        }\n        stage"
  },
  "4499": {
    "source_file": "syntax.txt",
    "text": "  agent any\n    stages {\n        stage('Example Build') {\n            steps {\n                echo 'Hello World'\n            }\n        }\n        stage('Example Deploy') {\n            when {\n                branch 'production'\n                anyOf {\n                    environment name: 'DEPLOY_TO', value: 'production'\n                    environment name: 'DEPLOY_TO', value: 'staging'\n           "
  },
  "4500": {
    "source_file": "syntax.txt",
    "text": "                    environment name: 'DEPLOY_TO', value: 'production'\n                    environment name: 'DEPLOY_TO', value: 'staging'\n                }\n            }\n            steps {\n                echo 'Deploying'\n            }\n        }\n    }\n}\n\n=====\n\n.Expression condition and nested condition\n=====\n\npipeline {\n    agent any\n    stages {\n        stage('Example Build') {\n            ste"
  },
  "4501": {
    "source_file": "syntax.txt",
    "text": "  }\n}\n\n=====\n\n.Expression condition and nested condition\n=====\n\npipeline {\n    agent any\n    stages {\n        stage('Example Build') {\n            steps {\n                echo 'Hello World'\n            }\n        }\n        stage('Example Deploy') {\n            when {\n                expression { BRANCH_NAME ==~ /(production|staging)/ }\n                anyOf {\n                    environment name: '"
  },
  "4502": {
    "source_file": "syntax.txt",
    "text": "          when {\n                expression { BRANCH_NAME ==~ /(production|staging)/ }\n                anyOf {\n                    environment name: 'DEPLOY_TO', value: 'production'\n                    environment name: 'DEPLOY_TO', value: 'staging'\n                }\n            }\n            steps {\n                echo 'Deploying'\n            }\n        }\n    }\n}\n\n=====\n\n.`beforeAgent`\n=====\n\npip"
  },
  "4503": {
    "source_file": "syntax.txt",
    "text": "                }\n            }\n            steps {\n                echo 'Deploying'\n            }\n        }\n    }\n}\n\n=====\n\n.`beforeAgent`\n=====\n\npipeline {\n    agent none\n    stages {\n        stage('Example Build') {\n            steps {\n                echo 'Hello World'\n            }\n        }\n        stage('Example Deploy') {\n            agent {\n                label \"some-label\"\n            }"
  },
  "4504": {
    "source_file": "syntax.txt",
    "text": "     echo 'Hello World'\n            }\n        }\n        stage('Example Deploy') {\n            agent {\n                label \"some-label\"\n            }\n            when {\n                beforeAgent true\n                branch 'production'\n            }\n            steps {\n                echo 'Deploying'\n            }\n        }\n    }\n}\n\n=====\n\n.`beforeInput`\n=====\n\npipeline {\n    agent none\n    st"
  },
  "4505": {
    "source_file": "syntax.txt",
    "text": " }\n            steps {\n                echo 'Deploying'\n            }\n        }\n    }\n}\n\n=====\n\n.`beforeInput`\n=====\n\npipeline {\n    agent none\n    stages {\n        stage('Example Build') {\n            steps {\n                echo 'Hello World'\n            }\n        }\n        stage('Example Deploy') {\n            when {\n                beforeInput true\n                branch 'production'\n         "
  },
  "4506": {
    "source_file": "syntax.txt",
    "text": "       }\n        }\n        stage('Example Deploy') {\n            when {\n                beforeInput true\n                branch 'production'\n            }\n            input {\n                message \"Deploy to production?\"\n                id \"simple-input\"\n            }\n            steps {\n                echo 'Deploying'\n            }\n        }\n    }\n}\n\n=====\n\n.`beforeOptions`\n=====\n\npipeline {\n "
  },
  "4507": {
    "source_file": "syntax.txt",
    "text": "input\"\n            }\n            steps {\n                echo 'Deploying'\n            }\n        }\n    }\n}\n\n=====\n\n.`beforeOptions`\n=====\n\npipeline {\n    agent none\n    stages {\n        stage('Example Build') {\n            steps {\n                echo 'Hello World'\n            }\n        }\n        stage('Example Deploy') {\n            when {\n                beforeOptions true\n                branch "
  },
  "4508": {
    "source_file": "syntax.txt",
    "text": " 'Hello World'\n            }\n        }\n        stage('Example Deploy') {\n            when {\n                beforeOptions true\n                branch 'testing'\n            }\n            options {\n                lock label: 'testing-deploy-envs', quantity: 1, variable: 'deployEnv'\n            }\n            steps {\n                echo \"Deploying to ${deployEnv}\"\n            }\n        }\n    }\n}\n\n=="
  },
  "4509": {
    "source_file": "syntax.txt",
    "text": "ntity: 1, variable: 'deployEnv'\n            }\n            steps {\n                echo \"Deploying to ${deployEnv}\"\n            }\n        }\n    }\n}\n\n=====\n\n.`triggeredBy`\n=====\n\npipeline {\n    agent none\n    stages {\n        stage('Example Build') {\n            steps {\n                echo 'Hello World'\n            }\n        }\n        stage('Example Deploy') {\n            when {\n                tri"
  },
  "4510": {
    "source_file": "syntax.txt",
    "text": "           steps {\n                echo 'Hello World'\n            }\n        }\n        stage('Example Deploy') {\n            when {\n                triggeredBy \"TimerTrigger\"\n            }\n            steps {\n                echo 'Deploying'\n            }\n        }\n    }\n}\n\n=====\n\nStages in Declarative Pipeline may have a `stages` section containing a list of nested stages to be run in sequential o"
  },
  "4511": {
    "source_file": "syntax.txt",
    "text": "   }\n        }\n    }\n}\n\n=====\n\nStages in Declarative Pipeline may have a `stages` section containing a list of nested stages to be run in sequential order.\n\nNOTE: A stage must have one and only one of `steps`, `stages`, `parallel`, or `matrix`.\nIt is not possible to nest a `parallel` or `matrix` block within a `stage` directive if that `stage` directive is nested within a `parallel` or `matrix` bl"
  },
  "4512": {
    "source_file": "syntax.txt",
    "text": " not possible to nest a `parallel` or `matrix` block within a `stage` directive if that `stage` directive is nested within a `parallel` or `matrix` block itself.\nHowever, a `stage` directive within a `parallel` or `matrix` block can use all other functionality of a `stage`, including `agent`, `tools`, `when`, etc.\n\n[[sequential-stages-example]]\n.Sequential Stages, Declarative Pipeline\n=====\n\npipel"
  },
  "4513": {
    "source_file": "syntax.txt",
    "text": "ctionality of a `stage`, including `agent`, `tools`, `when`, etc.\n\n[[sequential-stages-example]]\n.Sequential Stages, Declarative Pipeline\n=====\n\npipeline {\n    agent none\n    stages {\n        stage('Non-Sequential Stage') {\n            agent {\n                label 'for-non-sequential'\n            }\n            steps {\n                echo \"On Non-Sequential Stage\"\n            }\n        }\n        "
  },
  "4514": {
    "source_file": "syntax.txt",
    "text": "          label 'for-non-sequential'\n            }\n            steps {\n                echo \"On Non-Sequential Stage\"\n            }\n        }\n        stage('Sequential') {\n            agent {\n                label 'for-sequential'\n            }\n            environment {\n                FOR_SEQUENTIAL = \"some-value\"\n            }\n            stages {\n                stage('In Sequential 1') {\n     "
  },
  "4515": {
    "source_file": "syntax.txt",
    "text": "       environment {\n                FOR_SEQUENTIAL = \"some-value\"\n            }\n            stages {\n                stage('In Sequential 1') {\n                    steps {\n                        echo \"In Sequential 1\"\n                    }\n                }\n                stage('In Sequential 2') {\n                    steps {\n                        echo \"In Sequential 2\"\n                    }\n"
  },
  "4516": {
    "source_file": "syntax.txt",
    "text": "        }\n                stage('In Sequential 2') {\n                    steps {\n                        echo \"In Sequential 2\"\n                    }\n                }\n                stage('Parallel In Sequential') {\n                    parallel {\n                        stage('In Parallel 1') {\n                            steps {\n                                echo \"In Parallel 1\"\n             "
  },
  "4517": {
    "source_file": "syntax.txt",
    "text": "                       stage('In Parallel 1') {\n                            steps {\n                                echo \"In Parallel 1\"\n                            }\n                        }\n                        stage('In Parallel 2') {\n                            steps {\n                                echo \"In Parallel 2\"\n                            }\n                        }\n             "
  },
  "4518": {
    "source_file": "syntax.txt",
    "text": "                    steps {\n                                echo \"In Parallel 2\"\n                            }\n                        }\n                    }\n                }\n            }\n        }\n    }\n}\n\n=====\n\nStages in Declarative Pipeline may have a `parallel` section containing a list of nested stages to be run in parallel.\n\nNOTE: A stage must have one and only one of `steps`, `stages`, "
  },
  "4519": {
    "source_file": "syntax.txt",
    "text": "y have a `parallel` section containing a list of nested stages to be run in parallel.\n\nNOTE: A stage must have one and only one of `steps`, `stages`, `parallel`, or `matrix`.\nIt is not possible to nest a `parallel` or `matrix` block within a `stage` directive if that `stage` directive is nested within a `parallel` or `matrix` block itself.\nHowever, a `stage` directive within a `parallel` or `matri"
  },
  "4520": {
    "source_file": "syntax.txt",
    "text": "directive if that `stage` directive is nested within a `parallel` or `matrix` block itself.\nHowever, a `stage` directive within a `parallel` or `matrix` block can use all other functionality of a `stage`, including `agent`, `tools`, `when`, etc.\n\nIn addition, you can force your `parallel` stages to all be aborted when any one of them fails, by adding `failFast true` to the `stage` containing the `"
  },
  "4521": {
    "source_file": "syntax.txt",
    "text": "addition, you can force your `parallel` stages to all be aborted when any one of them fails, by adding `failFast true` to the `stage` containing the `parallel`.\nAnother option for adding `failfast` is adding an option to the pipeline definition: `parallelsAlwaysFailFast()`.\n\n[[parallel-stages-example]]\n.Parallel Stages, Declarative Pipeline\n=====\n\npipeline {\n    agent any\n    stages {\n        stag"
  },
  "4522": {
    "source_file": "syntax.txt",
    "text": "allelsAlwaysFailFast()`.\n\n[[parallel-stages-example]]\n.Parallel Stages, Declarative Pipeline\n=====\n\npipeline {\n    agent any\n    stages {\n        stage('Non-Parallel Stage') {\n            steps {\n                echo 'This stage will be executed first.'\n            }\n        }\n        stage('Parallel Stage') {\n            when {\n                branch 'master'\n            }\n            failFast tr"
  },
  "4523": {
    "source_file": "syntax.txt",
    "text": "t.'\n            }\n        }\n        stage('Parallel Stage') {\n            when {\n                branch 'master'\n            }\n            failFast true\n            parallel {\n                stage('Branch A') {\n                    agent {\n                        label \"for-branch-a\"\n                    }\n                    steps {\n                        echo \"On Branch A\"\n                    }\n"
  },
  "4524": {
    "source_file": "syntax.txt",
    "text": "              label \"for-branch-a\"\n                    }\n                    steps {\n                        echo \"On Branch A\"\n                    }\n                }\n                stage('Branch B') {\n                    agent {\n                        label \"for-branch-b\"\n                    }\n                    steps {\n                        echo \"On Branch B\"\n                    }\n        "
  },
  "4525": {
    "source_file": "syntax.txt",
    "text": "      label \"for-branch-b\"\n                    }\n                    steps {\n                        echo \"On Branch B\"\n                    }\n                }\n                stage('Branch C') {\n                    agent {\n                        label \"for-branch-c\"\n                    }\n                    stages {\n                        stage('Nested 1') {\n                            steps {\n"
  },
  "4526": {
    "source_file": "syntax.txt",
    "text": "bel \"for-branch-c\"\n                    }\n                    stages {\n                        stage('Nested 1') {\n                            steps {\n                                echo \"In stage Nested 1 within Branch C\"\n                            }\n                        }\n                        stage('Nested 2') {\n                            steps {\n                                echo \"In "
  },
  "4527": {
    "source_file": "syntax.txt",
    "text": " }\n                        }\n                        stage('Nested 2') {\n                            steps {\n                                echo \"In stage Nested 2 within Branch C\"\n                            }\n                        }\n                    }\n                }\n            }\n        }\n    }\n}\n\n=====\n\n.`parallelsAlwaysFailFast`\n=====\n\npipeline {\n    agent any\n    options {\n        p"
  },
  "4528": {
    "source_file": "syntax.txt",
    "text": "        }\n                }\n            }\n        }\n    }\n}\n\n=====\n\n.`parallelsAlwaysFailFast`\n=====\n\npipeline {\n    agent any\n    options {\n        parallelsAlwaysFailFast()\n    }\n    stages {\n        stage('Non-Parallel Stage') {\n            steps {\n                echo 'This stage will be executed first.'\n            }\n        }\n        stage('Parallel Stage') {\n            when {\n             "
  },
  "4529": {
    "source_file": "syntax.txt",
    "text": "{\n                echo 'This stage will be executed first.'\n            }\n        }\n        stage('Parallel Stage') {\n            when {\n                branch 'master'\n            }\n            parallel {\n                stage('Branch A') {\n                    agent {\n                        label \"for-branch-a\"\n                    }\n                    steps {\n                        echo \"On Br"
  },
  "4530": {
    "source_file": "syntax.txt",
    "text": "            agent {\n                        label \"for-branch-a\"\n                    }\n                    steps {\n                        echo \"On Branch A\"\n                    }\n                }\n                stage('Branch B') {\n                    agent {\n                        label \"for-branch-b\"\n                    }\n                    steps {\n                        echo \"On Branch B\"\n"
  },
  "4531": {
    "source_file": "syntax.txt",
    "text": "    agent {\n                        label \"for-branch-b\"\n                    }\n                    steps {\n                        echo \"On Branch B\"\n                    }\n                }\n                stage('Branch C') {\n                    agent {\n                        label \"for-branch-c\"\n                    }\n                    stages {\n                        stage('Nested 1') {\n      "
  },
  "4532": {
    "source_file": "syntax.txt",
    "text": "t {\n                        label \"for-branch-c\"\n                    }\n                    stages {\n                        stage('Nested 1') {\n                            steps {\n                                echo \"In stage Nested 1 within Branch C\"\n                            }\n                        }\n                        stage('Nested 2') {\n                            steps {\n           "
  },
  "4533": {
    "source_file": "syntax.txt",
    "text": "C\"\n                            }\n                        }\n                        stage('Nested 2') {\n                            steps {\n                                echo \"In stage Nested 2 within Branch C\"\n                            }\n                        }\n                    }\n                }\n            }\n        }\n    }\n}\n\n=====\n[[declarative-matrix]]\n\nStages in Declarative Pipelin"
  },
  "4534": {
    "source_file": "syntax.txt",
    "text": "                }\n                    }\n                }\n            }\n        }\n    }\n}\n\n=====\n[[declarative-matrix]]\n\nStages in Declarative Pipeline may have a `matrix` section defining a multi-dimensional matrix of name-value combinations to be run in parallel.\nWe'll refer these combinations as \"cells\" in a matrix.\nEach cell in a matrix can include one or more stages to be run sequentially usi"
  },
  "4535": {
    "source_file": "syntax.txt",
    "text": "un in parallel.\nWe'll refer these combinations as \"cells\" in a matrix.\nEach cell in a matrix can include one or more stages to be run sequentially using the configuration for that cell.\n\nNOTE: A stage must have one and only one of `steps`, `stages`, `parallel`, or `matrix`.\nIt is not possible to nest a `parallel` or `matrix` block within a `stage` directive if that `stage` directive is nested with"
  },
  "4536": {
    "source_file": "syntax.txt",
    "text": "`parallel`, or `matrix`.\nIt is not possible to nest a `parallel` or `matrix` block within a `stage` directive if that `stage` directive is nested within a `parallel` or `matrix` block itself.\nHowever, a `stage` directive within a `parallel` or `matrix` block can use all other functionality of a `stage`, including `agent`, `tools`, `when`, etc.\n\nIn addition, you can force your `matrix` cells to all"
  },
  "4537": {
    "source_file": "syntax.txt",
    "text": "x` block can use all other functionality of a `stage`, including `agent`, `tools`, `when`, etc.\n\nIn addition, you can force your `matrix` cells to all be aborted when any one of them fails, by adding `failFast true` to the `stage` containing the `matrix`.\nAnother option for adding `failfast` is adding an option to the pipeline definition: `parallelsAlwaysFailFast()`.\n\nThe `matrix` section must inc"
  },
  "4538": {
    "source_file": "syntax.txt",
    "text": "rix`.\nAnother option for adding `failfast` is adding an option to the pipeline definition: `parallelsAlwaysFailFast()`.\n\nThe `matrix` section must include an `axes` section and a `stages` section.\nThe `axes` section defines the values for each `axis` in the matrix.\nThe `stages` section defines a list of ``stage``s to run sequentially in each cell.\nA `matrix` may have an `excludes` section to remov"
  },
  "4539": {
    "source_file": "syntax.txt",
    "text": " in the matrix.\nThe `stages` section defines a list of ``stage``s to run sequentially in each cell.\nA `matrix` may have an `excludes` section to remove invalid cells from the matrix.\nMany of the directives available on  `stage`, including `agent`, `tools`, `when`, etc., can also be added to `matrix` to control the behavior of each cell.\n\n[[matrix-axes]]\n\nThe `axes` section specifies one or more `a"
  },
  "4540": {
    "source_file": "syntax.txt",
    "text": "ools`, `when`, etc., can also be added to `matrix` to control the behavior of each cell.\n\n[[matrix-axes]]\n\nThe `axes` section specifies one or more `axis` directives.\nEach `axis` consists of a `name` and a list of `values`.\nAll the values from each axis are combined with the others to produce the cells.\n\n[[matrix-axes-example]]\n.One-axis with 3 cells\n\nmatrix {\n    axes {\n        axis {\n           "
  },
  "4541": {
    "source_file": "syntax.txt",
    "text": "xis are combined with the others to produce the cells.\n\n[[matrix-axes-example]]\n.One-axis with 3 cells\n\nmatrix {\n    axes {\n        axis {\n            name 'PLATFORM'\n            values 'linux', 'mac', 'windows'\n        }\n    }\n    // ...\n}\n\n=====\n\n.Two-axis with 12 cells (three by four)\n=====\n\nmatrix {\n    axes {\n        axis {\n            name 'PLATFORM'\n            values 'linux', 'mac', 'windo"
  },
  "4542": {
    "source_file": "syntax.txt",
    "text": "Two-axis with 12 cells (three by four)\n=====\n\nmatrix {\n    axes {\n        axis {\n            name 'PLATFORM'\n            values 'linux', 'mac', 'windows'\n        }\n        axis {\n            name 'BROWSER'\n            values 'chrome', 'edge', 'firefox', 'safari'\n        }\n    }\n    // ...\n}\n\n=====\n\n[[three-axes]]\n.Three-axis matrix with 24 cells (three by four by two)\n=====\n\nmatrix {\n    axes {\n  "
  },
  "4543": {
    "source_file": "syntax.txt",
    "text": "x', 'safari'\n        }\n    }\n    // ...\n}\n\n=====\n\n[[three-axes]]\n.Three-axis matrix with 24 cells (three by four by two)\n=====\n\nmatrix {\n    axes {\n        axis {\n            name 'PLATFORM'\n            values 'linux', 'mac', 'windows'\n        }\n        axis {\n            name 'BROWSER'\n            values 'chrome', 'edge', 'firefox', 'safari'\n        }\n        axis {\n            name 'ARCHITECTURE"
  },
  "4544": {
    "source_file": "syntax.txt",
    "text": "    axis {\n            name 'BROWSER'\n            values 'chrome', 'edge', 'firefox', 'safari'\n        }\n        axis {\n            name 'ARCHITECTURE'\n            values '32-bit', '64-bit'\n        }\n    }\n    // ...\n}\n\n=====\n\n[[matrix-stages]]\n\nThe `stages` section specifies one or more ``stage``s to be executed sequentially in each cell.\nThis section is identical to any other <<#sequential-stage"
  },
  "4545": {
    "source_file": "syntax.txt",
    "text": "`stages` section specifies one or more ``stage``s to be executed sequentially in each cell.\nThis section is identical to any other <<#sequential-stages, `stages` section>>.\n\n[[matrix-stages-example]]\n\n.One-axis with 3 cells, each cell runs three stages - \"build\", \"test\", and \"deploy\"\n=====\n\nmatrix {\n    axes {\n        axis {\n            name 'PLATFORM'\n            values 'linux', 'mac', 'windows'\n"
  },
  "4546": {
    "source_file": "syntax.txt",
    "text": "es - \"build\", \"test\", and \"deploy\"\n=====\n\nmatrix {\n    axes {\n        axis {\n            name 'PLATFORM'\n            values 'linux', 'mac', 'windows'\n        }\n    }\n    stages {\n        stage('build') {\n            // ...\n        }\n        stage('test') {\n            // ...\n        }\n        stage('deploy') {\n            // ...\n        }\n    }\n}\n\n=====\n\n.Two-axis with 12 cells (three by four)\n==="
  },
  "4547": {
    "source_file": "syntax.txt",
    "text": "st') {\n            // ...\n        }\n        stage('deploy') {\n            // ...\n        }\n    }\n}\n\n=====\n\n.Two-axis with 12 cells (three by four)\n=====\n\nmatrix {\n    axes {\n        axis {\n            name 'PLATFORM'\n            values 'linux', 'mac', 'windows'\n        }\n        axis {\n            name 'BROWSER'\n            values 'chrome', 'edge', 'firefox', 'safari'\n        }\n    }\n    stages {\n"
  },
  "4548": {
    "source_file": "syntax.txt",
    "text": ", 'windows'\n        }\n        axis {\n            name 'BROWSER'\n            values 'chrome', 'edge', 'firefox', 'safari'\n        }\n    }\n    stages {\n        stage('build-and-test') {\n            // ...\n        }\n    }\n}\n\n=====\n\n[[matrix-excludes]]\n\nThe optional `excludes` section lets authors specify one or more `exclude` filter expressions that select cells to be excluded from the expanded set o"
  },
  "4549": {
    "source_file": "syntax.txt",
    "text": "The optional `excludes` section lets authors specify one or more `exclude` filter expressions that select cells to be excluded from the expanded set of matrix cells (aka, sparsening).\nFilters are constructed using a basic directive structure of one or more of exclude `axis` directives each with a `name` and `values` list.\n\nThe `axis` directives inside an `exclude` generate a set of combinations (s"
  },
  "4550": {
    "source_file": "syntax.txt",
    "text": "r more of exclude `axis` directives each with a `name` and `values` list.\n\nThe `axis` directives inside an `exclude` generate a set of combinations (similar to generating the matrix cells).\nThe matrix cells that match all the values from an `exclude` combination are removed from the matrix.\nIf more than one `exclude` directive is supplied, each is evaluated separately to remove cells.\n\nWhen dealin"
  },
  "4551": {
    "source_file": "syntax.txt",
    "text": " combination are removed from the matrix.\nIf more than one `exclude` directive is supplied, each is evaluated separately to remove cells.\n\nWhen dealing with a long list of values to exclude, exclude `axis` directives can use `notValues` instead of `values`.\nThese will exclude cells that *do not* match one of the values passed to `notValues`.\n\n[[matrix-excludes-example]]\n.Three-axis matrix with 24 "
  },
  "4552": {
    "source_file": "syntax.txt",
    "text": "alues`.\nThese will exclude cells that *do not* match one of the values passed to `notValues`.\n\n[[matrix-excludes-example]]\n.Three-axis matrix with 24 cells, exclude '32-bit, mac' (4 cells excluded)\n=====\n\nmatrix {\n    axes {\n        axis {\n            name 'PLATFORM'\n            values 'linux', 'mac', 'windows'\n        }\n        axis {\n            name 'BROWSER'\n            values 'chrome', 'edge'"
  },
  "4553": {
    "source_file": "syntax.txt",
    "text": "  name 'PLATFORM'\n            values 'linux', 'mac', 'windows'\n        }\n        axis {\n            name 'BROWSER'\n            values 'chrome', 'edge', 'firefox', 'safari'\n        }\n        axis {\n            name 'ARCHITECTURE'\n            values '32-bit', '64-bit'\n        }\n    }\n    excludes {\n        exclude {\n            axis {\n                name 'PLATFORM'\n                values 'mac'\n    "
  },
  "4554": {
    "source_file": "syntax.txt",
    "text": "2-bit', '64-bit'\n        }\n    }\n    excludes {\n        exclude {\n            axis {\n                name 'PLATFORM'\n                values 'mac'\n            }\n            axis {\n                name 'ARCHITECTURE'\n                values '32-bit'\n            }\n        }\n    }\n    // ...\n}\n\n=====\n\nExclude the `linux, safari` combination and exclude any platform that is *not* `windows` with the `edg"
  },
  "4555": {
    "source_file": "syntax.txt",
    "text": "         }\n        }\n    }\n    // ...\n}\n\n=====\n\nExclude the `linux, safari` combination and exclude any platform that is *not* `windows` with the `edge` browser.\n\n.Three-axis matrix with 24 cells, exclude '32-bit, mac' and invalid browser combinations (9 cells excluded)\n=====\n\nmatrix {\n    axes {\n        axis {\n            name 'PLATFORM'\n            values 'linux', 'mac', 'windows'\n        }\n    "
  },
  "4556": {
    "source_file": "syntax.txt",
    "text": "s (9 cells excluded)\n=====\n\nmatrix {\n    axes {\n        axis {\n            name 'PLATFORM'\n            values 'linux', 'mac', 'windows'\n        }\n        axis {\n            name 'BROWSER'\n            values 'chrome', 'edge', 'firefox', 'safari'\n        }\n        axis {\n            name 'ARCHITECTURE'\n            values '32-bit', '64-bit'\n        }\n    }\n    excludes {\n        exclude {\n           "
  },
  "4557": {
    "source_file": "syntax.txt",
    "text": "   }\n        axis {\n            name 'ARCHITECTURE'\n            values '32-bit', '64-bit'\n        }\n    }\n    excludes {\n        exclude {\n            // 4 cells\n            axis {\n                name 'PLATFORM'\n                values 'mac'\n            }\n            axis {\n                name 'ARCHITECTURE'\n                values '32-bit'\n            }\n        }\n        exclude {\n            // "
  },
  "4558": {
    "source_file": "syntax.txt",
    "text": "    }\n            axis {\n                name 'ARCHITECTURE'\n                values '32-bit'\n            }\n        }\n        exclude {\n            // 2 cells\n            axis {\n                name 'PLATFORM'\n                values 'linux'\n            }\n            axis {\n                name 'BROWSER'\n                values 'safari'\n            }\n        }\n        exclude {\n            // 3 more "
  },
  "4559": {
    "source_file": "syntax.txt",
    "text": "  }\n            axis {\n                name 'BROWSER'\n                values 'safari'\n            }\n        }\n        exclude {\n            // 3 more cells and '32-bit, mac' (already excluded)\n            axis {\n                name 'PLATFORM'\n                notValues 'windows'\n            }\n            axis {\n                name 'BROWSER'\n                values 'edge'\n            }\n        }\n  "
  },
  "4560": {
    "source_file": "syntax.txt",
    "text": "          notValues 'windows'\n            }\n            axis {\n                name 'BROWSER'\n                values 'edge'\n            }\n        }\n    }\n    // ...\n}\n\n=====\n\n[[matrix-cell-directives]]\n\nMatrix lets users efficiently configure the overall environment for each cell, by adding stage-level directives under `matrix` itself.\nThese directives behave the same as they would on a stage but "
  },
  "4561": {
    "source_file": "syntax.txt",
    "text": "rall environment for each cell, by adding stage-level directives under `matrix` itself.\nThese directives behave the same as they would on a stage but they can also accept values provided by the matrix for each cell.\n\nThe `axis` and `exclude` directives define the static set of cells that make up the matrix.\nThat set of combinations is generated before the start of the pipeline run.\nThe \"per-cell\" "
  },
  "4562": {
    "source_file": "syntax.txt",
    "text": "es define the static set of cells that make up the matrix.\nThat set of combinations is generated before the start of the pipeline run.\nThe \"per-cell\" directives, on the other hand, are evaluated at runtime.\n\nThese directives include:\n\n* <<agent>>\n* <<environment>>\n* <<input>>\n* <<options>>\n* <<post>>\n* <<tools>>\n* <<when>>\n\n[[matrix-cell-example]]\n.Complete Matrix Example, Declarative Pipeline\n==="
  },
  "4563": {
    "source_file": "syntax.txt",
    "text": "<environment>>\n* <<input>>\n* <<options>>\n* <<post>>\n* <<tools>>\n* <<when>>\n\n[[matrix-cell-example]]\n.Complete Matrix Example, Declarative Pipeline\n=====\n\npipeline {\n    parameters {\n        choice(name: 'PLATFORM_FILTER', choices: ['all', 'linux', 'windows', 'mac'], description: 'Run on specific platform')\n    }\n    agent none\n    stages {\n        stage('BuildAndTest') {\n            matrix {\n     "
  },
  "4564": {
    "source_file": "syntax.txt",
    "text": "indows', 'mac'], description: 'Run on specific platform')\n    }\n    agent none\n    stages {\n        stage('BuildAndTest') {\n            matrix {\n                agent {\n                    label \"${PLATFORM}-agent\"\n                }\n                when { anyOf {\n                    expression { params.PLATFORM_FILTER == 'all' }\n                    expression { params.PLATFORM_FILTER == env.PLATFO"
  },
  "4565": {
    "source_file": "syntax.txt",
    "text": "hen { anyOf {\n                    expression { params.PLATFORM_FILTER == 'all' }\n                    expression { params.PLATFORM_FILTER == env.PLATFORM }\n                } }\n                axes {\n                    axis {\n                        name 'PLATFORM'\n                        values 'linux', 'windows', 'mac'\n                    }\n                    axis {\n                        name "
  },
  "4566": {
    "source_file": "syntax.txt",
    "text": "ame 'PLATFORM'\n                        values 'linux', 'windows', 'mac'\n                    }\n                    axis {\n                        name 'BROWSER'\n                        values 'firefox', 'chrome', 'safari', 'edge'\n                    }\n                }\n                excludes {\n                    exclude {\n                        axis {\n                            name 'PLATFORM'"
  },
  "4567": {
    "source_file": "syntax.txt",
    "text": "\n                }\n                excludes {\n                    exclude {\n                        axis {\n                            name 'PLATFORM'\n                            values 'linux'\n                        }\n                        axis {\n                            name 'BROWSER'\n                            values 'safari'\n                        }\n                    }\n              "
  },
  "4568": {
    "source_file": "syntax.txt",
    "text": "\n                            name 'BROWSER'\n                            values 'safari'\n                        }\n                    }\n                    exclude {\n                        axis {\n                            name 'PLATFORM'\n                            notValues 'windows'\n                        }\n                        axis {\n                            name 'BROWSER'\n           "
  },
  "4569": {
    "source_file": "syntax.txt",
    "text": "                   notValues 'windows'\n                        }\n                        axis {\n                            name 'BROWSER'\n                            values 'edge'\n                        }\n                    }\n                }\n                stages {\n                    stage('Build') {\n                        steps {\n                            echo \"Do Build for ${PLATFORM} "
  },
  "4570": {
    "source_file": "syntax.txt",
    "text": "             stages {\n                    stage('Build') {\n                        steps {\n                            echo \"Do Build for ${PLATFORM} - ${BROWSER}\"\n                        }\n                    }\n                    stage('Test') {\n                        steps {\n                            echo \"Do Test for ${PLATFORM} - ${BROWSER}\"\n                        }\n                    }\n"
  },
  "4571": {
    "source_file": "syntax.txt",
    "text": "                      steps {\n                            echo \"Do Test for ${PLATFORM} - ${BROWSER}\"\n                        }\n                    }\n                }\n            }\n        }\n    }\n}\n\n=====\n\n[[declarative-steps]]\n\nDeclarative Pipelines may use all the available steps documented in the , which contains a comprehensive list of steps, with the addition of the steps listed below which"
  },
  "4572": {
    "source_file": "syntax.txt",
    "text": "es may use all the available steps documented in the , which contains a comprehensive list of steps, with the addition of the steps listed below which are *only supported* in Declarative Pipeline.\n\nThe `script` step takes a block of <<scripted-pipeline>> and executes that in the Declarative Pipeline.\nFor most use-cases, the `script` step should be unnecessary in Declarative Pipelines, but it can p"
  },
  "4573": {
    "source_file": "syntax.txt",
    "text": "ne>> and executes that in the Declarative Pipeline.\nFor most use-cases, the `script` step should be unnecessary in Declarative Pipelines, but it can provide a useful \"escape hatch\".\n`script` blocks of non-trivial size and/or complexity should be moved into <<shared-libraries#, Shared Libraries>> instead.\n\n[[script-example]]\n.Script Block in Declarative Pipeline\n=====\n\npipeline {\n    agent any\n    "
  },
  "4574": {
    "source_file": "syntax.txt",
    "text": "d into <<shared-libraries#, Shared Libraries>> instead.\n\n[[script-example]]\n.Script Block in Declarative Pipeline\n=====\n\npipeline {\n    agent any\n    stages {\n        stage('Example') {\n            steps {\n                echo 'Hello World'\n\n                script {\n                    def browsers = ['chrome', 'firefox']\n                    for (int i = 0; i < browsers.size(); ++i) {\n            "
  },
  "4575": {
    "source_file": "syntax.txt",
    "text": "        script {\n                    def browsers = ['chrome', 'firefox']\n                    for (int i = 0; i < browsers.size(); ++i) {\n                        echo \"Testing the ${browsers[i]} browser\"\n                    }\n                }\n            }\n        }\n    }\n}\n\n=====\n\n[[scripted-pipeline]]\n\nScripted Pipeline, like <<declarative-pipeline>>, is built on top of the underlying Pipeline "
  },
  "4576": {
    "source_file": "syntax.txt",
    "text": "      }\n        }\n    }\n}\n\n=====\n\n[[scripted-pipeline]]\n\nScripted Pipeline, like <<declarative-pipeline>>, is built on top of the underlying Pipeline sub-system.\nUnlike Declarative, Scripted Pipeline is effectively a general-purpose DSL footnote:dsl[] built with .\nMost functionality provided by the Groovy language is made available to users of Scripted Pipeline, which means it can be a very expres"
  },
  "4577": {
    "source_file": "syntax.txt",
    "text": "] built with .\nMost functionality provided by the Groovy language is made available to users of Scripted Pipeline, which means it can be a very expressive and flexible tool with which one can author continuous delivery pipelines.\n\nScripted Pipeline is serially executed from the top of a `Jenkinsfile` downwards, like most traditional scripts in Groovy or other languages.\nProviding flow control, the"
  },
  "4578": {
    "source_file": "syntax.txt",
    "text": "s serially executed from the top of a `Jenkinsfile` downwards, like most traditional scripts in Groovy or other languages.\nProviding flow control, therefore, rests on Groovy expressions, such as the `if/else` conditionals, for example:\n\n.Conditional Statement `if`, Scripted Pipeline\n=====\n\nnode {\n    stage('Example') {\n        if (env.BRANCH_NAME == 'master') {\n            echo 'I only execute on "
  },
  "4579": {
    "source_file": "syntax.txt",
    "text": "Statement `if`, Scripted Pipeline\n=====\n\nnode {\n    stage('Example') {\n        if (env.BRANCH_NAME == 'master') {\n            echo 'I only execute on the master branch'\n        } else {\n            echo 'I execute elsewhere'\n        }\n    }\n}\n\n=====\n\nAnother way Scripted Pipeline flow control can be managed is with Groovy's exception handling support.\nWhen <<scripted-steps>> fail for whatever reas"
  },
  "4580": {
    "source_file": "syntax.txt",
    "text": "\nAnother way Scripted Pipeline flow control can be managed is with Groovy's exception handling support.\nWhen <<scripted-steps>> fail for whatever reason they throw an exception.\nHandling behaviors on-error must make use of the `try/catch/finally` blocks in Groovy, for example:\n\n.Try-Catch Block, Scripted Pipeline\n=====\n\nnode {\n    stage('Example') {\n        try {\n            sh 'exit 1'\n        }\n"
  },
  "4581": {
    "source_file": "syntax.txt",
    "text": "cks in Groovy, for example:\n\n.Try-Catch Block, Scripted Pipeline\n=====\n\nnode {\n    stage('Example') {\n        try {\n            sh 'exit 1'\n        }\n        catch (exc) {\n            echo 'Something failed, I should sound the klaxons!'\n            throw\n        }\n    }\n}\n\n=====\n\n[[scripted-steps]]\n\nAs discussed at the , the most fundamental part of a Pipeline is the \"step\".\nFundamentally, steps t"
  },
  "4582": {
    "source_file": "syntax.txt",
    "text": "hrow\n        }\n    }\n}\n\n=====\n\n[[scripted-steps]]\n\nAs discussed at the , the most fundamental part of a Pipeline is the \"step\".\nFundamentally, steps tell Jenkins _what_ to do and serve as the basic building block for both Declarative and Scripted Pipeline syntax.\n\nScripted Pipeline does *not* introduce any steps which are specific to its syntax;  contains a comprehensive list of steps provided by "
  },
  "4583": {
    "source_file": "syntax.txt",
    "text": "eline syntax.\n\nScripted Pipeline does *not* introduce any steps which are specific to its syntax;  contains a comprehensive list of steps provided by Pipeline and plugins.\n\nIn order to provide _durability_, which means that running Pipelines can survive a restart of the Jenkins <<../glossary#controller, controller>>, Scripted Pipeline must serialize data back to the controller.\nDue to this design "
  },
  "4584": {
    "source_file": "syntax.txt",
    "text": "ive a restart of the Jenkins <<../glossary#controller, controller>>, Scripted Pipeline must serialize data back to the controller.\nDue to this design requirement, some Groovy idioms such as `collection.each { item -> /* perform operation */ }` are not fully supported.\nRefer to https://issues.jenkins.io/browse/JENKINS-27421[JENKINS-27421] and https://issues.jenkins.io/browse/JENKINS-26481[JENKINS-2"
  },
  "4585": {
    "source_file": "syntax.txt",
    "text": "t fully supported.\nRefer to https://issues.jenkins.io/browse/JENKINS-27421[JENKINS-27421] and https://issues.jenkins.io/browse/JENKINS-26481[JENKINS-26481] for more information.\n\n[[compare]]\n\nvideo::GJBlskiaRrI[youtube,width=800,height=420]\nThis video shares some differences between Scripted and Declarative Pipeline syntax.\n\nWhen Jenkins Pipeline was first created, Groovy was selected as the found"
  },
  "4586": {
    "source_file": "syntax.txt",
    "text": "o shares some differences between Scripted and Declarative Pipeline syntax.\n\nWhen Jenkins Pipeline was first created, Groovy was selected as the foundation.\nJenkins has long shipped with an embedded Groovy engine to provide advanced scripting capabilities for admins and users alike.\nAdditionally, the implementors of Jenkins Pipeline found Groovy to be a solid foundation upon which to build what is"
  },
  "4587": {
    "source_file": "syntax.txt",
    "text": "ities for admins and users alike.\nAdditionally, the implementors of Jenkins Pipeline found Groovy to be a solid foundation upon which to build what is now referred to as the \"Scripted Pipeline\" DSL. footnote:dsl[].\n\nAs it is a fully-featured programming environment, Scripted Pipeline offers a tremendous amount of flexibility and extensibility to Jenkins users.\nThe Groovy learning-curve isn't typic"
  },
  "4588": {
    "source_file": "syntax.txt",
    "text": "ing environment, Scripted Pipeline offers a tremendous amount of flexibility and extensibility to Jenkins users.\nThe Groovy learning-curve isn't typically desirable for all members of a given team, so Declarative Pipeline was created to offer a simpler and more opinionated syntax for authoring Jenkins Pipeline.\n\nBoth are fundamentally the same Pipeline sub-system underneath.\nThey are both durable "
  },
  "4589": {
    "source_file": "syntax.txt",
    "text": "er and more opinionated syntax for authoring Jenkins Pipeline.\n\nBoth are fundamentally the same Pipeline sub-system underneath.\nThey are both durable implementations of \"Pipeline as code\".\nThey are both able to use steps built into Pipeline or provided by plugins.\nBoth are able to utilize <<shared-libraries#, Shared Libraries>>\n\nWhere they differ however is in syntax and flexibility.\nDeclarative l"
  },
  "4590": {
    "source_file": "syntax.txt",
    "text": "ed by plugins.\nBoth are able to utilize <<shared-libraries#, Shared Libraries>>\n\nWhere they differ however is in syntax and flexibility.\nDeclarative limits what is available to the user with a more strict and pre-defined structure, making it an ideal choice for simpler continuous delivery pipelines.\nScripted provides very few limits, insofar that the only limits on structure and syntax tend to be "
  },
  "4591": {
    "source_file": "syntax.txt",
    "text": " choice for simpler continuous delivery pipelines.\nScripted provides very few limits, insofar that the only limits on structure and syntax tend to be defined by Groovy itself, rather than any Pipeline-specific systems, making it an ideal choice for power-users and those with more complex\nrequirements.\nAs the name implies, Declarative Pipeline encourages a declarative programming model.\nfootnote:de"
  },
  "4592": {
    "source_file": "syntax.txt",
    "text": "ower-users and those with more complex\nrequirements.\nAs the name implies, Declarative Pipeline encourages a declarative programming model.\nfootnote:declarative[]\nWhereas Scripted Pipelines follow a more imperative programming model.\nfootnote:imperative[]"
  },
  "4593": {
    "source_file": "syntax.txt",
    "text": "ve[]"
  },
  "4594": {
    "source_file": "system-configuration.txt",
    "text": "layout: section\ntitle: Configuring the System\n\n\nJenkins stores its global configuration in files on the Jenkins controller.\nAdministrators and privileged users modify the global configuration from the Jenkins configuration pages.\n\nThe `JENKINS_HOME` directory is the root of the disk directory structure that Jenkins uses to perform builds and store archives.\nThe Jenkins home directory is listed in "
  },
  "4595": {
    "source_file": "system-configuration.txt",
    "text": "directory is the root of the disk directory structure that Jenkins uses to perform builds and store archives.\nThe Jenkins home directory is listed in *Manage Jenkins* > *System* under the *Home directory* heading.\n\n* On Windows by default, this is set to `C:\\ProgramData\\Jenkins\\.jenkins`.\n* On Ubuntu by default, this is set to `/var/lib/jenkins`.\n\nDefault `JENKINS_HOME` locations vary by installat"
  },
  "4596": {
    "source_file": "system-configuration.txt",
    "text": "t to `C:\\ProgramData\\Jenkins\\.jenkins`.\n* On Ubuntu by default, this is set to `/var/lib/jenkins`.\n\nDefault `JENKINS_HOME` locations vary by installation method:\n\n* *Windows installer*: C:\\ProgramData\\Jenkins\\.jenkins\n* *Running from the `.war` file*: ~/.jenkins\n* *Debian/Ubuntu package (`apt install jenkins`)*: /var/lib/jenkins\n* *Red Hat package (`yum install jenkins`)*: /var/lib/jenkins\n* *Fedo"
  },
  "4597": {
    "source_file": "system-configuration.txt",
    "text": ": ~/.jenkins\n* *Debian/Ubuntu package (`apt install jenkins`)*: /var/lib/jenkins\n* *Red Hat package (`yum install jenkins`)*: /var/lib/jenkins\n* *Fedora package (`dnf install jenkins`)*: /var/lib/jenkins\n* *openSUSE package (`zypper install jenkins`)*: /var/lib/jenkins\n\nBut you can change this in one of the following ways:\n\n* Set the `JENKINS_HOME` environment variable.\n* Set the `JENKINS_HOME` Ja"
  },
  "4598": {
    "source_file": "system-configuration.txt",
    "text": "*: /var/lib/jenkins\n\nBut you can change this in one of the following ways:\n\n* Set the `JENKINS_HOME` environment variable.\n* Set the `JENKINS_HOME` Java system property.\n\nYou can change this location after you've used Jenkins for a while, too.\nTo do this:\n\nStop Jenkins completely.\nMove the contents from the old `JENKINS_HOME` to the new location.\nSet the `JENKINS_HOME` variable to the new location"
  },
  "4599": {
    "source_file": "system-configuration.txt",
    "text": "this:\n\nStop Jenkins completely.\nMove the contents from the old `JENKINS_HOME` to the new location.\nSet the `JENKINS_HOME` variable to the new location.\nRestart Jenkins.\n\nThe directory structure of the `JENKINS_HOME` tree is often structured as follows:\n[width=\"100%\",cols=\"100%\",]\n|===\na|\n....\nJENKINS_HOME\n +- builds            (build records)\n    +- [BUILD_ID]     (subdirectory for each build)\n   "
  },
  "4600": {
    "source_file": "system-configuration.txt",
    "text": "s:\n[width=\"100%\",cols=\"100%\",]\n|===\na|\n....\nJENKINS_HOME\n +- builds            (build records)\n    +- [BUILD_ID]     (subdirectory for each build)\n         +- build.xml      (build result summary)\n         +- changelog.xml  (change log)\n +- config.xml         (Jenkins root configuration file)\n +- *.xml              (other site-wide configuration files)\n +- fingerprints       (stores fingerprint re"
  },
  "4601": {
    "source_file": "system-configuration.txt",
    "text": "l         (Jenkins root configuration file)\n +- *.xml              (other site-wide configuration files)\n +- fingerprints       (stores fingerprint records, if any)\n +- identity.key.enc   (RSA key pair that identifies an instance)\n +- jobs               (root directory for all Jenkins jobs)\n     +- [JOBNAME]      (sub directory for each job)\n         +- config.xml (job configuration file)\n     +- "
  },
  "4602": {
    "source_file": "system-configuration.txt",
    "text": "    (root directory for all Jenkins jobs)\n     +- [JOBNAME]      (sub directory for each job)\n         +- config.xml (job configuration file)\n     +- [FOLDERNAME]   (sub directory for each folder)\n         +- config.xml (folder configuration file)\n         +- jobs       (subdirectory for all nested jobs)\n +- plugins            (root directory for all Jenkins plugins)\n     +- [PLUGIN]       (sub di"
  },
  "4603": {
    "source_file": "system-configuration.txt",
    "text": "       +- jobs       (subdirectory for all nested jobs)\n +- plugins            (root directory for all Jenkins plugins)\n     +- [PLUGIN]       (sub directory for each plugin)\n     +- [PLUGIN].jpi   (.jpi or .hpi file for the plugin)\n +- secret.key         (deprecated key used for some plugins' secure operations)\n +- secret.key.not-so-secret  (used for validating _$JENKINS_HOME_ creation date)\n +- "
  },
  "4604": {
    "source_file": "system-configuration.txt",
    "text": "      (deprecated key used for some plugins' secure operations)\n +- secret.key.not-so-secret  (used for validating _$JENKINS_HOME_ creation date)\n +- secrets        (root directory for the secret+key for credential decryption)\n     +- hudson.util.Secret   (used for encrypting some Jenkins data)\n     +- master.key           (used for encrypting the hudson.util.Secret key)\n     +- InstanceIdentity.K"
  },
  "4605": {
    "source_file": "system-configuration.txt",
    "text": "ret   (used for encrypting some Jenkins data)\n     +- master.key           (used for encrypting the hudson.util.Secret key)\n     +- InstanceIdentity.KEY (used to identity this instance)\n     +- jenkins.model.Jenkins.crumbSalt   (used for encrypting some Jenkins data)\n     +- initialAdminPassword (used for initial login)\n +- userContent        (files served under your https://server/userContent/)\n "
  },
  "4606": {
    "source_file": "system-configuration.txt",
    "text": "ome Jenkins data)\n     +- initialAdminPassword (used for initial login)\n +- userContent        (files served under your https://server/userContent/)\n +- workspace          (working directory for the version control system)\n....\n|===\n\nThe *Configure System* page (`/manage/configure`) allows administrators to configure global settings for the Jenkins controller.\nBelow are the key sections available "
  },
  "4607": {
    "source_file": "system-configuration.txt",
    "text": "ystem* page (`/manage/configure`) allows administrators to configure global settings for the Jenkins controller.\nBelow are the key sections available on this page:\n\nThe system message is displayed at the top of every page in Jenkins.\nIt can be used to communicate important information to all users, such as maintenance schedules or announcements.\n\nExample:\n\nThe system is undergoing maintenance on Y"
  },
  "4608": {
    "source_file": "system-configuration.txt",
    "text": "o communicate important information to all users, such as maintenance schedules or announcements.\n\nExample:\n\nThe system is undergoing maintenance on YYYY-MM-DD.\nExpect downtime.\n\nThe quiet period defines a delay before a build starts after a change is detected. This helps avoid triggering multiple builds for closely spaced changes.\n\nExample:\n\nSet a quiet period of 5 seconds to batch changes.\n\nThis"
  },
  "4609": {
    "source_file": "system-configuration.txt",
    "text": "s detected. This helps avoid triggering multiple builds for closely spaced changes.\n\nExample:\n\nSet a quiet period of 5 seconds to batch changes.\n\nThis is particularly useful for version control integrations, where commits may occur in quick succession.\n\nThis section defines the URL of the Jenkins controller.\nIt is important for proper communication with agents and external tools.\nIf Jenkins is beh"
  },
  "4610": {
    "source_file": "system-configuration.txt",
    "text": "n.\n\nThis section defines the URL of the Jenkins controller.\nIt is important for proper communication with agents and external tools.\nIf Jenkins is behind a reverse proxy, ensure the URL matches the proxy configuration.\n\nFor detailed instructions on configuring a reverse proxy, refer to the  guide.\n\nJenkins collects anonymous usage statistics to help improve the software. This section allows you to"
  },
  "4611": {
    "source_file": "system-configuration.txt",
    "text": "onfiguring a reverse proxy, refer to the  guide.\n\nJenkins collects anonymous usage statistics to help improve the software. This section allows you to opt-in or opt-out of this feature.\n\nMany plugins add their own global configuration options to the *Configure System* page. Since plugins extend Jenkins functionality, their settings often appear in this section and provide options for customization"
  },
  "4612": {
    "source_file": "system-configuration.txt",
    "text": "*Configure System* page. Since plugins extend Jenkins functionality, their settings often appear in this section and provide options for customization and fine-tuning.\nRefer to the online help for each plugin to understand these settings.\n\n*Tip:* Use the question mark (`?`) icon next to each setting to access detailed help for that specific configuration.\n\n*\n*\n*"
  },
  "4613": {
    "source_file": "system-configuration.txt",
    "text": " the question mark (`?`) icon next to each setting to access detailed help for that specific configuration.\n\n*\n*\n*"
  },
  "4614": {
    "source_file": "system-info.txt",
    "text": "layout: section\n\n\nifdef::env-github[:imagesdir: ../resources]\nifndef::env-github[:imagesdir: ../../resources]\n\nThe *Manage Jenkins >> System Information* page provides detailed information\nabout what is available on this Jenkins controller:\n\nThe *System Properties* section lists system properties that can be used as arguments to the command line used to start Jenkins.\n\nThe *Environment Variables* "
  },
  "4615": {
    "source_file": "system-info.txt",
    "text": "tem Properties* section lists system properties that can be used as arguments to the command line used to start Jenkins.\n\nThe *Environment Variables* section displays environment variables recognized on your system with their current values.\nThis includes the environment variables defined by Jenkins that are available on all systems, as well as environment variables associated with plugins install"
  },
  "4616": {
    "source_file": "system-info.txt",
    "text": "ludes the environment variables defined by Jenkins that are available on all systems, as well as environment variables associated with plugins installed on this controller.\n\nThe *Plugins* section provides a comprehensive list of all installed plugins, including their names, versions, and other relevant details.\n\nThe *Memory Usage* section provides a graphical representation of the controller's mem"
  },
  "4617": {
    "source_file": "system-info.txt",
    "text": ", including their names, versions, and other relevant details.\n\nThe *Memory Usage* section provides a graphical representation of the controller's memory usage, categorized into three timespans for better analysis:\n\n- **Short**: The short timespan covers memory usage over the last few minutes, broken down by seconds, for real-time monitoring.\n\n- **Medium**: The medium timespan displays memory tren"
  },
  "4618": {
    "source_file": "system-info.txt",
    "text": "vers memory usage over the last few minutes, broken down by seconds, for real-time monitoring.\n\n- **Medium**: The medium timespan displays memory trends over the past hour, broken down by minutes, which is useful for detecting gradual memory leaks.\n\n- **Long**: The long timespan illustrates extended memory usage patterns over a day or month to identify recurring issues.\nThis breakdown allows admin"
  },
  "4619": {
    "source_file": "system-info.txt",
    "text": "- **Long**: The long timespan illustrates extended memory usage patterns over a day or month to identify recurring issues.\nThis breakdown allows administrators to monitor memory trends, detect unusual spikes, and optimize resource allocation.\n\nThe **Thread Dump** section provides a link to a page that captures a real-time snapshot of all active threads running in the Jenkins controller\u2019s JVM. This"
  },
  "4620": {
    "source_file": "system-info.txt",
    "text": "Thread Dump** section provides a link to a page that captures a real-time snapshot of all active threads running in the Jenkins controller\u2019s JVM. This is essential for diagnosing performance issues, deadlocks, or excessive CPU utilization.\n\nEach thread entry includes:\n\n**Name**: The thread identifier.\n**ID**: The unique thread ID.\n**State**: The current execution state (RUNNABLE, TIMED_WAITING, BL"
  },
  "4621": {
    "source_file": "system-info.txt",
    "text": "ad entry includes:\n\n**Name**: The thread identifier.\n**ID**: The unique thread ID.\n**State**: The current execution state (RUNNABLE, TIMED_WAITING, BLOCKED).\n**Stack Trace**: The call sequence leading to the current state."
  },
  "4622": {
    "source_file": "system-properties.txt",
    "text": "layout: systemproperties\nreferences:\n- url: https://wiki.jenkins.io/display/JENKINS/Administering+Jenkins\n  title: Administering Jenkins\n- url: http://jenkins.io/doc/book/installing/#configuring-http\n  title: Configuring HTTP in Jenkins\n- url: https://github.com/jenkinsci/remoting/blob/master/docs/configuration.md\n  title: Remoting configuration\nproperties:\n# Style guide:\n# - Prefer literal blocks"
  },
  "4623": {
    "source_file": "system-properties.txt",
    "text": "//github.com/jenkinsci/remoting/blob/master/docs/configuration.md\n  title: Remoting configuration\nproperties:\n# Style guide:\n# - Prefer literal blocks over quoted blocks when necessary\n# - Format literal default values in `backticks` and descriptive parts of values outside backticks\n# - Use sentence-per-line formatting for descriptions\n\n# Tags:\n# - development: Mostly or only useful during develop"
  },
  "4624": {
    "source_file": "system-properties.txt",
    "text": "parts of values outside backticks\n# - Use sentence-per-line formatting for descriptions\n\n# Tags:\n# - development: Mostly or only useful during development and debugging. While in rare cases these may help troubleshoot an instance, primary use is development.\n# - escape hatch: Disables a behavior that is not generally expected to be disabled, such as security fixes. Intended to address unexpected c"
  },
  "4625": {
    "source_file": "system-properties.txt",
    "text": "lopment.\n# - escape hatch: Disables a behavior that is not generally expected to be disabled, such as security fixes. Intended to address unexpected compatibility problems.\n# - feature: Enables (or rarely disables) a feature. Distinction to escape hatches is fuzzy when it disables.\n# - internal: Not intended to be set by administrators, developers, or packaging scripts at all. Very rare.\n# - obsol"
  },
  "4626": {
    "source_file": "system-properties.txt",
    "text": "tches is fuzzy when it disables.\n# - internal: Not intended to be set by administrators, developers, or packaging scripts at all. Very rare.\n# - obsolete: This option no longer has an effect or a different option should be used instead.\n# - packaging: Options generally only useful when customizing the Jenkins packaging.\n# - security: Related to security, both security fixes, and hardening. Usually"
  },
  "4627": {
    "source_file": "system-properties.txt",
    "text": ": Options generally only useful when customizing the Jenkins packaging.\n# - security: Related to security, both security fixes, and hardening. Usually also escape hatches.\n# - tuning: Adjust thresholds, durations, and values of a similar nature that don't substantially alter behavior.\n# - ui: User interface related.\n\n- name: debug.YUI\n  tags:\n  - development\n  since: December 2006 # https://github"
  },
  "4628": {
    "source_file": "system-properties.txt",
    "text": "don't substantially alter behavior.\n# - ui: User interface related.\n\n- name: debug.YUI\n  tags:\n  - development\n  since: December 2006 # https://github.com/jenkinsci/jenkins/commit/ab68a9fce7672649b797ea6ff46f88c965e2404b\n  def: |\n    `false`\n  description: |\n    Whether to use the minified (`false`) or debug (`true`) JS files for the YUI library.\n\n- name: executable-war\n  def: |\n    Path to `jenki"
  },
  "4629": {
    "source_file": "system-properties.txt",
    "text": "ption: |\n    Whether to use the minified (`false`) or debug (`true`) JS files for the YUI library.\n\n- name: executable-war\n  def: |\n    Path to `jenkins.war` when invoked as `java -jar jenkins.war`, undefined otherwise.\n  tags:\n  - packaging\n  description: |\n    This is the path to `jenkins.war` and set by `executable.Main` when invoked using `java -jar jenkins.war`.\n    This allows Jenkins to fin"
  },
  "4630": {
    "source_file": "system-properties.txt",
    "text": "ption: |\n    This is the path to `jenkins.war` and set by `executable.Main` when invoked using `java -jar jenkins.war`.\n    This allows Jenkins to find its own `.war` file and e.g. replace it to apply an update.\n    If undefined, Jenkins will not e.g. offer to update itself.\n\n- name: hudson.bundled.plugins\n  tags:\n  - development\n  def: undefined\n  description: |\n    Specify a location for additio"
  },
  "4631": {
    "source_file": "system-properties.txt",
    "text": ". offer to update itself.\n\n- name: hudson.bundled.plugins\n  tags:\n  - development\n  def: undefined\n  description: |\n    Specify a location for additional bundled plugins during plugin development (`hpi:run`).\n    There is no reason this would be set by an administrator.\n\n- name: hudson.ClassicPluginStrategy.noBytecodeTransformer\n  tags:\n  - escape hatch\n  - obsolete\n  def: |\n    `false`\n  since: 1"
  },
  "4632": {
    "source_file": "system-properties.txt",
    "text": "by an administrator.\n\n- name: hudson.ClassicPluginStrategy.noBytecodeTransformer\n  tags:\n  - escape hatch\n  - obsolete\n  def: |\n    `false`\n  since: 1.538 # https://github.com/jenkinsci/jenkins/commit/f98c4627da3c21e37aff82c75c0ef7240e60b4da\n  description: |\n    Disable the bytecode transformer that retains compatibility at runtime after changing public Java APIs.\n    Has no effect since 2.296, as"
  },
  "4633": {
    "source_file": "system-properties.txt",
    "text": "ption: |\n    Disable the bytecode transformer that retains compatibility at runtime after changing public Java APIs.\n    Has no effect since 2.296, as the bytecode transformer has been removed.\n\n- name: hudson.ClassicPluginStrategy.useAntClassLoader\n  tags:\n  - escape hatch\n  def: |\n    `false` (until 2.309 and since 2.348), `true` (from 2.310 to 2.347)\n  since: 1.316\n  # Unused since https://gith"
  },
  "4634": {
    "source_file": "system-properties.txt",
    "text": "  tags:\n  - escape hatch\n  def: |\n    `false` (until 2.309 and since 2.348), `true` (from 2.310 to 2.347)\n  since: 1.316\n  # Unused since https://github.com/jenkinsci/jenkins/commit/47de54d070f67af95b4fefb6d006a72bb31a5cb8\n  # Restored and default in https://github.com/jenkinsci/jenkins/pull/5698\n  # Disabled since https://github.com/jenkinsci/jenkins/pull/6571\n  description: |\n    Unused between "
  },
  "4635": {
    "source_file": "system-properties.txt",
    "text": " https://github.com/jenkinsci/jenkins/pull/5698\n  # Disabled since https://github.com/jenkinsci/jenkins/pull/6571\n  description: |\n    Unused between 1.527 and 2.309.\n    Since 2.310, can be set to `false` to use `URLClassLoader` instead.\n    This is the default since 2.347.\n\n- name: hudson.cli.CLI.pingInterval\n  tags:\n  - tuning\n  def: |\n    `3000`\n  since: 2.199\n  description: |\n    Client-side "
  },
  "4636": {
    "source_file": "system-properties.txt",
    "text": " the default since 2.347.\n\n- name: hudson.cli.CLI.pingInterval\n  tags:\n  - tuning\n  def: |\n    `3000`\n  since: 2.199\n  description: |\n    Client-side HTTP CLI ping interval in milliseconds.\n    Set on the CLI client (`java -jar jenkins-cli.jar`), not Jenkins server process.\n\n- name: hudson.cli.CLIAction.ALLOW_WEBSOCKET\n  tags:\n  - escape hatch\n  - security\n  def: undefined\n  since: 2.426.3 / 2.442"
  },
  "4637": {
    "source_file": "system-properties.txt",
    "text": " Jenkins server process.\n\n- name: hudson.cli.CLIAction.ALLOW_WEBSOCKET\n  tags:\n  - escape hatch\n  - security\n  def: undefined\n  since: 2.426.3 / 2.442\n  description: |\n    Escape hatch for .\n    The default behavior (when undefined) is to apply an `Origin` header check when an attempt is made to access the CLI via WebSocket.\n    Set to `true` to allow CLI access via WebSocket connections without `"
  },
  "4638": {
    "source_file": "system-properties.txt",
    "text": "rigin` header check when an attempt is made to access the CLI via WebSocket.\n    Set to `true` to allow CLI access via WebSocket connections without `Origin` header check (the default before introduction of this system property).\n    Set to `false` to prohibit CLI access via WebSocket connections completely.\n\n- name: hudson.cli.CLICommand.allowAtSyntax\n  tags:\n  - escape hatch\n  - security\n  def: "
  },
  "4639": {
    "source_file": "system-properties.txt",
    "text": "o prohibit CLI access via WebSocket connections completely.\n\n- name: hudson.cli.CLICommand.allowAtSyntax\n  tags:\n  - escape hatch\n  - security\n  def: |\n    `false`\n  since: 2.426.3 / 2.442\n  description: |\n    Escape hatch for .\n\n- name: hudson.ConsoleNote.INSECURE\n  tags:\n  - escape hatch\n  - security\n  def: |\n    `false`\n  since: 2.32.2 / 2.44\n  description: |\n    Whether to load unsigned consol"
  },
  "4640": {
    "source_file": "system-properties.txt",
    "text": "leNote.INSECURE\n  tags:\n  - escape hatch\n  - security\n  def: |\n    `false`\n  since: 2.32.2 / 2.44\n  description: |\n    Whether to load unsigned console notes.\n    See SECURITY-382 on .\n\n- name: hudson.consoleTailKB\n  tags:\n  - tuning\n  def: |\n    `150`\n  since: March 2009 # https://github.com/jenkinsci/jenkins/commit/bf81f96ab3d5e90bca0963c51c40a62d2642548d\n  description: |\n    How many KB of cons"
  },
  "4641": {
    "source_file": "system-properties.txt",
    "text": "0`\n  since: March 2009 # https://github.com/jenkinsci/jenkins/commit/bf81f96ab3d5e90bca0963c51c40a62d2642548d\n  description: |\n    How many KB of console log to show in default console view.\n    This property had no effect from Jenkins 2.4 (inclusive) until 2.98/2.89.3 (exclusive), see JENKINS-48593.\n\n- name: hudson.diagnosis.HudsonHomeDiskUsageChecker.freeSpaceThreshold\n  tags:\n  - tuning\n  def: "
  },
  "4642": {
    "source_file": "system-properties.txt",
    "text": ") until 2.98/2.89.3 (exclusive), see JENKINS-48593.\n\n- name: hudson.diagnosis.HudsonHomeDiskUsageChecker.freeSpaceThreshold\n  tags:\n  - tuning\n  def: |\n    `1073741824` (1 GB, up to 2.39), `10737418240` (10 GB, from 2.40)\n  since: 1.339\n  description: |\n    If there's less than this amount of free disk space, in bytes, on the disk with the Jenkins home directory, and the disk is 90% or more full, "
  },
  "4643": {
    "source_file": "system-properties.txt",
    "text": ": |\n    If there's less than this amount of free disk space, in bytes, on the disk with the Jenkins home directory, and the disk is 90% or more full, a warning will be shown to administrators.\n\n- name: hudson.diyChunking\n  tags:\n  - feature\n  def: |\n    `false`\n  since: May 2009 # https://github.com/jenkinsci/jenkins/commit/703c50cf62dedfb7085d345ec102df7395cf7fca\n  description: |\n    Set to `true"
  },
  "4644": {
    "source_file": "system-properties.txt",
    "text": "    `false`\n  since: May 2009 # https://github.com/jenkinsci/jenkins/commit/703c50cf62dedfb7085d345ec102df7395cf7fca\n  description: |\n    Set to `true` if the servlet container doesn't support chunked encoding.\n\n- name: hudson.DNSMultiCast.disabled\n  tags:\n  - escape hatch\n  - obsolete\n  def: |\n    `false` until 2.218, `true` in 2.219\n  since: 1.359\n  description: |\n    Set to `true` to disable DN"
  },
  "4645": {
    "source_file": "system-properties.txt",
    "text": " tags:\n  - escape hatch\n  - obsolete\n  def: |\n    `false` until 2.218, `true` in 2.219\n  since: 1.359\n  description: |\n    Set to `true` to disable DNS multicast.\n    Has no effect since 2.220 as the feature has been removed.\n    See\n\n- name: hudson.FilePath.VALIDATE_ANT_FILE_MASK_BOUND\n  tags:\n  - tuning\n  def: |\n    `10000`\n  since: 1.592\n  description: |\n    Max. number of operations to validat"
  },
  "4646": {
    "source_file": "system-properties.txt",
    "text": "FilePath.VALIDATE_ANT_FILE_MASK_BOUND\n  tags:\n  - tuning\n  def: |\n    `10000`\n  since: 1.592\n  description: |\n    Max. number of operations to validate a file mask (e.g. pattern to archive artifacts).\n\n- name: hudson.footerURL\n  tags:\n  - feature\n  def: |\n    `+https://jenkins.io+`\n  since: 1.416\n  description: |\n    Allows tweaking the URL displayed at the bottom of Jenkins' UI\n\n- name: hudson.Fu"
  },
  "4647": {
    "source_file": "system-properties.txt",
    "text": "ef: |\n    `+https://jenkins.io+`\n  since: 1.416\n  description: |\n    Allows tweaking the URL displayed at the bottom of Jenkins' UI\n\n- name: hudson.Functions.autoRefreshSeconds\n  tags:\n  - obsolete\n  - tuning\n  def: |\n    `10`\n  since: 1.365\n  description: |\n    Number of seconds between reloads when Auto Refresh is enabled.\n    Obsolete since the feature was removed in Jenkins 2.223.\n\n- name: hud"
  },
  "4648": {
    "source_file": "system-properties.txt",
    "text": "ption: |\n    Number of seconds between reloads when Auto Refresh is enabled.\n    Obsolete since the feature was removed in Jenkins 2.223.\n\n- name: hudson.Functions.hidingPasswordFields\n  tags:\n  - security\n  - escape hatch\n  def: |\n    `true`\n  since: 2.205\n  description: |\n    Jenkins 2.205 and newer attempts to prevent browsers from offering to auto-fill password form fields by using a custom pa"
  },
  "4649": {
    "source_file": "system-properties.txt",
    "text": ": 2.205\n  description: |\n    Jenkins 2.205 and newer attempts to prevent browsers from offering to auto-fill password form fields by using a custom password control.\n    Setting this to `false` reverts to the legacy behavior of using mostly standard password form fields.\n\n- name: hudson.lifecycle\n  tags:\n  - packaging\n  def: |\n    automatically determined based on environment, see `hudson.lifecycl"
  },
  "4650": {
    "source_file": "system-properties.txt",
    "text": "password form fields.\n\n- name: hudson.lifecycle\n  tags:\n  - packaging\n  def: |\n    automatically determined based on environment, see `hudson.lifecycle.Lifecycle`\n  description: |\n    Specify full class name for Lifecycle implementation to override default.\n    See  for class names.\n\n- name: hudson.logging.LogRecorderManager.skipPermissionCheck\n  tags:\n  - security\n  - escape hatch\n  def: |\n    `f"
  },
  "4651": {
    "source_file": "system-properties.txt",
    "text": "efault.\n    See  for class names.\n\n- name: hudson.logging.LogRecorderManager.skipPermissionCheck\n  tags:\n  - security\n  - escape hatch\n  def: |\n    `false`\n  since: 2.121.3 / 2.138\n  description: |\n    Disable security hardening for LogRecorderManager Stapler access.\n    Possibly unsafe, .\n\n- name: hudson.Main.development\n  tags:\n  - development\n  def: |\n    `false` in production, `true` in develo"
  },
  "4652": {
    "source_file": "system-properties.txt",
    "text": "r Stapler access.\n    Possibly unsafe, .\n\n- name: hudson.Main.development\n  tags:\n  - development\n  def: |\n    `false` in production, `true` in development\n  description: |\n    This is set to `true` by the development tooling to identify when Jenkins is running via `jetty:run` or `hpi:run`.\n    Can be used to distinguish between development and production use; most prominently used to bypass the s"
  },
  "4653": {
    "source_file": "system-properties.txt",
    "text": " is running via `jetty:run` or `hpi:run`.\n    Can be used to distinguish between development and production use; most prominently used to bypass the setup wizard when running with an empty Jenkins home directory during development.\n\n- name: hudson.Main.timeout\n  tags:\n  - tuning\n  def: |\n    `15000`\n  description: |\n    When using `jenkins-core.jar` from the CLI, this is the connection timeout con"
  },
  "4654": {
    "source_file": "system-properties.txt",
    "text": "in.timeout\n  tags:\n  - tuning\n  def: |\n    `15000`\n  description: |\n    When using `jenkins-core.jar` from the CLI, this is the connection timeout connecting to Jenkins to report a build result.\n\n- name: hudson.markup.MarkupFormatter.previewsAllowGET\n  tags:\n  - security\n  - escape hatch\n  def: |\n    `false`\n  since: 2.263.2 / 2.275\n  description: |\n    Controls whether URLs implementing markup fo"
  },
  "4655": {
    "source_file": "system-properties.txt",
    "text": "\n  tags:\n  - security\n  - escape hatch\n  def: |\n    `false`\n  since: 2.263.2 / 2.275\n  description: |\n    Controls whether URLs implementing markup formatter previews are accessible via GET.\n    See .\n\n- name: hudson.markup.MarkupFormatter.previewsSetCSP\n  tags:\n  - security\n  - escape hatch\n  def: |\n    `true`\n  since: 2.263.2 / 2.275\n  description: |\n    Controls whether to set restrictive Conte"
  },
  "4656": {
    "source_file": "system-properties.txt",
    "text": "tCSP\n  tags:\n  - security\n  - escape hatch\n  def: |\n    `true`\n  since: 2.263.2 / 2.275\n  description: |\n    Controls whether to set restrictive Content-Security-Policy headers on URLs implementing markup formatter previews.\n    See .\n\n- name: hudson.matrix.MatrixConfiguration.useShortWorkspaceName\n  # TODO move to matrix-project plugin documentation\n  tags:\n  - feature\n  def: |\n    `false`\n  desc"
  },
  "4657": {
    "source_file": "system-properties.txt",
    "text": ".matrix.MatrixConfiguration.useShortWorkspaceName\n  # TODO move to matrix-project plugin documentation\n  tags:\n  - feature\n  def: |\n    `false`\n  description: |\n    Use shorter but cryptic names in matrix build workspace directories.\n    Avoids problems with 256 character limit on paths in Cygwin, path depths problems on Windows, and shell metacharacter problems with label expressions on most plat"
  },
  "4658": {
    "source_file": "system-properties.txt",
    "text": "ems with 256 character limit on paths in Cygwin, path depths problems on Windows, and shell metacharacter problems with label expressions on most platforms.\n    See https://issues.jenkins.io/browse/JENKINS-25783[JENKINS-25783].\n\n- name: hudson.model.AbstractItem.skipPermissionCheck\n  tags:\n  - security\n  - escape hatch\n  def: |\n    `false`\n  since: 2.121.3 / 2.138\n  description: |\n    Disable secu"
  },
  "4659": {
    "source_file": "system-properties.txt",
    "text": "AbstractItem.skipPermissionCheck\n  tags:\n  - security\n  - escape hatch\n  def: |\n    `false`\n  since: 2.121.3 / 2.138\n  description: |\n    Disable security hardening related to Stapler routing for AbstractItem.\n    Possibly unsafe, .\n\n- name: hudson.model.Api.INSECURE\n  tags:\n  - security\n  - escape hatch\n  - obsolete\n  def: |\n    `false`\n  since: 1.502\n  description: |\n    Set to `true` to permit "
  },
  "4660": {
    "source_file": "system-properties.txt",
    "text": "odel.Api.INSECURE\n  tags:\n  - security\n  - escape hatch\n  - obsolete\n  def: |\n    `false`\n  since: 1.502\n  description: |\n    Set to `true` to permit accessing the Jenkins remote API in an unsafe manner.\n    See SECURITY-47.\n    Deprecated, use e.g. https://plugins.jenkins.io/secure-requester-whitelist/[Secure Requester Whitelist] instead.\n\n- name: hudson.model.AsyncAperiodicWork.logRotateMinutes\n"
  },
  "4661": {
    "source_file": "system-properties.txt",
    "text": "https://plugins.jenkins.io/secure-requester-whitelist/[Secure Requester Whitelist] instead.\n\n- name: hudson.model.AsyncAperiodicWork.logRotateMinutes\n  tags:\n  - tuning\n  def: |\n    `1440`\n  since: 1.651\n  description: |\n    The number of minutes after which to try and rotate the log file used by any AsyncAperiodicWork extension.\n    For fine-grained control of a specific extension you can use the"
  },
  "4662": {
    "source_file": "system-properties.txt",
    "text": "er which to try and rotate the log file used by any AsyncAperiodicWork extension.\n    For fine-grained control of a specific extension you can use the `_FullyQualifiedClassName_.logRotateMinutes` system property to only affect a specific extension.\n    _It is not anticipated that you will ever need to change these defaults._\n\n- name: hudson.model.AsyncAperiodicWork.logRotateSize\n  tags:\n  - tuning"
  },
  "4663": {
    "source_file": "system-properties.txt",
    "text": "   _It is not anticipated that you will ever need to change these defaults._\n\n- name: hudson.model.AsyncAperiodicWork.logRotateSize\n  tags:\n  - tuning\n  def: |\n    `-1`\n  since: 1.651\n  description: |\n    When starting a new run of any AsyncAperiodicWork extension, if this value is non-negative and the existing log file is larger than the specified number of bytes then the log file will be rotated"
  },
  "4664": {
    "source_file": "system-properties.txt",
    "text": "Work extension, if this value is non-negative and the existing log file is larger than the specified number of bytes then the log file will be rotated.\n    For fine-grained control of a specific extension you can use the\u00a0`_FullyQualifiedClassName_.logRotateSize` system property to only affect a specific extension.\n    _It is not anticipated that you will ever need to change these defaults._\n\n- nam"
  },
  "4665": {
    "source_file": "system-properties.txt",
    "text": "gRotateSize` system property to only affect a specific extension.\n    _It is not anticipated that you will ever need to change these defaults._\n\n- name: hudson.model.AsyncPeriodicWork.logRotateMinutes\n  tags:\n  - tuning\n  def: |\n    `1440`\n  since: 1.651\n  description: |\n    The number of minutes after which to try and rotate the log file used by any AsyncPeriodicWork extension.\n    For fine-grain"
  },
  "4666": {
    "source_file": "system-properties.txt",
    "text": ".651\n  description: |\n    The number of minutes after which to try and rotate the log file used by any AsyncPeriodicWork extension.\n    For fine-grained control of a specific extension you can use the\u00a0`_FullyQualifiedClassName_.logRotateMinutes` system property to only affect a specific extension.\n    _It is not anticipated that you will ever need to change these defaults._\n\n    Some implementatio"
  },
  "4667": {
    "source_file": "system-properties.txt",
    "text": "em property to only affect a specific extension.\n    _It is not anticipated that you will ever need to change these defaults._\n\n    Some implementations that can be individually configured (see _FullyQualifiedClassName_ above):\n\n    * `hudson.model.WorkspaceCleanupThread`\n    * `hudson.model.FingerprintCleanupThread`\n    * `hudson.slaves.ConnectionActivityMonitor`\n    * `jenkins.DailyCheck`\n    * "
  },
  "4668": {
    "source_file": "system-properties.txt",
    "text": "orkspaceCleanupThread`\n    * `hudson.model.FingerprintCleanupThread`\n    * `hudson.slaves.ConnectionActivityMonitor`\n    * `jenkins.DailyCheck`\n    * `jenkins.model.BackgroundGlobalBuildDiscarder`\n    * `jenkins.telemetry.Telemetry$TelemetryReporter`\n\n- name: hudson.model.AsyncPeriodicWork.logRotateSize\n  tags:\n  - tuning\n  def: |\n    `-1`\n  since: 1.651\n  description: |\n    When starting a new ru"
  },
  "4669": {
    "source_file": "system-properties.txt",
    "text": "\n\n- name: hudson.model.AsyncPeriodicWork.logRotateSize\n  tags:\n  - tuning\n  def: |\n    `-1`\n  since: 1.651\n  description: |\n    When starting a new run of any AsyncPeriodicWork extension, if this value is non-negative and the existing log file is larger than the specified number of bytes then the log file will be rotated.\n    For fine-grained control of a specific extension you can use the\u00a0`_Fully"
  },
  "4670": {
    "source_file": "system-properties.txt",
    "text": "ger than the specified number of bytes then the log file will be rotated.\n    For fine-grained control of a specific extension you can use the\u00a0`_FullyQualifiedClassName_.logRotateSize` system property to only affect a specific extension.\n    _It is not anticipated that you will ever need to change these defaults_\n\n    Some implementations that can be individually configured (see _FullyQualifiedCla"
  },
  "4671": {
    "source_file": "system-properties.txt",
    "text": "ot anticipated that you will ever need to change these defaults_\n\n    Some implementations that can be individually configured (see _FullyQualifiedClassName_ above):\n\n    * `hudson.model.WorkspaceCleanupThread`\n    * `hudson.model.FingerprintCleanupThread`\n    * `hudson.slaves.ConnectionActivityMonitor`\n    * `jenkins.DailyCheck`\n    * `jenkins.model.BackgroundGlobalBuildDiscarder`\n    * `jenkins."
  },
  "4672": {
    "source_file": "system-properties.txt",
    "text": "hread`\n    * `hudson.slaves.ConnectionActivityMonitor`\n    * `jenkins.DailyCheck`\n    * `jenkins.model.BackgroundGlobalBuildDiscarder`\n    * `jenkins.telemetry.Telemetry$TelemetryReporter`\n\n- name: hudson.model.DirectoryBrowserSupport.allowAbsolutePath\n  tags:\n  - obsolete\n  - security\n  - escape hatch\n  def: |\n    `false`\n  since: 2.303.2 / 2.315\n  description: |\n    Deprecated: Escape hatch for "
  },
  "4673": {
    "source_file": "system-properties.txt",
    "text": "th\n  tags:\n  - obsolete\n  - security\n  - escape hatch\n  def: |\n    `false`\n  since: 2.303.2 / 2.315\n  description: |\n    Deprecated: Escape hatch for .\n    Has no effect since 2.463.\n\n- name: hudson.model.DirectoryBrowserSupport.allowSymlinkEscape\n  tags:\n  - security\n  - escape hatch\n  def: |\n    `false`\n  since: 2.138.4 / 2.154\n  description: |\n    Escape hatch for  and .\n\n- name: hudson.model.D"
  },
  "4674": {
    "source_file": "system-properties.txt",
    "text": "tags:\n  - security\n  - escape hatch\n  def: |\n    `false`\n  since: 2.138.4 / 2.154\n  description: |\n    Escape hatch for  and .\n\n- name: hudson.model.DirectoryBrowserSupport.allowTmpEscape\n  tags:\n  - security\n  - escape hatch\n  def: |\n    `false`\n  since: 2.375.4 / 2.394\n  description: |\n    Escape hatch for .\n\n- name: hudson.model.DirectoryBrowserSupport.CSP\n  tags:\n  - security\n  - escape hatch\n"
  },
  "4675": {
    "source_file": "system-properties.txt",
    "text": "ince: 2.375.4 / 2.394\n  description: |\n    Escape hatch for .\n\n- name: hudson.model.DirectoryBrowserSupport.CSP\n  tags:\n  - security\n  - escape hatch\n  def: |\n    `sandbox; default-src 'none'; image-src 'self'; style-src 'self';`\n  since: 1.625.3 / 1.641\n  description: |\n    Determines the Content Security Policy header sent for static files served by Jenkins.\n    Only affects controllers that don"
  },
  "4676": {
    "source_file": "system-properties.txt",
    "text": ".641\n  description: |\n    Determines the Content Security Policy header sent for static files served by Jenkins.\n    Only affects controllers that don't have a resource root URL set up.\n    See  for more details.\n\n- name: hudson.model.DownloadService$Downloadable.defaultInterval\n  tags:\n  - tuning\n  def: |\n    `86400000` (1 day)\n  since: 1.500\n  description: |\n    Interval between periodic downloa"
  },
  "4677": {
    "source_file": "system-properties.txt",
    "text": "$Downloadable.defaultInterval\n  tags:\n  - tuning\n  def: |\n    `86400000` (1 day)\n  since: 1.500\n  description: |\n    Interval between periodic downloads of _Downloadables_, typically tool installer metadata.\n\n- name: hudson.model.DownloadService.never\n  tags:\n  - obsolete\n  - escape hatch\n  def: |\n    `false`\n  since: 1.319 # https://github.com/jenkinsci/jenkins/commit/163c08003eb25cbe259fc8a8277b"
  },
  "4678": {
    "source_file": "system-properties.txt",
    "text": "r\n  tags:\n  - obsolete\n  - escape hatch\n  def: |\n    `false`\n  since: 1.319 # https://github.com/jenkinsci/jenkins/commit/163c08003eb25cbe259fc8a8277bb3e264e36d18\n  description: |\n    Suppress the periodic download of data files for plugins via browser-based download.\n    Since Jenkins 2.200, this has no effect.\n\n- name: hudson.model.DownloadService.noSignatureCheck\n  tags:\n  - security\n  - escape"
  },
  "4679": {
    "source_file": "system-properties.txt",
    "text": "er-based download.\n    Since Jenkins 2.200, this has no effect.\n\n- name: hudson.model.DownloadService.noSignatureCheck\n  tags:\n  - security\n  - escape hatch\n  def: |\n    `false`\n  since: 1.482 # https://github.com/jenkinsci/jenkins/commit/62f66f899c95ccdfdc7a5d3346240988b42a9aad\n  description: |\n    Skip the update site signature check.\n    Setting this to `true` can be unsafe.\n\n- name: hudson.mod"
  },
  "4680": {
    "source_file": "system-properties.txt",
    "text": "5ccdfdc7a5d3346240988b42a9aad\n  description: |\n    Skip the update site signature check.\n    Setting this to `true` can be unsafe.\n\n- name: hudson.model.Hudson.flyweightSupport\n  tags:\n  - obsolete\n  - feature\n  - escape hatch\n  def: |\n    `false` before 1.337; `true` from 1.337; unused since 1.598\n  since: 1.318\n  description: |\n    Matrix parent job and other flyweight tasks (e.g. Build Flow plu"
  },
  "4681": {
    "source_file": "system-properties.txt",
    "text": "fore 1.337; `true` from 1.337; unused since 1.598\n  since: 1.318\n  description: |\n    Matrix parent job and other flyweight tasks (e.g. Build Flow plugin) won't consume an executor when `true`.\n    Unused since 1.598, flyweight support is now always enabled.\n\n- name: hudson.model.Hudson.initLogLevel\n  tags:\n  - obsolete\n  description: |\n    Deprecated: Backward-compatible fallback for `jenkins.mod"
  },
  "4682": {
    "source_file": "system-properties.txt",
    "text": "enabled.\n\n- name: hudson.model.Hudson.initLogLevel\n  tags:\n  - obsolete\n  description: |\n    Deprecated: Backward-compatible fallback for `jenkins.model.Jenkins.initLogLevel`.\n    Removed since 2.272.\n\n- name: hudson.model.Hudson.killAfterLoad\n  tags:\n  - obsolete\n  description: |\n    Deprecated: Backward-compatible fallback for `jenkins.model.Jenkins.killAfterLoad`.\n    Removed since 2.272.\n\n- na"
  },
  "4683": {
    "source_file": "system-properties.txt",
    "text": ":\n  - obsolete\n  description: |\n    Deprecated: Backward-compatible fallback for `jenkins.model.Jenkins.killAfterLoad`.\n    Removed since 2.272.\n\n- name: hudson.model.Hudson.logStartupPerformance\n  tags:\n  - obsolete\n  description: |\n    Deprecated: Backward-compatible fallback for `jenkins.model.Jenkins.logStartupPerformance`.\n    Removed since 2.272.\n\n- name: hudson.model.Hudson.parallelLoad\n  t"
  },
  "4684": {
    "source_file": "system-properties.txt",
    "text": "Backward-compatible fallback for `jenkins.model.Jenkins.logStartupPerformance`.\n    Removed since 2.272.\n\n- name: hudson.model.Hudson.parallelLoad\n  tags:\n  - obsolete\n  description: |\n    Deprecated: Backward-compatible fallback for `jenkins.model.Jenkins.parallelLoad`.\n    Removed since 2.272.\n\n- name: hudson.model.Hudson.workspaceDirName\n  tags:\n  - obsolete\n  description: |\n    Deprecated: Bac"
  },
  "4685": {
    "source_file": "system-properties.txt",
    "text": "enkins.parallelLoad`.\n    Removed since 2.272.\n\n- name: hudson.model.Hudson.workspaceDirName\n  tags:\n  - obsolete\n  description: |\n    Deprecated: Backward-compatible fallback for `jenkins.model.Jenkins.workspaceDirName`.\n    Removed since 2.272.\n\n- name: hudson.model.LabelAtom.allowFolderTraversal\n  tags:\n  - security\n  - escape hatch\n  def: |\n    `false`\n  since: 2.263.2 / 2.275\n  description: |"
  },
  "4686": {
    "source_file": "system-properties.txt",
    "text": "name: hudson.model.LabelAtom.allowFolderTraversal\n  tags:\n  - security\n  - escape hatch\n  def: |\n    `false`\n  since: 2.263.2 / 2.275\n  description: |\n    Controls whether label names containing unsafe characters that lead to path traversal can be saved.\n    See .\n\n- name: hudson.model.LoadStatistics.clock\n  tags:\n  - tuning\n  def: |\n    `10000` (10 seconds)\n  since: January 2009 # https://github."
  },
  "4687": {
    "source_file": "system-properties.txt",
    "text": "ved.\n    See .\n\n- name: hudson.model.LoadStatistics.clock\n  tags:\n  - tuning\n  def: |\n    `10000` (10 seconds)\n  since: January 2009 # https://github.com/jenkinsci/jenkins/commit/8d771bc2e335fea5369ba06066c87866494fa5e3\n  description: |\n    Load statistics clock cycle in milliseconds.\n\n- name: hudson.model.LoadStatistics.decay\n  tags:\n  - tuning\n  def: |\n    `0.9`\n  since: January 2009 # https://g"
  },
  "4688": {
    "source_file": "system-properties.txt",
    "text": "istics clock cycle in milliseconds.\n\n- name: hudson.model.LoadStatistics.decay\n  tags:\n  - tuning\n  def: |\n    `0.9`\n  since: January 2009 # https://github.com/jenkinsci/jenkins/commit/8d771bc2e335fea5369ba06066c87866494fa5e3\n  description: |\n    Decay ratio for every clock cycle in node utilization charts.\n\n- name: hudson.model.MultiStageTimeSeries.chartFont\n  tags:\n  - feature\n  - ui\n  def: |\n  "
  },
  "4689": {
    "source_file": "system-properties.txt",
    "text": "ay ratio for every clock cycle in node utilization charts.\n\n- name: hudson.model.MultiStageTimeSeries.chartFont\n  tags:\n  - feature\n  - ui\n  def: |\n    `SansSerif-10`\n  since: 1.562\n  description: |\n    Font used for load statistics.\n    See http://docs.oracle.com/javase/7/docs/api/java/awt/Font.html#decode%28java.lang.String%29[Java documentation] on how the value is decoded.\n\n- name: hudson.mode"
  },
  "4690": {
    "source_file": "system-properties.txt",
    "text": "ocs.oracle.com/javase/7/docs/api/java/awt/Font.html#decode%28java.lang.String%29[Java documentation] on how the value is decoded.\n\n- name: hudson.model.MyViewsProperty.skipPermissionCheck\n  tags:\n  - security\n  - escape hatch\n  def: |\n    `false`\n  since: 2.452.4 / 2.471\n  description: |\n    Allow non-admin users to access (and potentially change) other users' \"My Views\".\n    Escape hatch for .\n\n-"
  },
  "4691": {
    "source_file": "system-properties.txt",
    "text": "ince: 2.452.4 / 2.471\n  description: |\n    Allow non-admin users to access (and potentially change) other users' \"My Views\".\n    Escape hatch for .\n\n- name: hudson.model.Node.SKIP_BUILD_CHECK_ON_FLYWEIGHTS\n  tags:\n  - security\n  - escape hatch\n  def: |\n    `true`\n  since: 2.111 # https://github.com/jenkinsci/jenkins/commit/036e0ce6bb0f257c1e90d49a0af907adf6bb79f7\n  description: |\n    Whether to al"
  },
  "4692": {
    "source_file": "system-properties.txt",
    "text": " |\n    `true`\n  since: 2.111 # https://github.com/jenkinsci/jenkins/commit/036e0ce6bb0f257c1e90d49a0af907adf6bb79f7\n  description: |\n    Whether to allow building flyweight tasks even if the necessary permission (Computer/Build) is missing.\n    See https://issues.jenkins.io/browse/JENKINS-46652[JENKINS-46652].\n\n- name: hudson.model.ParametersAction.keepUndefinedParameters\n  tags:\n  - security\n  - "
  },
  "4693": {
    "source_file": "system-properties.txt",
    "text": "ttps://issues.jenkins.io/browse/JENKINS-46652[JENKINS-46652].\n\n- name: hudson.model.ParametersAction.keepUndefinedParameters\n  tags:\n  - security\n  - escape hatch\n  def: undefined\n  since: 1.651.2 / 2.3\n  # TODO add advisory reference\n  description: |\n    If true, not discard parameters for builds that are not defined on the job.\n    *Enabling this can be unsafe.*\n    Since Jenkins 2.40, if set to"
  },
  "4694": {
    "source_file": "system-properties.txt",
    "text": "|\n    If true, not discard parameters for builds that are not defined on the job.\n    *Enabling this can be unsafe.*\n    Since Jenkins 2.40, if set to false, will not log a warning message that parameters were defined but ignored.\n\n- name: hudson.model.ParametersAction.safeParameters\n  tags:\n  - security\n  - escape hatch\n  def: undefined\n  since: 1.651.2 / 2.3\n  # TODO add advisory reference\n  des"
  },
  "4695": {
    "source_file": "system-properties.txt",
    "text": "el.ParametersAction.safeParameters\n  tags:\n  - security\n  - escape hatch\n  def: undefined\n  since: 1.651.2 / 2.3\n  # TODO add advisory reference\n  description: |\n    Comma-separated list of additional build parameter names that should not be discarded even when not defined on the job.\n\n- name: hudson.model.Queue.cacheRefreshPeriod\n  tags:\n  - tuning\n  def: |\n    `1000`\n  since: 1.577 up to 1.647\n "
  },
  "4696": {
    "source_file": "system-properties.txt",
    "text": "d even when not defined on the job.\n\n- name: hudson.model.Queue.cacheRefreshPeriod\n  tags:\n  - tuning\n  def: |\n    `1000`\n  since: 1.577 up to 1.647\n  description: |\n    Defines the refresh period for the internal queue cache (in milliseconds).\n    The greater period workarounds web UI delays on large installations, which may be caused by locking of the build queue by build executors.\n    Downside"
  },
  "4697": {
    "source_file": "system-properties.txt",
    "text": "he greater period workarounds web UI delays on large installations, which may be caused by locking of the build queue by build executors.\n    Downside: Builds appear in the queue with a noticeable delay.\n\n- name: hudson.model.Queue.Saver.DELAY_SECONDS\n  tags:\n  - tuning\n  def: |\n    `60`\n  since: 2.109\n  description: |\n    Maximal delay of a save operation when content of Jenkins queue changes.\n  "
  },
  "4698": {
    "source_file": "system-properties.txt",
    "text": "S\n  tags:\n  - tuning\n  def: |\n    `60`\n  since: 2.109\n  description: |\n    Maximal delay of a save operation when content of Jenkins queue changes.\n    This works as a balancing factor between queue consistency guarantee in case of Jenkins crash (short delay) and decreasing IO activity based on Jenkins load (long delay).\n\n- name: hudson.model.Run.ArtifactList.listCutoff\n  tags:\n  - tuning\n  - ui\n "
  },
  "4699": {
    "source_file": "system-properties.txt",
    "text": "rt delay) and decreasing IO activity based on Jenkins load (long delay).\n\n- name: hudson.model.Run.ArtifactList.listCutoff\n  tags:\n  - tuning\n  - ui\n  def: |\n    `16`\n  since: 1.330\n  description: |\n    More artifacts than this will use tree view or simple link rather than listing out artifacts\n\n- name: hudson.model.Run.ArtifactList.treeCutoff\n  tags:\n  - tuning\n  - ui\n  def: |\n    `40`\n  since: 1"
  },
  "4700": {
    "source_file": "system-properties.txt",
    "text": "simple link rather than listing out artifacts\n\n- name: hudson.model.Run.ArtifactList.treeCutoff\n  tags:\n  - tuning\n  - ui\n  def: |\n    `40`\n  since: 1.330\n  description: |\n    More artifacts than this will show a simple link to directory browser rather than showing artifacts in tree view\n\n- name: hudson.model.Slave.workspaceRoot\n  tags:\n  - tuning\n  def: |\n    `workspace`\n  since: 1.341?\n  descrip"
  },
  "4701": {
    "source_file": "system-properties.txt",
    "text": "er than showing artifacts in tree view\n\n- name: hudson.model.Slave.workspaceRoot\n  tags:\n  - tuning\n  def: |\n    `workspace`\n  since: 1.341?\n  description: |\n    name of the folder within the agent root directory to contain workspaces\n\n- name: hudson.model.UpdateCenter.className\n  tags:\n  - packaging\n  def: |\n    effectively `hudson.model.UpdateCenter`\n  since: 2.4\n  description: |\n    This allows"
  },
  "4702": {
    "source_file": "system-properties.txt",
    "text": ".model.UpdateCenter.className\n  tags:\n  - packaging\n  def: |\n    effectively `hudson.model.UpdateCenter`\n  since: 2.4\n  description: |\n    This allows overriding the implementation class for update center when customizing the `.war` packaging of Jenkins.\n    Cannot be used for plugins.\n\n- name: hudson.model.UpdateCenter.defaultUpdateSiteId\n  def: |\n    `default`\n  since: 2.4\n  # TODO figure out wh"
  },
  "4703": {
    "source_file": "system-properties.txt",
    "text": "ins.\n    Cannot be used for plugins.\n\n- name: hudson.model.UpdateCenter.defaultUpdateSiteId\n  def: |\n    `default`\n  since: 2.4\n  # TODO figure out what this even does, IIRC Jenkins doesn't care about the ID other than distinguish on the UI?\n  description: |\n    Configure a different ID for the default update site.\n    Useful for custom war distributions or externally provided UC data files.\n\n- na"
  },
  "4704": {
    "source_file": "system-properties.txt",
    "text": "ption: |\n    Configure a different ID for the default update site.\n    Useful for custom war distributions or externally provided UC data files.\n\n- name: hudson.model.UpdateCenter.never\n  def: |\n    `false`\n  description: |\n    When true, don't automatically check for new versions\n\n- name: hudson.model.UpdateCenter.pluginDownloadReadTimeoutSeconds\n  tags:\n  - tuning\n  def: |\n    `60`\n  description"
  },
  "4705": {
    "source_file": "system-properties.txt",
    "text": "atically check for new versions\n\n- name: hudson.model.UpdateCenter.pluginDownloadReadTimeoutSeconds\n  tags:\n  - tuning\n  def: |\n    `60`\n  description: |\n    Read timeout in seconds for downloading plugins.\n\n- name: hudson.model.UpdateCenter.skipPermissionCheck\n  tags:\n  - security\n  - escape hatch\n  def: |\n    `false`\n  since: 2.121.3 / 2.138\n  description: |\n    Disable security hardening relate"
  },
  "4706": {
    "source_file": "system-properties.txt",
    "text": "issionCheck\n  tags:\n  - security\n  - escape hatch\n  def: |\n    `false`\n  since: 2.121.3 / 2.138\n  description: |\n    Disable security hardening related to Stapler routing for UpdateCenter.\n    Possibly unsafe, .\n\n- name: hudson.model.UpdateCenter.updateCenterUrl\n  tags:\n  - obsolete\n  def: |\n    `+https://updates.jenkins.io/+`\n  description: |\n    Deprecated: Override the default update site URL.\n"
  },
  "4707": {
    "source_file": "system-properties.txt",
    "text": "ateCenterUrl\n  tags:\n  - obsolete\n  def: |\n    `+https://updates.jenkins.io/+`\n  description: |\n    Deprecated: Override the default update site URL.\n    May have no effect since Jenkins 1.333.\n\n- name: hudson.model.UsageStatistics.disabled\n  tags:\n  - feature\n  def: |\n    `false`\n  since: May 2009\n  # https://github.com/jenkinsci/jenkins/commit/49ace47432e473b8f5febb6cc00f177be5854ffb looks like "
  },
  "4708": {
    "source_file": "system-properties.txt",
    "text": " - feature\n  def: |\n    `false`\n  since: May 2009\n  # https://github.com/jenkinsci/jenkins/commit/49ace47432e473b8f5febb6cc00f177be5854ffb looks like a rename\n  # but it was originally added the same day https://github.com/jenkinsci/jenkins/commit/10cc0441aeaf7c042dc1ecca674a7cf9b8375863 just a typo\n  description: |\n    Set to `true` to opt out of usage statistics collection, independent of UI opt"
  },
  "4709": {
    "source_file": "system-properties.txt",
    "text": "cc0441aeaf7c042dc1ecca674a7cf9b8375863 just a typo\n  description: |\n    Set to `true` to opt out of usage statistics collection, independent of UI option.\n\n- name: hudson.model.User.allowNonExistentUserToLogin\n  tags:\n  - security\n  - escape hatch\n  def: |\n    `false`\n  since: 1.602\n  description: |\n    When `true`, does not check auth realm for existence of user if there's a record in Jenkins.\n  "
  },
  "4710": {
    "source_file": "system-properties.txt",
    "text": "def: |\n    `false`\n  since: 1.602\n  description: |\n    When `true`, does not check auth realm for existence of user if there's a record in Jenkins.\n    Unsafe, but may be used on some controllers for service accounts\n\n- name: hudson.model.User.allowUserCreationViaUrl\n  tags:\n  - security\n  - escape hatch\n  def: |\n    `false`\n  since: 2.32.2 / 2.44\n  description: |\n    Whether admins accessing `/us"
  },
  "4711": {
    "source_file": "system-properties.txt",
    "text": "serCreationViaUrl\n  tags:\n  - security\n  - escape hatch\n  def: |\n    `false`\n  since: 2.32.2 / 2.44\n  description: |\n    Whether admins accessing `/user/example` creates a user record (see SECURITY-406 on )\n\n- name: hudson.model.User.SECURITY_243_FULL_DEFENSE\n  tags:\n  - security\n  - escape hatch\n  def: |\n    `true`\n  since: 1.651.2 / 2.3\n  description: |\n    When false, skips part of the fix that"
  },
  "4712": {
    "source_file": "system-properties.txt",
    "text": "L_DEFENSE\n  tags:\n  - security\n  - escape hatch\n  def: |\n    `true`\n  since: 1.651.2 / 2.3\n  description: |\n    When false, skips part of the fix that tries to determine whether a given user ID exists, and if so, doesn't consider users with the same full name during resolution.\n\n- name: hudson.model.User.skipPermissionCheck\n  tags:\n  - security\n  - escape hatch\n  def: |\n    `false`\n  since: 2.121."
  },
  "4713": {
    "source_file": "system-properties.txt",
    "text": "full name during resolution.\n\n- name: hudson.model.User.skipPermissionCheck\n  tags:\n  - security\n  - escape hatch\n  def: |\n    `false`\n  since: 2.121.3 / 2.138\n  description: |\n    Disable security hardening related to Stapler routing for User.\n    Possibly unsafe, .\n\n- name: hudson.model.WorkspaceCleanupThread.disabled\n  tags:\n  - escape hatch\n  def: |\n    `false`\n  since: June 2009 # https://git"
  },
  "4714": {
    "source_file": "system-properties.txt",
    "text": "ossibly unsafe, .\n\n- name: hudson.model.WorkspaceCleanupThread.disabled\n  tags:\n  - escape hatch\n  def: |\n    `false`\n  since: June 2009 # https://github.com/jenkinsci/jenkins/commit/ee5cba8fac256580ac30878ed28cf3330cc9d4a4\n  description: |\n    Don't clean up old workspaces on agent nodes\n\n- name: hudson.model.WorkspaceCleanupThread.recurrencePeriodHours\n  tags:\n  - tuning\n  def: |\n    `24`\n  sinc"
  },
  "4715": {
    "source_file": "system-properties.txt",
    "text": " clean up old workspaces on agent nodes\n\n- name: hudson.model.WorkspaceCleanupThread.recurrencePeriodHours\n  tags:\n  - tuning\n  def: |\n    `24`\n  since: 1.608\n  description: |\n    How frequently workspace cleanup should run, in hours.\n\n- name: hudson.model.WorkspaceCleanupThread.retainForDays\n  tags:\n  - tuning\n  def: |\n    `30`\n  since: 1.608\n  description: |\n    Unused workspaces are retained fo"
  },
  "4716": {
    "source_file": "system-properties.txt",
    "text": ".model.WorkspaceCleanupThread.retainForDays\n  tags:\n  - tuning\n  def: |\n    `30`\n  since: 1.608\n  description: |\n    Unused workspaces are retained for this many days before qualifying for deletion.\n\n- name: hudson.node_monitors.AbstractNodeMonitorDescriptor.periodMinutes\n  tags:\n  - tuning\n  def: |\n    `60` (1 hour)\n  description: |\n    How frequently to update node monitors by default, in minute"
  },
  "4717": {
    "source_file": "system-properties.txt",
    "text": "scriptor.periodMinutes\n  tags:\n  - tuning\n  def: |\n    `60` (1 hour)\n  description: |\n    How frequently to update node monitors by default, in minutes.\n\n- name: hudson.PluginManager.checkUpdateAttempts\n  tags:\n  - tuning\n  def: |\n    `1`\n  since: 2.152\n  description: |\n    Number of attempts to check the updates sites.\n\n- name: hudson.PluginManager.checkUpdateSleepTimeMillis\n  tags:\n  - tuning\n  "
  },
  "4718": {
    "source_file": "system-properties.txt",
    "text": "152\n  description: |\n    Number of attempts to check the updates sites.\n\n- name: hudson.PluginManager.checkUpdateSleepTimeMillis\n  tags:\n  - tuning\n  def: |\n    `1000`\n  since: 2.152\n  description: |\n    Time (milliseconds) elapsed between retries to check the updates sites.\n\n- name: hudson.PluginManager.className\n  tags:\n  - packaging\n  def: |\n    effectively `hudson.LocalPluginManager`\n  descrip"
  },
  "4719": {
    "source_file": "system-properties.txt",
    "text": " check the updates sites.\n\n- name: hudson.PluginManager.className\n  tags:\n  - packaging\n  def: |\n    effectively `hudson.LocalPluginManager`\n  description: |\n    Can be used to specify a different `PluginManager` implementation when customizing the `.war` packaging of Jenkins.\n    Cannot be used for plugins.\n\n- name: hudson.PluginManager.noFastLookup\n  tags:\n  - escape hatch\n  def: |\n    `false`\n "
  },
  "4720": {
    "source_file": "system-properties.txt",
    "text": ".war` packaging of Jenkins.\n    Cannot be used for plugins.\n\n- name: hudson.PluginManager.noFastLookup\n  tags:\n  - escape hatch\n  def: |\n    `false`\n  description: |\n    Disable fast lookup using `ClassLoaderReflectionToolkit` which reflectively accesses internal methods of `ClassLoader`.\n\n- name: hudson.PluginManager.skipPermissionCheck\n  tags:\n  - security\n  - escape hatch\n  def: |\n    `false`\n "
  },
  "4721": {
    "source_file": "system-properties.txt",
    "text": "sses internal methods of `ClassLoader`.\n\n- name: hudson.PluginManager.skipPermissionCheck\n  tags:\n  - security\n  - escape hatch\n  def: |\n    `false`\n  since: 2.121.3 / 2.138\n  description: |\n    Disable security hardening related to Stapler routing for PluginManager.\n    Possibly unsafe, .\n\n- name: hudson.PluginManager.workDir\n  tags:\n  - feature\n  def: undefined\n  since: 1.649\n  description: |\n  "
  },
  "4722": {
    "source_file": "system-properties.txt",
    "text": "or PluginManager.\n    Possibly unsafe, .\n\n- name: hudson.PluginManager.workDir\n  tags:\n  - feature\n  def: undefined\n  since: 1.649\n  description: |\n    Location of the base directory for all exploded .hpi/.jpi plugins.\n    By default the plugins will be extracted under `$JENKINS_HOME/plugins/`.\n\n- name: hudson.PluginStrategy\n  tags:\n  - packaging\n  def: |\n    effectively `hudson.ClassicPluginStrat"
  },
  "4723": {
    "source_file": "system-properties.txt",
    "text": " be extracted under `$JENKINS_HOME/plugins/`.\n\n- name: hudson.PluginStrategy\n  tags:\n  - packaging\n  def: |\n    effectively `hudson.ClassicPluginStrategy`\n  description: |\n    Allow plugins to be loaded into a different environment, such as an existing DI container like Plexus.\n    Specify the full class name of a `hudson.PluginStrategy` implementation to override the default.\n\n- name: hudson.Plug"
  },
  "4724": {
    "source_file": "system-properties.txt",
    "text": "ng DI container like Plexus.\n    Specify the full class name of a `hudson.PluginStrategy` implementation to override the default.\n\n- name: hudson.PluginWrapper.dependenciesVersionCheck.enabled\n  tags:\n  - escape hatch\n  def: |\n    `true`\n  since: 2.0\n  description: |\n    Set to `false` to skip the version check for plugin dependencies.\n\n- name: hudson.ProxyConfiguration.DEFAULT_CONNECT_TIMEOUT_MIL"
  },
  "4725": {
    "source_file": "system-properties.txt",
    "text": "\n  description: |\n    Set to `false` to skip the version check for plugin dependencies.\n\n- name: hudson.ProxyConfiguration.DEFAULT_CONNECT_TIMEOUT_MILLIS\n  tags:\n  - tuning\n  def: |\n    `20000`\n  since: 2.0\n  description: |\n    Connection timeout applied to connections e.g. to the update site.\n\n- name: hudson.remoting.Channel.DISABLE_JAR_URL_VALIDATOR\n  tags:\n  - security\n  - escape hatch\n  def: |"
  },
  "4726": {
    "source_file": "system-properties.txt",
    "text": "lied to connections e.g. to the update site.\n\n- name: hudson.remoting.Channel.DISABLE_JAR_URL_VALIDATOR\n  tags:\n  - security\n  - escape hatch\n  def: |\n    `false`\n  since: 2.452.4 / 2.471\n  description: |\n    Disable validation of URLs attempted to be read by agents.\n    Escape hatch for .\n\n- name: hudson.remoting.ChannelBuilder.allCallablesCanIgnoreRoleChecker\n  tags:\n  - security\n  - scape hatch"
  },
  "4727": {
    "source_file": "system-properties.txt",
    "text": "e read by agents.\n    Escape hatch for .\n\n- name: hudson.remoting.ChannelBuilder.allCallablesCanIgnoreRoleChecker\n  tags:\n  - security\n  - scape hatch\n  def: |\n    `false`\n  since: 2.303.3 / 2.319\n  description: |\n    Disable requirement for remoting callables to perform a role check.\n    See .\n\n- name: hudson.remoting.ChannelBuilder.specificCallablesCanIgnoreRoleChecker\n  tags:\n  - security\n  - s"
  },
  "4728": {
    "source_file": "system-properties.txt",
    "text": " callables to perform a role check.\n    See .\n\n- name: hudson.remoting.ChannelBuilder.specificCallablesCanIgnoreRoleChecker\n  tags:\n  - security\n  - scape hatch\n  def: undefined\n  since: 2.303.3 / 2.319\n  description: |\n    Comma-separated list of class names allowed to bypass role check requirement.\n    See .\n\n- name: hudson.remoting.ClassFilter\n  tags:\n  - security\n  - escape hatch\n  def: undefi"
  },
  "4729": {
    "source_file": "system-properties.txt",
    "text": "ass names allowed to bypass role check requirement.\n    See .\n\n- name: hudson.remoting.ClassFilter\n  tags:\n  - security\n  - escape hatch\n  def: undefined\n  description: |\n    Allow or disallow the deserialization of specified types.\n    Comma-separated class names, entries are whitelisted unless prefixed with `!`.\n    See jep:200#backwards-compatibility[JEP-200] and https://issues.jenkins.io/brows"
  },
  "4730": {
    "source_file": "system-properties.txt",
    "text": "ed class names, entries are whitelisted unless prefixed with `!`.\n    See jep:200#backwards-compatibility[JEP-200] and https://issues.jenkins.io/browse/JENKINS-47736[JENKINS-47736].\n\n- name: hudson.scheduledRetention\n  tags:\n  - obsolete\n  # TODO figure out what this does\n  def: |\n    `false`\n  since: Up to 1.354\n  description: |\n    Control a agent based on a schedule\n\n- name: hudson.scm.SCM.useA"
  },
  "4731": {
    "source_file": "system-properties.txt",
    "text": "ure out what this does\n  def: |\n    `false`\n  since: Up to 1.354\n  description: |\n    Control a agent based on a schedule\n\n- name: hudson.scm.SCM.useAutoBrowserHolder\n  tags:\n  - feature\n  def: |\n    `false` since Jenkins 2.9, `true` before\n  description: |\n    When set to `true`, Jenkins will guess the repository browser used to render links in the changelog.\n\n- name: hudson.script.noCache\n  tags"
  },
  "4732": {
    "source_file": "system-properties.txt",
    "text": "tion: |\n    When set to `true`, Jenkins will guess the repository browser used to render links in the changelog.\n\n- name: hudson.script.noCache\n  tags:\n  - development\n  def: |\n    `false` in production, `true` during development\n  description: |\n    When set to true, Jenkins will not reference resource files through the `/static/.../` URL space, preventing their caching.\n    This is set to `true`"
  },
  "4733": {
    "source_file": "system-properties.txt",
    "text": " When set to true, Jenkins will not reference resource files through the `/static/.../` URL space, preventing their caching.\n    This is set to `true` during development by default, and `false` otherwise.\n\n- name: hudson.search.Search.MAX_SEARCH_SIZE\n  tags:\n  - security\n  - escape hatch\n  def: |\n    `500`\n  since: 2.375.4 / 2.394\n  description: |\n    Limits the number of results a search can rend"
  },
  "4734": {
    "source_file": "system-properties.txt",
    "text": "\n  tags:\n  - security\n  - escape hatch\n  def: |\n    `500`\n  since: 2.375.4 / 2.394\n  description: |\n    Limits the number of results a search can render.\n\n- name: hudson.search.Search.skipPermissionCheck\n  tags:\n  - security\n  - escape hatch\n  def: |\n    `false`\n  since: 2.121.3 / 2.138\n  description: |\n    Disable security hardening related to Stapler routing for Search.\n    Possibly unsafe, .\n\n-"
  },
  "4735": {
    "source_file": "system-properties.txt",
    "text": "\n    `false`\n  since: 2.121.3 / 2.138\n  description: |\n    Disable security hardening related to Stapler routing for Search.\n    Possibly unsafe, .\n\n- name: hudson.security.AccessDeniedException2.REPORT_GROUP_HEADERS\n  tags:\n  - escape hatch\n  def: |\n    `false`\n  since: 2.32.3 / 2.46\n  description: |\n    If set to true, restore pre-2.46 behavior of sending HTTP headers on \"access denied\" pages li"
  },
  "4736": {
    "source_file": "system-properties.txt",
    "text": "\n    `false`\n  since: 2.32.3 / 2.46\n  description: |\n    If set to true, restore pre-2.46 behavior of sending HTTP headers on \"access denied\" pages listing group memberships.\n\n- name: hudson.security.ArtifactsPermission\n  tags:\n  - security\n  - escape hatch\n  def: |\n    `false`\n  since: 1.374\n  description: |\n    The Artifacts permission allows to control access to artifacts; When this property is"
  },
  "4737": {
    "source_file": "system-properties.txt",
    "text": "e hatch\n  def: |\n    `false`\n  since: 1.374\n  description: |\n    The Artifacts permission allows to control access to artifacts; When this property is unset or set to false, access to artifacts is not controlled\n\n- name: hudson.security.csrf.CrumbFilter.UNPROCESSED_PATHINFO\n  tags:\n  - security\n  - escape hatch\n  def: |\n    `false`\n  since: 2.204.6 / 2.228\n  description: |\n    Escape hatch for .\n\n"
  },
  "4738": {
    "source_file": "system-properties.txt",
    "text": "ter.UNPROCESSED_PATHINFO\n  tags:\n  - security\n  - escape hatch\n  def: |\n    `false`\n  since: 2.204.6 / 2.228\n  description: |\n    Escape hatch for .\n\n- name: hudson.security.csrf.DefaultCrumbIssuer.EXCLUDE_SESSION_ID\n  tags:\n  - security\n  - escape hatch\n  def: |\n    `false`\n  since: 2.176.2 / 2.186\n  description: |\n    Escape hatch for .\n\n- name: hudson.security.csrf.GlobalCrumbIssuerConfiguratio"
  },
  "4739": {
    "source_file": "system-properties.txt",
    "text": "atch\n  def: |\n    `false`\n  since: 2.176.2 / 2.186\n  description: |\n    Escape hatch for .\n\n- name: hudson.security.csrf.GlobalCrumbIssuerConfiguration.DISABLE_CSRF_PROTECTION\n  tags:\n  - security\n  - escape hatch\n  def: |\n    `false`\n  since: 2.222\n  description: |\n    Restore the ability to disable CSRF protection after the UI for doing so was removed from Jenkins 2.222.\n\n- name: hudson.security"
  },
  "4740": {
    "source_file": "system-properties.txt",
    "text": "  description: |\n    Restore the ability to disable CSRF protection after the UI for doing so was removed from Jenkins 2.222.\n\n- name: hudson.security.csrf.requestfield\n  tags:\n  - security\n  - tuning\n  def: |\n    `.crumb` (Jenkins 1.x), `Jenkins-Crumb` (Jenkins 2.0)\n  since: 1.310\n  description: |\n    Parameter name that contains a crumb value on POST requests\n\n- name: hudson.security.ExtendedRea"
  },
  "4741": {
    "source_file": "system-properties.txt",
    "text": "mb` (Jenkins 2.0)\n  since: 1.310\n  description: |\n    Parameter name that contains a crumb value on POST requests\n\n- name: hudson.security.ExtendedReadPermission\n  tags:\n  - security\n  - feature\n  def: |\n    `false`\n  since: 1.324\n  description: |\n    The ExtendedReadPermission allows read-only access to \"Configure\" pages; can also enable with extended-read-permission plugin\n\n- name: hudson.securi"
  },
  "4742": {
    "source_file": "system-properties.txt",
    "text": "  The ExtendedReadPermission allows read-only access to \"Configure\" pages; can also enable with extended-read-permission plugin\n\n- name: hudson.security.HudsonPrivateSecurityRealm.ID_REGEX\n  tags:\n  - security\n  - escape hatch\n  def: |\n    `+[a-zA-Z0-9_-]++`\n  since: 2.107.3 / 2.121\n  description: |\n    Regex for legal user names in Jenkins user database.\n    See .\n\n- name: hudson.security.HudsonP"
  },
  "4743": {
    "source_file": "system-properties.txt",
    "text": "-9_-]++`\n  since: 2.107.3 / 2.121\n  description: |\n    Regex for legal user names in Jenkins user database.\n    See .\n\n- name: hudson.security.HudsonPrivateSecurityRealm.maximumBCryptLogRound\n  tags:\n  - security\n  - escape hatch\n  def: |\n    `18`\n  since: 2.161\n  description: |\n    Limits the number of rounds for pre-computed BCrypt hashes of user passwords for the Jenkins user database to preven"
  },
  "4744": {
    "source_file": "system-properties.txt",
    "text": "since: 2.161\n  description: |\n    Limits the number of rounds for pre-computed BCrypt hashes of user passwords for the Jenkins user database to prevent excessive computation.\n\n- name: hudson.security.LDAPSecurityRealm.groupSearch\n# TODO move out, it's LDAP plugin\n  # def: TODO recover default that was apparently lost after wiki\n  description: |\n    LDAP filter to look for groups by their names\n\n- "
  },
  "4745": {
    "source_file": "system-properties.txt",
    "text": "s LDAP plugin\n  # def: TODO recover default that was apparently lost after wiki\n  description: |\n    LDAP filter to look for groups by their names\n\n- name: hudson.security.SecurityRealm.sessionFixationProtectionMode\n  tags:\n  - security\n  - escape hatch\n  def: |\n    `1`\n  since: 2.289.2 / 2.300\n  description: |\n    Escape hatch for .\n    Set to `0` to disable the fix or to `2` to select an alterna"
  },
  "4746": {
    "source_file": "system-properties.txt",
    "text": "tch\n  def: |\n    `1`\n  since: 2.289.2 / 2.300\n  description: |\n    Escape hatch for .\n    Set to `0` to disable the fix or to `2` to select an alternative implementation.\n\n- name: hudson.security.TokenBasedRememberMeServices2.skipTooFarExpirationDateCheck\n  tags:\n  - security\n  - escape hatch\n  def: |\n    `false`\n  since: 2.150.2 / 2.160\n  description: |\n    Escape hatch for\n\n- name: hudson.securi"
  },
  "4747": {
    "source_file": "system-properties.txt",
    "text": "Check\n  tags:\n  - security\n  - escape hatch\n  def: |\n    `false`\n  since: 2.150.2 / 2.160\n  description: |\n    Escape hatch for\n\n- name: hudson.security.WipeOutPermission\n  tags:\n  - security\n  - feature\n  def: |\n    `false`\n  since: 1.416\n  description: |\n    The WipeOut permission allows to control access to the \"Wipe Out Workspace\" action, which is normally available as soon as the Build permis"
  },
  "4748": {
    "source_file": "system-properties.txt",
    "text": "ion: |\n    The WipeOut permission allows to control access to the \"Wipe Out Workspace\" action, which is normally available as soon as the Build permission is granted\n\n- name: hudson.slaves.ChannelPinger.pingInterval\n  tags:\n  - tuning\n  - obsolete\n  def: |\n    `5`\n  since: 1.405\n  description: |\n    Frequency (in minutes) of .\n    Deprecated since 2.37, use `hudson.slaves.ChannelPinger.pingInterva"
  },
  "4749": {
    "source_file": "system-properties.txt",
    "text": "def: |\n    `5`\n  since: 1.405\n  description: |\n    Frequency (in minutes) of .\n    Deprecated since 2.37, use `hudson.slaves.ChannelPinger.pingIntervalSeconds` instead.\n\n- name: hudson.slaves.ChannelPinger.pingIntervalSeconds\n  tags:\n  - tuning\n  def: |\n    `300`\n  since: 2.37\n  description: |\n    Frequency of , in seconds\n\n- name: hudson.slaves.ChannelPinger.pingTimeoutSeconds\n  tags:\n  - tuning\n"
  },
  "4750": {
    "source_file": "system-properties.txt",
    "text": ": |\n    `300`\n  since: 2.37\n  description: |\n    Frequency of , in seconds\n\n- name: hudson.slaves.ChannelPinger.pingTimeoutSeconds\n  tags:\n  - tuning\n  def: |\n    `240`\n  since: 2.37\n  description: |\n    Timeout for each , in seconds\n\n- name: hudson.slaves.ConnectionActivityMonitor.enabled\n  tags:\n  - feature\n# TODO: This looks like a dead feature? Introduced 2011 and disabled by default?\n  def: |"
  },
  "4751": {
    "source_file": "system-properties.txt",
    "text": "slaves.ConnectionActivityMonitor.enabled\n  tags:\n  - feature\n# TODO: This looks like a dead feature? Introduced 2011 and disabled by default?\n  def: |\n    `false`\n  since: 1.326\n  description: |\n    Whether to enable this feature that checks whether agents are alive and cuts them off if not.\n\n- name: hudson.slaves.ConnectionActivityMonitor.frequency\n  tags:\n  - tuning\n# TODO: Actually dual use: Bo"
  },
  "4752": {
    "source_file": "system-properties.txt",
    "text": "agents are alive and cuts them off if not.\n\n- name: hudson.slaves.ConnectionActivityMonitor.frequency\n  tags:\n  - tuning\n# TODO: Actually dual use: Both for timeout (4 minutes) and time to ping (3 minutes). Possibly copy & paste issue and bug in core?\n  def: |\n    `10000` (10 seconds)\n  since: 1.326\n  description: |\n    How frequently to check for channel activity, in milliseconds.\n\n- name: hudson"
  },
  "4753": {
    "source_file": "system-properties.txt",
    "text": "?\n  def: |\n    `10000` (10 seconds)\n  since: 1.326\n  description: |\n    How frequently to check for channel activity, in milliseconds.\n\n- name: hudson.slaves.ConnectionActivityMonitor.timeToPing\n  tags:\n  - tuning\n  def: |\n    `180000` (3 minutes)\n  since: 1.326\n  description: |\n    How long to wait after startup to start checking agent connections, in milliseconds.\n\n- name: hudson.slaves.NodeProv"
  },
  "4754": {
    "source_file": "system-properties.txt",
    "text": "since: 1.326\n  description: |\n    How long to wait after startup to start checking agent connections, in milliseconds.\n\n- name: hudson.slaves.NodeProvisioner.initialDelay\n  tags:\n  - tuning\n  def: |\n    10 times `hudson.model.LoadStatistics.clock`, typically 100 seconds\n  description: |\n    How long to wait after startup before starting to provision nodes from clouds.\n    This will allow static ag"
  },
  "4755": {
    "source_file": "system-properties.txt",
    "text": "ypically 100 seconds\n  description: |\n    How long to wait after startup before starting to provision nodes from clouds.\n    This will allow static agents to start and handle the load first.\n\n- name: hudson.slaves.NodeProvisioner.MARGIN\n  tags:\n  - tuning\n\n- name: hudson.slaves.NodeProvisioner.MARGIN0\n  tags:\n  - tuning\n\n- name: hudson.slaves.NodeProvisioner.MARGIN_DECAY\n  tags:\n  - tuning\n\n- name"
  },
  "4756": {
    "source_file": "system-properties.txt",
    "text": "uning\n\n- name: hudson.slaves.NodeProvisioner.MARGIN0\n  tags:\n  - tuning\n\n- name: hudson.slaves.NodeProvisioner.MARGIN_DECAY\n  tags:\n  - tuning\n\n- name: hudson.slaves.NodeProvisioner.recurrencePeriod\n  tags:\n  - tuning\n  def: |\n    Equal to `hudson.model.LoadStatistics.clock`, typically 10 seconds\n  description: |\n    How frequently to possibly provision nodes.\n\n- name: hudson.slaves.SlaveComputer."
  },
  "4757": {
    "source_file": "system-properties.txt",
    "text": "del.LoadStatistics.clock`, typically 10 seconds\n  description: |\n    How frequently to possibly provision nodes.\n\n- name: hudson.slaves.SlaveComputer.allowUnsupportedRemotingVersions\n  tags:\n  - escape hatch\n  def: |\n    `false`\n  since: 2.343\n  description: |\n    Allow connection by agents running unsupported remoting versions.\n\n- name: hudson.slaves.WorkspaceList\n  tags:\n  - tuning\n  def: |\n    "
  },
  "4758": {
    "source_file": "system-properties.txt",
    "text": "ription: |\n    Allow connection by agents running unsupported remoting versions.\n\n- name: hudson.slaves.WorkspaceList\n  tags:\n  - tuning\n  def: |\n    `@`\n  since: 1.424\n  description: |\n    When concurrent builds is enabled, a unique workspace directory name is required for each concurrent build.\n    To create this name, this token is placed between project name and a unique ID, e.g. \"my-project@1"
  },
  "4759": {
    "source_file": "system-properties.txt",
    "text": "ory name is required for each concurrent build.\n    To create this name, this token is placed between project name and a unique ID, e.g. \"my-project@123\".\n\n- name: hudson.tasks.ArtifactArchiver.warnOnEmpty\n  tags:\n  - feature\n  def: |\n    `false`\n  description: |\n    When true, builds don't fail when there is nothing to archive\n\n- name: hudson.tasks.Fingerprinter.enableFingerprintsInDependencyGrap"
  },
  "4760": {
    "source_file": "system-properties.txt",
    "text": "escription: |\n    When true, builds don't fail when there is nothing to archive\n\n- name: hudson.tasks.Fingerprinter.enableFingerprintsInDependencyGraph\n  tags:\n  - feature\n  def: |\n    `false`\n  since: 1.430\n  description: |\n    When true, jobs associated through fingerprints are added to the dependency graph, even when there is no configured upstream/downstream relationship between them.\n\n- name:"
  },
  "4761": {
    "source_file": "system-properties.txt",
    "text": "iated through fingerprints are added to the dependency graph, even when there is no configured upstream/downstream relationship between them.\n\n- name: hudson.tasks.MailSender.maxLogLines\n# TODO is this mailer plugin now?\n  def: |\n    `250`\n  description: |\n    Number of lines of console output to include in emails\n\n- name: hudson.TcpSlaveAgentListener.hostName\n  tags:\n  - feature\n  def: |\n    Same"
  },
  "4762": {
    "source_file": "system-properties.txt",
    "text": "ion: |\n    Number of lines of console output to include in emails\n\n- name: hudson.TcpSlaveAgentListener.hostName\n  tags:\n  - feature\n  def: |\n    Same as the configured Jenkins root URL\n  description: |\n    Host name that Jenkins advertises to inbound TCP agents.\n    Especially useful when running Jenkins behind a reverse proxy.\n\n- name: hudson.TcpSlaveAgentListener.port\n  tags:\n  - feature\n  def:"
  },
  "4763": {
    "source_file": "system-properties.txt",
    "text": "d TCP agents.\n    Especially useful when running Jenkins behind a reverse proxy.\n\n- name: hudson.TcpSlaveAgentListener.port\n  tags:\n  - feature\n  def: |\n    Same as the configured TCP agent port\n  description: |\n    Port that Jenkins advertises to inbound TCP agents.\n    Especially useful when running Jenkins behind a reverse proxy.\n\n- name: hudson.TreeView\n  tags:\n  - feature\n  - obsolete\n  def: "
  },
  "4764": {
    "source_file": "system-properties.txt",
    "text": "bound TCP agents.\n    Especially useful when running Jenkins behind a reverse proxy.\n\n- name: hudson.TreeView\n  tags:\n  - feature\n  - obsolete\n  def: |\n    `false`\n  description: |\n    Enables the experimental nested views feature.\n    Has no effect since 2.302, as the experimental nested views feature has been removed.\n\n- name: hudson.triggers.SafeTimerTask.logsTargetDir\n  tags:\n  - feature\n  def"
  },
  "4765": {
    "source_file": "system-properties.txt",
    "text": "since 2.302, as the experimental nested views feature has been removed.\n\n- name: hudson.triggers.SafeTimerTask.logsTargetDir\n  tags:\n  - feature\n  def: |\n    `$JENKINS_HOME/logs`\n  since: 2.114\n  description: |\n    Allows to move the logs usually found under `$JENKINS_HOME/logs` to another location.\n    Beware that no migration is handled if you change it on an existing deployment.\n\n- name: hudson"
  },
  "4766": {
    "source_file": "system-properties.txt",
    "text": "nd under `$JENKINS_HOME/logs` to another location.\n    Beware that no migration is handled if you change it on an existing deployment.\n\n- name: hudson.triggers.SCMTrigger.starvationThreshold\n  tags:\n  - tuning\n  def: |\n    `3600000` (1 hour)\n  description: |\n    Milliseconds waiting for polling executor before trigger reports it is clogged.\n\n- name: hudson.udp\n  tags:\n  - escape hatch\n  - obsolete"
  },
  "4767": {
    "source_file": "system-properties.txt",
    "text": "ption: |\n    Milliseconds waiting for polling executor before trigger reports it is clogged.\n\n- name: hudson.udp\n  tags:\n  - escape hatch\n  - obsolete\n  - tuning\n  def: |\n    `33848` until 2.218, `-1` in 2.219\n  description: |\n    Port for UDP multicast broadcast.\n    Set to -1 to disable.\n    Has no effect since 2.220 as the feature has been removed.\n    See\n\n- name: hudson.upstreamCulprits\n  tag"
  },
  "4768": {
    "source_file": "system-properties.txt",
    "text": "ast broadcast.\n    Set to -1 to disable.\n    Has no effect since 2.220 as the feature has been removed.\n    See\n\n- name: hudson.upstreamCulprits\n  tags:\n  - feature\n  def: |\n    `false`\n  since: 1.327\n  description: |\n    Pass blame information to downstream jobs.\n\n- name: hudson.util.AtomicFileWriter.DISABLE_FORCED_FLUSH\n  tags:\n  - escape hatch\n# The code is really confusing; there are two flags"
  },
  "4769": {
    "source_file": "system-properties.txt",
    "text": "wnstream jobs.\n\n- name: hudson.util.AtomicFileWriter.DISABLE_FORCED_FLUSH\n  tags:\n  - escape hatch\n# The code is really confusing; there are two flags, one is always false, and will be forcibly set to false here, except using a new constructor that was deprecated in the same PR it was introduced in.\n  def: |\n    `false`\n  since: 2.102\n  description: |\n    Disables the forced flushing when calling "
  },
  "4770": {
    "source_file": "system-properties.txt",
    "text": "as deprecated in the same PR it was introduced in.\n  def: |\n    `false`\n  since: 2.102\n  description: |\n    Disables the forced flushing when calling `#close()`.\n    Not expected to be used.\n\n- name: hudson.util.AtomicFileWriter.REQUIRES_DIR_FSYNC\n  tags:\n  - escape hatch\n  def: |\n    `true` on Unix, `false` on Windows\n  since: 2.440\n  description: |\n    Whether or not to flush the parent director"
  },
  "4771": {
    "source_file": "system-properties.txt",
    "text": "tags:\n  - escape hatch\n  def: |\n    `true` on Unix, `false` on Windows\n  since: 2.440\n  description: |\n    Whether or not to flush the parent directory to disk after flushing the file to disk,\n    which is needed to ensure crash consistency in several Unix filesystems.\n    Prior to 2.440, the parent directory was never flushed to disk.\n\n- name: hudson.util.CharacterEncodingFilter.disableFilter\n  t"
  },
  "4772": {
    "source_file": "system-properties.txt",
    "text": "l Unix filesystems.\n    Prior to 2.440, the parent directory was never flushed to disk.\n\n- name: hudson.util.CharacterEncodingFilter.disableFilter\n  tags:\n  - escape hatch\n  def: |\n    `false`\n  description: |\n    Set to `true` to disable the filter that sets request encoding to UTF-8 if it's undefined and its content type is `text/xml` or `application/xml` (API submissions).\n\n- name: hudson.util."
  },
  "4773": {
    "source_file": "system-properties.txt",
    "text": "that sets request encoding to UTF-8 if it's undefined and its content type is `text/xml` or `application/xml` (API submissions).\n\n- name: hudson.util.CharacterEncodingFilter.forceEncoding\n  tags:\n  - feature\n  def: |\n    `false`\n  description: |\n    Set to `true` to force the request encoding to UTF-8 even if a different character set is declared.\n\n- name: hudson.Util.deletionRetryWait\n  tags:\n  -"
  },
  "4774": {
    "source_file": "system-properties.txt",
    "text": "Set to `true` to force the request encoding to UTF-8 even if a different character set is declared.\n\n- name: hudson.Util.deletionRetryWait\n  tags:\n  - tuning\n  def: |\n    `100`\n  since: 2.2\n  description: |\n    The time (in milliseconds) to wait between attempts to delete files when retrying.\n    This has no effect unless _hudson.Util.maxFileDeletionRetries_ is greater than 1.\n    If zero, there w"
  },
  "4775": {
    "source_file": "system-properties.txt",
    "text": "een attempts to delete files when retrying.\n    This has no effect unless _hudson.Util.maxFileDeletionRetries_ is greater than 1.\n    If zero, there will be no delay between attempts.\n    If negative, the delay will be a (linearly) increasing multiple of this value between attempts.\n\n- name: hudson.util.Digester2.UNSAFE\n  tags:\n  - security\n  - escape hatch\n  - obsolete\n  def: |\n    `false`\n  sinc"
  },
  "4776": {
    "source_file": "system-properties.txt",
    "text": "e of this value between attempts.\n\n- name: hudson.util.Digester2.UNSAFE\n  tags:\n  - security\n  - escape hatch\n  - obsolete\n  def: |\n    `false`\n  since: 2.263.2 / 2.275\n  description: |\n    Opts out of a change in default behavior that disables the processing of XML external entities (XXE) for the `Digester2` class in Jenkins if set to `true`.\n    This system property can be changed while Jenkins "
  },
  "4777": {
    "source_file": "system-properties.txt",
    "text": "rocessing of XML external entities (XXE) for the `Digester2` class in Jenkins if set to `true`.\n    This system property can be changed while Jenkins is running and the change is effective immediately.\n    See .\n    Has no effect since 2.297, as the `Digester2` class has been removed.\n\n- name: hudson.util.FormValidation.applyContentSecurityPolicyHeaders\n  tags:\n  - security\n  - escape hatch\n  def:"
  },
  "4778": {
    "source_file": "system-properties.txt",
    "text": "`Digester2` class has been removed.\n\n- name: hudson.util.FormValidation.applyContentSecurityPolicyHeaders\n  tags:\n  - security\n  - escape hatch\n  def: |\n    `true`\n  since: 2.263.2 / 2.275\n  description: |\n    Controls whether to set restrictive Content-Security-Policy headers on URLs implementing form validation responses.\n    This reduces the impact of cross-site scripting (XSS) vulnerabilities "
  },
  "4779": {
    "source_file": "system-properties.txt",
    "text": "ent-Security-Policy headers on URLs implementing form validation responses.\n    This reduces the impact of cross-site scripting (XSS) vulnerabilities in form validation output.\n    See .\n\n- name: hudson.util.Graph.maxArea\n  tags:\n  - security\n  - escape hatch\n  def: |\n    `10000000` (10 million)\n  since: 2.263.2 / 2.275\n  description: |\n    Controls the maximum size (area) for requests to render g"
  },
  "4780": {
    "source_file": "system-properties.txt",
    "text": "ape hatch\n  def: |\n    `10000000` (10 million)\n  since: 2.263.2 / 2.275\n  description: |\n    Controls the maximum size (area) for requests to render graphs like load statistics.\n    See .\n\n- name: hudson.Util.maxFileDeletionRetries\n  tags:\n  - tuning\n  def: |\n    `3`\n  since: 2.2\n  description: |\n    The number of times to attempt to delete files/directory trees before giving up and throwing an ex"
  },
  "4781": {
    "source_file": "system-properties.txt",
    "text": "\n  def: |\n    `3`\n  since: 2.2\n  description: |\n    The number of times to attempt to delete files/directory trees before giving up and throwing an exception.\n    Specifying a value less than 1 is invalid and will be treated as if a value of 1 (i.e. one attempt, no retries) was specified.\n    See https://issues.jenkins.io/browse/JENKINS-10113[JENKINS-10113] and https://issues.jenkins.io/browse/JEN"
  },
  "4782": {
    "source_file": "system-properties.txt",
    "text": "one attempt, no retries) was specified.\n    See https://issues.jenkins.io/browse/JENKINS-10113[JENKINS-10113] and https://issues.jenkins.io/browse/JENKINS-15331[JENKINS-15331].\n\n- name: hudson.util.MultipartFormDataParser.FILEUPLOAD_MAX_FILES\n  tags:\n  - escape hatch\n  - tuning\n  - security\n  def: |\n    `1000`\n  since: 2.375.4 / 2.394\n  description: |\n    Limits the number of form fields that can "
  },
  "4783": {
    "source_file": "system-properties.txt",
    "text": "\n  - escape hatch\n  - tuning\n  - security\n  def: |\n    `1000`\n  since: 2.375.4 / 2.394\n  description: |\n    Limits the number of form fields that can be processed in one `multipart/form-data` request.\n    Used to set `org.apache.commons.fileupload.servlet.ServletFileUpload#setFileCountMax(long)`.\n    Despite the name, this applies to all form fields, not just actual file attachments.\n    `-1` disa"
  },
  "4784": {
    "source_file": "system-properties.txt",
    "text": "rvlet.ServletFileUpload#setFileCountMax(long)`.\n    Despite the name, this applies to all form fields, not just actual file attachments.\n    `-1` disables this limit.\n\n- name: hudson.util.MultipartFormDataParser.FILEUPLOAD_MAX_FILE_SIZE\n  tags:\n  # Not an escape hatch since it's disabled by default\n  - tuning\n  - security\n  def: |\n    `-1`\n  since: 2.375.4 / 2.394\n  description: |\n    Limits the s"
  },
  "4785": {
    "source_file": "system-properties.txt",
    "text": "ot an escape hatch since it's disabled by default\n  - tuning\n  - security\n  def: |\n    `-1`\n  since: 2.375.4 / 2.394\n  description: |\n    Limits the size (in bytes) of individual fields that can be processed in one `multipart/form-data` request.\n    Despite the name, this applies to all form fields, not just actual file attachments.\n    `-1` disables this limit.\n\n- name: hudson.util.MultipartFormD"
  },
  "4786": {
    "source_file": "system-properties.txt",
    "text": "Despite the name, this applies to all form fields, not just actual file attachments.\n    `-1` disables this limit.\n\n- name: hudson.util.MultipartFormDataParser.FILEUPLOAD_MAX_SIZE\n  tags:\n    # Not an escape hatch since it's disabled by default\n    - tuning\n    - security\n  def: |\n    `-1`\n  since: 2.375.4 / 2.394\n  description: |\n    Limits the total request size (in bytes) that can be processed "
  },
  "4787": {
    "source_file": "system-properties.txt",
    "text": " tuning\n    - security\n  def: |\n    `-1`\n  since: 2.375.4 / 2.394\n  description: |\n    Limits the total request size (in bytes) that can be processed in one `multipart/form-data` request.\n    Used to set `org.apache.commons.fileupload.servlet.ServletFileUpload#setSizeMax(long)`.\n    `-1` disables this limit.\n\n- name: hudson.Util.noSymLink\n  tags:\n  - feature\n  # TODO this is now in a plugin I thin"
  },
  "4788": {
    "source_file": "system-properties.txt",
    "text": "FileUpload#setSizeMax(long)`.\n    `-1` disables this limit.\n\n- name: hudson.Util.noSymLink\n  tags:\n  - feature\n  # TODO this is now in a plugin I think?\n  def: |\n    `false`\n  description: |\n    True to disable creation of symbolic links in job/builds directories\n\n- name: hudson.Util.performGCOnFailedDelete\n  tags:\n  - tuning\n  def: |\n    `false`\n  since: 2.2\n  description: |\n    If this flag is s"
  },
  "4789": {
    "source_file": "system-properties.txt",
    "text": "s directories\n\n- name: hudson.Util.performGCOnFailedDelete\n  tags:\n  - tuning\n  def: |\n    `false`\n  since: 2.2\n  description: |\n    If this flag is set to `true` then we will request a garbage collection after a deletion failure before we next retry the delete.\n    It is ignored unless _hudson.Util.maxFileDeletionRetries_ is greater than 1.\n    Setting this flag to `true` _may_ resolve some probl"
  },
  "4790": {
    "source_file": "system-properties.txt",
    "text": " the delete.\n    It is ignored unless _hudson.Util.maxFileDeletionRetries_ is greater than 1.\n    Setting this flag to `true` _may_ resolve some problems on Windows, and also for directory trees residing on an NFS share, but it can have a negative impact on performance and may have no effect at all (GC behavior is JVM-specific).\n    **Warning**: This should only ever be used if you find that your "
  },
  "4791": {
    "source_file": "system-properties.txt",
    "text": "pact on performance and may have no effect at all (GC behavior is JVM-specific).\n    **Warning**: This should only ever be used if you find that your builds are failing because Jenkins is unable to delete files, that this failure is because Jenkins itself has those files locked \"open\", and even then it should only be used on agents with relatively few executors (because the garbage collection can "
  },
  "4792": {
    "source_file": "system-properties.txt",
    "text": "tself has those files locked \"open\", and even then it should only be used on agents with relatively few executors (because the garbage collection can impact the performance of all job executors on that agent).\n    _Setting this flag is a act of last resort - it is not recommended, and should not be used on your main Jenkins server unless you can tolerate the performance impact_.\n\n- name: hudson.ut"
  },
  "4793": {
    "source_file": "system-properties.txt",
    "text": "resort - it is not recommended, and should not be used on your main Jenkins server unless you can tolerate the performance impact_.\n\n- name: hudson.util.ProcessTree.disable\n  tags:\n  - feature\n  def: |\n    `false`\n  description: |\n    True to disable cleanup of child processes.\n\n- name: hudson.util.RingBufferLogHandler.defaultSize\n  tags:\n  - tuning\n  def: |\n    `256`\n  since: 1.563\n  description:"
  },
  "4794": {
    "source_file": "system-properties.txt",
    "text": " cleanup of child processes.\n\n- name: hudson.util.RingBufferLogHandler.defaultSize\n  tags:\n  - tuning\n  def: |\n    `256`\n  since: 1.563\n  description: |\n    Number of log entries in loggers available on the UI at `/log/`\n\n- name: hudson.util.RobustReflectionConverter.recordFailuresForAdmins\n  tags:\n  - security\n  - escape hatch\n  def: |\n    `false`\n  since: 2.263.2 / 2.275\n  description: |\n    If "
  },
  "4795": {
    "source_file": "system-properties.txt",
    "text": "flectionConverter.recordFailuresForAdmins\n  tags:\n  - security\n  - escape hatch\n  def: |\n    `false`\n  since: 2.263.2 / 2.275\n  description: |\n    If set to `true`, Old Data Monitor will record some failures to load data submitted by users with Overall/Administer permission, partially disabling a security fix.\n    See  and .\n\n- name: hudson.util.RobustReflectionConverter.recordFailuresForAllAuthen"
  },
  "4796": {
    "source_file": "system-properties.txt",
    "text": "ll/Administer permission, partially disabling a security fix.\n    See  and .\n\n- name: hudson.util.RobustReflectionConverter.recordFailuresForAllAuthentications\n  tags:\n  - security\n  - escape hatch\n  def: |\n    `false`\n  since: 2.263.2 / 2.275\n  description: |\n    If set to `true`, Old Data Monitor will record some failures to load data submitted by all authorized users, completely disabling a sec"
  },
  "4797": {
    "source_file": "system-properties.txt",
    "text": "ription: |\n    If set to `true`, Old Data Monitor will record some failures to load data submitted by all authorized users, completely disabling a security fix.\n    See  and .\n\n- name: hudson.util.Secret.AUTO_ENCRYPT_PASSWORD_CONTROL\n  tags:\n  - security\n  - escape hatch\n  def: |\n    `true`\n  since: 2.236\n  description: |\n    Jenkins automatically round-trips `f:password` based form fields as encr"
  },
  "4798": {
    "source_file": "system-properties.txt",
    "text": "rity\n  - escape hatch\n  def: |\n    `true`\n  since: 2.236\n  description: |\n    Jenkins automatically round-trips `f:password` based form fields as encrypted `Secret` even if the field is not of type `Secret`.\n    Set this to `false` to disable this behavior, doing so is discouraged.\n\n- name: hudson.util.Secret.BLANK_NONSECRET_PASSWORD_FIELDS_WITHOUT_ITEM_CONFIGURE\n  tags:\n  - escape hatch\n  - secur"
  },
  "4799": {
    "source_file": "system-properties.txt",
    "text": "havior, doing so is discouraged.\n\n- name: hudson.util.Secret.BLANK_NONSECRET_PASSWORD_FIELDS_WITHOUT_ITEM_CONFIGURE\n  tags:\n  - escape hatch\n  - security\n  def: |\n    `true`\n  since: 2.236\n  description: |\n    If the user is missing _Item/Configure_ permission, Jenkins 2.236 and newer will blank out the password value automatically even if the form field is not backed by a `Secret`.\n    Set this t"
  },
  "4800": {
    "source_file": "system-properties.txt",
    "text": "permission, Jenkins 2.236 and newer will blank out the password value automatically even if the form field is not backed by a `Secret`.\n    Set this to `false` to disable this behavior, doing so is discouraged.\n\n- name: hudson.util.Secret.provider\n  tags:\n  - escape hatch\n  def: system default\n  since: 1.360\n  description: |\n    Force a particular crypto provider; with Glassfish Enterprise set val"
  },
  "4801": {
    "source_file": "system-properties.txt",
    "text": "tags:\n  - escape hatch\n  def: system default\n  since: 1.360\n  description: |\n    Force a particular crypto provider; with Glassfish Enterprise set value to `SunJCE` to workaround https://issues.jenkins.io/browse/JENKINS-6459[JENKINS-6459] and GLASSFISH-11862.\n\n- name: hudson.util.StreamTaskListener.AUTO_FLUSH\n  tags:\n  - escape hatch\n# https://github.com/jenkinsci/jenkins/pull/3961\n  def: |\n    `f"
  },
  "4802": {
    "source_file": "system-properties.txt",
    "text": "SH-11862.\n\n- name: hudson.util.StreamTaskListener.AUTO_FLUSH\n  tags:\n  - escape hatch\n# https://github.com/jenkinsci/jenkins/pull/3961\n  def: |\n    `false`\n  since: 2.173\n  description: |\n    Jenkins no longer automatically flushes streams for code running remotely on agents for better performance.\n    This may lead to loss of messages for plugins which print to a build log from the agent machine "
  },
  "4803": {
    "source_file": "system-properties.txt",
    "text": "unning remotely on agents for better performance.\n    This may lead to loss of messages for plugins which print to a build log from the agent machine but do not flush their output.\n    Use this flag to restore the previous behavior for freestyle builds.\n\n- name: hudson.Util.symlinkEscapeHatch\n  tags:\n  - escape hatch\n  def: |\n    `false`\n  description: |\n    True to use exec of \"ln\" binary to crea"
  },
  "4804": {
    "source_file": "system-properties.txt",
    "text": "ds.\n\n- name: hudson.Util.symlinkEscapeHatch\n  tags:\n  - escape hatch\n  def: |\n    `false`\n  description: |\n    True to use exec of \"ln\" binary to create symbolic links instead of native code\n\n- name: hudson.Util.useNativeChmodAndMode\n  tags:\n  - escape hatch\n  def: |\n    `false`\n  since: 2.93\n  description: |\n    True to use native (JNA/JNR) implementation to set file permissions instead of NIO.\n "
  },
  "4805": {
    "source_file": "system-properties.txt",
    "text": "pe hatch\n  def: |\n    `false`\n  since: 2.93\n  description: |\n    True to use native (JNA/JNR) implementation to set file permissions instead of NIO.\n    Removed without replacement in 2.304.\n\n- name: hudson.util.XStream2.collectionUpdateLimit\n  tags:\n  - security\n  - tuning\n  - escape hatch\n  def: |\n    `5`\n  since: 2.319.3 / 2.334\n  description: |\n    The maximum number of seconds that adding ele"
  },
  "4806": {
    "source_file": "system-properties.txt",
    "text": "\n  - security\n  - tuning\n  - escape hatch\n  def: |\n    `5`\n  since: 2.319.3 / 2.334\n  description: |\n    The maximum number of seconds that adding elements to collections may cumulatively take when loading an XML document using XStream, or `-1` to disable.\n    See  for context.\n\n- name: hudson.WebAppMain.forceSessionTrackingByCookie\n  tags:\n  - escape hatch\n  - security\n  def: |\n    `true`\n  since"
  },
  "4807": {
    "source_file": "system-properties.txt",
    "text": "sable.\n    See  for context.\n\n- name: hudson.WebAppMain.forceSessionTrackingByCookie\n  tags:\n  - escape hatch\n  - security\n  def: |\n    `true`\n  since: 2.234\n  description: |\n    Set to `false` to not force session tracking to be done via cookie.\n    Escape hatch for https://issues.jenkins.io/browse/JENKINS-61738[JENKINS-61738].\n\n- name: hudson.widgets.HistoryWidget.threshold\n  tags:\n  - tuning\n  "
  },
  "4808": {
    "source_file": "system-properties.txt",
    "text": " Escape hatch for https://issues.jenkins.io/browse/JENKINS-61738[JENKINS-61738].\n\n- name: hudson.widgets.HistoryWidget.threshold\n  tags:\n  - tuning\n  def: |\n    `30`\n  since: 1.433\n  description: |\n    How many builds to show in the build history side panel widget.\n\n- name: historyWidget.descriptionLimit\n  tags:\n  - feature\n  - UI\n  def: |\n    `100`\n  since: 2.223\n  description: |\n    Defines a li"
  },
  "4809": {
    "source_file": "system-properties.txt",
    "text": "e panel widget.\n\n- name: historyWidget.descriptionLimit\n  tags:\n  - feature\n  - UI\n  def: |\n    `100`\n  since: 2.223\n  description: |\n    Defines a limit for the characters shown in the description field for each build row in the Build History column.\n    A positive integer (e.g. `300`) will define the limit.\n    After the limit is reached (...) will be shown.\n    The value `-1` disables the limit"
  },
  "4810": {
    "source_file": "system-properties.txt",
    "text": ".\n    A positive integer (e.g. `300`) will define the limit.\n    After the limit is reached (...) will be shown.\n    The value `-1` disables the limit and allows unlimited characters in the build description.\n    The value `0` shows no description.\n\n- name: HUDSON_HOME\n  def: n/a\n  tags:\n  - obsolete\n  description: |\n    Backward compatible fallback name for `JENKINS_HOME`.\n    See documentation t"
  },
  "4811": {
    "source_file": "system-properties.txt",
    "text": "- name: HUDSON_HOME\n  def: n/a\n  tags:\n  - obsolete\n  description: |\n    Backward compatible fallback name for `JENKINS_HOME`.\n    See documentation there.\n\n- name: io.jenkins.lib.support_log_formatter.SupportLogFormatter.DO_NOT_FORMAT_FOR_CLI\n  def: false\n  tags:\n  - security\n  - escape hatch\n  since: 2.516.3 / 2.528\n  description: |\n    Set to `true` to disable newline indicators in multiline lo"
  },
  "4812": {
    "source_file": "system-properties.txt",
    "text": " false\n  tags:\n  - security\n  - escape hatch\n  since: 2.516.3 / 2.528\n  description: |\n    Set to `true` to disable newline indicators in multiline log messages.\n    See .\n\n- name: io.jenkins.lib.support_log_formatter.SupportLogFormatter.NEWLINE_INDICATOR\n  def: |\n    `>&nbsp;`\n  tags:\n  - security\n  since: 2.516.3 / 2.528\n  description: |\n    Can be used to customize the newline indicator in mult"
  },
  "4813": {
    "source_file": "system-properties.txt",
    "text": "CATOR\n  def: |\n    `>&nbsp;`\n  tags:\n  - security\n  since: 2.516.3 / 2.528\n  description: |\n    Can be used to customize the newline indicator in multiline log messages.\n    See .\n\n- name: jenkins.CLI.disabled\n  tags:\n  - feature\n  - obsolete\n  def: |\n    `false`\n  since: 2.19.3 / 2.32\n  description: |\n    `true` to disable Jenkins CLI via JNLP and HTTP (SSHD can still be enabled). This has no eff"
  },
  "4814": {
    "source_file": "system-properties.txt",
    "text": "|\n    `false`\n  since: 2.19.3 / 2.32\n  description: |\n    `true` to disable Jenkins CLI via JNLP and HTTP (SSHD can still be enabled). This has no effect since 2.165.\n\n- name: jenkins.InitReactorRunner.concurrency\n  tags:\n  - tuning\n  def: 2x of CPU\n  description: |\n    During the start of Jenkins, the loading of jobs in parallel have a fixed number of threads by default (twice the CPU).\n    To ma"
  },
  "4815": {
    "source_file": "system-properties.txt",
    "text": "  description: |\n    During the start of Jenkins, the loading of jobs in parallel have a fixed number of threads by default (twice the CPU).\n    To make Jenkins load time 8x faster (assuming sufficient IO), increase it to 8x.\n    For example, 24 CPU Jenkins controller host use this: `-Djenkins.InitReactorRunner.concurrency=192`\n\n- name: jenkins.health.HealthCheckAction.thresholdTimeout\n  tags:\n  -"
  },
  "4816": {
    "source_file": "system-properties.txt",
    "text": "Jenkins controller host use this: `-Djenkins.InitReactorRunner.concurrency=192`\n\n- name: jenkins.health.HealthCheckAction.thresholdTimeout\n  tags:\n  - tuning\n  def: |\n    `PT10S` (10 seconds)\n  since: 2.536\n  description: |\n    Log a thread dump when a `/health` check exceeds this timeout to help diagnose stuck requests.\n    Useful for debugging Kubernetes liveness probe failures caused by stuck h"
  },
  "4817": {
    "source_file": "system-properties.txt",
    "text": " a `/health` check exceeds this timeout to help diagnose stuck requests.\n    Useful for debugging Kubernetes liveness probe failures caused by stuck health checks.\n    The value can be specified in ISO-8601 duration format (e.g., `PT20S`) or simple format with 1-character suffix (e.g., `20s`).\n\n- name: jenkins.install.runSetupWizard\n  tags:\n  - feature\n  def: undefined\n  since: 2.0\n  description: "
  },
  "4818": {
    "source_file": "system-properties.txt",
    "text": "ormat with 1-character suffix (e.g., `20s`).\n\n- name: jenkins.install.runSetupWizard\n  tags:\n  - feature\n  def: undefined\n  since: 2.0\n  description: |\n    Set to `false` to skip install wizard.\n    Note that doing so leaves Jenkins unsecured.\n    Development-mode only: Set to `true` to not skip showing the setup wizard during Jenkins development.\n    This property is only effective the first time"
  },
  "4819": {
    "source_file": "system-properties.txt",
    "text": "velopment-mode only: Set to `true` to not skip showing the setup wizard during Jenkins development.\n    This property is only effective the first time you run Jenkins in given `JENKINS_HOME`.\n\n- name: jenkins.install.SetupWizard.adminInitialApiToken\n  tags:\n  - security\n  - packaging\n  def: The default admin account will not have an API Token unless a value is provided for this system property\n  s"
  },
  "4820": {
    "source_file": "system-properties.txt",
    "text": "  tags:\n  - security\n  - packaging\n  def: The default admin account will not have an API Token unless a value is provided for this system property\n  since: 2.260\n  description: |\n    This property determines the behavior during the SetupWizard install phase concerning the API Token creation for the initial admin account.\n    The behavior depends on the provided value:\n\n    `true`:: A token is gene"
  },
  "4821": {
    "source_file": "system-properties.txt",
    "text": "l phase concerning the API Token creation for the initial admin account.\n    The behavior depends on the provided value:\n\n    `true`:: A token is generated using random value at startup and the information is put in the file `$JENKINS_HOME/secrets/initialAdminApiToken`.\n    \"token\" in plain text:: A fixed API Token will be created for the user with provided value as the token.\n    \"@[file-location"
  },
  "4822": {
    "source_file": "system-properties.txt",
    "text": "itialAdminApiToken`.\n    \"token\" in plain text:: A fixed API Token will be created for the user with provided value as the token.\n    \"@[file-location]\" which contains plain text value of the token:: A fixed API Token will be created for the user with the value read from the file.\n    Jenkins will not delete the file after read, so the script is responsible to remove it when no longer needed.\n\n   "
  },
  "4823": {
    "source_file": "system-properties.txt",
    "text": "h the value read from the file.\n    Jenkins will not delete the file after read, so the script is responsible to remove it when no longer needed.\n\n    Token format is `[2-char hash version][32-hex-char of secret]`, where the hash version is currently only 11, e.g., `110123456789abcdef0123456789abcdef`.\n    For example can be generated in following ways:\n\n    * manually by prepending `11` to output"
  },
  "4824": {
    "source_file": "system-properties.txt",
    "text": " only 11, e.g., `110123456789abcdef0123456789abcdef`.\n    For example can be generated in following ways:\n\n    * manually by prepending `11` to output of random generator website.\n      Ask for 32 hex digits or 16 bytes in hex, e.g. https://www.browserling.com/tools/random-hex, https://www.random.org/bytes/\n    * in a shell: `echo \"11$(openssl rand -hex 16)\"`\n    * in JavaScript: `const genRanHex "
  },
  "4825": {
    "source_file": "system-properties.txt",
    "text": "erling.com/tools/random-hex, https://www.random.org/bytes/\n    * in a shell: `echo \"11$(openssl rand -hex 16)\"`\n    * in JavaScript: `const genRanHex = size => [...Array(size)].map(() => Math.floor(Math.random() * 16).toString(16)).join(''); console.log('11' + genRanHex(32));`\n\n    When the API Token is generated using this system property, it should be revoked during the installation script using"
  },
  "4826": {
    "source_file": "system-properties.txt",
    "text": "log('11' + genRanHex(32));`\n\n    When the API Token is generated using this system property, it should be revoked during the installation script using the other ways at your disposal so that you have a fresh (random) token with less traces for your script.\n    See https://javadoc.jenkins.io/jenkins/security/ApiTokenProperty.html#generateNewToken-java.lang.String-[ApiTokenProperty#generateNewToken("
  },
  "4827": {
    "source_file": "system-properties.txt",
    "text": "cript.\n    See https://javadoc.jenkins.io/jenkins/security/ApiTokenProperty.html#generateNewToken-java.lang.String-[ApiTokenProperty#generateNewToken(String)] and https://javadoc.jenkins.io/jenkins/security/ApiTokenProperty.html#revokeAllTokensExceptOne-java.lang.String-[ApiTokenProperty#revokeAllTokensExceptOne(String)] for scripting methods or using the web API calls:\n    `/user/[user-login]/des"
  },
  "4828": {
    "source_file": "system-properties.txt",
    "text": "One-java.lang.String-[ApiTokenProperty#revokeAllTokensExceptOne(String)] for scripting methods or using the web API calls:\n    `/user/[user-login]/descriptorByName/jenkins.security.ApiTokenProperty/generateNewToken` and `/user/[user-login]/descriptorByName/jenkins.security.ApiTokenProperty/revokeAllExcept`\n\n- name: jenkins.model.Jenkins.additionalReadablePaths\n  tags:\n  - security\n  - escape hatch"
  },
  "4829": {
    "source_file": "system-properties.txt",
    "text": "ByName/jenkins.security.ApiTokenProperty/revokeAllExcept`\n\n- name: jenkins.model.Jenkins.additionalReadablePaths\n  tags:\n  - security\n  - escape hatch\n  def: |\n    undefined\n  since: 2.263.2 / 2.275\n  description: |\n    A comma-separated list of additional top level path segments that should be accessible to users without Overall/Read permission.\n    See .\n\n- name: jenkins.model.Jenkins.buildsDir\n"
  },
  "4830": {
    "source_file": "system-properties.txt",
    "text": "tional top level path segments that should be accessible to users without Overall/Read permission.\n    See .\n\n- name: jenkins.model.Jenkins.buildsDir\n  tags:\n  - feature\n  def: |\n    `${ITEM_ROOTDIR}/builds`\n  since: 2.119\n  description: |\n    The configuration of a given job is located under\u00a0`$JENKINS_HOME/jobs/[JOB_NAME]/config.xml`\u00a0and its builds are under\u00a0`$JENKINS_HOME/jobs/[JOB_NAME]/builds`"
  },
  "4831": {
    "source_file": "system-properties.txt",
    "text": "nfiguration of a given job is located under\u00a0`$JENKINS_HOME/jobs/[JOB_NAME]/config.xml`\u00a0and its builds are under\u00a0`$JENKINS_HOME/jobs/[JOB_NAME]/builds` by default.\n    This option allows you to store builds elsewhere, which can be useful with finer-grained backup policies, or to store the build data on a faster disk such as an SSD.\n    The following placeholders are supported for this value:\n\n    *"
  },
  "4832": {
    "source_file": "system-properties.txt",
    "text": "ained backup policies, or to store the build data on a faster disk such as an SSD.\n    The following placeholders are supported for this value:\n\n    * `${JENKINS_HOME}`\u00a0 \u2013 Resolves to the Jenkins home directory.\n    * `${ITEM_ROOTDIR}` \u2013 The directory containing the job metadata within Jenkins home.\n    * `${ITEM_FULL_NAME}` \u2013 The full name of the item, with file system unsafe characters\u00a0replaced "
  },
  "4833": {
    "source_file": "system-properties.txt",
    "text": "y containing the job metadata within Jenkins home.\n    * `${ITEM_FULL_NAME}` \u2013 The full name of the item, with file system unsafe characters\u00a0replaced by others.\n    * `${ITEM_FULLNAME}` \u2013 See above, but does not replace unsafe characters.\n      This is a legacy option and should not be used.\n\n    For instance, if you would like to store builds outside of Jenkins home, you can use a value like the "
  },
  "4834": {
    "source_file": "system-properties.txt",
    "text": "is a legacy option and should not be used.\n\n    For instance, if you would like to store builds outside of Jenkins home, you can use a value like the following:\u00a0`/some_other_root/builds/${ITEM_FULL_NAME}` This used to be a UI setting, but was removed in 2.119 as it did not support migration of existing build records and could lead to build-related errors until restart.\n\n    To manually migrate exi"
  },
  "4835": {
    "source_file": "system-properties.txt",
    "text": " in 2.119 as it did not support migration of existing build records and could lead to build-related errors until restart.\n\n    To manually migrate existing build records when starting to use this option (`TARGET_DIR` is the value supplied to `jenkins.model.Jenkins.buildsDir`):\n\n    For  and Freestyle job types, run this for each `JOB_NAME`:\n\n    ```sh\n    mkdir -p [TARGET_DIR]\n    mv $JENKINS_HOME"
  },
  "4836": {
    "source_file": "system-properties.txt",
    "text": ".model.Jenkins.buildsDir`):\n\n    For  and Freestyle job types, run this for each `JOB_NAME`:\n\n    ```sh\n    mkdir -p [TARGET_DIR]\n    mv $JENKINS_HOME/jobs/[JOB_NAME]/builds [TARGET_DIR]/[JOB_NAME]\n    ```\n\n    For  jobs, run for each `BRANCH_NAME`:\n\n    ```sh\n    mkdir -p [TARGET_DIR]/[JOB_NAME]/branches/\n    mv $JENKINS_HOME/jobs/[JOB_NAME]/branches/[BRANCH_NAME]/builds \\\n        [TARGET_DIR]/[J"
  },
  "4837": {
    "source_file": "system-properties.txt",
    "text": "\n    ```sh\n    mkdir -p [TARGET_DIR]/[JOB_NAME]/branches/\n    mv $JENKINS_HOME/jobs/[JOB_NAME]/branches/[BRANCH_NAME]/builds \\\n        [TARGET_DIR]/[JOB_NAME]/branches/[BRANCH_NAME]\n    ```\n\n    For , run this for each `REPO_NAME` and `BRANCH_NAME`:\n\n    ```sh\n    mkdir -p [TARGET_DIR]/[ORG_NAME]/jobs/[REPO_NAME]/branches/\n    mv $JENKINS_HOME/jobs/[ORG_NAME]/jobs/[REPO_NAME]/branches/[BRANCH_NAME"
  },
  "4838": {
    "source_file": "system-properties.txt",
    "text": "\n    ```sh\n    mkdir -p [TARGET_DIR]/[ORG_NAME]/jobs/[REPO_NAME]/branches/\n    mv $JENKINS_HOME/jobs/[ORG_NAME]/jobs/[REPO_NAME]/branches/[BRANCH_NAME]/builds \\\n        [TARGET_DIR]/[ORG_NAME]/jobs/[REPO_NAME]/branches/[BRANCH_NAME]\n    ```\n\n- name: jenkins.model.Jenkins.crumbIssuerProxyCompatibility\n  tags:\n  - escape hatch\n  - feature\n  def: |\n    `false`\n  since: 2.119\n  description: |\n    `tru"
  },
  "4839": {
    "source_file": "system-properties.txt",
    "text": "jenkins.model.Jenkins.crumbIssuerProxyCompatibility\n  tags:\n  - escape hatch\n  - feature\n  def: |\n    `false`\n  since: 2.119\n  description: |\n    `true` to enable crumb proxy compatibility when running the Setup Wizard for the first time.\n\n- name: jenkins.model.Jenkins.disableExceptionOnNullInstance\n  tags:\n  - escape hatch\n  def: |\n    `false`\n  since: 2.4 *only*, replaced in 2.5+ by jenkins.mode"
  },
  "4840": {
    "source_file": "system-properties.txt",
    "text": "nkins.model.Jenkins.disableExceptionOnNullInstance\n  tags:\n  - escape hatch\n  def: |\n    `false`\n  since: 2.4 *only*, replaced in 2.5+ by jenkins.model.Jenkins.enableExceptionOnNullInstance\n  description: |\n    `true` to disable throwing an `IllegalStateException` when `Jenkins.getInstance()` returns `null`\n\n- name: jenkins.model.Jenkins.enableExceptionOnNullInstance\n  tags:\n  - escape hatch\n  def"
  },
  "4841": {
    "source_file": "system-properties.txt",
    "text": "tateException` when `Jenkins.getInstance()` returns `null`\n\n- name: jenkins.model.Jenkins.enableExceptionOnNullInstance\n  tags:\n  - escape hatch\n  def: |\n    `false`\n  since: 2.5\n  description: |\n    `true` to enable throwing an `IllegalStateException` when `Jenkins.getInstance()` returns `null`\n\n- name: jenkins.model.Jenkins.exitCodeOnRestart\n  tags:\n  - packaging\n  def: |\n    `5`\n  since: 2.102\n"
  },
  "4842": {
    "source_file": "system-properties.txt",
    "text": "n` when `Jenkins.getInstance()` returns `null`\n\n- name: jenkins.model.Jenkins.exitCodeOnRestart\n  tags:\n  - packaging\n  def: |\n    `5`\n  since: 2.102\n  description: |\n    When using the `-Dhudson.lifecycle=hudson.lifecycle.ExitLifecycle`, exit using this exit code when Jenkins is restarted\n\n- name: jenkins.model.Jenkins.initLogLevel\n  def: |\n    `FINE`\n  description: |\n    Log level for verbose me"
  },
  "4843": {
    "source_file": "system-properties.txt",
    "text": "this exit code when Jenkins is restarted\n\n- name: jenkins.model.Jenkins.initLogLevel\n  def: |\n    `FINE`\n  description: |\n    Log level for verbose messages from the init reactor listener.\n\n- name: jenkins.model.Jenkins.killAfterLoad\n  def: |\n    `false`\n  description: |\n    Exit Jenkins right after loading.\n    Intended as a development/testing aid only.\n\n- name: jenkins.model.Jenkins.logStartupP"
  },
  "4844": {
    "source_file": "system-properties.txt",
    "text": "lse`\n  description: |\n    Exit Jenkins right after loading.\n    Intended as a development/testing aid only.\n\n- name: jenkins.model.Jenkins.logStartupPerformance\n  def: |\n    `false`\n  description: |\n    Log startup timing info.\n    Note that some messages are not logged on levels visible by default (i.e. INFO and up).\n\n- name: jenkins.model.Jenkins.nameValidationRejectsTrailingDot\n  tags:\n  - secu"
  },
  "4845": {
    "source_file": "system-properties.txt",
    "text": "sages are not logged on levels visible by default (i.e. INFO and up).\n\n- name: jenkins.model.Jenkins.nameValidationRejectsTrailingDot\n  tags:\n  - security\n  - escape hatch\n  def: |\n    `true`\n  since: 2.303.2 / 2.315\n  description: |\n    Set to `false` to allow names to end with a trailing `.` character, which can cause problems on Windows.\n    Escape hatch for .\n\n- name: jenkins.model.Jenkins.par"
  },
  "4846": {
    "source_file": "system-properties.txt",
    "text": "e` to allow names to end with a trailing `.` character, which can cause problems on Windows.\n    Escape hatch for .\n\n- name: jenkins.model.Jenkins.parallelLoad\n  tags:\n  - escape hatch\n  def: |\n    `true`\n  description: |\n    Loads job configurations in parallel on startup.\n\n- name: jenkins.model.Jenkins.slaveAgentPort\n  tags:\n  - feature\n  def: |\n    `-1` (disabled) since 2.0, `0` in Jenkins 1.x."
  },
  "4847": {
    "source_file": "system-properties.txt",
    "text": " in parallel on startup.\n\n- name: jenkins.model.Jenkins.slaveAgentPort\n  tags:\n  - feature\n  def: |\n    `-1` (disabled) since 2.0, `0` in Jenkins 1.x.\n  since: 1.643\n  description: |\n    Specifies the default TCP agent port unless/until configured differently on the UI.\n    `-1` to disable, `0` for random port, other values for fixed port.\n\n- name: jenkins.model.Jenkins.slaveAgentPortEnforce\n  tag"
  },
  "4848": {
    "source_file": "system-properties.txt",
    "text": "fferently on the UI.\n    `-1` to disable, `0` for random port, other values for fixed port.\n\n- name: jenkins.model.Jenkins.slaveAgentPortEnforce\n  tags:\n  - feature\n  def: |\n    `false`\n  since: 2.19.4 / 2.24\n  description: |\n    If true, enforces the specified `jenkins.model.Jenkins.slaveAgentPort` on startup and will not allow changing it through the UI\n\n- name: jenkins.model.Jenkins.workspaceDi"
  },
  "4849": {
    "source_file": "system-properties.txt",
    "text": "e specified `jenkins.model.Jenkins.slaveAgentPort` on startup and will not allow changing it through the UI\n\n- name: jenkins.model.Jenkins.workspaceDirName\n  tags:\n  - obsolete\n  def: |\n    `workspace`\n  description: |\n    Obsolete: Was used as the default workspace directory name in the legacy workspace directory layout (workspace directories within job directories).\n\n- name: jenkins.model.Jenkin"
  },
  "4850": {
    "source_file": "system-properties.txt",
    "text": "efault workspace directory name in the legacy workspace directory layout (workspace directories within job directories).\n\n- name: jenkins.model.Jenkins.workspacesDir\n  tags:\n  - feature\n  def: |\n    `${JENKINS_HOME}/workspace/${ITEM_FULL_NAME}`\n  since: 2.119\n  description: |\n    Allows to change the directory layout for the job workspaces on the controller node.\n    See\u00a0`jenkins.model.Jenkins.bui"
  },
  "4851": {
    "source_file": "system-properties.txt",
    "text": "ce: 2.119\n  description: |\n    Allows to change the directory layout for the job workspaces on the controller node.\n    See\u00a0`jenkins.model.Jenkins.buildsDir` for supported placeholders.\n\n- name: jenkins.model.JenkinsLocationConfiguration.disableUrlValidation\n  tags:\n  - escape hatch\n  def: |\n    `false`\n  since: 2.176.4 / 2.197\n  description: |\n    Disable URL validation intended to prevent an XSS"
  },
  "4852": {
    "source_file": "system-properties.txt",
    "text": "lidation\n  tags:\n  - escape hatch\n  def: |\n    `false`\n  since: 2.176.4 / 2.197\n  description: |\n    Disable URL validation intended to prevent an XSS vulnerability.\n    See  for details.\n\n- name: jenkins.model.lazy.BuildReference.MODE\n  tags:\n  - development\n  - tuning\n  def: |\n    `soft`\n  since: 1.548\n  description: |\n    Configure the kind of reference Jenkins uses to hold builds in memory.\n  "
  },
  "4853": {
    "source_file": "system-properties.txt",
    "text": "velopment\n  - tuning\n  def: |\n    `soft`\n  since: 1.548\n  description: |\n    Configure the kind of reference Jenkins uses to hold builds in memory.\n    Choose from among `soft`, `weak`, `strong`, and `not` (do not hold builds in memory at all).\n    Intended mostly as a debugging aid.\n    See https://issues.jenkins.io/browse/JENKINS-19400[JENKINS-19400].\n\n- name: jenkins.model.Nodes.enforceNameRest"
  },
  "4854": {
    "source_file": "system-properties.txt",
    "text": "ntended mostly as a debugging aid.\n    See https://issues.jenkins.io/browse/JENKINS-19400[JENKINS-19400].\n\n- name: jenkins.model.Nodes.enforceNameRestrictions\n  tags:\n  - security\n  - escape hatch\n  def: |\n    `true`\n  since: 2.263.2 / 2.275\n  description: |\n    Whether to enforce new name restrictions for agent names.\n    See .\n\n- name: jenkins.model.StandardArtifactManager.disableTrafficCompress"
  },
  "4855": {
    "source_file": "system-properties.txt",
    "text": "ption: |\n    Whether to enforce new name restrictions for agent names.\n    See .\n\n- name: jenkins.model.StandardArtifactManager.disableTrafficCompression\n  tags:\n  - tuning\n  - feature\n  def: |\n    `false`\n  since: 2.196\n  description: |\n    `true` to disable GZIP compression of artifacts when they're transferred from agent nodes to controller.\u00a0 Uses less CPU at the cost of increased network traff"
  },
  "4856": {
    "source_file": "system-properties.txt",
    "text": "o disable GZIP compression of artifacts when they're transferred from agent nodes to controller.\u00a0 Uses less CPU at the cost of increased network traffic.\n- name: jenkins.monitor.JavaVersionRecommendationAdminMonitor.disable\n  tags:\n  - feature\n  def: |\n    `false`\n  since: 2.305\n  description: |\n    `true` to disable the monitor that recommends newer Java versions.\n\n- name: jenkins.security.ApiTok"
  },
  "4857": {
    "source_file": "system-properties.txt",
    "text": " |\n    `false`\n  since: 2.305\n  description: |\n    `true` to disable the monitor that recommends newer Java versions.\n\n- name: jenkins.security.ApiTokenProperty.adminCanGenerateNewTokens\u00a0\n  tags:\n  - escape hatch\n  - security\n  def: |\n    `false`\n  since: 2.129\n  description: |\n    `true` to allow users with\u00a0Overall/Administer permission to create API tokens using the new system for any user.\n    "
  },
  "4858": {
    "source_file": "system-properties.txt",
    "text": "ince: 2.129\n  description: |\n    `true` to allow users with\u00a0Overall/Administer permission to create API tokens using the new system for any user.\n    Note that the user will not be able to use that token since it's only displayed to the creator, once.\n\n- name: jenkins.security.ApiTokenProperty.showTokenToAdmins\n  tags:\n  - escape hatch\n  - security\n  def: |\n    `false`\n  since: 1.638\n  description"
  },
  "4859": {
    "source_file": "system-properties.txt",
    "text": ".\n\n- name: jenkins.security.ApiTokenProperty.showTokenToAdmins\n  tags:\n  - escape hatch\n  - security\n  def: |\n    `false`\n  since: 1.638\n  description: |\n    True to show API tokens for users to administrators on the user configuration page.\n    This was set to `false` as part of\n\n- name: jenkins.security.ClassFilterImpl.SUPPRESS_ALL\n  tags:\n  - escape hatch\n  - security\n  def: |\n    `false`\n  sin"
  },
  "4860": {
    "source_file": "system-properties.txt",
    "text": " was set to `false` as part of\n\n- name: jenkins.security.ClassFilterImpl.SUPPRESS_ALL\n  tags:\n  - escape hatch\n  - security\n  def: |\n    `false`\n  since: 2.102\n  description: |\n    Do not perform any JEP-200 class filtering when deserializing data.\n    Setting this to `true` is unsafe.\n    See .\n\n- name: jenkins.security.csp.CspHeader.headerName\n  tags:\n  - escape hatch\n  - security\n  def: |\n    u"
  },
  "4861": {
    "source_file": "system-properties.txt",
    "text": "   Setting this to `true` is unsafe.\n    See .\n\n- name: jenkins.security.csp.CspHeader.headerName\n  tags:\n  - escape hatch\n  - security\n  def: |\n    undefined\n  since: 2.539\n  description: |\n    Defines the name of the Content Security Policy header to enforce.\n    This option takes precedence over UI configuration, Configuration as Code, and `mvn hpi:run` defaults.\n    The only possible values ar"
  },
  "4862": {
    "source_file": "system-properties.txt",
    "text": "to enforce.\n    This option takes precedence over UI configuration, Configuration as Code, and `mvn hpi:run` defaults.\n    The only possible values are `Content-Security-Policy` and `Content-Security-Policy-Report-Only`.\n    For escape hatch use, choose `Content-Security-Policy-Report-Only` to disable enforcement of too restrictive Content Security Policy.\n    See .\n\n- name: jenkins.security.csp.i"
  },
  "4863": {
    "source_file": "system-properties.txt",
    "text": "ose `Content-Security-Policy-Report-Only` to disable enforcement of too restrictive Content Security Policy.\n    See .\n\n- name: jenkins.security.csp.impl.DevelopmentHeaderDecider.DISABLED\n  tags:\n  - escape hatch\n  - security\n  def: |\n    `false`\n  since: 2.539\n  description: |\n    Disables the enforcement of Content Security Policy during development and testing.\n    If this is set to `true` (and"
  },
  "4864": {
    "source_file": "system-properties.txt",
    "text": "ince: 2.539\n  description: |\n    Disables the enforcement of Content Security Policy during development and testing.\n    If this is set to `true` (and `jenkins.security.csp.CspHeader.headerName` is not set), Jenkins will allow configuring CSP through the UI even in development mode.\n    See .\n\n- name: jenkins.security.DefaultConfidentialStore.file\n  tags:\n  - feature\n  def: |\n    `$JENKINS_HOME/se"
  },
  "4865": {
    "source_file": "system-properties.txt",
    "text": " the UI even in development mode.\n    See .\n\n- name: jenkins.security.DefaultConfidentialStore.file\n  tags:\n  - feature\n  def: |\n    `$JENKINS_HOME/secrets/master.key`\n  since: 2.497\n  description: |\n    Allows to provide an alternative path to load/store the master key.\n\n- name: jenkins.security.DefaultConfidentialStore.readOnly\n  tags:\n  - feature\n  def: |\n    `false`\n  since: 2.497\n  descriptio"
  },
  "4866": {
    "source_file": "system-properties.txt",
    "text": "store the master key.\n\n- name: jenkins.security.DefaultConfidentialStore.readOnly\n  tags:\n  - feature\n  def: |\n    `false`\n  since: 2.497\n  description: |\n    Setting this to `true` will make Jenkins fail fast in case the `master.key` is missing from the expected path. This is useful if the `master.key` is provided from an external location.\n\n- name: jenkins.security.ClassFilterImpl.SUPPRESS_WHITE"
  },
  "4867": {
    "source_file": "system-properties.txt",
    "text": " the expected path. This is useful if the `master.key` is provided from an external location.\n\n- name: jenkins.security.ClassFilterImpl.SUPPRESS_WHITELIST\n  tags:\n  - escape hatch\n  - security\n  def: |\n    `false`\n  since: 2.102\n  description: |\n    Do not perform whitelist-based JEP-200 class filtering when deserializing data.\n    With this flag set, only explicitly blacklisted types will be reje"
  },
  "4868": {
    "source_file": "system-properties.txt",
    "text": "Do not perform whitelist-based JEP-200 class filtering when deserializing data.\n    With this flag set, only explicitly blacklisted types will be rejected.\n    Setting this to `true` is unsafe.\n    See .\n\n- name: jenkins.security.FIPS140.COMPLIANCE\n  tags:\n  - feature\n  - security\n  def: |\n    `false`\n  since: 2.424\n  description: |\n    If Jenkins and plugins systems should prefer  compliant crypt"
  },
  "4869": {
    "source_file": "system-properties.txt",
    "text": " tags:\n  - feature\n  - security\n  def: |\n    `false`\n  since: 2.424\n  description: |\n    If Jenkins and plugins systems should prefer  compliant cryptography.\n    Not all features/plugins have been adapted, and this only indicates a preference.\n    If you set this flag to `true`, it does not make Jenkins and its plugins FIPS-140 compliant.\n    Refer to  for more information.\n\n- name: jenkins.secur"
  },
  "4870": {
    "source_file": "system-properties.txt",
    "text": "f you set this flag to `true`, it does not make Jenkins and its plugins FIPS-140 compliant.\n    Refer to  for more information.\n\n- name: jenkins.security.FrameOptionsPageDecorator.enabled\n  tags:\n  - escape hatch\n  - security\n  def: |\n    `true`\n  since: 1.581\n  description: |\n    Whether to send `X-Frame-Options: sameorigin` header, set to `false` to disable and make Jenkins embeddable\n\n- name: j"
  },
  "4871": {
    "source_file": "system-properties.txt",
    "text": "nce: 1.581\n  description: |\n    Whether to send `X-Frame-Options: sameorigin` header, set to `false` to disable and make Jenkins embeddable\n\n- name: jenkins.security.ignoreBasicAuth\n  # TODO test whether this actually works\n  tags:\n  - feature\n  - security\n  def: |\n    `false`\n  since: 1.421\n  description: |\n    When set to `true`, disable `Basic` authentication with username and password (rather "
  },
  "4872": {
    "source_file": "system-properties.txt",
    "text": "curity\n  def: |\n    `false`\n  since: 1.421\n  description: |\n    When set to `true`, disable `Basic` authentication with username and password (rather than API token).\n\n- name: jenkins.security.JettySameSiteCookieSetup.sameSiteDefault\n  tags:\n  - escape hatch\n  - security\n  - tuning\n  def: |\n    Lax\n  since: 2.513\n  description: |\n    When running in Jetty (usually with `java -jar jenkins.war`), th"
  },
  "4873": {
    "source_file": "system-properties.txt",
    "text": "pe hatch\n  - security\n  - tuning\n  def: |\n    Lax\n  since: 2.513\n  description: |\n    When running in Jetty (usually with `java -jar jenkins.war`), this allows customizing the value of the `SameSite` attribute of cookies set by Jenkins.\n    Other possible values are `Strict`, `None`, and empty string to leave the attribute unspecified (the behavior before 2.513).\n\n- name: jenkins.security.ManagePe"
  },
  "4874": {
    "source_file": "system-properties.txt",
    "text": "sible values are `Strict`, `None`, and empty string to leave the attribute unspecified (the behavior before 2.513).\n\n- name: jenkins.security.ManagePermission\n  tags:\n  - feature\n  - security\n  def: |\n    `false`\n  since: 2.222\n  description: |\n    Enable the optional Overall/Manage permission that allows limited access to administrative features suitable for a hosted Jenkins environment.\n    See "
  },
  "4875": {
    "source_file": "system-properties.txt",
    "text": "nable the optional Overall/Manage permission that allows limited access to administrative features suitable for a hosted Jenkins environment.\n    See https://github.com/jenkinsci/jep/tree/master/jep/223[JEP-223].\n\n- name: jenkins.security.ResourceDomainRootAction.allowAuthenticatedUser\n  tags:\n  - security\n  - escape hatch\n  def: |\n    `false`\n  since: 2.475\n  description: |\n    Allow authenticate"
  },
  "4876": {
    "source_file": "system-properties.txt",
    "text": "ainRootAction.allowAuthenticatedUser\n  tags:\n  - security\n  - escape hatch\n  def: |\n    `false`\n  since: 2.475\n  description: |\n    Allow authenticated user access to .\n    Escape hatch for a security improvement related to the .\n\n- name: jenkins.security.ResourceDomainRootAction.validForMinutes\n  tags:\n  - tuning\n  - security\n  def: |\n    `30`\n  since: 2.200\n  description: |\n    How long a resour"
  },
  "4877": {
    "source_file": "system-properties.txt",
    "text": "urity.ResourceDomainRootAction.validForMinutes\n  tags:\n  - tuning\n  - security\n  def: |\n    `30`\n  since: 2.200\n  description: |\n    How long a resource URL served from the resource root URL will be valid for before users are required to reauthenticate to access it.\n    See inline documentation in Jenkins for details.\n\n- name: jenkins.security.s2m.CallableDirectionChecker.allow\n  tags:\n  - securit"
  },
  "4878": {
    "source_file": "system-properties.txt",
    "text": "te to access it.\n    See inline documentation in Jenkins for details.\n\n- name: jenkins.security.s2m.CallableDirectionChecker.allow\n  tags:\n  - security\n  - escape hatch\n  def: |\n    `false`\n  since: 1.580.1 / 1.587\n  description: |\n    This flag can be set to `true` to disable the agent-to-controller security system entirely.\n    Since Jenkins 2.326, this is the only way to do that, as the UI opti"
  },
  "4879": {
    "source_file": "system-properties.txt",
    "text": "be set to `true` to disable the agent-to-controller security system entirely.\n    Since Jenkins 2.326, this is the only way to do that, as the UI option has been removed.\n\n- name: jenkins.security.s2m.CallableDirectionChecker.allowAnyRole\n  tags:\n  - security\n  - obsolete\n  def: |\n    `true`\n  since: 2.303.3 / 2.319\n  description: |\n    This flag can be set to `false` to explicitly reject `Callabl"
  },
  "4880": {
    "source_file": "system-properties.txt",
    "text": " security\n  - obsolete\n  def: |\n    `true`\n  since: 2.303.3 / 2.319\n  description: |\n    This flag can be set to `false` to explicitly reject `Callable` implementations that do not declare any required role.\n    It is unclear whether this can safely be set to `false` in Jenkins before 2.335, or whether that would cause problems with some remoting built-in callables.\n    This flag was removed in Je"
  },
  "4881": {
    "source_file": "system-properties.txt",
    "text": "be set to `false` in Jenkins before 2.335, or whether that would cause problems with some remoting built-in callables.\n    This flag was removed in Jenkins 2.335.\n\n- name: jenkins.security.s2m.DefaultFilePathFilter.allow\n  tags:\n  - escape hatch\n  - security\n  def: |\n    `false`\n  since: 1.580.1 / 1.587\n  description: |\n    Allow all file paths on the Jenkins controller to be accessed from agents."
  },
  "4882": {
    "source_file": "system-properties.txt",
    "text": "security\n  def: |\n    `false`\n  since: 1.580.1 / 1.587\n  description: |\n    Allow all file paths on the Jenkins controller to be accessed from agents.\n    This disables a big part of  protections.\n\n- name: jenkins.security.s2m.JarURLValidatorImpl.REJECT_ALL\n  tags:\n  - security\n  def: |\n    `false`\n  since: 2.452.4 / 2.471\n  description: |\n    Reject all attempts by agents to use `ClassLoaderProxy"
  },
  "4883": {
    "source_file": "system-properties.txt",
    "text": "ECT_ALL\n  tags:\n  - security\n  def: |\n    `false`\n  since: 2.452.4 / 2.471\n  description: |\n    Reject all attempts by agents to use `ClassLoaderProxy#fetchJar`.\n    Drops backward compatibility with releases of remoting (`agent.jar`) before 2024-08.\n    See .\n\n- name: jenkins.security.s2m.RunningBuildFilePathFilter.FAIL\n  tags:\n  - escape hatch\n  - security\n  def: |\n    `true`\n  since: 2.303.3 / "
  },
  "4884": {
    "source_file": "system-properties.txt",
    "text": "\n    See .\n\n- name: jenkins.security.s2m.RunningBuildFilePathFilter.FAIL\n  tags:\n  - escape hatch\n  - security\n  def: |\n    `true`\n  since: 2.303.3 / 2.319\n  description: |\n    Set to `false` to not reject attempts to access file paths in build directories of builds not currently being built on the accessing agent.\n    Instead, only a warning is logged.\n    Attempts to access file paths in build d"
  },
  "4885": {
    "source_file": "system-properties.txt",
    "text": "tories of builds not currently being built on the accessing agent.\n    Instead, only a warning is logged.\n    Attempts to access file paths in build directories from other processes will still fail.\n    See  for context.\n\n- name: jenkins.security.s2m.RunningBuildFilePathFilter.SKIP\n  tags:\n  - escape hatch\n  - security\n  def: |\n    `false`\n  since: 2.303.3 / 2.319\n  description: |\n    Set to `true"
  },
  "4886": {
    "source_file": "system-properties.txt",
    "text": ".RunningBuildFilePathFilter.SKIP\n  tags:\n  - escape hatch\n  - security\n  def: |\n    `false`\n  since: 2.303.3 / 2.319\n  description: |\n    Set to `true` to disable the additional protection to not reject attempts to access file paths in build directories.\n    This will restore access to any build directories both from agents and from other processes with a remoting channel, like Maven Integration P"
  },
  "4887": {
    "source_file": "system-properties.txt",
    "text": "ies.\n    This will restore access to any build directories both from agents and from other processes with a remoting channel, like Maven Integration Plugin.\n    See  for context.\n\n- name: jenkins.security.seed.UserSeedProperty.disableUserSeed\n  tags:\n  - escape hatch\n  - security\n  def: |\n    `false`\n  since: 2.105.2 / 2.160\n  description: |\n    Disables _user seed_.\n    Escape hatch for .\n\n- name"
  },
  "4888": {
    "source_file": "system-properties.txt",
    "text": "\n  - escape hatch\n  - security\n  def: |\n    `false`\n  since: 2.105.2 / 2.160\n  description: |\n    Disables _user seed_.\n    Escape hatch for .\n\n- name: jenkins.security.seed.UserSeedProperty.hideUserSeedSection\n  tags:\n  - ui\n  - security\n  def: |\n    `false`\n  since: 2.105.2 / 2.160\n  description: |\n    Hide the UI for _user seed_ introduced for .\n\n- name: jenkins.security.stapler.StaplerDispatch"
  },
  "4889": {
    "source_file": "system-properties.txt",
    "text": "  `false`\n  since: 2.105.2 / 2.160\n  description: |\n    Hide the UI for _user seed_ introduced for .\n\n- name: jenkins.security.stapler.StaplerDispatchValidator.disabled\n  tags:\n  - escape hatch\n  - security\n  def: |\n    `false`\n  since: 2.176.2 / 2.186\n  description: |\n    Escape hatch for .\n\n- name: jenkins.security.stapler.StaplerDispatchValidator.whitelist\n  tags:\n  - escape hatch\n  - security\n"
  },
  "4890": {
    "source_file": "system-properties.txt",
    "text": "86\n  description: |\n    Escape hatch for .\n\n- name: jenkins.security.stapler.StaplerDispatchValidator.whitelist\n  tags:\n  - escape hatch\n  - security\n  def: |\n    `stapler-views-whitelist.txt` in `JENKINS_HOME`\n  since: 2.176.2 / 2.186\n  description: |\n    Override the location of the user configurable whitelist for stapler view dispatches.\n    This augments the built-in whitelist for  that allows"
  },
  "4891": {
    "source_file": "system-properties.txt",
    "text": " |\n    Override the location of the user configurable whitelist for stapler view dispatches.\n    This augments the built-in whitelist for  that allows dispatches to views that would otherwise be prohibited.\n\n- name: jenkins.security.stapler.StaticRoutingDecisionProvider.whitelist\n  tags:\n  - escape hatch\n  - security\n  def: |\n    `stapler-whitelist.txt` in `JENKINS_HOME`\n  since: 2.138.4 / 2.154\n "
  },
  "4892": {
    "source_file": "system-properties.txt",
    "text": "tingDecisionProvider.whitelist\n  tags:\n  - escape hatch\n  - security\n  def: |\n    `stapler-whitelist.txt` in `JENKINS_HOME`\n  since: 2.138.4 / 2.154\n  description: |\n    Override the location of the user configurable whitelist for stapler request routing.\n    This augments the built-in whitelist for  that allows routing requests through methods that would otherwise be prohibited.\n\n- name: jenkins."
  },
  "4893": {
    "source_file": "system-properties.txt",
    "text": "ting.\n    This augments the built-in whitelist for  that allows routing requests through methods that would otherwise be prohibited.\n\n- name: jenkins.security.stapler.TypedFilter.prohibitStaticAccess\n  tags:\n  - escape hatch\n  - security\n  def: |\n    `true`\n  since: 2.138.4 / 2.154\n  description: |\n    Prohibits access to `public static` fields when routing requests in Stapler.\n    Escape hatch fo"
  },
  "4894": {
    "source_file": "system-properties.txt",
    "text": " `true`\n  since: 2.138.4 / 2.154\n  description: |\n    Prohibits access to `public static` fields when routing requests in Stapler.\n    Escape hatch for .\n\n- name: jenkins.security.stapler.TypedFilter.skipTypeCheck\n  tags:\n  - escape hatch\n  - security\n  def: |\n    `false`\n  since: 2.138.4 / 2.154\n  description: |\n    Skip (return) type check when determining whether a method or field should be rou"
  },
  "4895": {
    "source_file": "system-properties.txt",
    "text": "y\n  def: |\n    `false`\n  since: 2.138.4 / 2.154\n  description: |\n    Skip (return) type check when determining whether a method or field should be routable with Stapler (i.e. allow any return type).\n    Escape hatch for .\n\n- name: jenkins.security.SuspiciousRequestFilter.allowSemicolonsInPath\n  tags:\n  - escape hatch\n  - security\n  def: |\n    `false`\n  since: 2.204.6 / 2.228\n  description: |\n    E"
  },
  "4896": {
    "source_file": "system-properties.txt",
    "text": "spiciousRequestFilter.allowSemicolonsInPath\n  tags:\n  - escape hatch\n  - security\n  def: |\n    `false`\n  since: 2.204.6 / 2.228\n  description: |\n    Escape hatch for .\n    Allows requests to URLs with semicolon characters (`;`) in the request path.\n\n- name: jenkins.security.SystemReadPermission\n  tags:\n  - feature\n  - security\n  def: |\n    `false`\n  since: 2.222\n  description: |\n    Enable the opt"
  },
  "4897": {
    "source_file": "system-properties.txt",
    "text": "- name: jenkins.security.SystemReadPermission\n  tags:\n  - feature\n  - security\n  def: |\n    `false`\n  since: 2.222\n  description: |\n    Enable the optional Overall/SystemRead permission that allows read-only access to administrative features suitable for a managed Jenkins Configuration as Code environment.\n    See https://github.com/jenkinsci/jep/tree/master/jep/224[JEP-224].\n\n- name: jenkins.secu"
  },
  "4898": {
    "source_file": "system-properties.txt",
    "text": " for a managed Jenkins Configuration as Code environment.\n    See https://github.com/jenkinsci/jep/tree/master/jep/224[JEP-224].\n\n- name: jenkins.security.UserDetailsCache.EXPIRE_AFTER_WRITE_SEC\n  tags:\n  - tuning\n  - security\n  def: |\n    `120` (2 minutes)\n  since: 2.15\n  description: |\n    How long a cache for `UserDetails` should be valid for before it is looked up again from the security realm"
  },
  "4899": {
    "source_file": "system-properties.txt",
    "text": "inutes)\n  since: 2.15\n  description: |\n    How long a cache for `UserDetails` should be valid for before it is looked up again from the security realm.\n    See https://issues.jenkins.io/browse/JENKINS-35493[JENKINS-35493].\n\n- name: jenkins.slaves.DefaultJnlpSlaveReceiver.disableStrictVerification\n  tags:\n  - security\n  def: |\n    `false`\n  since: 2.28\n  #description: ''\n# TODO describe\n\n- name: je"
  },
  "4900": {
    "source_file": "system-properties.txt",
    "text": "aultJnlpSlaveReceiver.disableStrictVerification\n  tags:\n  - security\n  def: |\n    `false`\n  since: 2.28\n  #description: ''\n# TODO describe\n\n- name: jenkins.slaves.JnlpSlaveAgentProtocol3.enabled\n  tags:\n  - obsolete\n  # TODO update this\n  def: undefined\n  since: 1.653\n  description: |\n    `false` to disable the JNLP3 agent protocol, `true` to enable it.\n    Otherwise it's randomly enabled/disabled"
  },
  "4901": {
    "source_file": "system-properties.txt",
    "text": "ned\n  since: 1.653\n  description: |\n    `false` to disable the JNLP3 agent protocol, `true` to enable it.\n    Otherwise it's randomly enabled/disabled to A/B test it.\n    Obsolete since the protocol was removed in 2.214.\n\n- name: jenkins.slaves.NioChannelSelector.disabled\n  tags:\n  - escape hatch\n  def: |\n    `false`\n  since: 1.560\n  description: |\n    `true` to disable Nio for JNLP agents\n\n- name"
  },
  "4902": {
    "source_file": "system-properties.txt",
    "text": "annelSelector.disabled\n  tags:\n  - escape hatch\n  def: |\n    `false`\n  since: 1.560\n  description: |\n    `true` to disable Nio for JNLP agents\n\n- name: jenkins.slaves.StandardOutputSwapper.disabled\n  tags:\n  - escape hatch\n# TODO Unsure how this works. References:\n# - https://github.com/jenkinsci/jenkins/blob/3fd66ff22051a3309b8dc5130d8da0759ee27f48/core/src/main/java/jenkins/slaves/StandardOutput"
  },
  "4903": {
    "source_file": "system-properties.txt",
    "text": "s. References:\n# - https://github.com/jenkinsci/jenkins/blob/3fd66ff22051a3309b8dc5130d8da0759ee27f48/core/src/main/java/jenkins/slaves/StandardOutputSwapper.java\n# - https://github.com/jenkinsci/remoting/commit/fad8c38724068dfbd155e64508e5d4c154240b87\n  def: |\n    `false`\n  since: 1.429\n  description: |\n    Some Unix-like agents (e.g. SSH Build Agents) can communicate via stdin/stdout, which is v"
  },
  "4904": {
    "source_file": "system-properties.txt",
    "text": "87\n  def: |\n    `false`\n  since: 1.429\n  description: |\n    Some Unix-like agents (e.g. SSH Build Agents) can communicate via stdin/stdout, which is very convenient.\n    Unfortunately, some JVM output (e.g. related to GC) also goes to standard out.\n    This will swap output streams around to prevent stream corruption through unexpected writes to standard out.\n\n- name: jenkins.SoloFilePathFilter.re"
  },
  "4905": {
    "source_file": "system-properties.txt",
    "text": "   This will swap output streams around to prevent stream corruption through unexpected writes to standard out.\n\n- name: jenkins.SoloFilePathFilter.redactErrors\n  tags:\n  - escape hatch\n  - security\n  def: |\n    `true`\n  since: 2.303.3 / 2.319\n  description: |\n    Set to `false` to not redact error messages when the agent-to-controller file path filters reject a file access.\n    This can give atta"
  },
  "4906": {
    "source_file": "system-properties.txt",
    "text": "ription: |\n    Set to `false` to not redact error messages when the agent-to-controller file path filters reject a file access.\n    This can give attackers information about files and directories on the Jenkins controller file system.\n\n- name: jenkins.telemetry.Telemetry.endpoint\n  tags:\n  - development\n# https://github.com/jenkinsci/jenkins/pull/3604\n  def: |\n    `+https://uplink.jenkins.io/event"
  },
  "4907": {
    "source_file": "system-properties.txt",
    "text": "s.telemetry.Telemetry.endpoint\n  tags:\n  - development\n# https://github.com/jenkinsci/jenkins/pull/3604\n  def: |\n    `+https://uplink.jenkins.io/events+`\n  since: 2.143\n  description: |\n    Change the endpoint that JEP-214/Uplink telemetry sends data to.\n    Expected to be used for testing only.\n\n- name: jenkins.ui.refresh\n  tags:\n  - ui\n  - feature\n  def: |\n    `false`\n  since: 2.222\n  descriptio"
  },
  "4908": {
    "source_file": "system-properties.txt",
    "text": " to.\n    Expected to be used for testing only.\n\n- name: jenkins.ui.refresh\n  tags:\n  - ui\n  - feature\n  def: |\n    `false`\n  since: 2.222\n  description: |\n    `true` to enable the new experimental UX on Jenkins.\n    See https://issues.jenkins.io/browse/JENKINS-60920[JENKINS-60920].\n    Also see .\n    Has no effect since https://github.com/jenkinsci/jenkins/commit/51e7142d5705c10833e0959fdf2534a32b"
  },
  "4909": {
    "source_file": "system-properties.txt",
    "text": "se/JENKINS-60920[JENKINS-60920].\n    Also see .\n    Has no effect since https://github.com/jenkinsci/jenkins/commit/51e7142d5705c10833e0959fdf2534a32b0e7d86[2.344] as the feature has been removed.\n\n- name: jenkins.websocket.idleTimeout\n  tags:\n  - tuning\n  def: |\n    `60`\n  since: 2.395\n  description: |\n    Number of seconds a WebSocket agent connection may stay idle until it expires. `0` to disab"
  },
  "4910": {
    "source_file": "system-properties.txt",
    "text": "ning\n  def: |\n    `60`\n  since: 2.395\n  description: |\n    Number of seconds a WebSocket agent connection may stay idle until it expires. `0` to disable. Must be higher than `jenkins.websocket.pingInterval`.\n\n- name: jenkins.websocket.pingInterval\n  tags:\n  - tuning\n  def: |\n    `30`\n  since: 2.217\n  description: |\n    Number of seconds between server-sent pings over WebSocket agent connections. `"
  },
  "4911": {
    "source_file": "system-properties.txt",
    "text": "tags:\n  - tuning\n  def: |\n    `30`\n  since: 2.217\n  description: |\n    Number of seconds between server-sent pings over WebSocket agent connections. `0` to disable. Must be lower than `jenkins.websocket.idleTimeout`.\n\n- name: jenkins.util.ProgressiveRendering.DEBUG_SLEEP\n  def: |\n    `0`\n  description: |\n    Debug/development option to slow down the cancelling of progressive rendering when the cli"
  },
  "4912": {
    "source_file": "system-properties.txt",
    "text": "Rendering.DEBUG_SLEEP\n  def: |\n    `0`\n  description: |\n    Debug/development option to slow down the cancelling of progressive rendering when the client fails to send a heartbeat.\n\n- name: JENKINS_HOME\n  tags:\n  - feature\n  def: |\n    `~/.jenkins`\n  description: |\n    While typically set as an environment variable, Jenkins also looks up the path to its home directory as a system property.\n    `JE"
  },
  "4913": {
    "source_file": "system-properties.txt",
    "text": " description: |\n    While typically set as an environment variable, Jenkins also looks up the path to its home directory as a system property.\n    `JENKINS_HOME` set via JNDI context has higher priority than this, but this takes precedence over the environment variable.\n\n- name: org.jenkinsci.main.modules.sshd.SSHD.idle-timeout\n  tags:\n  - tuning\n# This is a core module, so this documentation shou"
  },
  "4914": {
    "source_file": "system-properties.txt",
    "text": "nvironment variable.\n\n- name: org.jenkinsci.main.modules.sshd.SSHD.idle-timeout\n  tags:\n  - tuning\n# This is a core module, so this documentation should remain here.\n  def: undefined\n  since: 2.22\n  description: |\n    Allows to configure the SSHD client idle timeout (value in milliseconds).\n    Default value is 10min (600000ms).\n\n- name: org.jenkinsci.plugins.workflow.steps.durable_task.DurableTas"
  },
  "4915": {
    "source_file": "system-properties.txt",
    "text": "ent idle timeout (value in milliseconds).\n    Default value is 10min (600000ms).\n\n- name: org.jenkinsci.plugins.workflow.steps.durable_task.DurableTaskStep.REMOTE_TIMEOUT\n  tags:\n  - tuning\n# TODO move to plugin documentation\n  def: 20 seconds\n  since: workflow-durable-task-step-plugin 2.29\n  description: |\n    How long to wait, in seconds, before interrupting remote calls and forcing cleanup when"
  },
  "4916": {
    "source_file": "system-properties.txt",
    "text": "e: workflow-durable-task-step-plugin 2.29\n  description: |\n    How long to wait, in seconds, before interrupting remote calls and forcing cleanup when the step is stopped.\n    See https://issues.jenkins.io/browse/JENKINS-46507[JENKINS-46507] for more information.\n\n- name: org.jenkinsci.plugins.workflow.steps.durable_task.DurableTaskStep.USE_WATCHING\n  tags:\n  - feature\n  def: |\n    `false`\n  since"
  },
  "4917": {
    "source_file": "system-properties.txt",
    "text": " information.\n\n- name: org.jenkinsci.plugins.workflow.steps.durable_task.DurableTaskStep.USE_WATCHING\n  tags:\n  - feature\n  def: |\n    `false`\n  since: workflow-durable-task-step-plugin 2.22\n  description: |\n    `true` to enable the experimental push mode for durable task logging.\n    See https://issues.jenkins.io/browse/JENKINS-52165[JENKINS-52165] for more information.\n\n- name: org.jenkinsci.plu"
  },
  "4918": {
    "source_file": "system-properties.txt",
    "text": " mode for durable task logging.\n    See https://issues.jenkins.io/browse/JENKINS-52165[JENKINS-52165] for more information.\n\n- name: org.jenkinsci.plugins.workflow.support.pickles.ExecutorPickle.timeoutForNodeMillis\n  tags:\n  - tuning\n  def: 5 minutes (300,000 milliseconds)\n  since: workflow-durable-task-step-plugin 2.14\n  description: |\n    How long to wait, in milliseconds, before aborting the b"
  },
  "4919": {
    "source_file": "system-properties.txt",
    "text": "s (300,000 milliseconds)\n  since: workflow-durable-task-step-plugin 2.14\n  description: |\n    How long to wait, in milliseconds, before aborting the build if an agent has been removed.\n    See https://issues.jenkins.io/browse/JENKINS-36013[JENKINS-36013] for more information.\n\n- name: org.jenkinsci.plugins.workflow.support.steps.ExecutorStepExecution.REMOVED_NODE_DETECTION\n  tags:\n  - feature\n  de"
  },
  "4920": {
    "source_file": "system-properties.txt",
    "text": "013] for more information.\n\n- name: org.jenkinsci.plugins.workflow.support.steps.ExecutorStepExecution.REMOVED_NODE_DETECTION\n  tags:\n  - feature\n  def: |\n    `true`\n  since: workflow-durable-task-step-plugin 2.32\n  description: |\n    `false` to prevent Jenkins from aborting the build if an agent has been removed.\n    See https://issues.jenkins.io/browse/JENKINS-49707[JENKINS-49707] for more infor"
  },
  "4921": {
    "source_file": "system-properties.txt",
    "text": "ent Jenkins from aborting the build if an agent has been removed.\n    See https://issues.jenkins.io/browse/JENKINS-49707[JENKINS-49707] for more information.\n\n- name: org.kohsuke.stapler.Facet.allowViewNamePathTraversal\n  tags:\n  - escape hatch\n  - security\n  def: |\n    `false`\n  since: 2.138.2 / 2.146\n  description: |\n    Allows specifying non-simple names for views, including ones resulting in p"
  },
  "4922": {
    "source_file": "system-properties.txt",
    "text": "ecurity\n  def: |\n    `false`\n  since: 2.138.2 / 2.146\n  description: |\n    Allows specifying non-simple names for views, including ones resulting in path traversal.\n    This is an escape hatch for the  fix.\n\n- name: org.kohsuke.stapler.jelly.IncludeTag.skipLoggingClassSetter\n  tags:\n  - escape hatch\n  def: |\n    `false`\n  since: 2.288\n  description: |\n    Do not log attempts to set the `class` pro"
  },
  "4923": {
    "source_file": "system-properties.txt",
    "text": "ag.skipLoggingClassSetter\n  tags:\n  - escape hatch\n  def: |\n    `false`\n  since: 2.288\n  description: |\n    Do not log attempts to set the `class` property of `st:include` tags directly.\n    No log messages should be emitted in regular use, but they can be disabled if they cause unnecessary noise in the system log.\n\n- name: org.kohsuke.stapler.RequestImpl.ALLOWED_HTTP_VERBS_FOR_FORMS\n  tags:\n  - e"
  },
  "4924": {
    "source_file": "system-properties.txt",
    "text": "can be disabled if they cause unnecessary noise in the system log.\n\n- name: org.kohsuke.stapler.RequestImpl.ALLOWED_HTTP_VERBS_FOR_FORMS\n  tags:\n  - escape hatch\n  - security\n  def: |\n    `POST`\n  since: 2.277.2 / 2.287\n  description: |\n    HTTP verbs of requests that are allowed to provide `StaplerRequest#getSubmittedForm` or `@SubmittedForm`.\n    Escape hatch for a security hardening, see .\n\n- n"
  },
  "4925": {
    "source_file": "system-properties.txt",
    "text": "s of requests that are allowed to provide `StaplerRequest#getSubmittedForm` or `@SubmittedForm`.\n    Escape hatch for a security hardening, see .\n\n- name: org.kohsuke.stapler.RequestImpl.FILEUPLOAD_MAX_FILES\n  tags:\n  - escape hatch\n  - tuning\n  - security\n  def: |\n    `1000`\n  since: 2.375.4 / 2.394\n  description: |\n    Limits the number of form fields that can be processed in one `multipart/form"
  },
  "4926": {
    "source_file": "system-properties.txt",
    "text": "curity\n  def: |\n    `1000`\n  since: 2.375.4 / 2.394\n  description: |\n    Limits the number of form fields that can be processed in one `multipart/form-data` request.\n    Used to set `org.apache.commons.fileupload.servlet.ServletFileUpload#setFileCountMax(long)`.\n    Despite the name, this applies to all form fields, not just actual file attachments.\n    `-1` disables this limit.\n\n- name: org.kohsu"
  },
  "4927": {
    "source_file": "system-properties.txt",
    "text": "tMax(long)`.\n    Despite the name, this applies to all form fields, not just actual file attachments.\n    `-1` disables this limit.\n\n- name: org.kohsuke.stapler.RequestImpl.FILEUPLOAD_MAX_FILE_SIZE\n  tags:\n  # Not an escape hatch since it's disabled by default\n  - tuning\n  - security\n  def: |\n    `-1`\n  since: 2.375.4 / 2.394\n  description: |\n    Limits the size (in bytes) of individual fields tha"
  },
  "4928": {
    "source_file": "system-properties.txt",
    "text": "by default\n  - tuning\n  - security\n  def: |\n    `-1`\n  since: 2.375.4 / 2.394\n  description: |\n    Limits the size (in bytes) of individual fields that can be processed in one `multipart/form-data` request.\n    Despite the name, this applies to all form fields, not just actual file attachments.\n    `-1` disables this limit.\n\n- name: org.kohsuke.stapler.RequestImpl.FILEUPLOAD_MAX_SIZE\n  tags:\n  # N"
  },
  "4929": {
    "source_file": "system-properties.txt",
    "text": "orm fields, not just actual file attachments.\n    `-1` disables this limit.\n\n- name: org.kohsuke.stapler.RequestImpl.FILEUPLOAD_MAX_SIZE\n  tags:\n  # Not an escape hatch since it's disabled by default\n  - tuning\n  - security\n  def: |\n    `-1`\n  since: 2.375.4 / 2.394\n  description: |\n    Limits the total request size (in bytes) that can be processed in one `multipart/form-data` request.\n    Used to"
  },
  "4930": {
    "source_file": "system-properties.txt",
    "text": " 2.375.4 / 2.394\n  description: |\n    Limits the total request size (in bytes) that can be processed in one `multipart/form-data` request.\n    Used to set `org.apache.commons.fileupload.servlet.ServletFileUpload#setSizeMax(long)`.\n    `-1` disables this limit.\n\n- name: stapler.jelly.noCache\n  tags:\n  - development\n  def: |\n    `false`\n  description: |\n    Controls both caching of various cacheable"
  },
  "4931": {
    "source_file": "system-properties.txt",
    "text": "his limit.\n\n- name: stapler.jelly.noCache\n  tags:\n  - development\n  def: |\n    `false`\n  description: |\n    Controls both caching of various cacheable resources (Jelly scripts etc.) as well as the `Expires` HTTP response header for some static resources.\n    Useful during development to see the effect of changes after reload.\n\n- name: stapler.jelly.trace\n  tags:\n  - development\n  def: |\n    `false"
  },
  "4932": {
    "source_file": "system-properties.txt",
    "text": "ces.\n    Useful during development to see the effect of changes after reload.\n\n- name: stapler.jelly.trace\n  tags:\n  - development\n  def: |\n    `false`\n  description: |\n    Enables tracing of Jelly view composition.\n    View the resulting page source to see comments indicating which parts of the view were created from which view fragments.\n\n- name: stapler.legacyGetterDispatcherMode\n  tags:\n  - se"
  },
  "4933": {
    "source_file": "system-properties.txt",
    "text": " to see comments indicating which parts of the view were created from which view fragments.\n\n- name: stapler.legacyGetterDispatcherMode\n  tags:\n  - security\n  - escape hatch\n  def: |\n    `false`\n  description: |\n    Do not filter get methods at the Stapler framework level.\n    Escape hatch for .\n\n- name: stapler.legacyWebMethodDispatcherMode\n  tags:\n  - security\n  - escape hatch\n  def: |\n    `fals"
  },
  "4934": {
    "source_file": "system-properties.txt",
    "text": "tapler framework level.\n    Escape hatch for .\n\n- name: stapler.legacyWebMethodDispatcherMode\n  tags:\n  - security\n  - escape hatch\n  def: |\n    `false`\n  description: |\n    Do not filter web methods (\"do\" actions) at the Stapler framework level.\n    Escape hatch for .\n\n- name: stapler.resourcePath\n  tags:\n  - development\n  def: undefined\n  description: |\n    Additional debug resource paths.\n    S"
  },
  "4935": {
    "source_file": "system-properties.txt",
    "text": " Escape hatch for .\n\n- name: stapler.resourcePath\n  tags:\n  - development\n  def: undefined\n  description: |\n    Additional debug resource paths.\n    Set by the core development tooling so developers can see the effect of changes immediately after reloading the page.\n\n- name: stapler.trace\n  tags:\n  - development\n  def: |\n    `true` when run using `mvn jetty:run` (core war) or `mvn hpi:run` (plugin"
  },
  "4936": {
    "source_file": "system-properties.txt",
    "text": "oading the page.\n\n- name: stapler.trace\n  tags:\n  - development\n  def: |\n    `true` when run using `mvn jetty:run` (core war) or `mvn hpi:run` (plugins), `false` otherwise\n  description: |\n    Trace request handling and report the result using `Stapler-Trace-...` response headers.\n    Additionally renders a diagnostic HTTP 404 error page when the request could not be processed.\n\n- name: stapler.tr"
  },
  "4937": {
    "source_file": "system-properties.txt",
    "text": "er-Trace-...` response headers.\n    Additionally renders a diagnostic HTTP 404 error page when the request could not be processed.\n\n- name: stapler.trace.per-request\n  tags:\n  - development\n  def: |\n    `false`\n  description: |\n    Trace request handling (see above) for requests with the `X-Stapler-Trace` request header set.\n\n- name: jenkins.util.groovy.GroovyHookScript.ROOT_PATH\n  since: 2.273\n  "
  },
  "4938": {
    "source_file": "system-properties.txt",
    "text": "ling (see above) for requests with the `X-Stapler-Trace` request header set.\n\n- name: jenkins.util.groovy.GroovyHookScript.ROOT_PATH\n  since: 2.273\n  tags:\n  - packaging\n  def: |\n    `$JENKINS_HOME`\n  description: |\n    Set the root directory used to load groovy hooks scripts.\n\n- name: jenkins.branch.MultiBranchProject.fireSCMSourceBuildsAfterSave\n  since: branch-api 2.7.0\n  tags:\n  - feature\n  de"
  },
  "4939": {
    "source_file": "system-properties.txt",
    "text": " load groovy hooks scripts.\n\n- name: jenkins.branch.MultiBranchProject.fireSCMSourceBuildsAfterSave\n  since: branch-api 2.7.0\n  tags:\n  - feature\n  def: |\n    `true`\n  description: |\n    When Multibranch Pipeline is reloaded from XML, it notifies its branch sources about it and triggers a scan if possible.\n    This flag allows turning off this behavior.\n    When Job DSL manages the items, this can"
  },
  "4940": {
    "source_file": "system-properties.txt",
    "text": " branch sources about it and triggers a scan if possible.\n    This flag allows turning off this behavior.\n    When Job DSL manages the items, this can avoid triggering many scans, which can potentially cause a build storm.\n    The downside is that the branch source might use this notification to register webhooks or do any other useful setup work.\n\n\nJenkins has several \"hidden\" features that can b"
  },
  "4941": {
    "source_file": "system-properties.txt",
    "text": "e branch source might use this notification to register webhooks or do any other useful setup work.\n\n\nJenkins has several \"hidden\" features that can be enabled with system properties.\nThis page documents many of them and explains how to configure them on your controller.\n\nSome system properties related to the Remoting library used for communication between controller and agents are documented in h"
  },
  "4942": {
    "source_file": "system-properties.txt",
    "text": "m on your controller.\n\nSome system properties related to the Remoting library used for communication between controller and agents are documented in https://github.com/jenkinsci/remoting/blob/master/docs/configuration.md[that component's repository].\n\nSystem properties are defined by passing `-Dproperty=value` to the `java` command line to start Jenkins.\nMake sure to pass all of these arguments *b"
  },
  "4943": {
    "source_file": "system-properties.txt",
    "text": "\n\nSystem properties are defined by passing `-Dproperty=value` to the `java` command line to start Jenkins.\nMake sure to pass all of these arguments *before* the `-jar` argument, otherwise they will be ignored.\nExample:\n\n```sh\njava -Dhudson.footerURL=http://example.org -jar jenkins.war\n```\n\nThe following lists the properties and the version of Jenkins they were introduced in.\n\n* `*Property*` - Java"
  },
  "4944": {
    "source_file": "system-properties.txt",
    "text": "http://example.org -jar jenkins.war\n```\n\nThe following lists the properties and the version of Jenkins they were introduced in.\n\n* `*Property*` - Java property name\n* *Default* - Default value if not explicitly set\n* *Since* - The version of Jenkins the property was introduced in\n* *Description* - Other notes\n\nWe do **NOT** guarantee that system properties will remain unchanged and functional inde"
  },
  "4945": {
    "source_file": "system-properties.txt",
    "text": "the property was introduced in\n* *Description* - Other notes\n\nWe do **NOT** guarantee that system properties will remain unchanged and functional indefinitely.\nThese switches are often experimental in nature, and subject to change without notice.\nIf you find these useful, please file a ticket to promote it to an official feature.\n\n[NOTE]\nDue to the very large number of system properties used, ofte"
  },
  "4946": {
    "source_file": "system-properties.txt",
    "text": "you find these useful, please file a ticket to promote it to an official feature.\n\n[NOTE]\nDue to the very large number of system properties used, often just added as a \"safety valve\" or \"escape hatch\" in case a change causes problems, this list is not expected to be complete.\n\n+++\n<style>\ndd {\n  margin-left: 30px;\n}\ndd div.tag {\n}\nspan.tag {\n    display: inline-block;\n    border: 1px solid #666;\n "
  },
  "4947": {
    "source_file": "system-properties.txt",
    "text": "t expected to be complete.\n\n+++\n<style>\ndd {\n  margin-left: 30px;\n}\ndd div.tag {\n}\nspan.tag {\n    display: inline-block;\n    border: 1px solid #666;\n    background-color: #eee;\n    color: #333;\n    border-radius: 4px;\n    font-size: 0.75rem;\n    font-weight: 500;\n    padding: 0 0.5rem;\n    margin: 0.25rem 0.5rem 0.25rem 0;\n    text-decoration: none;\n    text-align: center;\n    white-space: nowrap;"
  },
  "4948": {
    "source_file": "system-properties.txt",
    "text": "-weight: 500;\n    padding: 0 0.5rem;\n    margin: 0.25rem 0.5rem 0.25rem 0;\n    text-decoration: none;\n    text-align: center;\n    white-space: nowrap;\n    vertical-align: baseline;\n    text-transform: capitalize;\n}\n/* Work around wrapper block elements added for Asciidoctor conversions that would break the layout */\n.def div {\n    display: inline-block;\n}\n.def div p {\n    margin: 0;\n}\n</style>\n<sc"
  },
  "4949": {
    "source_file": "system-properties.txt",
    "text": "ts added for Asciidoctor conversions that would break the layout */\n.def div {\n    display: inline-block;\n}\n.def div p {\n    margin: 0;\n}\n</style>\n<script>\ndocument.addEventListener('DOMContentLoaded', function(event) {\n    anchors.add('dt');\n});\n</script>\n+++"
  },
  "4950": {
    "source_file": "system-properties.txt",
    "text": "cript>\n+++"
  },
  "4951": {
    "source_file": "systemd-services.txt",
    "text": "layout: section\n\n\nBeginning with Jenkins 2.332.1 and Jenkins 2.335, the Linux package installers use `systemd` to manage services.\nThe RPM and deb package installers migrate configuration settings from System V `init` to `systemd` overrides.\n\nvideo::pwR9TPW2oG4[youtube,width=800,height=420]\n\nThe current service configuration of the Jenkins service as configured by the package installers and any ov"
  },
  "4952": {
    "source_file": "systemd-services.txt",
    "text": "pwR9TPW2oG4[youtube,width=800,height=420]\n\nThe current service configuration of the Jenkins service as configured by the package installers and any overrides can be viewed with:\n\nsystemctl cat jenkins\n# /etc/systemd/system/jenkins.service\n#\n# This file is managed by systemd(1). Do NOT edit this file manually!\n# To override these settings, run:\n#\n#     systemctl edit jenkins\n#\n# For more informatio"
  },
  "4953": {
    "source_file": "systemd-services.txt",
    "text": "le is managed by systemd(1). Do NOT edit this file manually!\n# To override these settings, run:\n#\n#     systemctl edit jenkins\n#\n# For more information about drop-in files, see:\n#\n#     https://www.freedesktop.org/software/systemd/man/systemd.unit.html\n#\n\n[Unit]\nDescription=Jenkins Continuous Integration Server\nRequires=network.target\nAfter=network.target\n\n[Service]\nType=notify\nNotifyAccess=main\nE"
  },
  "4954": {
    "source_file": "systemd-services.txt",
    "text": "ml\n#\n\n[Unit]\nDescription=Jenkins Continuous Integration Server\nRequires=network.target\nAfter=network.target\n\n[Service]\nType=notify\nNotifyAccess=main\nExecStart=/usr/bin/jenkins\nRestart=on-failure\nSuccessExitStatus=143\n\n# /etc/systemd/system/jenkins.service.d/override.conf\n[Service]\nEnvironment=\"JAVA_OPTS=-Djava.awt.headless=true\"\n\nWhen installed on a modern Linux distribution running `systemd(1)`, "
  },
  "4955": {
    "source_file": "systemd-services.txt",
    "text": "rvice.d/override.conf\n[Service]\nEnvironment=\"JAVA_OPTS=-Djava.awt.headless=true\"\n\nWhen installed on a modern Linux distribution running `systemd(1)`, the `systemd(1)`  is delivered to:\n\nDebian:: `/lib/systemd/system/jenkins.service`\nRed Hat:: `/usr/lib/systemd/system/jenkins.service`\nopenSUSE:: `/usr/lib/systemd/system/jenkins.service`\n\nThe main service unit is read-only and not intended to be edi"
  },
  "4956": {
    "source_file": "systemd-services.txt",
    "text": "ib/systemd/system/jenkins.service`\nopenSUSE:: `/usr/lib/systemd/system/jenkins.service`\n\nThe main service unit is read-only and not intended to be edited manually.\nIt contains a large notice at the top of the file reminding the user that it is read-only.\n\nValues may be overridden in the drop-in unit (`override.conf` file) for the service.\nEdit the drop-in unit with:\n\n# systemctl edit jenkins\n\nThe "
  },
  "4957": {
    "source_file": "systemd-services.txt",
    "text": "nly.\n\nValues may be overridden in the drop-in unit (`override.conf` file) for the service.\nEdit the drop-in unit with:\n\n# systemctl edit jenkins\n\nThe `override.conf` file is stored at `/etc/systemd/system/jenkins.service.d/override.conf` and can be used to customize the service.\nNote that such customizations must be done in a `[Service]` section in order to take effect.\nExample content of the `ove"
  },
  "4958": {
    "source_file": "systemd-services.txt",
    "text": "sed to customize the service.\nNote that such customizations must be done in a `[Service]` section in order to take effect.\nExample content of the `override.conf` file might include:\n\n[Unit]\nDescription=My Company Jenkins Controller\n\n[Service]\n# Add JVM configuration options\nEnvironment=\"JAVA_OPTS=-Djava.awt.headless=true -XX:+UseStringDeduplication\"\n\n# Arbitrary additional arguments to pass to Jen"
  },
  "4959": {
    "source_file": "systemd-services.txt",
    "text": "VM configuration options\nEnvironment=\"JAVA_OPTS=-Djava.awt.headless=true -XX:+UseStringDeduplication\"\n\n# Arbitrary additional arguments to pass to Jenkins.\n# Full option list: java -jar jenkins.war --help\nEnvironment=\"JENKINS_OPTS=--prefix=/jenkins --javaHome=/opt/jdk-21\"\n\n# Configuration as code directory\nEnvironment=\"CASC_JENKINS_CONFIG=/var/lib/jenkins/configuration-as-code/\"\n\nWARNING: `systemc"
  },
  "4960": {
    "source_file": "systemd-services.txt",
    "text": "-javaHome=/opt/jdk-21\"\n\n# Configuration as code directory\nEnvironment=\"CASC_JENKINS_CONFIG=/var/lib/jenkins/configuration-as-code/\"\n\nWARNING: `systemctl edit jenkins` creates the drop-in unit as `root` with 0644 (`-rw-r--r--`) permissions.\nThe migration logic, on the other hand, creates the drop-in unit as `root` with 0600 (`-rw---`) permissions.\nThis might be of consequence if you store an HTTPS "
  },
  "4961": {
    "source_file": "systemd-services.txt",
    "text": "ion logic, on the other hand, creates the drop-in unit as `root` with 0600 (`-rw---`) permissions.\nThis might be of consequence if you store an HTTPS keystore location and/or password in the drop-in unit\nand also run jobs directly on the controller,\na practice which the Jenkins project .\nWhen in doubt, secure the drop-in unit by setting its permissions to 0600 with `chmod(1)`.\n\nThe drop-in unit un"
  },
  "4962": {
    "source_file": "systemd-services.txt",
    "text": "a practice which the Jenkins project .\nWhen in doubt, secure the drop-in unit by setting its permissions to 0600 with `chmod(1)`.\n\nThe drop-in unit unifies configuration across all three distributions: Debian, Red Hat, and openSUSE.\nAlso note that the drop-in unit is not overwritten on upgrades.\n\nNOTE: Unlike the System V `init(8)` configuration, the `override.conf` file only contains customizatio"
  },
  "4963": {
    "source_file": "systemd-services.txt",
    "text": "e drop-in unit is not overwritten on upgrades.\n\nNOTE: Unlike the System V `init(8)` configuration, the `override.conf` file only contains customizations, not the original defaults.\nUsers who are accustomed to editing an existing set of defaults must refer to the (read-only) service unit side-by-side when editing the drop-in unit\nor use a command like `systemctl edit jenkins --full`, which copies t"
  },
  "4964": {
    "source_file": "systemd-services.txt",
    "text": "refer to the (read-only) service unit side-by-side when editing the drop-in unit\nor use a command like `systemctl edit jenkins --full`, which copies the original service unit instead of creating a drop-in unit.\n\nEditing the drop-in unit with `systemctl edit jenkins` will automatically reload the `systemd(1)` configuration.\nThe settings will take effect the next time Jenkins is restarted.\nIf you ed"
  },
  "4965": {
    "source_file": "systemd-services.txt",
    "text": "tl edit jenkins` will automatically reload the `systemd(1)` configuration.\nThe settings will take effect the next time Jenkins is restarted.\nIf you edit the drop-in unit without `systemctl(1)`, you need to run `systemctl daemon-reload` for the changes to take effect.\n\nA final point to mention about the service unit is its use of specifiers,\nwhich may be unfamiliar to some users.\nThe drop-in unit d"
  },
  "4966": {
    "source_file": "systemd-services.txt",
    "text": "s to take effect.\n\nA final point to mention about the service unit is its use of specifiers,\nwhich may be unfamiliar to some users.\nThe drop-in unit does not perform shell expansion.\nSpecifiers can insert contextual information (like system hostname, unit name, and operating system kernel release) into the drop-in unit.\nThe `systemd(1)` documentation contains .\n\nOnce the Jenkins `systemd` service "
  },
  "4967": {
    "source_file": "systemd-services.txt",
    "text": " unit name, and operating system kernel release) into the drop-in unit.\nThe `systemd(1)` documentation contains .\n\nOnce the Jenkins `systemd` service has been defined, it can be started with:\n\n# systemctl start jenkins\n\nIf Jenkins does not signal startup completion within a configured time,\nthe service will be considered failed and will be shut down again.\nAs each initialization milestone (i.e., \""
  },
  "4968": {
    "source_file": "systemd-services.txt",
    "text": "rtup completion within a configured time,\nthe service will be considered failed and will be shut down again.\nAs each initialization milestone (i.e., \"Started initialization\", \"Listed all plugins\",\n\"Prepared all plugins\", \"Started all plugins\", \"Augmented all extensions\",\n\"System config loaded\", \"System config adapted\", \"Loaded all jobs\",\n\"Configuration for all jobs updated\", and \"Completed initial"
  },
  "4969": {
    "source_file": "systemd-services.txt",
    "text": "nted all extensions\",\n\"System config loaded\", \"System config adapted\", \"Loaded all jobs\",\n\"Configuration for all jobs updated\", and \"Completed initialization\") is attained,\nthe timeout is extended by the value of the `jenkins.model.Jenkins.extendTimeoutSeconds` system property (by default, 15 seconds).\nThe timeout can be configured with the `TimeoutStartSec` directive in the service unit.\n\nThe Jen"
  },
  "4970": {
    "source_file": "systemd-services.txt",
    "text": "outSeconds` system property (by default, 15 seconds).\nThe timeout can be configured with the `TimeoutStartSec` directive in the service unit.\n\nThe Jenkins `systemd` service can be stopped with:\n\n# systemctl stop jenkins\n\nThe Jenkins `systemd` service can be restarted with:\n\n# systemctl restart jenkins\n\nAfter changes to configuration files, the service definition may need to be reloaded with:\n\n# sy"
  },
  "4971": {
    "source_file": "systemd-services.txt",
    "text": " can be restarted with:\n\n# systemctl restart jenkins\n\nAfter changes to configuration files, the service definition may need to be reloaded with:\n\n# systemctl daemon-reload\n\nLogs for the Jenkins service can be read with the command:\n\njournalctl -u jenkins\n\nLog files retained by `systemd` are commonly configured to automatically rotate.\nIf the log files need to be reduced in size, use the command:\n\n"
  },
  "4972": {
    "source_file": "systemd-services.txt",
    "text": "kins\n\nLog files retained by `systemd` are commonly configured to automatically rotate.\nIf the log files need to be reduced in size, use the command:\n\njournalctl --vacuum-size=500M\n\nThe Jenkins `systemd` service status can be viewed with `systemctl status jenkins`.\nSome examples are shown below.\n\nAfter upgrading plugins:\n\nsystemctl status jenkins\n\u25cf jenkins.service - Jenkins Continuous Integration S"
  },
  "4973": {
    "source_file": "systemd-services.txt",
    "text": "atus jenkins`.\nSome examples are shown below.\n\nAfter upgrading plugins:\n\nsystemctl status jenkins\n\u25cf jenkins.service - Jenkins Continuous Integration Server\n     Loaded: loaded (/lib/systemd/system/jenkins.service; enabled; vendor preset: enabled)\n    Drop-In: /etc/systemd/system/jenkins.service.d\n             \u2514\u2500override.conf\n     Active: active (running) [\u2026]\n   Main PID: [\u2026] (java)\n     Status: \"R"
  },
  "4974": {
    "source_file": "systemd-services.txt",
    "text": " Drop-In: /etc/systemd/system/jenkins.service.d\n             \u2514\u2500override.conf\n     Active: active (running) [\u2026]\n   Main PID: [\u2026] (java)\n     Status: \"Restart in 10 seconds\"\n\nAs Jenkins is being brought down:\n\nsystemctl status jenkins\n\u25cf jenkins.service - Jenkins Continuous Integration Server\n     Loaded: loaded (/lib/systemd/system/jenkins.service; enabled; vendor preset: enabled)\n    Drop-In: /etc/"
  },
  "4975": {
    "source_file": "systemd-services.txt",
    "text": " - Jenkins Continuous Integration Server\n     Loaded: loaded (/lib/systemd/system/jenkins.service; enabled; vendor preset: enabled)\n    Drop-In: /etc/systemd/system/jenkins.service.d\n             \u2514\u2500override.conf\n     Active: deactivating (stop-sigterm) since [\u2026]\n   Main PID: [\u2026] (java)\n     Status: \"Stopping Jenkins\"\n\nAs Jenkins is starting up:\n\nsystemctl status jenkins\n\u25cf jenkins.service - Jenkins"
  },
  "4976": {
    "source_file": "systemd-services.txt",
    "text": "m) since [\u2026]\n   Main PID: [\u2026] (java)\n     Status: \"Stopping Jenkins\"\n\nAs Jenkins is starting up:\n\nsystemctl status jenkins\n\u25cf jenkins.service - Jenkins Continuous Integration Server\n     Loaded: loaded (/lib/systemd/system/jenkins.service; enabled; vendor preset: enabled)\n    Drop-In: /etc/systemd/system/jenkins.service.d\n             \u2514\u2500override.conf\n     Active: activating (start) since [\u2026]\n   Mai"
  },
  "4977": {
    "source_file": "systemd-services.txt",
    "text": "ndor preset: enabled)\n    Drop-In: /etc/systemd/system/jenkins.service.d\n             \u2514\u2500override.conf\n     Active: activating (start) since [\u2026]\n   Main PID: [\u2026] (java)\n\nAfter successful startup:\n\nsystemctl status jenkins\n\u25cf jenkins.service - Jenkins Continuous Integration Server\n     Loaded: loaded (/lib/systemd/system/jenkins.service; enabled; vendor preset: enabled)\n    Drop-In: /etc/systemd/syst"
  },
  "4978": {
    "source_file": "systemd-services.txt",
    "text": "ontinuous Integration Server\n     Loaded: loaded (/lib/systemd/system/jenkins.service; enabled; vendor preset: enabled)\n    Drop-In: /etc/systemd/system/jenkins.service.d\n             \u2514\u2500override.conf\n     Active: active (running) since [\u2026]\n   Main PID: [\u2026] (java)\n\nSome recommended readings on this subject:\n\n*\n*  by the Fedora project\n*  from freedesktop.org\n*"
  },
  "4979": {
    "source_file": "systemd-services.txt",
    "text": "D: [\u2026] (java)\n\nSome recommended readings on this subject:\n\n*\n*  by the Fedora project\n*  from freedesktop.org\n*"
  },
  "4980": {
    "source_file": "table-to-div-migration.txt",
    "text": "title: Table to div layout migration\nlayout: developer\n\n\nNOTE: This is documentation for a new feature in Jenkins core.\nSee jira:JENKINS-56109[Change Jenkins configuration UI from tables to divs] for details.\n\nJenkins core changed its form layout from ``<table>`` to ``<div>`` in 2.264 (weekly) and 2.277.1 (LTS).\nJenkins 2.263.x (LTS) releases did *not* change their form layout from ``<table>`` to "
  },
  "4981": {
    "source_file": "table-to-div-migration.txt",
    "text": "m ``<table>`` to ``<div>`` in 2.264 (weekly) and 2.277.1 (LTS).\nJenkins 2.263.x (LTS) releases did *not* change their form layout from ``<table>`` to ``<div>``.\n\nAll core ``taglib``s and views were updated in  as part of jira:JENKINS-56109[].\n\nThe vast majority of plugins do not require any changes at all because they use the standard Jelly tags in Jenkins for their forms, such as ``<f:entry>``, `"
  },
  "4982": {
    "source_file": "table-to-div-migration.txt",
    "text": "st majority of plugins do not require any changes at all because they use the standard Jelly tags in Jenkins for their forms, such as ``<f:entry>``, ``<f:textbox>``, and ``<f:checkbox>``.\n\nIf you are experiencing configuration form problems (e.g., form controls not working, the save button not working, etc.):\n\nVerify that you followed the instructions in the , including updating plugins after inst"
  },
  "4983": {
    "source_file": "table-to-div-migration.txt",
    "text": "rm controls not working, the save button not working, etc.):\n\nVerify that you followed the instructions in the , including updating plugins after installing Jenkins 2.277.1.\nRefer to the ; if you are using a plugin that is known to be broken, disable it and upvote the issue.\nDisable any plugins that are no longer in use, particularly if those plugins are https://github.com/jenkins-infra/update-cen"
  },
  "4984": {
    "source_file": "table-to-div-migration.txt",
    "text": " it and upvote the issue.\nDisable any plugins that are no longer in use, particularly if those plugins are https://github.com/jenkins-infra/update-center2/blob/master/resources/artifact-ignores.properties[no longer distributed on the Jenkins update site] (including Team Foundation Server and Perforce).\n\nIf the problem persists, perform bisection to identify the broken plugin.\n\nIf you are uncomfort"
  },
  "4985": {
    "source_file": "table-to-div-migration.txt",
    "text": "ite] (including Team Foundation Server and Perforce).\n\nIf the problem persists, perform bisection to identify the broken plugin.\n\nIf you are uncomfortable using your production Jenkins installation, set up a minimal Jenkins installation:\nJENKINS_HOST=username:password@myhost.com:port\ncurl -sSL \"http://$JENKINS_HOST/pluginManager/api/xml?depth=1&xpath=/*/*/shortName|/*/*/version&wrapper=plugins\" | "
  },
  "4986": {
    "source_file": "table-to-div-migration.txt",
    "text": "=username:password@myhost.com:port\ncurl -sSL \"http://$JENKINS_HOST/pluginManager/api/xml?depth=1&xpath=/*/*/shortName|/*/*/version&wrapper=plugins\" | perl -pe 's/.*?<shortName>([\\w-]+).*?<version>([^<]+)()(<\\/\\w+>)+/\\1 \\2\\n/g'| sed 's/ /:/' | cut -d ':' -f 1 | sort > plugins.txt\nwget https://github.com/jenkinsci/plugin-installation-manager-tool/releases/download/2.9.0/jenkins-plugin-manager-2.9.0."
  },
  "4987": {
    "source_file": "table-to-div-migration.txt",
    "text": "':' -f 1 | sort > plugins.txt\nwget https://github.com/jenkinsci/plugin-installation-manager-tool/releases/download/2.9.0/jenkins-plugin-manager-2.9.0.jar\nwget https://get.jenkins.io/war-stable/2.277.1/jenkins.war\nexport JENKINS_HOME=~/.jenkins-tables-to-div\njava -jar jenkins-plugin-manager-2.9.0.jar -f plugins.txt -d $JENKINS_HOME/plugins --war jenkins.war\njava -jar jenkins.war\n\nCreate a \"freestyl"
  },
  "4988": {
    "source_file": "table-to-div-migration.txt",
    "text": "-to-div\njava -jar jenkins-plugin-manager-2.9.0.jar -f plugins.txt -d $JENKINS_HOME/plugins --war jenkins.war\njava -jar jenkins.war\n\nCreate a \"freestyle\" job to reproduce the issue.\nGenerally disable plugins in groups of 10, recording which plugins you have disabled.\nRestart Jenkins.\nIf the problem persists, keep disabling plugins.\nOnce the problem is resolved, enable plugins one at a time to ident"
  },
  "4989": {
    "source_file": "table-to-div-migration.txt",
    "text": "u have disabled.\nRestart Jenkins.\nIf the problem persists, keep disabling plugins.\nOnce the problem is resolved, enable plugins one at a time to identify the broken plugin.\n\nWhen reporting an issue, include the following information:\n\nProvide the _complete_ list of installed plugins as suggested in the .\nProvide a screenshot.\nProvide steps to reproduce the problem on a minimal Jenkins installation"
  },
  "4990": {
    "source_file": "table-to-div-migration.txt",
    "text": "mplete_ list of installed plugins as suggested in the .\nProvide a screenshot.\nProvide steps to reproduce the problem on a minimal Jenkins installation; the scenario should fail when the broken plugin is enabled and pass when the broken plugin is disabled.\nUse the `tables-to-divs-regression` label.\n\nBelow are some areas that may require you to adjust the form layout or JavaScript in your plugin:\n\n*"
  },
  "4991": {
    "source_file": "table-to-div-migration.txt",
    "text": "bled.\nUse the `tables-to-divs-regression` label.\n\nBelow are some areas that may require you to adjust the form layout or JavaScript in your plugin:\n\n* Adding `td` / `tr` elements directly instead of using the `f:entry` tag, e.g.\n\n* Custom JavaScript that is brittle to the Jenkins form UI layout. We\u2019ve done our best to introduce shims, to not cause breakage here,\nbut if you have written JavaScript "
  },
  "4992": {
    "source_file": "table-to-div-migration.txt",
    "text": "that is brittle to the Jenkins form UI layout. We\u2019ve done our best to introduce shims, to not cause breakage here,\nbut if you have written JavaScript that is reliant on the DOM structure you may need to make adjustments,\ntake a look at the JavaScript .\n\n* Forking jelly taglibs from core and extending them, e.g. ,\nit would be good to contribute fixes or enhancements to core rather than doing this w"
  },
  "4993": {
    "source_file": "table-to-div-migration.txt",
    "text": " .\n\n* Forking jelly taglibs from core and extending them, e.g. ,\nit would be good to contribute fixes or enhancements to core rather than doing this where possible.\n\n* Using tables in the plugin for layout, e.g.  and .\n\nMaintaining such support is preferred where it is easily possible, to allow plugins to be updated and used\non Jenkins deployments with older core versions (including current LTS 2."
  },
  "4994": {
    "source_file": "table-to-div-migration.txt",
    "text": "eferred where it is easily possible, to allow plugins to be updated and used\non Jenkins deployments with older core versions (including current LTS 2.263.x at the time of this writing).\n\nThere is a jelly property set on Jenkins controllers that use div's for form layout called `divBasedFormLayout`,\nso you can adapt your plugin UI based on the presence of this property.\n\n_Note: This property is onl"
  },
  "4995": {
    "source_file": "table-to-div-migration.txt",
    "text": "iv's for form layout called `divBasedFormLayout`,\nso you can adapt your plugin UI based on the presence of this property.\n\n_Note: This property is only set if the form tag uses the `f:form` jelly tag, and not the HTML `form` tag,\nthis will be done automatically for you in form sections but not in actions or custom views._\n\nJelly example:\n\n<j:jelly xmlns:j=\"jelly:core\" xmlns:d=\"jelly:define\" xmlns:"
  },
  "4996": {
    "source_file": "table-to-div-migration.txt",
    "text": "tomatically for you in form sections but not in actions or custom views._\n\nJelly example:\n\n<j:jelly xmlns:j=\"jelly:core\" xmlns:d=\"jelly:define\" xmlns:local=\"local\">\n  <d:taglib uri=\"local\">\n    <d:tag name=\"blockWrapper\">\n          <j:choose>\n              <j:when test=\"${divBasedFormLayout}\">\n                  <div>\n                      <d:invokeBody/>\n                  </div>\n              </j:"
  },
  "4997": {
    "source_file": "table-to-div-migration.txt",
    "text": "       <j:when test=\"${divBasedFormLayout}\">\n                  <div>\n                      <d:invokeBody/>\n                  </div>\n              </j:when>\n              <j:otherwise>\n                  <table style=\"width:100%\">\n                      <d:invokeBody/>\n                  </table>\n              </j:otherwise>\n          </j:choose>\n      </d:tag>\n  </d:taglib>\n\n  <local:blockWrapper>\n  "
  },
  "4998": {
    "source_file": "table-to-div-migration.txt",
    "text": " <d:invokeBody/>\n                  </table>\n              </j:otherwise>\n          </j:choose>\n      </d:tag>\n  </d:taglib>\n\n  <local:blockWrapper>\n  ...\n  </local:blockWrapper>\n</j:jelly>\n\nThis will use a table on Jenkins controllers that don't have `divBasedFormLayout` and will use a div when it is set.\n\n_Note: You will likely need more tags to adapt the `tr` and `td` tags to divs see  for a ful"
  },
  "4999": {
    "source_file": "table-to-div-migration.txt",
    "text": " `divBasedFormLayout` and will use a div when it is set.\n\n_Note: You will likely need more tags to adapt the `tr` and `td` tags to divs see  for a full example, or  for an even more extensive example of different wrapper types (note they are shipped in separate files, included from the jelly files to edit with references like `xmlns:p=\"/lib/notification\"` with a path part relative to `src/main/res"
  },
  "5000": {
    "source_file": "table-to-div-migration.txt",
    "text": "in separate files, included from the jelly files to edit with references like `xmlns:p=\"/lib/notification\"` with a path part relative to `src/main/resources/` directory)._\n\nGroovy example:\n\nblockWrapper {\n    p('Hello, World!')\n}\n\ndef blockWrapper(Closure closure) {\n    if (context.getVariableWithDefaultValue(\"divBasedFormLayout\", false) == true) {\n        div() {\n            closure.call()\n      "
  },
  "5001": {
    "source_file": "table-to-div-migration.txt",
    "text": "osure closure) {\n    if (context.getVariableWithDefaultValue(\"divBasedFormLayout\", false) == true) {\n        div() {\n            closure.call()\n        }\n    } else {\n        table(style: \"width: 100%\") {\n            closure.call()\n        }\n    }\n}\n\nContact the  on ."
  },
  "5002": {
    "source_file": "table-to-div-migration.txt",
    "text": "\nContact the  on ."
  },
  "5003": {
    "source_file": "taglibs.txt",
    "text": "layout: developersection\ntitle: Taglibs\n\n\nDocumentation for jelly tag libraries is published in the following places:\n\n-\n-\n-"
  },
  "5004": {
    "source_file": "tests-and-artifacts.txt",
    "text": "layout: documentation\ntitle: Recording tests and artifacts\n\n\nWhile testing is a critical part of a good continuous delivery pipeline, most\npeople don't want to sift through thousands of lines of console output to find\ninformation about failing tests. To make this easier, Jenkins can record and\naggregate test results so long as your test runner can output test result\nfiles. Jenkins typically comes "
  },
  "5005": {
    "source_file": "tests-and-artifacts.txt",
    "text": " To make this easier, Jenkins can record and\naggregate test results so long as your test runner can output test result\nfiles. Jenkins typically comes bundled with the `junit` step, but if your test\nrunner cannot output JUnit-style XML reports, there are additional plugins\nwhich process practically any widely-used test report format.\n\nTo collect our test results and artifacts, we will use the `post"
  },
  "5006": {
    "source_file": "tests-and-artifacts.txt",
    "text": "are additional plugins\nwhich process practically any widely-used test report format.\n\nTo collect our test results and artifacts, we will use the `post` section.\n\n[pipeline]\n\n// Declarative //\npipeline {\n    agent any\n    stages {\n        stage('Test') {\n            steps {\n                sh './gradlew check'\n            }\n        }\n    }\n    post {\n        always {\n            junit 'build/report"
  },
  "5007": {
    "source_file": "tests-and-artifacts.txt",
    "text": ") {\n            steps {\n                sh './gradlew check'\n            }\n        }\n    }\n    post {\n        always {\n            junit 'build/reports/**/*.xml'\n        }\n    }\n}\n// Scripted //\nnode {\n    try {\n        stage('Test') {\n            sh './gradlew check'\n        }\n    } finally {\n        junit 'build/reports/**/*.xml'\n    }\n}\n\nThis will _always_ grab the test results and let Jenkins "
  },
  "5008": {
    "source_file": "tests-and-artifacts.txt",
    "text": " './gradlew check'\n        }\n    } finally {\n        junit 'build/reports/**/*.xml'\n    }\n}\n\nThis will _always_ grab the test results and let Jenkins track them, calculate\ntrends and report on them. A Pipeline that has failing tests will be marked as\n\"\", denoted by yellow in the\nweb UI. That is distinct from the\n\"\" state, denoted by red.\n\nNOTE: Pipeline execution will by default proceed even when "
  },
  "5009": {
    "source_file": "tests-and-artifacts.txt",
    "text": "\n\"\", denoted by yellow in the\nweb UI. That is distinct from the\n\"\" state, denoted by red.\n\nNOTE: Pipeline execution will by default proceed even when the build is unstable.\nTo skip deployment after test failures in Declarative syntax,\nuse the `skipStagesAfterUnstable` option.\nIn Scripted syntax, you may check `currentBuild.currentResult == 'SUCCESS'`.\n\nWhen there are test failures, it is often use"
  },
  "5010": {
    "source_file": "tests-and-artifacts.txt",
    "text": "agesAfterUnstable` option.\nIn Scripted syntax, you may check `currentBuild.currentResult == 'SUCCESS'`.\n\nWhen there are test failures, it is often useful to grab built artifacts from\nJenkins for local analysis and investigation. This is made practical by\nJenkins's built-in support for storing \"artifacts\", files generated during the\nexecution of the Pipeline.\n\nThis is easily done with the `archiveA"
  },
  "5011": {
    "source_file": "tests-and-artifacts.txt",
    "text": "l by\nJenkins's built-in support for storing \"artifacts\", files generated during the\nexecution of the Pipeline.\n\nThis is easily done with the `archiveArtifacts` step and a file-globbing\nexpression, as is demonstrated in the example below:\n\n[pipeline]\n\n// Declarative //\npipeline {\n    agent any\n    stages {\n        stage('Build') {\n            steps {\n                sh './gradlew build'\n           "
  },
  "5012": {
    "source_file": "tests-and-artifacts.txt",
    "text": "\n// Declarative //\npipeline {\n    agent any\n    stages {\n        stage('Build') {\n            steps {\n                sh './gradlew build'\n            }\n        }\n        stage('Test') {\n            steps {\n                sh './gradlew check'\n            }\n        }\n    }\n\n    post {\n        always {\n            archiveArtifacts artifacts: 'build/libs/**/*.jar', fingerprint: true\n            juni"
  },
  "5013": {
    "source_file": "tests-and-artifacts.txt",
    "text": "      }\n        }\n    }\n\n    post {\n        always {\n            archiveArtifacts artifacts: 'build/libs/**/*.jar', fingerprint: true\n            junit 'build/reports/**/*.xml'\n        }\n    }\n}\n// Scripted //\nnode {\n    try {\n        stage('Test') {\n            sh './gradlew check'\n        }\n    } finally {\n        archiveArtifacts artifacts: 'build/libs/**/*.jar', fingerprint: true\n        junit"
  },
  "5014": {
    "source_file": "tests-and-artifacts.txt",
    "text": "\n            sh './gradlew check'\n        }\n    } finally {\n        archiveArtifacts artifacts: 'build/libs/**/*.jar', fingerprint: true\n        junit 'build/reports/**/*.xml'\n    }\n}\n\nIf more than one parameter is specified in the `archiveArtifacts` step, then\neach parameter's name must explicitly be specified in the step code - i.e.\n`artifacts` for the artifact's path and file name and `fingerpr"
  },
  "5015": {
    "source_file": "tests-and-artifacts.txt",
    "text": " step, then\neach parameter's name must explicitly be specified in the step code - i.e.\n`artifacts` for the artifact's path and file name and `fingerprint` to choose\nthis option. If you only need to specify the artifacts' path and file name/s,\nthen you can omit the parameter name `artifacts` - e.g. +\n`+archiveArtifacts 'build/libs/**/*.jar'+`\n\nRecording tests and artifacts in Jenkins is useful for "
  },
  "5016": {
    "source_file": "tests-and-artifacts.txt",
    "text": "u can omit the parameter name `artifacts` - e.g. +\n`+archiveArtifacts 'build/libs/**/*.jar'+`\n\nRecording tests and artifacts in Jenkins is useful for quickly and easily\nsurfacing information to various members of the team. In the next section we'll\ntalk about how to *tell* those members of the team what's been happening in our\nPipeline.\n\n\n\n'''\n+++\n\n+++"
  },
  "5017": {
    "source_file": "tests-and-artifacts.txt",
    "text": "alk about how to *tell* those members of the team what's been happening in our\nPipeline.\n\n\n\n'''\n+++\n\n+++"
  },
  "5018": {
    "source_file": "thank-you-for-your-feedback.txt",
    "text": "layout: documentation\ntitle: Jenkins User Documentation\nsection: doc\n\n\n+++\n<!-- This JavaScript code retrieves the value of the current feedback page's URL\n     (stored in the variable \"feedbackPageUrl\" in the browser's local storage),\n     which is used to return the reader back to the page they provided feedback\n     on. -->\n<script>\n  function origUrl() {\n    location.replace(localStorage.getIt"
  },
  "5019": {
    "source_file": "thank-you-for-your-feedback.txt",
    "text": "used to return the reader back to the page they provided feedback\n     on. -->\n<script>\n  function origUrl() {\n    location.replace(localStorage.getItem(\"feedbackPageUrl\"));\n  }\n</script>\n\n<style>\n  #link {\n    color: #069;\n  }\n  #link:hover {\n    text-decoration: underline;\n    cursor: pointer;\n  }\n</style>\n\n<p/>\n\n<h3>Thank you for your feedback!</h3>\n\n<p/>\n\n<p>Click <span id=\"link\" onclick=\"orig"
  },
  "5020": {
    "source_file": "thank-you-for-your-feedback.txt",
    "text": "xt-decoration: underline;\n    cursor: pointer;\n  }\n</style>\n\n<p/>\n\n<h3>Thank you for your feedback!</h3>\n\n<p/>\n\n<p>Click <span id=\"link\" onclick=\"origUrl()\">here</span> to return to the page\nyou provided feedback on.</p>\n+++"
  },
  "5021": {
    "source_file": "tools.txt",
    "text": "layout: section\nwip: true"
  },
  "5022": {
    "source_file": "translate-a-help-file.txt",
    "text": "title: Translate a help file\nlayout: developer\n\n\nThis guide explains how to generate and translate help files used in Jenkins localization.\n\nStand-alone HTML files are often used in Jenkins for things like inline help messages.\nTo translate these resources, add the locale code between the file name and the extension.\nFor example, the Japanese version of `+abc.html+` would be `+abc_ja.html+`.\nThese"
  },
  "5023": {
    "source_file": "translate-a-help-file.txt",
    "text": "ources, add the locale code between the file name and the extension.\nFor example, the Japanese version of `+abc.html+` would be `+abc_ja.html+`.\nThese files must be encoded in UTF-8.\n\nHelp text is stored in HTML files.\nThe maintainers of the plugin usually provide those files for the default locale.\nTranslators create help files for their specific locale by appending the locale identifier to the f"
  },
  "5024": {
    "source_file": "translate-a-help-file.txt",
    "text": "sually provide those files for the default locale.\nTranslators create help files for their specific locale by appending the locale identifier to the file name.\nFor example, `Messages.properties` for Portuguese as spoken in Brazil is named `Messages_pt_BR.properties`.\n`Messages.properties` for Japanese is named `Messages_ja.properties`.\n\nInsert instructions here\n\nTranslate the HTML help files and s"
  },
  "5025": {
    "source_file": "translate-a-help-file.txt",
    "text": "t_BR.properties`.\n`Messages.properties` for Japanese is named `Messages_ja.properties`.\n\nInsert instructions here\n\nTranslate the HTML help files and save them with the UTF-8 character set.\n\nTest the translation by running Jenkins in the target locale with the plugin enabled.\n\nLANG=pt_BR.utf-8 mvn hpi:run\n\nCommit the changes and submit a pull request with the changes."
  },
  "5026": {
    "source_file": "translate-a-help-file.txt",
    "text": " with the plugin enabled.\n\nLANG=pt_BR.utf-8 mvn hpi:run\n\nCommit the changes and submit a pull request with the changes."
  },
  "5027": {
    "source_file": "translate-a-properties-file.txt",
    "text": "title: Translate a properties file\nlayout: developer\nreferences:\n- url: https://en.wikipedia.org/wiki/.properties\n  title: .properties file format on Wikipedia\n\n\nThis guide explains how to generate and translate property files used in Jenkins localization.\nProperty files provide the strings that are displayed to users.\n\nProperty files can be associated with Java files or with Jelly views.\n\nJava me"
  },
  "5028": {
    "source_file": "translate-a-properties-file.txt",
    "text": "ation.\nProperty files provide the strings that are displayed to users.\n\nProperty files can be associated with Java files or with Jelly views.\n\nJava messages are stored in `Messages.properties` files.\nThe maintainers of the plugin usually provide those files for the default locale.\nTranslators create property files for their specific locale by appending the local to the file name.\nFor example, `Mes"
  },
  "5029": {
    "source_file": "translate-a-properties-file.txt",
    "text": "e files for the default locale.\nTranslators create property files for their specific locale by appending the local to the file name.\nFor example, `Messages.properties` for Portuguese as spoken in Brazil is named `Messages_pt_BR.properties`.\n`Messages.properties` for Japanese is named `Messages_ja.properties`.\n\nThe other messages that need to be translated are in Jelly view files,\nwhich are in `+sr"
  },
  "5030": {
    "source_file": "translate-a-properties-file.txt",
    "text": ".properties` for Japanese is named `Messages_ja.properties`.\n\nThe other messages that need to be translated are in Jelly view files,\nwhich are in `+src/main/resources/**.jelly+`. To localize them, first\ngenerate the skeleton property file for your locale with:\n\nmvn stapler:i18n -Dlocale=fr\n\nThis generates `+*_fr.properties+` throughout `+src/main/resources+` with empty values.\nIf the file already "
  },
  "5031": {
    "source_file": "translate-a-properties-file.txt",
    "text": "cale with:\n\nmvn stapler:i18n -Dlocale=fr\n\nThis generates `+*_fr.properties+` throughout `+src/main/resources+` with empty values.\nIf the file already exists, missing entries are appended.\n\nIt is not necessary to translate the entire file.\nEntries that are empty will use the default locale.\n\nTranslate the property files by assigning values to the properties in the file.\nStrings in the property file"
  },
  "5032": {
    "source_file": "translate-a-properties-file.txt",
    "text": "t are empty will use the default locale.\n\nTranslate the property files by assigning values to the properties in the file.\nStrings in the property file should be encoded in `UTF-8`.\n\nTest the translation by running Jenkins in the target locale with the plugin enabled.\n\nLANG=pt_BR.utf-8 mvn hpi:run\n\nCommit the changes and submit a pull request with the changes."
  },
  "5033": {
    "source_file": "translate-a-properties-file.txt",
    "text": "e plugin enabled.\n\nLANG=pt_BR.utf-8 mvn hpi:run\n\nCommit the changes and submit a pull request with the changes."
  },
  "5034": {
    "source_file": "translating-plugins.txt",
    "text": "title: Translating plugins through Crowdin\nlayout: developersection\n\n\nWatch the recording of the , where we introduced Crowdin, setup projects and showed how to proofread content.\n\nvideo::40H0bqGRiL4[youtube,width=800,height=450]\n\nOn , select the project and language you want to help to translate.\n\nThis is the view that comes up, when you are translating plugins. Let's break down how to use it and"
  },
  "5035": {
    "source_file": "translating-plugins.txt",
    "text": "ject and language you want to help to translate.\n\nThis is the view that comes up, when you are translating plugins. Let's break down how to use it and what the different parts do.\n\nimage::/images/developer/crowdin/source-string-list.png\n\nOn the left side, you can see a list of strings in the file selected. The strings with a red square are still up to translate.\n\nStrings with a green box have alre"
  },
  "5036": {
    "source_file": "translating-plugins.txt",
    "text": "side, you can see a list of strings in the file selected. The strings with a red square are still up to translate.\n\nStrings with a green box have already been translated. You can vote on it, if you agree with the proposal, or comment a different translation.\n\nStrings with a green tick have been translated and gone through the proofreading process and have been accepted by a project maintainer.\n\nTh"
  },
  "5037": {
    "source_file": "translating-plugins.txt",
    "text": "slation.\n\nStrings with a green tick have been translated and gone through the proofreading process and have been accepted by a project maintainer.\n\nThe box right to the string overview is where you can propose translations.\n\nThe \"Source String\" reflects the string you are proposing a translation for.\nRight below, \"Enter translation here\", is where you can suggest a translation for it. Crowdin lear"
  },
  "5038": {
    "source_file": "translating-plugins.txt",
    "text": "cts the string you are proposing a translation for.\nRight below, \"Enter translation here\", is where you can suggest a translation for it. Crowdin learns from the Jenkins terminology, the more projects are using it. If the \"TM and MT Suggestions\" are appropriate, you can click on one you want to choose and modify it, if required, before hitting the \"SAVE\" button.\n\nOnce you saved a suggestion, the r"
  },
  "5039": {
    "source_file": "translating-plugins.txt",
    "text": "appropriate, you can click on one you want to choose and modify it, if required, before hitting the \"SAVE\" button.\n\nOnce you saved a suggestion, the red box turns green and the string is up for proofreading by a project maintainer. Now you can move on to the next string.\n\nOn the right side, translators, proofreaders and project maintainers can leave comments about translation proposals, in case so"
  },
  "5040": {
    "source_file": "translating-plugins.txt",
    "text": "n to the next string.\n\nOn the right side, translators, proofreaders and project maintainers can leave comments about translation proposals, in case something is unclear."
  },
  "5041": {
    "source_file": "troubleshooting.txt",
    "text": "title: Troubleshooting crowdin issues\nlayout: developersection\n\n\nThis guide covers a few troubleshooting questions.\n\nIf you are in the \"Crowdsourcing\" view of the editor, you can select, which strings Crowdin should display. On the left side, in the upper right corner of the source list box, you can select which strings you want to see.\n\nNo, Crowdin takes care of it when proposing a pull request o"
  },
  "5042": {
    "source_file": "troubleshooting.txt",
    "text": "upper right corner of the source list box, you can select which strings you want to see.\n\nNo, Crowdin takes care of it when proposing a pull request on GitHub. You can use the regular letters of your language.\n\nNo, you can always unapprove and reapprove strings, if translators are addressing changes\n\nThe default workflow runs once every 24 hours. To sync your project manually, you can trigger the "
  },
  "5043": {
    "source_file": "troubleshooting.txt",
    "text": "ove strings, if translators are addressing changes\n\nThe default workflow runs once every 24 hours. To sync your project manually, you can trigger the workflow on GitHub by hand.\n\nIf there is a configuration issue, take a look at the workflow log. The crowdin action highlights issues like a wrong PAT, path to the source files, etc.\n\nIf you need additional help to set up your project, you are welcom"
  },
  "5044": {
    "source_file": "troubleshooting.txt",
    "text": " crowdin action highlights issues like a wrong PAT, path to the source files, etc.\n\nIf you need additional help to set up your project, you are welcome to ask on the  or on ."
  },
  "5045": {
    "source_file": "tutorial-for-installing-jenkins-on-AWS.txt",
    "text": "layout: documentation\ntitle: Jenkins on AWS\nsection: doc\n\n\nJenkins is an open-source automation server that integrates with a number of\nAWS Services, including: AWS CodeCommit, AWS CodeDeploy, Amazon EC2 Spot, and Amazon EC2 Fleet.\nYou can use Amazon Elastic Compute Cloud (Amazon EC2) to deploy a Jenkins application on AWS.\n\nThis tutorial walks you through the process of deploying a Jenkins applic"
  },
  "5046": {
    "source_file": "tutorial-for-installing-jenkins-on-AWS.txt",
    "text": " Elastic Compute Cloud (Amazon EC2) to deploy a Jenkins application on AWS.\n\nThis tutorial walks you through the process of deploying a Jenkins application.\nYou will launch an EC2 instance, install Jenkins on that instance, and configure\nJenkins to automatically spin up Jenkins agents if build abilities\nneed to be augmented on the instance.\n\nIn this tutorial, you will perform the following steps:\n"
  },
  "5047": {
    "source_file": "tutorial-for-installing-jenkins-on-AWS.txt",
    "text": "utomatically spin up Jenkins agents if build abilities\nneed to be augmented on the instance.\n\nIn this tutorial, you will perform the following steps:\n\n<<Prerequisites>>.\n<<Creating a key pair,Create a key pair>> using Amazon EC2.\nIf you already have one, you can skip to step 3.\n<<Creating a security group,Create a security group>> for your Amazon EC2 instance. If you already have one, you can skip"
  },
  "5048": {
    "source_file": "tutorial-for-installing-jenkins-on-AWS.txt",
    "text": "one, you can skip to step 3.\n<<Creating a security group,Create a security group>> for your Amazon EC2 instance. If you already have one, you can skip to step 4.\n<<Launching an Amazon EC2 instance,Launch an Amazon EC2 instance>>.\n<<Installing and configuring Jenkins,Install and configure Jenkins>>.\n<<Cleaning up,Clean up tutorial resources>>.\n\nAn *AWS account*. If you don't have one, you can regis"
  },
  "5049": {
    "source_file": "tutorial-for-installing-jenkins-on-AWS.txt",
    "text": "figuring Jenkins,Install and configure Jenkins>>.\n<<Cleaning up,Clean up tutorial resources>>.\n\nAn *AWS account*. If you don't have one, you can register .\nAn Amazon EC2 key pair. If you don't have one, refer to <<Creating a key pair>>.\nAn AWS IAM User with programmatic key access and\n\nCreating a key pair helps ensure that the correct form of authentication is used when you install Jenkins.\n\nTo cr"
  },
  "5050": {
    "source_file": "tutorial-for-installing-jenkins-on-AWS.txt",
    "text": "er with programmatic key access and\n\nCreating a key pair helps ensure that the correct form of authentication is used when you install Jenkins.\n\nTo create your key pair:\n\nOpen the Amazon EC2 console at https://console.aws.amazon.com/ec2/ and sign in.\n\nIn the navigation pane, under *NETWORK & SECURITY*, select *Key Pairs*.\n\nSelect **Create key pair**.\n\nFor *Name*, enter a descriptive name for the k"
  },
  "5051": {
    "source_file": "tutorial-for-installing-jenkins-on-AWS.txt",
    "text": "\n\nIn the navigation pane, under *NETWORK & SECURITY*, select *Key Pairs*.\n\nSelect **Create key pair**.\n\nFor *Name*, enter a descriptive name for the key pair.\nAmazon EC2 associates the public key with the name that you specify as the *key name*.\nA key name can include up to 255 ASCII characters.\nIt cannot include leading or trailing spaces.\n\nFor *File format*, select the format in which to save th"
  },
  "5052": {
    "source_file": "tutorial-for-installing-jenkins-on-AWS.txt",
    "text": "y name can include up to 255 ASCII characters.\nIt cannot include leading or trailing spaces.\n\nFor *File format*, select the format in which to save the private key.\n* For OpenSSH compatibility, select *pem*.\n* For PuTTY compatibility, select *ppk*.\n\nSelect *Create key pair*.\n\nThe private key file downloads automatically.\nThe base file name is the name you specified as the name of your key pair, an"
  },
  "5053": {
    "source_file": "tutorial-for-installing-jenkins-on-AWS.txt",
    "text": "Select *Create key pair*.\n\nThe private key file downloads automatically.\nThe base file name is the name you specified as the name of your key pair, and the file name extension is determined by the file format you chose.\nSave the private key file in a safe place.\nIMPORTANT: This is the only chance for you to save the private key file.\nIf you use an SSH client on a macOS or Linux computer to connect"
  },
  "5054": {
    "source_file": "tutorial-for-installing-jenkins-on-AWS.txt",
    "text": " safe place.\nIMPORTANT: This is the only chance for you to save the private key file.\nIf you use an SSH client on a macOS or Linux computer to connect to your Linux instance, run the following command to set the permissions of your private key file so that only you can read it.\n$ chmod 400 <key_pair_name>.pem\n\nNOTE: If you do not set these permissions, you cannot connect to your instance using thi"
  },
  "5055": {
    "source_file": "tutorial-for-installing-jenkins-on-AWS.txt",
    "text": "o that only you can read it.\n$ chmod 400 <key_pair_name>.pem\n\nNOTE: If you do not set these permissions, you cannot connect to your instance using this key pair. For more information, refer to .\n\nA security group acts as a firewall that controls the traffic allowed to reach one or more EC2 instances.\nWhen you launch an instance, you can assign it one or more security groups.\nYou add rules that con"
  },
  "5056": {
    "source_file": "tutorial-for-installing-jenkins-on-AWS.txt",
    "text": "traffic allowed to reach one or more EC2 instances.\nWhen you launch an instance, you can assign it one or more security groups.\nYou add rules that control the traffic allowed to reach the instances in each security group.\nYou can modify a security group's rules any time, and the new rules take effect immediately.\n\nFor this tutorial, you will create a security group and add the following rules:\n\n* "
  },
  "5057": {
    "source_file": "tutorial-for-installing-jenkins-on-AWS.txt",
    "text": "oup's rules any time, and the new rules take effect immediately.\n\nFor this tutorial, you will create a security group and add the following rules:\n\n* Allow inbound HTTP access from anywhere.\n* Allow inbound SSH traffic from your computer's public IP address so you can connect to your instance.\n\nTo create and configure your security group:\n\n[[step1-security-group]]Decide who may access your instanc"
  },
  "5058": {
    "source_file": "tutorial-for-installing-jenkins-on-AWS.txt",
    "text": "address so you can connect to your instance.\n\nTo create and configure your security group:\n\n[[step1-security-group]]Decide who may access your instance.\nFor example, a single computer or all trusted computers on a network.\nFor this tutorial, you can use the public IP address of your computer.\n* To find your IP address, use the\n from AWS3 or search for the phrase \"what is my IP address\" in any sear"
  },
  "5059": {
    "source_file": "tutorial-for-installing-jenkins-on-AWS.txt",
    "text": "use the public IP address of your computer.\n* To find your IP address, use the\n from AWS3 or search for the phrase \"what is my IP address\" in any search engine.\n* If you connect through an ISP or from behind your firewall without a static IP address, you will need the range of IP addresses used by client computers.\nIf you don't know this address range, you can use 0.0.0.0/0 for this tutorial.\nIMPO"
  },
  "5060": {
    "source_file": "tutorial-for-installing-jenkins-on-AWS.txt",
    "text": " you will need the range of IP addresses used by client computers.\nIf you don't know this address range, you can use 0.0.0.0/0 for this tutorial.\nIMPORTANT: This is unsafe for production environments because it allows everyone to\naccess your instance using SSH.\n\nSign in to the .\nOpen the Amazon EC2 console by selecting *EC2* under *Compute*.\nIn the left-hand navigation bar, select **Security Group"
  },
  "5061": {
    "source_file": "tutorial-for-installing-jenkins-on-AWS.txt",
    "text": " using SSH.\n\nSign in to the .\nOpen the Amazon EC2 console by selecting *EC2* under *Compute*.\nIn the left-hand navigation bar, select **Security Groups**, and then select *Create Security Group*.\nIn **Security group name**, enter *WebServerSG* or any preferred name of your choice, and provide a description.\nSelect your VPC from the list. You can use the default VPC.\nOn the **Inbound tab**, add the"
  },
  "5062": {
    "source_file": "tutorial-for-installing-jenkins-on-AWS.txt",
    "text": " preferred name of your choice, and provide a description.\nSelect your VPC from the list. You can use the default VPC.\nOn the **Inbound tab**, add the rules as follows:\n.. Select *Add Rule*, and then select *SSH* from the Type list.\n.. Under *Source*, select *Custom*, and in the text box, enter <<step1-security-group,the IP address from step 1>>, followed by /32 indicating a single IP Address.\nFor"
  },
  "5063": {
    "source_file": "tutorial-for-installing-jenkins-on-AWS.txt",
    "text": ", select *Custom*, and in the text box, enter <<step1-security-group,the IP address from step 1>>, followed by /32 indicating a single IP Address.\nFor example, 104.34.241.123/32 is a single IP address, while 198.51.100.2/24 results in a range of 256 IP addresses.\n.. Select *Add Rule*, and then select *HTTP* from the Type list.\n.. Select *Add Rule*, and then select *Custom TCP Rule* from the\nType l"
  },
  "5064": {
    "source_file": "tutorial-for-installing-jenkins-on-AWS.txt",
    "text": "IP addresses.\n.. Select *Add Rule*, and then select *HTTP* from the Type list.\n.. Select *Add Rule*, and then select *Custom TCP Rule* from the\nType list.\n.. Under *Port Range*, enter *8080*.\nSelect Create.\n\nFor more information, refer to  in the Amazon EC2 User Guide for\nLinux Instances.\n\nNow that you have configured a key pair and security group, you can launch an EC2 instance.\n\nTo launch an EC2"
  },
  "5065": {
    "source_file": "tutorial-for-installing-jenkins-on-AWS.txt",
    "text": "zon EC2 User Guide for\nLinux Instances.\n\nNow that you have configured a key pair and security group, you can launch an EC2 instance.\n\nTo launch an EC2 instance:\n\nSign in to the .\nOpen the Amazon EC2 console by selecting EC2 under *Compute*.\nFrom the Amazon EC2 dashboard, select *Launch Instance*.\nThe *Choose an Amazon Machine Image (AMI)* page displays a list of basic configurations called Amazon "
  },
  "5066": {
    "source_file": "tutorial-for-installing-jenkins-on-AWS.txt",
    "text": "Amazon EC2 dashboard, select *Launch Instance*.\nThe *Choose an Amazon Machine Image (AMI)* page displays a list of basic configurations called Amazon Machine Images (AMIs) that serve as templates for your instance.\nSelect the HVM edition of the *Amazon Linux AMI*.\nNOTE: This configuration is marked *Free tier eligible*.\nScroll down and select the key pair you created in the <<Creating a key pair, "
  },
  "5067": {
    "source_file": "tutorial-for-installing-jenkins-on-AWS.txt",
    "text": "on Linux AMI*.\nNOTE: This configuration is marked *Free tier eligible*.\nScroll down and select the key pair you created in the <<Creating a key pair, creating a key pair>> section above or any existing key pair you intend to use.\n.. Select *Select an existing security group*.\n.. Select the *WebServerSG* security group that you created.\n.. Select *Launch Instance*.\nIn the left-hand navigation bar, "
  },
  "5068": {
    "source_file": "tutorial-for-installing-jenkins-on-AWS.txt",
    "text": " existing security group*.\n.. Select the *WebServerSG* security group that you created.\n.. Select *Launch Instance*.\nIn the left-hand navigation bar, choose **Instances** to view the status of your instance.\nInitially, the status of your instance is pending.\nAfter the status changes to running, your instance is ready for use.\nNow that the Amazon EC2 instance has been launched, Jenkins can be insta"
  },
  "5069": {
    "source_file": "tutorial-for-installing-jenkins-on-AWS.txt",
    "text": "pending.\nAfter the status changes to running, your instance is ready for use.\nNow that the Amazon EC2 instance has been launched, Jenkins can be installed properly.\n\nIn this step you will deploy Jenkins on your EC2 instance by completing the following tasks:\n\n<<Connecting to your Linux instance>>\n<<Downloading and installing Jenkins>>\n<<Configuring Jenkins>>\n\nAfter you launch your instance, you ca"
  },
  "5070": {
    "source_file": "tutorial-for-installing-jenkins-on-AWS.txt",
    "text": "g tasks:\n\n<<Connecting to your Linux instance>>\n<<Downloading and installing Jenkins>>\n<<Configuring Jenkins>>\n\nAfter you launch your instance, you can connect to it and use it the same way as your local machine.\n\nBefore you connect to your instance, get the *public DNS* name of the instance using the Amazon EC2 console.\n\nSelect the instance and locate Public DNS.\nNOTE: If your instance doesn't ha"
  },
  "5071": {
    "source_file": "tutorial-for-installing-jenkins-on-AWS.txt",
    "text": " get the *public DNS* name of the instance using the Amazon EC2 console.\n\nSelect the instance and locate Public DNS.\nNOTE: If your instance doesn't have a public DNS name, open the VPC console, select the VPC, and check the *Summary* tab.\nIf either DNS resolution or DNS hostnames is *no*, select *Edit* and change the value to *yes*.\n\nThe tool that you use to connect to your Linux instance depends "
  },
  "5072": {
    "source_file": "tutorial-for-installing-jenkins-on-AWS.txt",
    "text": "NS resolution or DNS hostnames is *no*, select *Edit* and change the value to *yes*.\n\nThe tool that you use to connect to your Linux instance depends on your operating system.\n\n* If your computer runs Windows, you will connect using OpenSSH (built into Windows 10 version 1809 and later).\n* If your computer runs Linux or Mac OS X, you will connect using the SSH client.\n\nThese tools require the use "
  },
  "5073": {
    "source_file": "tutorial-for-installing-jenkins-on-AWS.txt",
    "text": "to Windows 10 version 1809 and later).\n* If your computer runs Linux or Mac OS X, you will connect using the SSH client.\n\nThese tools require the use of your key pair.\nBe sure that you have created your key pair as described in <<Creating a key pair>>.\n\nOpen a terminal or PowerShell window.\nUse the `ssh` command to connect to the instance.\nYou will specify the private key (.pem) file and ec2-user@"
  },
  "5074": {
    "source_file": "tutorial-for-installing-jenkins-on-AWS.txt",
    "text": ">.\n\nOpen a terminal or PowerShell window.\nUse the `ssh` command to connect to the instance.\nYou will specify the private key (.pem) file and ec2-user@public_dns_name.\n$ ssh -i /path/my-key-pair.pem ec2-user@ec2-198-51-100-1.compute-1.amazonaws.com\n\nYou will receive a response like the following:\nThe authenticity of host 'ec2-198-51-100-1.compute1.amazonaws.com (10.254.142.33)' can't be\nestablished"
  },
  "5075": {
    "source_file": "tutorial-for-installing-jenkins-on-AWS.txt",
    "text": "ou will receive a response like the following:\nThe authenticity of host 'ec2-198-51-100-1.compute1.amazonaws.com (10.254.142.33)' can't be\nestablished.\n\nRSA key fingerprint is 1f:51:ae:28:bf:89:e9:d8:1f:25:5d:37:2d:7d:b8:ca:9f:f5:f1:6f.\n\nAre you sure you want to continue connecting\n(yes/no)?\n\nEnter yes.\nYou will receive a response like the following:\nWarning: Permanently added 'ec2-198-51-100-1.co"
  },
  "5076": {
    "source_file": "tutorial-for-installing-jenkins-on-AWS.txt",
    "text": " you want to continue connecting\n(yes/no)?\n\nEnter yes.\nYou will receive a response like the following:\nWarning: Permanently added 'ec2-198-51-100-1.compute1.amazonaws.com' (RSA) to the list of known hosts.\n\nUse the ssh command to connect to the instance.\nYou will specify the private key (.pem) file and ec2-user@public_dns_name.\n$ ssh -i /path/my-key-pair.pem ec2-user@ec2-198-51-100-1.compute-1.ama"
  },
  "5077": {
    "source_file": "tutorial-for-installing-jenkins-on-AWS.txt",
    "text": "nce.\nYou will specify the private key (.pem) file and ec2-user@public_dns_name.\n$ ssh -i /path/my-key-pair.pem ec2-user@ec2-198-51-100-1.compute-1.amazonaws.com\n\nYou will receive a response like the following:\nThe authenticity of host 'ec2-198-51-100-1.compute1.amazonaws.com (10.254.142.33)' cant be\nestablished.\n\nRSA key fingerprint is 1f:51:ae:28:bf:89:e9:d8:1f:25:5d:37:2d:7d:b8:ca:9f:f5:f1:6f.\n\n"
  },
  "5078": {
    "source_file": "tutorial-for-installing-jenkins-on-AWS.txt",
    "text": "-1.compute1.amazonaws.com (10.254.142.33)' cant be\nestablished.\n\nRSA key fingerprint is 1f:51:ae:28:bf:89:e9:d8:1f:25:5d:37:2d:7d:b8:ca:9f:f5:f1:6f.\n\nAre you sure you want to continue connecting\n(yes/no)?\n\nEnter yes.\nYou will receive a response like the following:\nWarning: Permanently added 'ec2-198-51-100-1.compute1.amazonaws.com' (RSA) to the list of known hosts.\n\nCompleting the previous steps e"
  },
  "5079": {
    "source_file": "tutorial-for-installing-jenkins-on-AWS.txt",
    "text": "the following:\nWarning: Permanently added 'ec2-198-51-100-1.compute1.amazonaws.com' (RSA) to the list of known hosts.\n\nCompleting the previous steps enables you to download and install Jenkins on AWS.\nTo download and install Jenkins:\n\nNOTE: The following steps are written for *Amazon Linux 2*. If you're using *Amazon Linux 2023*, it's recommended to use `dnf` instead of `yum`. While the `yum` comm"
  },
  "5080": {
    "source_file": "tutorial-for-installing-jenkins-on-AWS.txt",
    "text": "wing steps are written for *Amazon Linux 2*. If you're using *Amazon Linux 2023*, it's recommended to use `dnf` instead of `yum`. While the `yum` command is still available for compatibility in this context, it is actually a symbolic link to `dnf` and may not support all of its features. For more details, please refer to the https://docs.aws.amazon.com/linux/al2023/ug/package-management.html[offic"
  },
  "5081": {
    "source_file": "tutorial-for-installing-jenkins-on-AWS.txt",
    "text": "d may not support all of its features. For more details, please refer to the https://docs.aws.amazon.com/linux/al2023/ug/package-management.html[official AWS documentation].\n\nEnsure that your software packages are up to date on your instance by using the following command to perform a quick software update:\n[ec2-user ~]$ sudo yum update \u2013y\n\nAdd the Jenkins repo using the following command:\n[ec2-us"
  },
  "5082": {
    "source_file": "tutorial-for-installing-jenkins-on-AWS.txt",
    "text": " the following command to perform a quick software update:\n[ec2-user ~]$ sudo yum update \u2013y\n\nAdd the Jenkins repo using the following command:\n[ec2-user ~]$ sudo wget -O /etc/yum.repos.d/jenkins.repo \\\n    https://pkg.jenkins.io/redhat-stable/jenkins.repo\n\nImport a key file from Jenkins-CI to enable installation from the package:\n[ec2-user ~]$ sudo rpm --import https://pkg.jenkins.io/redhat-stable"
  },
  "5083": {
    "source_file": "tutorial-for-installing-jenkins-on-AWS.txt",
    "text": ".repo\n\nImport a key file from Jenkins-CI to enable installation from the package:\n[ec2-user ~]$ sudo rpm --import https://pkg.jenkins.io/redhat-stable/jenkins.io-2023.key\n\n[ec2-user ~]$ sudo yum upgrade\n\nInstall Java:\n[ec2-user ~]$ sudo yum install java-21-amazon-corretto -y\n\nInstall Jenkins:\n[ec2-user ~]$ sudo yum install jenkins -y\n\nEnable the Jenkins service to start at boot:\n[ec2-user ~]$ sudo"
  },
  "5084": {
    "source_file": "tutorial-for-installing-jenkins-on-AWS.txt",
    "text": "ava-21-amazon-corretto -y\n\nInstall Jenkins:\n[ec2-user ~]$ sudo yum install jenkins -y\n\nEnable the Jenkins service to start at boot:\n[ec2-user ~]$ sudo systemctl enable jenkins\n\nStart Jenkins as a service:\n[ec2-user ~]$ sudo systemctl start jenkins\n\nYou can check the status of the Jenkins service using the command:\n\n[ec2-user ~]$ sudo systemctl status jenkins\n\nJenkins is now installed and running o"
  },
  "5085": {
    "source_file": "tutorial-for-installing-jenkins-on-AWS.txt",
    "text": "ou can check the status of the Jenkins service using the command:\n\n[ec2-user ~]$ sudo systemctl status jenkins\n\nJenkins is now installed and running on your EC2 instance.\nTo configure Jenkins:\n\nConnect to http://<your_server_public_DNS>:8080 from your browser.\nYou will be able to access Jenkins through its management interface:\nAs prompted, enter the password found in */var/lib/jenkins/secrets/ini"
  },
  "5086": {
    "source_file": "tutorial-for-installing-jenkins-on-AWS.txt",
    "text": "r browser.\nYou will be able to access Jenkins through its management interface:\nAs prompted, enter the password found in */var/lib/jenkins/secrets/initialAdminPassword*.\n\n.. Use the following command to display this password:\n[ec2-user ~]$ sudo cat /var/lib/jenkins/secrets/initialAdminPassword\n\nThe Jenkins installation script directs you to the *Customize Jenkins page*.\nClick *Install suggested pl"
  },
  "5087": {
    "source_file": "tutorial-for-installing-jenkins-on-AWS.txt",
    "text": "var/lib/jenkins/secrets/initialAdminPassword\n\nThe Jenkins installation script directs you to the *Customize Jenkins page*.\nClick *Install suggested plugins*.\n\nOnce the installation is complete, the *Create First Admin User* will open.\nEnter your information, and then select *Save and Continue*.\nOn the left-hand side, select *Manage Jenkins*, and then select *Manage\nPlugins*.\nSelect the *Available*"
  },
  "5088": {
    "source_file": "tutorial-for-installing-jenkins-on-AWS.txt",
    "text": "rmation, and then select *Save and Continue*.\nOn the left-hand side, select *Manage Jenkins*, and then select *Manage\nPlugins*.\nSelect the *Available* tab, and then enter *Amazon EC2 plugin* at the top\nright.\nSelect the checkbox next to *Amazon EC2 plugin*, and then select *Install\nwithout restart*.\nOnce the installation is done, select *Back to Dashboard*.\nSelect *Configure a cloud* if there are "
  },
  "5089": {
    "source_file": "tutorial-for-installing-jenkins-on-AWS.txt",
    "text": "lugin*, and then select *Install\nwithout restart*.\nOnce the installation is done, select *Back to Dashboard*.\nSelect *Configure a cloud* if there are no existing nodes or clouds.\nIf you already have other nodes or clouds set up, select *Manage Jenkins*.\n.. After navigating to *Manage Jenkins*, select *Configure Nodes and Clouds* from the left hand side of the page.\n.. From here, select *Clouds*.\nS"
  },
  "5090": {
    "source_file": "tutorial-for-installing-jenkins-on-AWS.txt",
    "text": "s*.\n.. After navigating to *Manage Jenkins*, select *Configure Nodes and Clouds* from the left hand side of the page.\n.. From here, select *Clouds*.\nSelect *Add a new cloud*, and select *Amazon EC2*.\nA collection of new fields appears.\nClick *Add* under Amazon EC2 Credentials\n.. From the Jenkins Credentials Provider, select AWS Credentials as the *Kind*.\n.. Scroll down and enter in the IAM User pr"
  },
  "5091": {
    "source_file": "tutorial-for-installing-jenkins-on-AWS.txt",
    "text": "der Amazon EC2 Credentials\n.. From the Jenkins Credentials Provider, select AWS Credentials as the *Kind*.\n.. Scroll down and enter in the IAM User programmatic access keys with permissions to launch EC2 instances and select *Add*.\n.. Scroll down to select your region using the drop-down, and select *Add* for the EC2 Key Pair's Private Key.\n.. From the Jenkins Credentials Provider, select SSH User"
  },
  "5092": {
    "source_file": "tutorial-for-installing-jenkins-on-AWS.txt",
    "text": "select your region using the drop-down, and select *Add* for the EC2 Key Pair's Private Key.\n.. From the Jenkins Credentials Provider, select SSH Username with private key as the Kind and set the Username to `ec2-user`.\n.. Scroll down and select *Enter Directly* under Private Key, then select *Add*.\n.. Open the private key pair you created in the <<Creating a key pair, creating a key pair>> step a"
  },
  "5093": {
    "source_file": "tutorial-for-installing-jenkins-on-AWS.txt",
    "text": "er Directly* under Private Key, then select *Add*.\n.. Open the private key pair you created in the <<Creating a key pair, creating a key pair>> step and paste in the contents from \"-BEGIN RSA PRIVATE KEY-\" to \"-END RSA PRIVATE KEY-\".\nSelect *Add* when completed.\n.. Scroll down to \"Test Connection\" and ensure it states \"Success\".\nSelect *Save* when done\nYou are now ready to use EC2 instances as Jen"
  },
  "5094": {
    "source_file": "tutorial-for-installing-jenkins-on-AWS.txt",
    "text": "n completed.\n.. Scroll down to \"Test Connection\" and ensure it states \"Success\".\nSelect *Save* when done\nYou are now ready to use EC2 instances as Jenkins agents.\n\nAfter completing this tutorial, be sure to delete the AWS resources that you\ncreated so you do not continue to accrue charges.\n\nIn the left-hand navigation bar of the Amazon EC2 console, select\n*Instances*.\nRight-click on the instance y"
  },
  "5095": {
    "source_file": "tutorial-for-installing-jenkins-on-AWS.txt",
    "text": "o you do not continue to accrue charges.\n\nIn the left-hand navigation bar of the Amazon EC2 console, select\n*Instances*.\nRight-click on the instance you created earlier, and select *Terminate instance*.\nIf you are using an older version of Windows or prefer to use PuTTY, follow these steps:\n\nEnsure you have PuTTY installed on your system.\nYou can download it from the .\nIf you generated a `.pem` ke"
  },
  "5096": {
    "source_file": "tutorial-for-installing-jenkins-on-AWS.txt",
    "text": " prefer to use PuTTY, follow these steps:\n\nEnsure you have PuTTY installed on your system.\nYou can download it from the .\nIf you generated a `.pem` key file in AWS, you will need to convert it to a `.ppk` file for use with PuTTY. To do this:\n   .. Download and install PuTTYgen (included with PuTTY).\n   .. Open PuTTYgen and select *Load*.\n   .. Load your `.pem` file (you may need to select \"All Fil"
  },
  "5097": {
    "source_file": "tutorial-for-installing-jenkins-on-AWS.txt",
    "text": "wnload and install PuTTYgen (included with PuTTY).\n   .. Open PuTTYgen and select *Load*.\n   .. Load your `.pem` file (you may need to select \"All Files\" in the file dialog to see it).\n   .. Once loaded, select *Save private key* and save the file as a `.ppk` file.\nNOTE: If you already generated a `.ppk` file in AWS (by selecting the PuTTY-compatible format during key pair creation), you can skip "
  },
  "5098": {
    "source_file": "tutorial-for-installing-jenkins-on-AWS.txt",
    "text": " a `.ppk` file.\nNOTE: If you already generated a `.ppk` file in AWS (by selecting the PuTTY-compatible format during key pair creation), you can skip this step.\n\nFrom the *Start* menu, select *All Programs* > *PuTTY* > *PuTTY*.\nIn the *Category* pane, select *Session*, and complete the following fields:\n.. In *Host Name*, enter **`ec2-user@public_dns_name`**.\n   Make sure to replace `public_dns_na"
  },
  "5099": {
    "source_file": "tutorial-for-installing-jenkins-on-AWS.txt",
    "text": ", select *Session*, and complete the following fields:\n.. In *Host Name*, enter **`ec2-user@public_dns_name`**.\n   Make sure to replace `public_dns_name` with the actual public DNS of your instance.\nIMPORTANT: You must prefix the public DNS name with `ec2-user@` to successfully connect to the instance.\nFor example, if your public DNS is `ec2-198-51-100-1.compute-1.amazonaws.com`, enter `ec2-user@e"
  },
  "5100": {
    "source_file": "tutorial-for-installing-jenkins-on-AWS.txt",
    "text": " `ec2-user@` to successfully connect to the instance.\nFor example, if your public DNS is `ec2-198-51-100-1.compute-1.amazonaws.com`, enter `ec2-user@ec2-198-51-100-1.compute-1.amazonaws.com`.\n.. Ensure that *Port* is 22.\nIn the *Category* pane, expand *Connection*, expand *SSH*, and then select *Auth*. Complete the following:\n.. Select *Browse*.\n.. Select the `.ppk` file that you generated for you"
  },
  "5101": {
    "source_file": "tutorial-for-installing-jenkins-on-AWS.txt",
    "text": "d *Connection*, expand *SSH*, and then select *Auth*. Complete the following:\n.. Select *Browse*.\n.. Select the `.ppk` file that you generated for your key pair (either directly from AWS or converted using PuTTYgen).\n.. Select *Open* to load the key.\nSelect *Open* to start the PuTTY session.\n* **PEM Keys**: Used by OpenSSH and other SSH clients. These are text-based files that start with `-BEGIN R"
  },
  "5102": {
    "source_file": "tutorial-for-installing-jenkins-on-AWS.txt",
    "text": "\nSelect *Open* to start the PuTTY session.\n* **PEM Keys**: Used by OpenSSH and other SSH clients. These are text-based files that start with `-BEGIN RSA PRIVATE KEY-`.\n* **PPK Keys**: Used by PuTTY. These are binary files and are not compatible with OpenSSH without conversion.\n\nFor more detailed instructions, refer to the official AWS documentation:"
  },
  "5103": {
    "source_file": "tutorial-for-installing-jenkins-on-AWS.txt",
    "text": "OpenSSH without conversion.\n\nFor more detailed instructions, refer to the official AWS documentation:"
  },
  "5104": {
    "source_file": "tutorial-for-installing-jenkins-on-IBM-Cloud.txt",
    "text": "layout: redirect\nredirect_url: \"/doc/book/installing/kubernetes/\""
  },
  "5105": {
    "source_file": "tutorials-for-installing-jenkins-on-Google-Cloud.txt",
    "text": "layout: documentation\ntitle: Jenkins on Google Cloud\nsection: doc\n\n\nYou should have a Google Cloud account, otherwise you can https://cloud.google.com/gcp/getting-started[start here].\n\nA  provides detailed steps to configure Google Cloud and Google Kubernetes Engine with Jenkins.\n\nAdditional guidance is available from https://cloud.google.com/blog/products/gcp/using-jenkins-on-google-compute-engin"
  },
  "5106": {
    "source_file": "tutorials-for-installing-jenkins-on-Google-Cloud.txt",
    "text": "ubernetes Engine with Jenkins.\n\nAdditional guidance is available from https://cloud.google.com/blog/products/gcp/using-jenkins-on-google-compute-engine-for-distributed-builds[Vic Iglesias' blog post].\n\nDarin Pope has created several video tutorials of various aspects of Google Cloud Platform.\n\n## Using the gcloud command line interface\n\nGoogle Cloud operations are often performed with the .\nThis t"
  },
  "5107": {
    "source_file": "tutorials-for-installing-jenkins-on-Google-Cloud.txt",
    "text": "f various aspects of Google Cloud Platform.\n\n## Using the gcloud command line interface\n\nGoogle Cloud operations are often performed with the .\nThis tutorial illustrates the steps to configure and use the `gcloud` command line interface from a Jenkins Pipeline.\n\nvideo::Zy_FQEYkaRw[youtube, width=640, height=360,  align=\"center\"]\n\n## Using Google Cloud Run\n\n is a managed compute platform that enabl"
  },
  "5108": {
    "source_file": "tutorials-for-installing-jenkins-on-Google-Cloud.txt",
    "text": "s Pipeline.\n\nvideo::Zy_FQEYkaRw[youtube, width=640, height=360,  align=\"center\"]\n\n## Using Google Cloud Run\n\n is a managed compute platform that enables you to run containers that are invocable via requests or events.\nCloud Run is serverless: it abstracts away all infrastructure management, so you can focus on what matters most - building great applications.\nThis tutorial illustrates the steps to "
  },
  "5109": {
    "source_file": "tutorials-for-installing-jenkins-on-Google-Cloud.txt",
    "text": "racts away all infrastructure management, so you can focus on what matters most - building great applications.\nThis tutorial illustrates the steps to deploy a container image to Google Cloud Run.\n\nvideo::71Nd_6OqdQk[youtube, width=640, height=360,  align=\"center\"]\n\n## Using Google Secret Manager\n\n as a centralized credential manager available with Google Cloud.\nThis tutorial illustrates the steps "
  },
  "5110": {
    "source_file": "tutorials-for-installing-jenkins-on-Google-Cloud.txt",
    "text": "lign=\"center\"]\n\n## Using Google Secret Manager\n\n as a centralized credential manager available with Google Cloud.\nThis tutorial illustrates the steps to use Google Secret Manager for Jenkins credentials.\n\nvideo::eHtRGc6EMY4[youtube, width=640, height=360,  align=\"center\"]"
  },
  "5111": {
    "source_file": "tutorials-for-installing-jenkins-on-Google-Cloud.txt",
    "text": "=360,  align=\"center\"]"
  },
  "5112": {
    "source_file": "ui-themes.txt",
    "text": "layout: section\ntitle: Themes for user interface\n\n\nifdef::env-github[:imagesdir: ../resources]\nifndef::env-github[:imagesdir: ../../resources]\n\nIt is possible to customize Jenkins' appearance with custom themes.\nThis feature is not a part of the Jenkins core, but it is supported through plugins.\n\nThere are several plugins that provide built-in themes, the most popular are\n\n* plugin:dark-theme[Dark"
  },
  "5113": {
    "source_file": "ui-themes.txt",
    "text": "ins core, but it is supported through plugins.\n\nThere are several plugins that provide built-in themes, the most popular are\n\n* plugin:dark-theme[Dark Theme Plugin] -\n  provides a dark theme for Jenkins.\n  Supports configuration as code to select the theme configuration.\n* plugin:material-theme[Material Theme Plugin] -\n  port of Afonso F's  to use Theme Manager.\n* plugin:solarized-theme[Solarized "
  },
  "5114": {
    "source_file": "ui-themes.txt",
    "text": " theme configuration.\n* plugin:material-theme[Material Theme Plugin] -\n  port of Afonso F's  to use Theme Manager.\n* plugin:solarized-theme[Solarized Theme Plugin] -\n  provides Solarized (light and dark) themes.\n\nInstalling any of these will also install their common dependency: the plugin:theme-manager[Theme Manager Plugin].\nThis plugin allows administrators to set the default theme for a Jenkins"
  },
  "5115": {
    "source_file": "ui-themes.txt",
    "text": "tall their common dependency: the plugin:theme-manager[Theme Manager Plugin].\nThis plugin allows administrators to set the default theme for a Jenkins installation via _Manage Jenkins > System > Built-in Themes_\nand users can set their preferred theme in their personal settings.\nYou can also configure this plugin using plugin:configuration-as-code[Configuration-as-Code Plugin].\nSee the plugin docu"
  },
  "5116": {
    "source_file": "ui-themes.txt",
    "text": "e in their personal settings.\nYou can also configure this plugin using plugin:configuration-as-code[Configuration-as-Code Plugin].\nSee the plugin documentation for more details.\n\nTo be able to fully customize Jenkins appearance you can install the plugin:simple-theme-plugin[Simple Theme Plugin].\nIt allows customizing the Jenkins UI by providing custom CSS and Javascript files.\nIt also supports rep"
  },
  "5117": {
    "source_file": "ui-themes.txt",
    "text": "ugin:simple-theme-plugin[Simple Theme Plugin].\nIt allows customizing the Jenkins UI by providing custom CSS and Javascript files.\nIt also supports replacing the Favicon.\n\nTo configure a theme, you can go to _Manage Jenkins > System > Theme_ and enter the URL of your stylesheet and/or Javascript file.\nYou can also configure this plugin using plugin:configuration-as-code[Configuration-as-Code Plugin"
  },
  "5118": {
    "source_file": "ui-themes.txt",
    "text": " the URL of your stylesheet and/or Javascript file.\nYou can also configure this plugin using plugin:configuration-as-code[Configuration-as-Code Plugin].\nSee the plugin documentation for the detailed usage guidelines and links to sample themes.\n\nSince Jenkins 2.128 themes configured using Simple Theme Plugin do not allow you to customize the login screen\n().\nTo customize the login screen you can in"
  },
  "5119": {
    "source_file": "ui-themes.txt",
    "text": " Jenkins 2.128 themes configured using Simple Theme Plugin do not allow you to customize the login screen\n().\nTo customize the login screen you can install the plugin:login-theme[Login Theme Plugin].\n\nWARNING: Jenkins themes are provided \u201cas is\u201d, without warranty of any kind, implicit or explicit.\nThe Jenkins core, plugins and other component updates may break theme compatibility without notice.\n\n"
  },
  "5120": {
    "source_file": "ui-themes.txt",
    "text": "hout warranty of any kind, implicit or explicit.\nThe Jenkins core, plugins and other component updates may break theme compatibility without notice.\n\nAt the moment, the Jenkins project does not provide specification for layouts/CSS,\nand we cannot guarantee backward or forward compatibility.\nWe try to reflect major changes in changelogs\n(e.g. see the \u2018developer\u2019 changes in the ),\nbut minor changes "
  },
  "5121": {
    "source_file": "ui-themes.txt",
    "text": "rantee backward or forward compatibility.\nWe try to reflect major changes in changelogs\n(e.g. see the \u2018developer\u2019 changes in the ),\nbut minor changes may not be included there.\n\nThere is an ongoing effort focused on improving Jenkins look-and-feel, accessibility, and user experience.\nThis area is mission-critical to the project.\nThere are multiple initiatives in the  being coordinated by the .\n\nMa"
  },
  "5122": {
    "source_file": "ui-themes.txt",
    "text": "ccessibility, and user experience.\nThis area is mission-critical to the project.\nThere are multiple initiatives in the  being coordinated by the .\n\nMajor UI changes imply incompatible changes in layouts and the CSS structure which is critical for theme plugins.\nHistorically Jenkins had no explicit support policy for themes,\nand we do not want to provide compatibility requirements which would creat"
  },
  "5123": {
    "source_file": "ui-themes.txt",
    "text": "me plugins.\nHistorically Jenkins had no explicit support policy for themes,\nand we do not want to provide compatibility requirements which would create obstacles for reworking the main Jenkins interface.\nLater, once the Jenkins UI rework reaches its destination and the UI becomes more stable, we could consider creating specifications for theme extensibility so that we could make themes more stable"
  },
  "5124": {
    "source_file": "ui-themes.txt",
    "text": "destination and the UI becomes more stable, we could consider creating specifications for theme extensibility so that we could make themes more stable and maintain compatibility.\n\nFor built-in themes, users are welcome to report discovered compatibility issues to theme maintainers,\nand to submit patches there.\n\nWe will generally reject bug reports to the Jenkins core/plugins involving broken UI el"
  },
  "5125": {
    "source_file": "ui-themes.txt",
    "text": "ity issues to theme maintainers,\nand to submit patches there.\n\nWe will generally reject bug reports to the Jenkins core/plugins involving broken UI elements with a custom theme.\nWe will consider pull requests which restore compatibility and do not block further Web UI evolvement.\n\nNOTE: If a theme outside the  GitHub organization is no longer maintained,\nit is fine to fork it and to create a new v"
  },
  "5126": {
    "source_file": "ui-themes.txt",
    "text": "ock further Web UI evolvement.\n\nNOTE: If a theme outside the  GitHub organization is no longer maintained,\nit is fine to fork it and to create a new version.\nFor themes hosted within the `jenkinsci` organization,\nwe have an  which also applies to themes.\n\nWe encourage Jenkins users to create themes and to share them.\nSuch themes could be a great way to experiment with UI enhancements,\nand we would"
  },
  "5127": {
    "source_file": "ui-themes.txt",
    "text": "mes.\n\nWe encourage Jenkins users to create themes and to share them.\nSuch themes could be a great way to experiment with UI enhancements,\nand we would be happy to consider enhancements from them for a default Jenkins theme.\n\nTo improve the user experience,\nplease consider the following recommendations:\n\n* Version themes with tags on Git and to maintain changelogs with explicit references to change"
  },
  "5128": {
    "source_file": "ui-themes.txt",
    "text": "ience,\nplease consider the following recommendations:\n\n* Version themes with tags on Git and to maintain changelogs with explicit references to changes in the supported versions (e.g. see our release drafter documentation as one of the ways to automate changelogs).\n* Explicitly define an  so that users can freely modify and redistribute them.\n** This is also a prerequisite for hosting themes in Je"
  },
  "5129": {
    "source_file": "ui-themes.txt",
    "text": "te changelogs).\n* Explicitly define an  so that users can freely modify and redistribute them.\n** This is also a prerequisite for hosting themes in Jenkins GitHub organizations and, in the future, theme marketplaces or other similar promotion engines.\n\nIf you would like to share a story about Jenkins themes,\nplease let the  know!"
  },
  "5130": {
    "source_file": "ui-themes.txt",
    "text": ".\n\nIf you would like to share a story about Jenkins themes,\nplease let the  know!"
  },
  "5131": {
    "source_file": "update-base-jenkins-version.txt",
    "text": "layout: developersection\ntitle: Update Jenkins version\n\n\n.Require a newer minimum Jenkins version\nvideo::Fev8KfFsPZE[youtube,width=800,height=420,start=2430]\n\nJenkins plugins declare a minimum supported Jenkins version.\nThe minimum Jenkins version is a good way for plugin developers to indicate the range of Jenkins versions they are willing to support and test.\nSee the  for the recommended minimum"
  },
  "5132": {
    "source_file": "update-base-jenkins-version.txt",
    "text": " a good way for plugin developers to indicate the range of Jenkins versions they are willing to support and test.\nSee the  for the recommended minimum Jenkins version.\n\n// Create the branch\n\nUpdate the minimum required Jenkins version by setting a `jenkins.version` value in the properties section of the `pom.xml` file:\n\n   <properties>\n     <jenkins.version>2.516.3</jenkins.version>\n   </propertie"
  },
  "5133": {
    "source_file": "update-base-jenkins-version.txt",
    "text": "enkins.version` value in the properties section of the `pom.xml` file:\n\n   <properties>\n     <jenkins.version>2.516.3</jenkins.version>\n   </properties>\n\nIf the plugin is already using the plugin bill of materials, then the bill of materials also needs to be updated with the matching `artifactId` for the minimum required Jenkins version.\nThe `version` may also need an upgrade see the .\n\nThe `git d"
  },
  "5134": {
    "source_file": "update-base-jenkins-version.txt",
    "text": "ds to be updated with the matching `artifactId` for the minimum required Jenkins version.\nThe `version` may also need an upgrade see the .\n\nThe `git diff` might look like this:\n\n  <dependencyManagement>\n    <dependencies>\n      <dependency>\n        <groupId>io.jenkins.tools.bom</groupId>\n-        <artifactId>bom-2.440.x</artifactId>\n<artifactId>bom-2.504.x</artifactId>\n-        <version>3435.v238d"
  },
  "5135": {
    "source_file": "update-base-jenkins-version.txt",
    "text": "groupId>io.jenkins.tools.bom</groupId>\n-        <artifactId>bom-2.440.x</artifactId>\n<artifactId>bom-2.504.x</artifactId>\n-        <version>3435.v238d66a_043fb_</version>\n<version>5701.va_b_018a_a_6b_0d3</version>\n        <type>pom</type>\n        <scope>import</scope>\n      </dependency>\n    </dependencies>\n  </dependencyManagement>\n\n// Compile the plugin\n\n// Create a pull request"
  },
  "5136": {
    "source_file": "update-base-jenkins-version.txt",
    "text": "ope>import</scope>\n      </dependency>\n    </dependencies>\n  </dependencyManagement>\n\n// Compile the plugin\n\n// Create a pull request"
  },
  "5137": {
    "source_file": "update-parent-pom.txt",
    "text": "layout: developersection\ntitle: Update parent POM\n\n\n.Use latest parent POM\nvideo::Fev8KfFsPZE[youtube,width=800,height=420,start=807]\n\nThe Maven project object model (\"POM\") defines a parent project object model that provides default settings.\nAn update of the parent POM will allow this plugin to compile with recent Java versions.\nThe most recent parent POM files also provide additional static ana"
  },
  "5138": {
    "source_file": "update-parent-pom.txt",
    "text": "ate of the parent POM will allow this plugin to compile with recent Java versions.\nThe most recent parent POM files also provide additional static analysis like spotbugs and optional automated source code formatting.\n\n// Create the branch\n\n// Install and configure Apache Maven\n\n// Compile the plugin\n\nWhen modernizing older plugins, You may need to use Java 8 to compile the plugin initially.\nOnce t"
  },
  "5139": {
    "source_file": "update-parent-pom.txt",
    "text": " and configure Apache Maven\n\n// Compile the plugin\n\nWhen modernizing older plugins, You may need to use Java 8 to compile the plugin initially.\nOnce the parent POM has been updated, you'll be able to compile and test with recent Java versions.\n\nUse Apache Maven to update the parent POM:\n\nmvn -ntp versions:update-parent\n\n[INFO] Scanning for projects...\n[INFO]\n[INFO] ---< org.jenkins-ci.plugins:your"
  },
  "5140": {
    "source_file": "update-parent-pom.txt",
    "text": "pache Maven to update the parent POM:\n\nmvn -ntp versions:update-parent\n\n[INFO] Scanning for projects...\n[INFO]\n[INFO] ---< org.jenkins-ci.plugins:your-plugin >\n[INFO] Building Schedule Build Plugin 1.0.0-SNAPSHOT\n[INFO] [ hpi ]-\n[INFO]\n[INFO] --- versions-maven-plugin:2.8.1:update-parent (default-cli) @ your-plugin ---\n[INFO] Updating parent from 3.50 to 4.47\n[INFO]\n[INFO] BUILD SUCCESS\n[INFO]\n[IN"
  },
  "5141": {
    "source_file": "update-parent-pom.txt",
    "text": "sions-maven-plugin:2.8.1:update-parent (default-cli) @ your-plugin ---\n[INFO] Updating parent from 3.50 to 4.47\n[INFO]\n[INFO] BUILD SUCCESS\n[INFO]\n[INFO] Total time:  3.013 s\n[INFO] Finished at: 2021-09-26T20:03:00-06:00\n[INFO]\n\nReview the change that Apache Maven performed for you with the command:\n\ngit diff\n\ndiff --git a/pom.xml b/pom.xml\nindex e6a8356..3a42d47 100644\n--- a/pom.xml\n++ b/pom.xml\n"
  },
  "5142": {
    "source_file": "update-parent-pom.txt",
    "text": "t Apache Maven performed for you with the command:\n\ngit diff\n\ndiff --git a/pom.xml b/pom.xml\nindex e6a8356..3a42d47 100644\n--- a/pom.xml\n++ b/pom.xml\n@@ -3,7 +3,7 @@\n   <parent>\n     <groupId>org.jenkins-ci.plugins</groupId>\n     <artifactId>plugin</artifactId>\n-    <version>3.50</version>\n<version>4.80</version>\n     <relativePath />\n   </parent>\n\n   <artifactId>your-plugin</artifactId>\n\n// Compi"
  },
  "5143": {
    "source_file": "update-parent-pom.txt",
    "text": "artifactId>\n-    <version>3.50</version>\n<version>4.80</version>\n     <relativePath />\n   </parent>\n\n   <artifactId>your-plugin</artifactId>\n\n// Compile the plugin\n\nIf there is a `<java.level>` property defined in the POM, remove it.\nThe minimum version required for a specific pom is now implicit in the POM.\nThe plugin maintainer does not need to specify a `<java.level>` property.\n\nIn many cases, "
  },
  "5144": {
    "source_file": "update-parent-pom.txt",
    "text": "ion required for a specific pom is now implicit in the POM.\nThe plugin maintainer does not need to specify a `<java.level>` property.\n\nIn many cases, other changes will be needed to the pom.xml file in order to use the most recent parent POM.\nSome of the other changes may include:\n\n* Resolve spotbugs warnings\n* Resolve\n* Prevent cross-site scripting by\n* Resolve ambiguous property encodings by\n\n//"
  },
  "5145": {
    "source_file": "update-parent-pom.txt",
    "text": " the other changes may include:\n\n* Resolve spotbugs warnings\n* Resolve\n* Prevent cross-site scripting by\n* Resolve ambiguous property encodings by\n\n// Create a pull request"
  },
  "5146": {
    "source_file": "update-scm-url.txt",
    "text": "layout: developersection\ntitle: Update SCM URL\n\n\n.Update the SCM URL in the SCM section of the pom file\nvideo::Fev8KfFsPZE[youtube,width=800,height=420,start=2961]\n\nGitHub has deprecated one of the unauthenticated access protocols (git:// protocol).\nThe `pom.xml` section that defines the `scm` for the plugin should refer to the repository with the `https://` protocol instead of the `git://` protoc"
  },
  "5147": {
    "source_file": "update-scm-url.txt",
    "text": "The `pom.xml` section that defines the `scm` for the plugin should refer to the repository with the `https://` protocol instead of the `git://` protocol\n\n// Create the branch\n\nEdit the scm section in the pom XML file to replace git:// with https:// .\n\n   <scm>\n-    <connection>scm:git:git://github.com/jenkinsci/your-plugin.git</connection>\n<connection>scm:git:https://github.com/jenkinsci/your-plug"
  },
  "5148": {
    "source_file": "update-scm-url.txt",
    "text": "\n\n   <scm>\n-    <connection>scm:git:git://github.com/jenkinsci/your-plugin.git</connection>\n<connection>scm:git:https://github.com/jenkinsci/your-plugin.git</connection>\n   </scm>\n\n// Create a pull request"
  },
  "5149": {
    "source_file": "updating-parent.txt",
    "text": "title: Updating Your Maven Parent POM\nlayout: developer\n\n\nMost Jenkins plugins use Apache Maven as their build tool.\nHere are some tips on bringing your plugin up to current recommendations.\n\n## Using the 2.x (or newer) parent POM\n\nProperly maintained Jenkins plugins are expected to use a 2.x-series (or newer) parent POM,\nthe later the better, to define the basic structure of `pom.xml`.\n\nhttps://g"
  },
  "5150": {
    "source_file": "updating-parent.txt",
    "text": "d Jenkins plugins are expected to use a 2.x-series (or newer) parent POM,\nthe later the better, to define the basic structure of `pom.xml`.\n\nhttps://github.com/jenkinsci/plugin-pom#usage[Parent POM general usage instructions]\n\nYou can use Maven itself to create a new plugin:\n\nhttps://github.com/jenkinsci/archetypes#usage[Archetype usage instructions]\n\nIf you are instead upgrading an older plugin, "
  },
  "5151": {
    "source_file": "updating-parent.txt",
    "text": "f to create a new plugin:\n\nhttps://github.com/jenkinsci/archetypes#usage[Archetype usage instructions]\n\nIf you are instead upgrading an older plugin, replace a header such as\n\n<parent>\n    <groupId>org.jenkins-ci.plugins</groupId>\n    <artifactId>plugin</artifactId>\n    <version>1.625</version>\n</parent>\n\nwith the new format:\n\n<parent>\n    <groupId>org.jenkins-ci.plugins</groupId>\n    <artifactId>"
  },
  "5152": {
    "source_file": "updating-parent.txt",
    "text": "gin</artifactId>\n    <version>1.625</version>\n</parent>\n\nwith the new format:\n\n<parent>\n    <groupId>org.jenkins-ci.plugins</groupId>\n    <artifactId>plugin</artifactId>\n    <version>2.33</version>\n    <relativePath />\n</parent>\n<properties>\n    <jenkins.version>1.625</jenkins.version>\n</properties>\n\n## Understanding `requireUpperBoundDeps` failures and fixes\n\nSometimes after changing dependency v"
  },
  "5153": {
    "source_file": "updating-parent.txt",
    "text": "kins.version>1.625</jenkins.version>\n</properties>\n\n## Understanding `requireUpperBoundDeps` failures and fixes\n\nSometimes after changing dependency versions in a POM and building,\nyou will encounter Maven Enforcer errors referring to a rule named `RequireUpperBoundDeps`.\nThis rule means that if your plugin depends on some component (such as another plugin) A in version 13,\nand another component B"
  },
  "5154": {
    "source_file": "updating-parent.txt",
    "text": "equireUpperBoundDeps`.\nThis rule means that if your plugin depends on some component (such as another plugin) A in version 13,\nand another component B in version 7,\nyet A version 13 expressed a dependency on B version 9 or newer,\nthen you may have a problem.\nThe practical impact could vary depending on the situation,\nbut in some cases it could mean ``LinkageError``s at runtime.\n\n### Transitive dep"
  },
  "5155": {
    "source_file": "updating-parent.txt",
    "text": "problem.\nThe practical impact could vary depending on the situation,\nbut in some cases it could mean ``LinkageError``s at runtime.\n\n### Transitive dependency plugin too old\n\nFor example, changing only the `git` test dependency version from `3.9.1` to `4.0.0-rc` in the `kubernetes` plugin might print:\n\n--- maven-enforcer-plugin:3.0.0-M2:enforce (display-info) @ kubernetes ---\nAdding ignore: module-"
  },
  "5156": {
    "source_file": "updating-parent.txt",
    "text": " `4.0.0-rc` in the `kubernetes` plugin might print:\n\n--- maven-enforcer-plugin:3.0.0-M2:enforce (display-info) @ kubernetes ---\nAdding ignore: module-info\nRule 5: org.apache.maven.plugins.enforcer.RequireUpperBoundDeps failed with message:\nFailed while enforcing RequireUpperBoundDeps. The error(s) are [\nRequire upper bound dependencies error for org.jenkins-ci.plugins:git-client:2.7.5 paths to dep"
  },
  "5157": {
    "source_file": "updating-parent.txt",
    "text": "le enforcing RequireUpperBoundDeps. The error(s) are [\nRequire upper bound dependencies error for org.jenkins-ci.plugins:git-client:2.7.5 paths to dependency are:\n-org.csanchez.jenkins.plugins:kubernetes:1.17.3-SNAPSHOT\n  +-org.jenkinsci.plugins:pipeline-model-definition:1.3.7\n    +-org.jenkins-ci.plugins:git-client:2.7.5\nand\n-org.csanchez.jenkins.plugins:kubernetes:1.17.3-SNAPSHOT\n  +-org.jenkins"
  },
  "5158": {
    "source_file": "updating-parent.txt",
    "text": "line-model-definition:1.3.7\n    +-org.jenkins-ci.plugins:git-client:2.7.5\nand\n-org.csanchez.jenkins.plugins:kubernetes:1.17.3-SNAPSHOT\n  +-org.jenkins-ci.plugins:git:4.0.0-rc\n    +-org.jenkins-ci.plugins:git-client:2.7.5 (managed) <-- org.jenkins-ci.plugins:git-client:3.0.0-rc\nand\n-org.csanchez.jenkins.plugins:kubernetes:1.17.3-SNAPSHOT\n  +-org.jenkins-ci.plugins:git:3.9.1\n    +-org.jenkins-ci.plu"
  },
  "5159": {
    "source_file": "updating-parent.txt",
    "text": "plugins:git-client:3.0.0-rc\nand\n-org.csanchez.jenkins.plugins:kubernetes:1.17.3-SNAPSHOT\n  +-org.jenkins-ci.plugins:git:3.9.1\n    +-org.jenkins-ci.plugins:git-client:2.7.5 (managed) <-- org.jenkins-ci.plugins:git-client:2.7.3\nand\n-org.csanchez.jenkins.plugins:kubernetes:1.17.3-SNAPSHOT\n  +-org.jenkinsci.plugins:pipeline-model-definition:1.3.7\n    +-org.jenkins-ci.plugins.workflow:workflow-cps-glob"
  },
  "5160": {
    "source_file": "updating-parent.txt",
    "text": "s.plugins:kubernetes:1.17.3-SNAPSHOT\n  +-org.jenkinsci.plugins:pipeline-model-definition:1.3.7\n    +-org.jenkins-ci.plugins.workflow:workflow-cps-global-lib:2.9\n      +-org.jenkins-ci.plugins:git-client:2.7.5 (managed) <-- org.jenkins-ci.plugins:git-client:2.7.0\nand\n-org.csanchez.jenkins.plugins:kubernetes:1.17.3-SNAPSHOT\n  +-org.jenkinsci.plugins:pipeline-model-definition:1.3.7\n    +-org.jenkins-"
  },
  "5161": {
    "source_file": "updating-parent.txt",
    "text": "client:2.7.0\nand\n-org.csanchez.jenkins.plugins:kubernetes:1.17.3-SNAPSHOT\n  +-org.jenkinsci.plugins:pipeline-model-definition:1.3.7\n    +-org.jenkins-ci.plugins.workflow:workflow-cps-global-lib:2.9\n      +-org.jenkins-ci.plugins:git-server:1.7\n        +-org.jenkins-ci.plugins:git-client:2.7.5 (managed) <-- org.jenkins-ci.plugins:git-client:2.3.0\n]\n\nIt takes a while to read the meaning behind this "
  },
  "5162": {
    "source_file": "updating-parent.txt",
    "text": "  +-org.jenkins-ci.plugins:git-client:2.7.5 (managed) <-- org.jenkins-ci.plugins:git-client:2.3.0\n]\n\nIt takes a while to read the meaning behind this message,\nbut it is saying that `git:4.0.0-rc` depends on `git-client:3.0.0-rc`\nand yet we are currently using `git-client:2.7.5` in our classpath.\nPlugin tests in this configuration are likely to fail even if the Enforcer rule were suppressed,\nsince "
  },
  "5163": {
    "source_file": "updating-parent.txt",
    "text": "tly using `git-client:2.7.5` in our classpath.\nPlugin tests in this configuration are likely to fail even if the Enforcer rule were suppressed,\nsince code added to Git 4 might be expecting to use APIs added to Git Client 3.\n\nIn this case (a bad plugin \u2192 plugin dependency),\nthe `InjectedTest` in Jenkins 2.12 or later would also catch the mistake,\nalbeit more slowly (so less suitably for quick itera"
  },
  "5164": {
    "source_file": "updating-parent.txt",
    "text": "n \u2192 plugin dependency),\nthe `InjectedTest` in Jenkins 2.12 or later would also catch the mistake,\nalbeit more slowly (so less suitably for quick iteration):\n\n\u2026 jenkins.InitReactorRunner$1 onTaskFailed\nSEVERE: Failed Loading plugin Jenkins Git plugin v4.0.0-rc (git)\njava.io.IOException: Jenkins Git plugin version 4.0.0-rc failed to load.\n - Jenkins Git client plugin version 2.7.5 is older than requ"
  },
  "5165": {
    "source_file": "updating-parent.txt",
    "text": "v4.0.0-rc (git)\njava.io.IOException: Jenkins Git plugin version 4.0.0-rc failed to load.\n - Jenkins Git client plugin version 2.7.5 is older than required. To fix, install version 3.0.0-rc or later.\n\tat hudson.PluginWrapper.resolvePluginDependencies(PluginWrapper.java:868)\n\tat hudson.PluginManager$2$1$1.run(PluginManager.java:544)\n\tat org.jvnet.hudson.reactor.TaskGraphBuilder$TaskImpl.run(TaskGrap"
  },
  "5166": {
    "source_file": "updating-parent.txt",
    "text": "PluginWrapper.java:868)\n\tat hudson.PluginManager$2$1$1.run(PluginManager.java:544)\n\tat org.jvnet.hudson.reactor.TaskGraphBuilder$TaskImpl.run(TaskGraphBuilder.java:169)\n\tat org.jvnet.hudson.reactor.Reactor.runTask(Reactor.java:296)\n\tat jenkins.model.Jenkins$5.runTask(Jenkins.java:1091)\n\tat org.jvnet.hudson.reactor.Reactor$2.run(Reactor.java:214)\n\tat org.jvnet.hudson.reactor.Reactor$Node.run(Reacto"
  },
  "5167": {
    "source_file": "updating-parent.txt",
    "text": "Jenkins$5.runTask(Jenkins.java:1091)\n\tat org.jvnet.hudson.reactor.Reactor$2.run(Reactor.java:214)\n\tat org.jvnet.hudson.reactor.Reactor$Node.run(Reactor.java:117)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n\u2026\njava.lang.Error: Plugin gi"
  },
  "5168": {
    "source_file": "updating-parent.txt",
    "text": "java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n\u2026\njava.lang.Error: Plugin git failed to start\n\tat org.jvnet.hudson.test.PluginAutomaticTestBuilder$OtherTests.testPluginActive(PluginAutomaticTestBuilder.java:99)\n\nIn other cases you might get a more cryptic `NoSuchMethodError` error during tests;\nor, worse, all tests might pas"
  },
  "5169": {
    "source_file": "updating-parent.txt",
    "text": "luginAutomaticTestBuilder.java:99)\n\nIn other cases you might get a more cryptic `NoSuchMethodError` error during tests;\nor, worse, all tests might pass yet your plugin might throw an endless stream of errors at runtime.\nThe standard POM defines this Enforcer rule to reduce the likelihood of such mistakes.\n\nThe fix here is to also update the `git-client` plugin version.\nThat in turn might also requ"
  },
  "5170": {
    "source_file": "updating-parent.txt",
    "text": "Enforcer rule to reduce the likelihood of such mistakes.\n\nThe fix here is to also update the `git-client` plugin version.\nThat in turn might also require another plugin to be updated.\nThis process can get tedious,\nso you could consider using the \u201cBill of Materials\u201d for plugins (under development):\n\nhttps://github.com/jenkinsci/bom#usage[Plugin BOM usage instructions]\n\nAt least for commonly encount"
  },
  "5171": {
    "source_file": "updating-parent.txt",
    "text": "l of Materials\u201d for plugins (under development):\n\nhttps://github.com/jenkinsci/bom#usage[Plugin BOM usage instructions]\n\nAt least for commonly encountered dependencies,\nthe BOM can eliminate the need to specify individual versions and check that they work together.\n\n### Improper attempt to use core component\n\nTODO unless using `pluginFirstClassLoader`, a dep on a dep of `jenkins-core` will be igno"
  },
  "5172": {
    "source_file": "updating-parent.txt",
    "text": " work together.\n\n### Improper attempt to use core component\n\nTODO unless using `pluginFirstClassLoader`, a dep on a dep of `jenkins-core` will be ignored at runtime\n\n### Test-scoped dependency mismatch\n\nTODO if using a plugin and its `<classifier>tests</classifier>` JAR too, introduce a POM property to make sure both are at the same version\n\n### Picking up fixes to dependency plugins\n\nTODO if a pr"
  },
  "5173": {
    "source_file": "updating-parent.txt",
    "text": "ts</classifier>` JAR too, introduce a POM property to make sure both are at the same version\n\n### Picking up fixes to dependency plugins\n\nTODO if a problematic dep\u2019s trail includes another plugin, check whether that plugin is built using a new POM and best practices\n\n### Suppressing violations\n\nTODO similar to https://github.com/jenkinsci/plugin-pom/blob/439ab3d2fb3dd91717538bef4d38bb67e31d65d4/po"
  },
  "5174": {
    "source_file": "updating-parent.txt",
    "text": "d best practices\n\n### Suppressing violations\n\nTODO similar to https://github.com/jenkinsci/plugin-pom/blob/439ab3d2fb3dd91717538bef4d38bb67e31d65d4/pom.xml#L572-L589 but for https://github.com/jenkinsci/plugin-pom/blob/439ab3d2fb3dd91717538bef4d38bb67e31d65d4/pom.xml#L604-L611\n\n### Shading libraries\n\nTODO can use a distinct version of a library if it is repackaged\n\n## Optional dependencies and ext"
  },
  "5175": {
    "source_file": "updating-parent.txt",
    "text": "7e31d65d4/pom.xml#L604-L611\n\n### Shading libraries\n\nTODO can use a distinct version of a library if it is repackaged\n\n## Optional dependencies and extensions\n\nTODO"
  },
  "5176": {
    "source_file": "upgrade-java-guidelines.txt",
    "text": "layout: redirect\nredirect_url: /doc/book/platform-information/upgrade-java-to-11/"
  },
  "5177": {
    "source_file": "upgrade-java-to-11.txt",
    "text": "layout: subsection\ntitle: Upgrade to Java 11\n\n\nWhen upgrading the JVM used to run Jenkins from Java 8 to Java 11, there are some details you should know and precautions you should take.\n\nvideo::L2Uomz8RWUM[youtube,width=800,height=420]\n\nAs with any upgrade, we recommend:\n\n.\nTesting the upgrade with your backup.\nOnly after all required tests pass, performing the upgrade on your production instance."
  },
  "5178": {
    "source_file": "upgrade-java-to-11.txt",
    "text": "pgrade, we recommend:\n\n.\nTesting the upgrade with your backup.\nOnly after all required tests pass, performing the upgrade on your production instance.\n\nIf you need to upgrade Jenkins, as well as the JVM, we recommend you:\n\n.\nStop the Jenkins controller.\nUpgrade the JVM on which Jenkins is running.\n** Use a package manager to install the new JVM.\n** Ensure the default JVM is the newly installed ver"
  },
  "5179": {
    "source_file": "upgrade-java-to-11.txt",
    "text": "er.\nUpgrade the JVM on which Jenkins is running.\n** Use a package manager to install the new JVM.\n** Ensure the default JVM is the newly installed version.\n*** If it is not, run `systemctl edit jenkins`, and set either the `JAVA_HOME` environment variable or the `JENKINS_JAVA_CMD` environment variable.\nUpgrade Jenkins to the most recent version.\n** How you upgrade Jenkins is dependent upon your or"
  },
  "5180": {
    "source_file": "upgrade-java-to-11.txt",
    "text": "iable or the `JENKINS_JAVA_CMD` environment variable.\nUpgrade Jenkins to the most recent version.\n** How you upgrade Jenkins is dependent upon your original Jenkins installation method.\nTIP: We recommend that you use the package manager of your system (such as `apt` or `yum`).\nValidate the upgrade to confirm that all plugins and jobs are loaded.\nUpgrade the required plugins.\nRefer to <<Upgrading P"
  },
  "5181": {
    "source_file": "upgrade-java-to-11.txt",
    "text": "m (such as `apt` or `yum`).\nValidate the upgrade to confirm that all plugins and jobs are loaded.\nUpgrade the required plugins.\nRefer to <<Upgrading Plugins>> for further information.\n\nStarting with Jenkins releases 2.357 and LTS 2.361.1, Java 11 or Java 17 is required.\n\nWhen upgrading the Java version for Jenkins and the JVM, it is important to upgrade all plugins that support Java 11.\nPlugin upg"
  },
  "5182": {
    "source_file": "upgrade-java-to-11.txt",
    "text": "Java 17 is required.\n\nWhen upgrading the Java version for Jenkins and the JVM, it is important to upgrade all plugins that support Java 11.\nPlugin upgrades assure compatibility with the most recent Jenkins releases.\n\nNOTE: If you discover a previously unreported issue, please let us know. Refer to  for guidance.\n\n// Commented because pipeline support plugin 3.0 is over 3 years old and has 8+ later"
  },
  "5183": {
    "source_file": "upgrade-java-to-11.txt",
    "text": "y unreported issue, please let us know. Refer to  for guidance.\n\n// Commented because pipeline support plugin 3.0 is over 3 years old and has 8+ later releases\n//\n// One of the most important plugin upgrades is the plugin:workflow-support[Pipeline: Support plugin]: make sure that the version of the plugin is at least `3.0`.\n//\n// NOTE: Stop all Pipeline jobs before upgrading this plugin because th"
  },
  "5184": {
    "source_file": "upgrade-java-to-11.txt",
    "text": "upport plugin]: make sure that the version of the plugin is at least `3.0`.\n//\n// NOTE: Stop all Pipeline jobs before upgrading this plugin because this upgrade changes the serialization of Pipeline builds. As a general rule, even though Pipeline jobs are supposed to survive a Jenkins restart, it's always a better option to make sure that no Pipeline builds are in progress before any scheduled Jen"
  },
  "5185": {
    "source_file": "upgrade-java-to-11.txt",
    "text": "s are supposed to survive a Jenkins restart, it's always a better option to make sure that no Pipeline builds are in progress before any scheduled Jenkins maintenance.\n\nSome plugins use JAXB libraries provided by the JDK.\nHowever, the `java.xml.bind` and `javax.activation` modules are no longer included in OpenJDK 11, and plugins might fail if no replacement is offered.\n\nTo fix this problem, we've"
  },
  "5186": {
    "source_file": "upgrade-java-to-11.txt",
    "text": " and `javax.activation` modules are no longer included in OpenJDK 11, and plugins might fail if no replacement is offered.\n\nTo fix this problem, we've bundled those libraries into a new detached plugin: plugin:jaxb[JAXB plugin].\nWhen any Jenkins core more recent than `2.163` is running on Java 11, this plugin is automatically installed.\nHowever, if you manage your plugins outside Jenkins, for exam"
  },
  "5187": {
    "source_file": "upgrade-java-to-11.txt",
    "text": " more recent than `2.163` is running on Java 11, this plugin is automatically installed.\nHowever, if you manage your plugins outside Jenkins, for example using a `plugins.txt` in your Docker images, you might need to install the plugin explicitly.\n\nAll agents must be running on the same JVM version as the controller due to how controllers and agents communicate.\nIf you're upgrading your Jenkins co"
  },
  "5188": {
    "source_file": "upgrade-java-to-11.txt",
    "text": "ll agents must be running on the same JVM version as the controller due to how controllers and agents communicate.\nIf you're upgrading your Jenkins controller to run on Java 11, you must upgrade the JVM on your agents.\n\nYou can validate the version of each agent with the plugin:versioncolumn[Versions Node Monitors] plugin.\nThis plugin provides information about the JVM version of each agent on the"
  },
  "5189": {
    "source_file": "upgrade-java-to-11.txt",
    "text": "f each agent with the plugin:versioncolumn[Versions Node Monitors] plugin.\nThis plugin provides information about the JVM version of each agent on the node management screen of your Jenkins instance.\nYou can also configure this plugin to automatically disconnect any agent with an incorrect JVM version.\n\nJava Web Start has been removed in Java 11.\nWhen a Jenkins controller runs on Java 11, the Java"
  },
  "5190": {
    "source_file": "upgrade-java-to-11.txt",
    "text": "y disconnect any agent with an incorrect JVM version.\n\nJava Web Start has been removed in Java 11.\nWhen a Jenkins controller runs on Java 11, the Java Web Start button will no longer appear in the Web UI.\nYou can't launch agents for a Java 11 Jenkins controller from a `*.jnlp` file downloaded to a web browser.\n\nThere are no plans to replace this functionality.\nConnect agents to Jenkins on Java 11 "
  },
  "5191": {
    "source_file": "upgrade-java-to-11.txt",
    "text": " controller from a `*.jnlp` file downloaded to a web browser.\n\nThere are no plans to replace this functionality.\nConnect agents to Jenkins on Java 11 with plugins like plugin:ssh-slaves[SSH Build Agents Plugin], with operating system command line calls to `java -jar agent.jar`, or using containers.\n\nOracle JDK 11 licensing prevents the Jenkins community from listing the Oracle JDKs.\nBecause of thi"
  },
  "5192": {
    "source_file": "upgrade-java-to-11.txt",
    "text": "ls to `java -jar agent.jar`, or using containers.\n\nOracle JDK 11 licensing prevents the Jenkins community from listing the Oracle JDKs.\nBecause of this licensing restriction, Oracle JDK 11 can't be automatically installed by Jenkins.\nThis problem is tracked in the issue .\n\nAs an alternative, we encourage you to use containers based on images that contain all the tooling needed for your builds."
  },
  "5193": {
    "source_file": "upgrade-java-to-11.txt",
    "text": "tracked in the issue .\n\nAs an alternative, we encourage you to use containers based on images that contain all the tooling needed for your builds."
  },
  "5194": {
    "source_file": "upgrade-java-to-17.txt",
    "text": "layout: subsection\ntitle: Upgrade to Java 17\n\n\nWhen upgrading the JVM used to run Jenkins from Java 11 to Java 17, there are some details you should know and precautions you should take.\n\n.Upgrading Jenkins Java Version From 11 to 17\nvideo::ZabUz6sl-8I[youtube,width=800,height=420]\n\nAs with any upgrade, we recommend:\n\n.\nTesting the upgrade with your backup.\nOnly after all required tests pass, perf"
  },
  "5195": {
    "source_file": "upgrade-java-to-17.txt",
    "text": "8I[youtube,width=800,height=420]\n\nAs with any upgrade, we recommend:\n\n.\nTesting the upgrade with your backup.\nOnly after all required tests pass, performing the upgrade on your production controller.\n\nIf you need to upgrade Jenkins, as well as the JVM, we recommend you:\n\n.\nStop the Jenkins controller.\nUpgrade the JVM on which Jenkins is running.\n** Use a package manager to install the new JVM.\n** "
  },
  "5196": {
    "source_file": "upgrade-java-to-17.txt",
    "text": "M, we recommend you:\n\n.\nStop the Jenkins controller.\nUpgrade the JVM on which Jenkins is running.\n** Use a package manager to install the new JVM.\n** Ensure the default JVM is the newly installed version.\n*** If it is not, run `systemctl edit jenkins`, and set either the `JAVA_HOME` environment variable or the `JENKINS_JAVA_CMD` environment variable.\nUpgrade Jenkins to the most recent version.\n** "
  },
  "5197": {
    "source_file": "upgrade-java-to-17.txt",
    "text": "`, and set either the `JAVA_HOME` environment variable or the `JENKINS_JAVA_CMD` environment variable.\nUpgrade Jenkins to the most recent version.\n** How you upgrade Jenkins is dependent upon your original Jenkins installation method.\nTIP: We recommend that you use the package manager of your system (such as `apt` or `yum`).\nValidate the upgrade to confirm that all plugins and jobs are loaded.\nUpg"
  },
  "5198": {
    "source_file": "upgrade-java-to-17.txt",
    "text": "nd that you use the package manager of your system (such as `apt` or `yum`).\nValidate the upgrade to confirm that all plugins and jobs are loaded.\nUpgrade the required plugins.\n\nWhen upgrading the Java version for Jenkins and the JVM, it is important to upgrade all plugins that support Java 17.\nPlugin upgrades assure compatibility with the most recent Jenkins releases.\n\nNOTE: If you discover a pre"
  },
  "5199": {
    "source_file": "upgrade-java-to-17.txt",
    "text": " to upgrade all plugins that support Java 17.\nPlugin upgrades assure compatibility with the most recent Jenkins releases.\n\nNOTE: If you discover a previously unreported issue, please let us know.\nRefer to  for guidance.\n\nAll agents must be running on the same JVM version as the controller, due to how controllers and agents communicate.\nIf you're upgrading your Jenkins controller to run on Java 17,"
  },
  "5200": {
    "source_file": "upgrade-java-to-17.txt",
    "text": " the same JVM version as the controller, due to how controllers and agents communicate.\nIf you're upgrading your Jenkins controller to run on Java 17, you must upgrade the JVM on your agents.\n\nValidating the version of each agent can be done with the plugin:versioncolumn[Versions Node Monitors] plugin.\nThis plugin provides information about the JVM version of each agent on the node management scre"
  },
  "5201": {
    "source_file": "upgrade-java-to-17.txt",
    "text": " plugin:versioncolumn[Versions Node Monitors] plugin.\nThis plugin provides information about the JVM version of each agent on the node management screen of your Jenkins controller.\nThis plugin can also be configured to automatically disconnect any agent with an incorrect JVM version."
  },
  "5202": {
    "source_file": "upgrade-java-to-17.txt",
    "text": "ent with an incorrect JVM version."
  },
  "5203": {
    "source_file": "upgrade-java-to-21.txt",
    "text": "layout: subsection\ntitle: Upgrade to Java 21\n\n\nWhen upgrading the JVM used to run Jenkins from Java 17 to Java 21, there are some details you should know and precautions you should take.\nNOTE: Java 21 is supported as of LTS 2.426.1 and Jenkins Weekly 2.419.\n\nAs with any upgrade, we recommend:\n\n.\nTesting the upgrade with your backup.\nAfter all required tests pass, execute the upgrade on your produc"
  },
  "5204": {
    "source_file": "upgrade-java-to-21.txt",
    "text": " 2.419.\n\nAs with any upgrade, we recommend:\n\n.\nTesting the upgrade with your backup.\nAfter all required tests pass, execute the upgrade on your production controller.\n\n.Upgrading Jenkins Java Version From 17 to 21\nvideo::8xQVGpWeIe0[youtube,width=800,height=420]\n\nTo verify the Java version currently used in your controller:\n\nNavigate to *Manage Jenkins* and then select *System Information* in the "
  },
  "5205": {
    "source_file": "upgrade-java-to-21.txt",
    "text": ",height=420]\n\nTo verify the Java version currently used in your controller:\n\nNavigate to *Manage Jenkins* and then select *System Information* in the *Status Information* section.\nOn the *System Properties* tab, locate the `java.runtime.version` and reveal the hidden value to display your current Java version.\n\nTo verify the Java version currently used in your agent:\n\nSelect an agent name from the"
  },
  "5206": {
    "source_file": "upgrade-java-to-21.txt",
    "text": "reveal the hidden value to display your current Java version.\n\nTo verify the Java version currently used in your agent:\n\nSelect an agent name from the *Build Executor Status* widget and then select *System Information*.\nLocate the `java.runtime.version` and reveal the hidden value to display the current Java version.\n\nThe `checkNodes` script determines what version of Java is running the controlle"
  },
  "5207": {
    "source_file": "upgrade-java-to-21.txt",
    "text": "on` and reveal the hidden value to display the current Java version.\n\nThe `checkNodes` script determines what version of Java is running the controller process, along with the version of the agent that's associated with that controller.\nThe script then checks the version of Java that is on the agent.\nWhen these values are returned, `OK` means that the agent Java version matches the controller Java"
  },
  "5208": {
    "source_file": "upgrade-java-to-21.txt",
    "text": "en checks the version of Java that is on the agent.\nWhen these values are returned, `OK` means that the agent Java version matches the controller Java version.\nOtherwise, the result displays the expected Java version and the version found instead.\n\nTo run the `checkNodes` script:\n\nNavigate to *Manage Jenkins* and select *Script Console* from the *Tools and Actions* section.\nCopy the following scri"
  },
  "5209": {
    "source_file": "upgrade-java-to-21.txt",
    "text": "o run the `checkNodes` script:\n\nNavigate to *Manage Jenkins* and select *Script Console* from the *Tools and Actions* section.\nCopy the following script into the empty text box and select *Run*:\n\n/*** BEGIN META {\n \"name\" : \"Check Nodes Version\",\n \"comment\" : \"Check the .jar version and the java version of the Nodes against the Master versions\",\n \"parameters\" : [ ],\n \"core\": \"1.609\",\n \"authors\" : "
  },
  "5210": {
    "source_file": "upgrade-java-to-21.txt",
    "text": "omment\" : \"Check the .jar version and the java version of the Nodes against the Master versions\",\n \"parameters\" : [ ],\n \"core\": \"1.609\",\n \"authors\" : [\n { name : \"Allan Burdajewicz\" }\n ]\n } END META**/\n\nimport hudson.remoting.Launcher\nimport hudson.slaves.SlaveComputer\nimport jenkins.model.Jenkins\n\ndef expectedAgentVersion = Launcher.VERSION\ndef expectedJavaVersion = System.getProperty(\"java.versi"
  },
  "5211": {
    "source_file": "upgrade-java-to-21.txt",
    "text": "laves.SlaveComputer\nimport jenkins.model.Jenkins\n\ndef expectedAgentVersion = Launcher.VERSION\ndef expectedJavaVersion = System.getProperty(\"java.version\")\nprintln \"Master\"\nprintln \" Expected Agent Version = '${expectedAgentVersion}'\"\nprintln \" Expected Java Version = '${expectedJavaVersion}'\"\nJenkins.instance.getComputers()\n        .findAll { it instanceof SlaveComputer }\n        .each { computer "
  },
  "5212": {
    "source_file": "upgrade-java-to-21.txt",
    "text": "ed Java Version = '${expectedJavaVersion}'\"\nJenkins.instance.getComputers()\n        .findAll { it instanceof SlaveComputer }\n        .each { computer ->\n    println \"Node '${computer.name}'\"\n    if (!computer.getChannel()) {\n        println \" is disconnected.\"\n    } else {\n        def isOk = true\n        def agentVersion = computer.getSlaveVersion()\n        if (!expectedAgentVersion.equals(agentVe"
  },
  "5213": {
    "source_file": "upgrade-java-to-21.txt",
    "text": "onnected.\"\n    } else {\n        def isOk = true\n        def agentVersion = computer.getSlaveVersion()\n        if (!expectedAgentVersion.equals(agentVersion)) {\n            println \" expected agent version '${expectedAgentVersion}' but got '${agentVersion}'\"\n            isOk = false\n        }\n        def javaVersion = computer.getSystemProperties().get(\"java.version\")\n        if (!expectedJavaVersi"
  },
  "5214": {
    "source_file": "upgrade-java-to-21.txt",
    "text": "sion}'\"\n            isOk = false\n        }\n        def javaVersion = computer.getSystemProperties().get(\"java.version\")\n        if (!expectedJavaVersion.equals(javaVersion)) {\n            println \" expected java version '${expectedJavaVersion}' but got '${javaVersion}'\"\n            isOk = false\n        }\n\n        if(isOk) {\n            println \" OK\"\n        }\n    }\n}\nreturn;\n\nThe following steps a"
  },
  "5215": {
    "source_file": "upgrade-java-to-21.txt",
    "text": "ot '${javaVersion}'\"\n            isOk = false\n        }\n\n        if(isOk) {\n            println \" OK\"\n        }\n    }\n}\nreturn;\n\nThe following steps are taken from the video linked at the top of this page.\n\nStop the Jenkins controller with `systemctl stop jenkins`.\nInstall the corresponding Java version with `dnf -y install temurin-21-jdk` or with the package manager your system uses.\nCheck the Ja"
  },
  "5216": {
    "source_file": "upgrade-java-to-21.txt",
    "text": " stop jenkins`.\nInstall the corresponding Java version with `dnf -y install temurin-21-jdk` or with the package manager your system uses.\nCheck the Java version with `java -version`.\nChange the default Java for the system by running `update-alternatives --config java` and then enter the number that corresponds to Java 21, for example `2` if that is the correct option.\nRestart Jenkins with `systemc"
  },
  "5217": {
    "source_file": "upgrade-java-to-21.txt",
    "text": "ves --config java` and then enter the number that corresponds to Java 21, for example `2` if that is the correct option.\nRestart Jenkins with `systemctl restart jenkins`.\n\nTo upgrade Jenkins, as well as the JVM, we recommend you:\n\n.\nStop the Jenkins controller.\nUpgrade the JVM on which Jenkins is running.\n** Use a package manager to install the new JVM.\n** Ensure the default JVM is the newly insta"
  },
  "5218": {
    "source_file": "upgrade-java-to-21.txt",
    "text": "controller.\nUpgrade the JVM on which Jenkins is running.\n** Use a package manager to install the new JVM.\n** Ensure the default JVM is the newly installed version.\n*** If it is not, run `systemctl edit jenkins`, and set either the `JAVA_HOME` environment variable or the `JENKINS_JAVA_CMD` environment variable.\nUpgrade Jenkins to the most recent version.\n** How you upgrade Jenkins is dependent upon"
  },
  "5219": {
    "source_file": "upgrade-java-to-21.txt",
    "text": "ment variable or the `JENKINS_JAVA_CMD` environment variable.\nUpgrade Jenkins to the most recent version.\n** How you upgrade Jenkins is dependent upon your original Jenkins installation method.\nTIP: We recommend that you use the package manager of your system (such as `apt` or `yum`).\nValidate the upgrade to confirm that all plugins and jobs are loaded.\nUpgrade the required plugins.\n\nWhen upgradin"
  },
  "5220": {
    "source_file": "upgrade-java-to-21.txt",
    "text": "ur system (such as `apt` or `yum`).\nValidate the upgrade to confirm that all plugins and jobs are loaded.\nUpgrade the required plugins.\n\nWhen upgrading the Java version for Jenkins and the JVM, it is important to upgrade all plugins that support Java 21.\nPlugin upgrades assure compatibility with the most recent Jenkins releases.\n\nNOTE: If you discover a previously unreported issue, please let us k"
  },
  "5221": {
    "source_file": "upgrade-java-to-21.txt",
    "text": " 21.\nPlugin upgrades assure compatibility with the most recent Jenkins releases.\n\nNOTE: If you discover a previously unreported issue, please let us know.\nRefer to  for guidance.\n\nDue to how controllers and agents communicate, all agents must run on the same JVM version as the controller.\nIf you're upgrading your Jenkins controller to run on Java 21, you must upgrade the JVM on your agents.\n\nValid"
  },
  "5222": {
    "source_file": "upgrade-java-to-21.txt",
    "text": "the same JVM version as the controller.\nIf you're upgrading your Jenkins controller to run on Java 21, you must upgrade the JVM on your agents.\n\nValidating the version of each agent can be done with the plugin:versioncolumn[Versions Node Monitors] plugin.\nThis plugin provides information about the JVM version of each agent on the node management screen of your Jenkins controller.\nYou can configure"
  },
  "5223": {
    "source_file": "upgrade-java-to-21.txt",
    "text": "ugin.\nThis plugin provides information about the JVM version of each agent on the node management screen of your Jenkins controller.\nYou can configure this plugin to automatically disconnect any agent with an incorrect JVM version.\n\nThe following steps are taken from the video linked at the top of this page.\n\nIn the command line, log into the agent.\nEnter `dnf -y install temurin-21-jdk`, or use th"
  },
  "5224": {
    "source_file": "upgrade-java-to-21.txt",
    "text": "ps are taken from the video linked at the top of this page.\n\nIn the command line, log into the agent.\nEnter `dnf -y install temurin-21-jdk`, or use the appropriate command for your package manager.\nCheck your java version using `java -version`.\nChange the default Java version using `update-alternatives --config java` and then enter the selection corresponding to Java 21.\nVerify the Java version ha"
  },
  "5225": {
    "source_file": "upgrade-java-to-21.txt",
    "text": "e the default Java version using `update-alternatives --config java` and then enter the selection corresponding to Java 21.\nVerify the Java version has been updated with `java -version`.\nFrom the agent page in your Jenkins controller, select *Disconnect*.\nAfter disconnecting the agent, reconnect it by selecting *Bring this node back online* and then selecting *Launch agent*."
  },
  "5226": {
    "source_file": "upgrade-java-to-21.txt",
    "text": "ect*.\nAfter disconnecting the agent, reconnect it by selecting *Bring this node back online* and then selecting *Launch agent*."
  },
  "5227": {
    "source_file": "usage-in-plugins.txt",
    "text": "layout: developer\ntitle: Searching for API Usages in Plugins\n\n\nThe need to search for API usages in plugins arises in several use cases:\n\n* When deprecating an old API in favor of a newer one, one must identify consumers of the old API that need to be migrated.\n* When removing a deprecated API, one must identify consumers that still remain and therefore block the removal.\n* When upgrading a librar"
  },
  "5228": {
    "source_file": "usage-in-plugins.txt",
    "text": "e migrated.\n* When removing a deprecated API, one must identify consumers that still remain and therefore block the removal.\n* When upgrading a library, one must identify the library's breaking changes and if any consumers are relying on the old functionality.\n* When removing or detaching a library from Jenkins core, one must identify which plugins are relying on it and therefore need to be update"
  },
  "5229": {
    "source_file": "usage-in-plugins.txt",
    "text": "tionality.\n* When removing or detaching a library from Jenkins core, one must identify which plugins are relying on it and therefore need to be updated.\n* When creating a test plan, one must identify which plugins are using a particular feature and therefore need to be tested when the implementation changes.\n\nThe following two queries can be used to search for API usages in sources in the `jenkins"
  },
  "5230": {
    "source_file": "usage-in-plugins.txt",
    "text": "herefore need to be tested when the implementation changes.\n\nThe following two queries can be used to search for API usages in sources in the `jenkinsci` and `jenkins-infra` GitHub organizations.\nOrganizations with private repositories can also be searched if you have access.\n\n* https://github.com/search?ref=simplesearch&type=Code&q=user%3Ajenkinsci+PrincipalAcegiUserToken[`jenkinsci` GitHub organ"
  },
  "5231": {
    "source_file": "usage-in-plugins.txt",
    "text": "arched if you have access.\n\n* https://github.com/search?ref=simplesearch&type=Code&q=user%3Ajenkinsci+PrincipalAcegiUserToken[`jenkinsci` GitHub organization]\n* https://github.com/search?ref=simplesearch&type=Code&q=user%3Ajenkins-infra+PrincipalAcegiUserToken[`jenkins-infra` GitHub organization]\n\nTo search for API usages in plugin binaries, run `org.jenkinsci.deprecatedusage.Main` from https://gi"
  },
  "5232": {
    "source_file": "usage-in-plugins.txt",
    "text": "iUserToken[`jenkins-infra` GitHub organization]\n\nTo search for API usages in plugin binaries, run `org.jenkinsci.deprecatedusage.Main` from https://github.com/jenkins-infra/usage-in-plugins[jenkins-infra/usage-in-plugins].\n\nCAUTION: Running this for the first time will download _all_ plugins, requiring about 10 GiB of disk space.\n\nNarrow your search by passing either `--additionalClasses`, `--addi"
  },
  "5233": {
    "source_file": "usage-in-plugins.txt",
    "text": "the first time will download _all_ plugins, requiring about 10 GiB of disk space.\n\nNarrow your search by passing either `--additionalClasses`, `--additionalMethods`, or `--additionalFields`.\nAlso pass `--onlyIncludeSpecified` to avoid unrelated results, thus making the above arguments \"`additional`\" to the empty set.\n\nCAUTION: `--additionalClasses` uses syntax like `javax/inject/Inject`; in contra"
  },
  "5234": {
    "source_file": "usage-in-plugins.txt",
    "text": "ts, thus making the above arguments \"`additional`\" to the empty set.\n\nCAUTION: `--additionalClasses` uses syntax like `javax/inject/Inject`; in contrast, `--additionalMethods` and `--additionalFields` use syntax like `javax.inject.Provider#get`.\n\nAfter downloading all plugins, you will get a long report of usages.\nIt is often helpful to sort the results by plugin popularity and start working on th"
  },
  "5235": {
    "source_file": "usage-in-plugins.txt",
    "text": "er downloading all plugins, you will get a long report of usages.\nIt is often helpful to sort the results by plugin popularity and start working on the most popular plugins first.\nTo sort the list, use https://github.com/basil/update-center-sql[Update Center SQL] with a query like this:\n\nSELECT name,popularity FROM plugins WHERE name IN ('email-ext', 'script-security', 'htmlpublisher') ORDER BY po"
  },
  "5236": {
    "source_file": "usage-in-plugins.txt",
    "text": "e Center SQL] with a query like this:\n\nSELECT name,popularity FROM plugins WHERE name IN ('email-ext', 'script-security', 'htmlpublisher') ORDER BY popularity DESC;\n\nYou can search not only direct usages by plugins but also transitive usages by libraries that plugins depend on by adding `--includePluginLibs`.\nThis significantly increases search time, so it is only recommended when upgrading librar"
  },
  "5237": {
    "source_file": "usage-in-plugins.txt",
    "text": "ries that plugins depend on by adding `--includePluginLibs`.\nThis significantly increases search time, so it is only recommended when upgrading libraries or removing/detaching a library.\n\nWhen upgrading a library, one often needs to identify the breaking changes in order to search for usages.\nWe recommend the https://diff.revapi.org/[Revapi diff] tool for this purpose.\n\nFinally, https://github.com"
  },
  "5238": {
    "source_file": "usage-in-plugins.txt",
    "text": "king changes in order to search for usages.\nWe recommend the https://diff.revapi.org/[Revapi diff] tool for this purpose.\n\nFinally, https://github.com/jenkinsci/jep/blob/master/jep/227/README.adoc#searching-for-api-usages-in-binaries[JEP-227] revealed a way for the general public to search for usages in proprietary CloudBees CI plugin binaries."
  },
  "5239": {
    "source_file": "usage-in-plugins.txt",
    "text": "d a way for the general public to search for usages in proprietary CloudBees CI plugin binaries."
  },
  "5240": {
    "source_file": "usage-statistics.txt",
    "text": "title: Usage Statistics\nlayout: developersection\n\n\nAnonymous usage statistics are collected from Jenkins controllers that have not opted out from this.\nThey help us identify trends in Jenkins use and configuration, like the popularity of plugins and average number of plugins installed on controllers.\n\nThose usage statistics are encrypted on individual Jenkins controllers and sent to the Jenkins pr"
  },
  "5241": {
    "source_file": "usage-statistics.txt",
    "text": "average number of plugins installed on controllers.\n\nThose usage statistics are encrypted on individual Jenkins controllers and sent to the Jenkins project infrastructure, where they are stored.\nDecryption and anonymization is done in one step using the https://github.com/jenkins-infra/usage-log-decrypter[Usage Log Decrypter] to ensure no private data, like private-source plugin usage information,"
  },
  "5242": {
    "source_file": "usage-statistics.txt",
    "text": "the https://github.com/jenkins-infra/usage-log-decrypter[Usage Log Decrypter] to ensure no private data, like private-source plugin usage information, is published.\nOnly members of the  have the decryption key.\n\nThe data is then further transformed using https://github.com/jenkinsci/infra-statistics[various scripts] and then published on https://stats.jenkins.io\n\nA number of different statistics a"
  },
  "5243": {
    "source_file": "usage-statistics.txt",
    "text": "sing https://github.com/jenkinsci/infra-statistics[various scripts] and then published on https://stats.jenkins.io\n\nA number of different statistics are published on https://stats.jenkins.io/[stats.jenkins.io].\nThe following stats are most useful to plugin developers:\n\n* https://stats.jenkins.io/plugin-installation-trend/[Plugin Installation Trend] contains the raw numbers for known installations "
  },
  "5244": {
    "source_file": "usage-statistics.txt",
    "text": "plugin developers:\n\n* https://stats.jenkins.io/plugin-installation-trend/[Plugin Installation Trend] contains the raw numbers for known installations of each plugin, both by version and total.\n* https://stats.jenkins.io/pluginversions/[Install Counts Per Plugin Version and Core Version] provides tables showing what versions of any given plugin are installed on what versions of Jenkins.\n  This can "
  },
  "5245": {
    "source_file": "usage-statistics.txt",
    "text": " Per Plugin Version and Core Version] provides tables showing what versions of any given plugin are installed on what versions of Jenkins.\n  This can help plugin maintainers decide on Jenkins baselines to depend on."
  },
  "5246": {
    "source_file": "use-plugin-bill-of-materials.txt",
    "text": "layout: developersection\ntitle: Use plugin bill of materials\n\n\n.Simplify dependency management with the plugin bill of materials\n\nvideo::pk1gweLvcEI[youtube,width=800,height=420,start=1749]\n\nUpdating the versions of plugin dependencies manually can be exhausting, looking for the correct set of versions that work with each other and do not cause upper-bounds dependency error reports.\nThe  simplifie"
  },
  "5247": {
    "source_file": "use-plugin-bill-of-materials.txt",
    "text": "e exhausting, looking for the correct set of versions that work with each other and do not cause upper-bounds dependency error reports.\nThe  simplifies that by shifting the evaluation of versions from each plugin author to a centralized process maintained by members of the Jenkins community.\n\n// Create the branch\n\nAdd a `dependencyManagement` section to the `dependencies` section of the pom file t"
  },
  "5248": {
    "source_file": "use-plugin-bill-of-materials.txt",
    "text": "ained by members of the Jenkins community.\n\n// Create the branch\n\nAdd a `dependencyManagement` section to the `dependencies` section of the pom file that references the  of the plugin bill of materials for that line.\nFor example, the addition might look like:\n\n<dependencyManagement>\n  <dependencies>\n    <dependency>\n      <groupId>io.jenkins.tools.bom</groupId>\n      <artifactId>bom-2.504.x</artif"
  },
  "5249": {
    "source_file": "use-plugin-bill-of-materials.txt",
    "text": "ook like:\n\n<dependencyManagement>\n  <dependencies>\n    <dependency>\n      <groupId>io.jenkins.tools.bom</groupId>\n      <artifactId>bom-2.504.x</artifactId>\n      <version>5701.va_b_018a_a_6b_0d3</version>\n      <scope>import</scope>\n      <type>pom</type>\n    </dependency>\n  </dependencies>\n</dependencyManagement>\n\nRemove as many `<version>` declarations from the pom file as you can while still c"
  },
  "5250": {
    "source_file": "use-plugin-bill-of-materials.txt",
    "text": "/type>\n    </dependency>\n  </dependencies>\n</dependencyManagement>\n\nRemove as many `<version>` declarations from the pom file as you can while still compiling successfully.\n\n// Compile the plugin\n\nConfirm that there are no errors reported and no test failures reported.\n\n// Create a pull request"
  },
  "5251": {
    "source_file": "use-plugin-bill-of-materials.txt",
    "text": " failures reported.\n\n// Create a pull request"
  },
  "5252": {
    "source_file": "user-content.txt",
    "text": "title: Rendering User Content\nlayout: section\n\n\nifdef::env-github[:imagesdir: ../resources]\nifndef::env-github[:imagesdir: ../../resources]\n\nMultiple features of Jenkins, and many more in plugins, serve files that can be viewed or downloaded from Jenkins.\nSome built-in examples of that are the workspace browser, archived artifacts, file parameters to builds, or the `/userContent/` directory.\nPlugi"
  },
  "5253": {
    "source_file": "user-content.txt",
    "text": "kins.\nSome built-in examples of that are the workspace browser, archived artifacts, file parameters to builds, or the `/userContent/` directory.\nPlugins like plugin:javadoc[Javadoc], plugin:htmlpublisher[HTML Publisher], or plugin:maven-plugin[Maven Integration] (when publishing the Maven site) prominently feature functionality that serves HTML controlled by users from Jenkins.\n\nThis can be a risk"
  },
  "5254": {
    "source_file": "user-content.txt",
    "text": "Integration] (when publishing the Maven site) prominently feature functionality that serves HTML controlled by users from Jenkins.\n\nThis can be a risk, as https://owasp.org/www-community/attacks/xss/[Cross-Site Scripting] attacks could be put into those HTML files by people with influence over builds who may not be fully trusted.\n\nBy default, Jenkins serves files that could come from less trusted "
  },
  "5255": {
    "source_file": "user-content.txt",
    "text": "ose HTML files by people with influence over builds who may not be fully trusted.\n\nBy default, Jenkins serves files that could come from less trusted sources with a strict `Content-Security-Policy` HTTP response header.\nThis default prevents all JavaScript and other active elements, and only allows CSS and images served from other files in Jenkins.\n\nWhile this is safe, it also prevents a lot of us"
  },
  "5256": {
    "source_file": "user-content.txt",
    "text": "Script and other active elements, and only allows CSS and images served from other files in Jenkins.\n\nWhile this is safe, it also prevents a lot of useful functionality from working, such as rich, dynamic HTML reports created during builds.\nIt is possible to .\nThis is often a difficult tradeoff between functionality and security, so should only be done with great care.\n\nAs an alternative to relaxi"
  },
  "5257": {
    "source_file": "user-content.txt",
    "text": "sible to .\nThis is often a difficult tradeoff between functionality and security, so should only be done with great care.\n\nAs an alternative to relaxing `Content-Security-Policy`, administrators can configure Jenkins to serve files from potentially less trusted sources from a different domain.\nThis option can be configured in _Manage Jenkins \u00bb System_ in the section _Serve resource files from anot"
  },
  "5258": {
    "source_file": "user-content.txt",
    "text": "ess trusted sources from a different domain.\nThis option can be configured in _Manage Jenkins \u00bb System_ in the section _Serve resource files from another domain_.\n\n// TODO Screenshot\n\n// All of what follows is taken from https://github.com/jenkinsci/jenkins/blob/master/core/src/main/resources/jenkins/security/ResourceDomainConfiguration/help-url.html\n\nIf the resource root URL is defined, Jenkins w"
  },
  "5259": {
    "source_file": "user-content.txt",
    "text": "jenkins/blob/master/core/src/main/resources/jenkins/security/ResourceDomainConfiguration/help-url.html\n\nIf the resource root URL is defined, Jenkins will instead redirect requests for user-created resource files to URLs starting with the URL configured here.\nThese URLs will not set the CSP header, allowing JavaScript and similar features to work.\nFor this option to work as expected, the following "
  },
  "5260": {
    "source_file": "user-content.txt",
    "text": "ed here.\nThese URLs will not set the CSP header, allowing JavaScript and similar features to work.\nFor this option to work as expected, the following constraints and considerations apply:\n\n* The resource root URL must be a valid alternative choice for the Jenkins URL for requests to be processed correctly.\n* The Jenkins URL must be set and it must be different from this resource root URL (in fact,"
  },
  "5261": {
    "source_file": "user-content.txt",
    "text": "r the Jenkins URL for requests to be processed correctly.\n* The Jenkins URL must be set and it must be different from this resource root URL (in fact, a different host name is required).\n* Once set, Jenkins will only serve resource URL requests via the resource root URL.\n  All other requests will get _HTTP 404 Not Found_ responses.\n\nOnce this URL has been set up correctly, Jenkins will redirect re"
  },
  "5262": {
    "source_file": "user-content.txt",
    "text": "he resource root URL.\n  All other requests will get _HTTP 404 Not Found_ responses.\n\nOnce this URL has been set up correctly, Jenkins will redirect requests to workspaces, archived artifacts, and similar collections of usually user-generated content to URLs starting with the resource root URL.\nInstead of a path like `job/name_here/ws`, resource URLs will contain a token encoding that path, the use"
  },
  "5263": {
    "source_file": "user-content.txt",
    "text": "to URLs starting with the resource root URL.\nInstead of a path like `job/name_here/ws`, resource URLs will contain a token encoding that path, the user for which the URL was created, and when it was created.\nThese resource URLs access static files as if the user for which they were created would access them: If the user\u2019s permission to access these files is removed, the corresponding resource URLs"
  },
  "5264": {
    "source_file": "user-content.txt",
    "text": " if the user for which they were created would access them: If the user\u2019s permission to access these files is removed, the corresponding resource URLs will not work anymore either.\n**These URLs are accessible to anyone without authentication until they expire, so sharing these URLs is akin to sharing the files directly.**\n\nResource URLs do not require authentication (users will not have a valid se"
  },
  "5265": {
    "source_file": "user-content.txt",
    "text": "ey expire, so sharing these URLs is akin to sharing the files directly.**\n\nResource URLs do not require authentication (users will not have a valid session for the resource root URL).\nSharing a resource URL with another user, even one lacking Overall/Read permission for Jenkins, will grant that user access to these files until the URLs expire.\n\nResource URLs expire after 30 minutes by default.\nExp"
  },
  "5266": {
    "source_file": "user-content.txt",
    "text": "/Read permission for Jenkins, will grant that user access to these files until the URLs expire.\n\nResource URLs expire after 30 minutes by default.\nExpired resource URLs will redirect users to their equivalent Jenkins URLs, so that the user can reauthenticate, if necessary, and then be redirected back to a new resource URL that will be valid for another 30 minutes.\nThis will generally be transparen"
  },
  "5267": {
    "source_file": "user-content.txt",
    "text": "enticate, if necessary, and then be redirected back to a new resource URL that will be valid for another 30 minutes.\nThis will generally be transparent to the user if they have a valid Jenkins session.\nOtherwise, they will need to authenticate with Jenkins again.\nHowever, when browsing pages with HTML frames, like Javadoc sites, the login form cannot appear in a frame.\nIn these cases, users will n"
  },
  "5268": {
    "source_file": "user-content.txt",
    "text": "enkins again.\nHowever, when browsing pages with HTML frames, like Javadoc sites, the login form cannot appear in a frame.\nIn these cases, users will need to reload the top-level frame to make the login form appear.\n\nTo change how quickly resource URLs expire, set the system property `jenkins.security.ResourceDomainRootAction.validForMinutes` to the desired value in minutes.\nEarlier expiration migh"
  },
  "5269": {
    "source_file": "user-content.txt",
    "text": "s expire, set the system property `jenkins.security.ResourceDomainRootAction.validForMinutes` to the desired value in minutes.\nEarlier expiration might make it harder to use these URLs, while later expiration increases the likelihood of unauthorized users gaining access through URLs shared with them by authorized users.\n\nResource URLs encode the URL, the user for which they were created, and their"
  },
  "5270": {
    "source_file": "user-content.txt",
    "text": "users gaining access through URLs shared with them by authorized users.\n\nResource URLs encode the URL, the user for which they were created, and their creation timestamp.\nAdditionally, this string contains an https://en.wikipedia.org/wiki/HMAC[HMAC] to ensure the authenticity of the URL.\nThis prevents attackers from forging URLs that would grant them access to resource files as if they were anothe"
  },
  "5271": {
    "source_file": "user-content.txt",
    "text": "to ensure the authenticity of the URL.\nThis prevents attackers from forging URLs that would grant them access to resource files as if they were another user."
  },
  "5272": {
    "source_file": "users.txt",
    "text": "layout: section\ntitle: Users\n\n\nifdef::env-github[:imagesdir: ../resources]\nifndef::env-github[:imagesdir: ../../resources]\n\nManaging users in Jenkins involves creating, configuring, and maintaining user accounts for individuals who interact with the Jenkins instance. This page provides a step-by-step guide on how to manage users effectively.\n\n_Jenkins supports external authentication systems like "
  },
  "5273": {
    "source_file": "users.txt",
    "text": "Jenkins instance. This page provides a step-by-step guide on how to manage users effectively.\n\n_Jenkins supports external authentication systems like GitHub, GitLab, Google, and LDAP. If an external authentication method is configured, user management may be handled outside Jenkins. This guide applies only when using Jenkins' **internal user database**._\n\nIn Jenkins, managing users refers to the p"
  },
  "5274": {
    "source_file": "users.txt",
    "text": "t may be handled outside Jenkins. This guide applies only when using Jenkins' **internal user database**._\n\nIn Jenkins, managing users refers to the process of creating, configuring, and maintaining user accounts. This includes:\n\n- Creating new users.\n- Configuring user details such as full name, email address, and password.\n- Modifying user information.\n- Deleting users.\n\nAdministrators with the "
  },
  "5275": {
    "source_file": "users.txt",
    "text": ".\n- Configuring user details such as full name, email address, and password.\n- Modifying user information.\n- Deleting users.\n\nAdministrators with the appropriate permissions can perform these actions.\n\nTo manage users in Jenkins, you need to have administrative privileges. Follow these steps to access the user management section:\n\nLog in to your Jenkins instance with an account that has administra"
  },
  "5276": {
    "source_file": "users.txt",
    "text": "inistrative privileges. Follow these steps to access the user management section:\n\nLog in to your Jenkins instance with an account that has administrative permissions.\nNavigate to the **Manage Jenkins** page from the Jenkins dashboard.\nSelect **Users** under the **Security** section.\nTo create a new user in Jenkins:\n\nOn the **Users** page, select **Create User**.\nFill in the required details:\n   -"
  },
  "5277": {
    "source_file": "users.txt",
    "text": "** under the **Security** section.\nTo create a new user in Jenkins:\n\nOn the **Users** page, select **Create User**.\nFill in the required details:\n   - **Username**: A unique identifier for the user.\n   - **Password**: A secure password for the user.\n   - **Confirm Password**: Re-enter the password.\n   - **Full Name**: The full name of the user.\n   - **Email Address**: The email address of the user"
  },
  "5278": {
    "source_file": "users.txt",
    "text": "   - **Confirm Password**: Re-enter the password.\n   - **Full Name**: The full name of the user.\n   - **Email Address**: The email address of the user.\nSelect **Create User** to save the new user.\nFor example:\nOnce a user is created, you can configure their settings:\n\nOn the **Manage Users** page, select the user you want to configure.\nUpdate the following details as needed:\n   - **Full Name**: Ed"
  },
  "5279": {
    "source_file": "users.txt",
    "text": "e their settings:\n\nOn the **Manage Users** page, select the user you want to configure.\nUpdate the following details as needed:\n   - **Full Name**: Edit the user's full name.\n   - **Description**: Update the user's description.\n   - **Credentials**: Change the user's credentials.\nSelect **Save** to apply the changes.\n\nAdministrators can modify user information at any time:\n\nNavigate to the **Manag"
  },
  "5280": {
    "source_file": "users.txt",
    "text": "Change the user's credentials.\nSelect **Save** to apply the changes.\n\nAdministrators can modify user information at any time:\n\nNavigate to the **Manage Users** page.\nSelect the user whose information you want to modify.\nUpdate the relevant fields such as full name, email address, or password.\nSelect **Save** to apply the changes.\n\nTo remove a user from Jenkins, there are two approaches. Let\u2019s expl"
  },
  "5281": {
    "source_file": "users.txt",
    "text": "h as full name, email address, or password.\nSelect **Save** to apply the changes.\n\nTo remove a user from Jenkins, there are two approaches. Let\u2019s explore both of them:\n\nNavigate to **Users**.\nFind the user you want to delete.\nSelect the **Delete** option next to the user\u2019s name.\nConfirm the deletion.\n\nNavigate to **Manage Jenkins**.\nThen navigate to **Users**.\nSelect the trash icon on the right-mo"
  },
  "5282": {
    "source_file": "users.txt",
    "text": "tion next to the user\u2019s name.\nConfirm the deletion.\n\nNavigate to **Manage Jenkins**.\nThen navigate to **Users**.\nSelect the trash icon on the right-most side of the user you want to delete.\nConfirm the deletion.\n\nWARNING: Deleting a user **permanently removes their account** from Jenkins. Make sure they don't have active jobs or responsibilities before proceeding.\n\nUser management is closely tied "
  },
  "5283": {
    "source_file": "users.txt",
    "text": "y removes their account** from Jenkins. Make sure they don't have active jobs or responsibilities before proceeding.\n\nUser management is closely tied to Jenkins' security settings. For more information on configuring permissions and authorization, refer to the  documentation.\n\nHere are some common issues you may encounter while managing users:\n\n- **User creation fails:** Ensure that all required f"
  },
  "5284": {
    "source_file": "users.txt",
    "text": "fer to the  documentation.\n\nHere are some common issues you may encounter while managing users:\n\n- **User creation fails:** Ensure that all required fields are filled and the username is unique.\n- **User permissions are incorrect:** Check the security settings under *Manage Jenkins > Configure Global Security*.\n- **Cannot delete a user:** If a user is associated with active jobs, consider disablin"
  },
  "5285": {
    "source_file": "users.txt",
    "text": "y settings under *Manage Jenkins > Configure Global Security*.\n- **Cannot delete a user:** If a user is associated with active jobs, consider disabling their account instead of deleting it.\n\nManaging users in Jenkins is a straightforward process that involves creating users, configuring their settings, and ensuring they have the appropriate permissions. By following this guide, you can effectively"
  },
  "5286": {
    "source_file": "users.txt",
    "text": " involves creating users, configuring their settings, and ensuring they have the appropriate permissions. By following this guide, you can effectively manage users in your Jenkins instance."
  },
  "5287": {
    "source_file": "using-agents.txt",
    "text": "layout: section\ntitle: Using Jenkins agents\n\n\nifdef::env-github[:imagesdir: ../resources]\nifndef::env-github[:imagesdir: ../../resources]\n\nThe Jenkins architecture is designed for distributed build environments.\nIt allows us to use different environments for each build project balancing\nthe workload among multiple agents running jobs in parallel.\n\nThe Jenkins controller is the original node in the"
  },
  "5288": {
    "source_file": "using-agents.txt",
    "text": "ents for each build project balancing\nthe workload among multiple agents running jobs in parallel.\n\nThe Jenkins controller is the original node in the Jenkins installation.\nThe Jenkins controller administers the Jenkins agents and orchestrates their work, including scheduling jobs on agents and monitoring agents.\nAgents may be connected to the Jenkins controller using either local or cloud compute"
  },
  "5289": {
    "source_file": "using-agents.txt",
    "text": "work, including scheduling jobs on agents and monitoring agents.\nAgents may be connected to the Jenkins controller using either local or cloud computers.\n\nThe agents require a Java installation and a network connection to the Jenkins controller.\nView the 3 minute video below for a brief explanation of Jenkins agents.\n\n.What is a Jenkins Agent\nvideo::4KghHJEz5no[youtube, width=640, height=360]\n\nJen"
  },
  "5290": {
    "source_file": "using-agents.txt",
    "text": " the 3 minute video below for a brief explanation of Jenkins agents.\n\n.What is a Jenkins Agent\nvideo::4KghHJEz5no[youtube, width=640, height=360]\n\nJenkins agents provide executors that perform work when requested by the Jenkins controller.\nAgents can run Pipeline steps, freestyle jobs, and other jobs.\n\nSpecific capabilities of agents are often noted by assigning labels to the agents.\nAn agent runn"
  },
  "5291": {
    "source_file": "using-agents.txt",
    "text": " run Pipeline steps, freestyle jobs, and other jobs.\n\nSpecific capabilities of agents are often noted by assigning labels to the agents.\nAn agent running on an Arm64 computer might be assigned the `aarch64` label so that jobs can limit themselves to only run on agents with the Arm64 processor.\nAn agent running with a code signing application might be assigned the `code-signing` label so that jobs "
  },
  "5292": {
    "source_file": "using-agents.txt",
    "text": "only run on agents with the Arm64 processor.\nAn agent running with a code signing application might be assigned the `code-signing` label so that jobs that need to sign executables would run there.\n\nAgents may be allowed to run any job or they may be restricted to only run jobs that are specifically assigned to the agent.\n\nThe number of executors determines how many concurrent tasks can be run on a"
  },
  "5293": {
    "source_file": "using-agents.txt",
    "text": "restricted to only run jobs that are specifically assigned to the agent.\n\nThe number of executors determines how many concurrent tasks can be run on an agent.\nFor Jenkins controllers, it is recommended to set this to `0` to avoid resource contention.\nExecutors should be configured on agents (nodes) instead.\n\n*Why set executors to 0 on the controller?*\nSetting executors to `0` ensures that the cont"
  },
  "5294": {
    "source_file": "using-agents.txt",
    "text": "\nExecutors should be configured on agents (nodes) instead.\n\n*Why set executors to 0 on the controller?*\nSetting executors to `0` ensures that the controller is dedicated to managing builds and coordinating agents, rather than executing builds itself.\nThis improves stability and performance.\n\nFor instance, agents with specific capabilities can be configured with multiple executors to handle concurr"
  },
  "5295": {
    "source_file": "using-agents.txt",
    "text": "\nThis improves stability and performance.\n\nFor instance, agents with specific capabilities can be configured with multiple executors to handle concurrent builds effectively.\n\nLabels are used to group agents (nodes) based on specific criteria.\nThey help in assigning jobs to specific agents.\nFor example, you can label agents based on their operating system or hardware capabilities.\n\nExample:\n\nlinux,"
  },
  "5296": {
    "source_file": "using-agents.txt",
    "text": "lp in assigning jobs to specific agents.\nFor example, you can label agents based on their operating system or hardware capabilities.\n\nExample:\n\nlinux, windows, docker, high-memory\n\nLabels can be assigned in the agent configuration settings.\n\nThis section defines how jobs are assigned to agents.\nOptions include:\n\n* **Use this node as much as possible**: Jobs will be assigned to this node whenever p"
  },
  "5297": {
    "source_file": "using-agents.txt",
    "text": "tion defines how jobs are assigned to agents.\nOptions include:\n\n* **Use this node as much as possible**: Jobs will be assigned to this node whenever possible.\n* **Only build jobs with label expressions matching this node**: Jobs will only be assigned if their label matches.\n\nJenkins agents can be launched in physical machines, virtual machines, Kubernetes clusters, and with Docker images.\nThis sec"
  },
  "5298": {
    "source_file": "using-agents.txt",
    "text": " if their label matches.\n\nJenkins agents can be launched in physical machines, virtual machines, Kubernetes clusters, and with Docker images.\nThis section connects Docker agents to Jenkins with SSH.\n\nTo run this guide you will need a machine with:\n\n* Java installation\n* Jenkins installation\n* Docker installation\n* SSH key pair\n\nIf you need help to install Java, Jenkins and Docker please visit the "
  },
  "5299": {
    "source_file": "using-agents.txt",
    "text": " Java installation\n* Jenkins installation\n* Docker installation\n* SSH key pair\n\nIf you need help to install Java, Jenkins and Docker please visit the section\n\nTo generate the SSH key pair, you have to execute a command line tool named `ssh-keygen` on a machine you have access to. It could be:\n\n * the machine on which your Jenkins controller runs\n * the host (if using containers)\n * a machine on wh"
  },
  "5300": {
    "source_file": "using-agents.txt",
    "text": " a machine you have access to. It could be:\n\n * the machine on which your Jenkins controller runs\n * the host (if using containers)\n * a machine on which you have an agent running\n * or even your developer machine\n\nThe SSH key pair generation can be done on any operating system:\n\n* On Windows, you can use any OpenSSH installation such as https://docs.microsoft.com/en-us/windows-server/administrati"
  },
  "5301": {
    "source_file": "using-agents.txt",
    "text": "done on any operating system:\n\n* On Windows, you can use any OpenSSH installation such as https://docs.microsoft.com/en-us/windows-server/administration/openssh/openssh_install_firstuse[Windows OpenSSH], the `ssh-keygen` that is included with https://gitforwindows.org/[git for Windows], or https://cygwin.com/[Cygwin]\n * On Unix (Linux, macOS, BSD, etc.) you can use any OpenSSH installation package"
  },
  "5302": {
    "source_file": "using-agents.txt",
    "text": "/gitforwindows.org/[git for Windows], or https://cygwin.com/[Cygwin]\n * On Unix (Linux, macOS, BSD, etc.) you can use any OpenSSH installation packaged with your system as well\n\nTIP: Note that you will have to be able to copy the key value to your controller and agent afterwards, so check that you can copy a file content into the clipboard beforehand.\n\n1. In a terminal window run the command: `ssh"
  },
  "5303": {
    "source_file": "using-agents.txt",
    "text": "ntroller and agent afterwards, so check that you can copy a file content into the clipboard beforehand.\n\n1. In a terminal window run the command: `ssh-keygen -f ~/.ssh/jenkins_agent_key`\n2. Provide a passphrase to use with the key (it can be empty)\n3. Confirm the output looks something like this:\nubuntu@desktop:~$ ssh-keygen -f ~/.ssh/jenkins_agent_key\nGenerating public/private rsa key pair.\nEnter"
  },
  "5304": {
    "source_file": "using-agents.txt",
    "text": ". Confirm the output looks something like this:\nubuntu@desktop:~$ ssh-keygen -f ~/.ssh/jenkins_agent_key\nGenerating public/private rsa key pair.\nEnter passphrase (empty for no passphrase):\nEnter same passphrase again:\nYour identification has been saved in /home/ubuntu/.ssh/jenkins_agent_key\nYour public key has been saved in /home/ubuntu/.ssh/jenkins_agent_key.pub\nThe key fingerprint is:\nSHA256:Xqx"
  },
  "5305": {
    "source_file": "using-agents.txt",
    "text": "ed in /home/ubuntu/.ssh/jenkins_agent_key\nYour public key has been saved in /home/ubuntu/.ssh/jenkins_agent_key.pub\nThe key fingerprint is:\nSHA256:XqxxjqsLlvDD0ZHm9Y2iR7zC6IbsUlMEHo3ffy8TzGs\nThe key's randomart image is:\n---[RSA 3072]+\n|  o+             |\n| ...o  .         |\n|  .o .+ .        |\n|    o+.+ o o     |\n|  ... o.So* .    |\n|  o+ = +.X=      |\n| o oO + *..+     |\n|. oo.o o .E .    |\n| o."
  },
  "5306": {
    "source_file": "using-agents.txt",
    "text": "    |\n| ...o  .         |\n|  .o .+ .        |\n|    o+.+ o o     |\n|  ... o.So* .    |\n|  o+ = +.X=      |\n| o oO + *..+     |\n|. oo.o o .E .    |\n| o... oo.. o     |\n[SHA256]-+\n\nFrom your Jenkins dashboard, navigate to *Manage Jenkins*.\nIn the Security section, select *Credentials*.\nUnder *Stores scoped to Jenkins*, select `Add Credentials` from the global option.\nFill in the following information"
  },
  "5307": {
    "source_file": "using-agents.txt",
    "text": "ty section, select *Credentials*.\nUnder *Stores scoped to Jenkins*, select `Add Credentials` from the global option.\nFill in the following information, as shown in the example, substituting your information as needed:\n* Kind: SSH username with private key\n* ID: jenkins\n* Description: The Jenkins SSH key\n* Username: jenkins\n* Private Key: Select *Enter directly* and then select *Add* to insert the "
  },
  "5308": {
    "source_file": "using-agents.txt",
    "text": "e key\n* ID: jenkins\n* Description: The Jenkins SSH key\n* Username: jenkins\n* Private Key: Select *Enter directly* and then select *Add* to insert the content of your private key file (`~/.ssh/jenkins_agent_key`).\n* Passphrase: Enter the passphrase used to generate the SSH key pair (or leave it empty if you didn't use one in the previous step).\nSelect *Create* to complete your credential configurat"
  },
  "5309": {
    "source_file": "using-agents.txt",
    "text": "ed to generate the SSH key pair (or leave it empty if you didn't use one in the previous step).\nSelect *Create* to complete your credential configuration.\n\nHere we will use the  to create the agent containers.\n\n1. run the command to start your first agent:\ndocker run -d --rm --name=agent1 -p 22:22 \\\n-e \"JENKINS_AGENT_SSH_PUBKEY=<your_public_key>\" \\\njenkins/ssh-agent:alpine-jdk21\n\n* Remember to rep"
  },
  "5310": {
    "source_file": "using-agents.txt",
    "text": "agent:\ndocker run -d --rm --name=agent1 -p 22:22 \\\n-e \"JENKINS_AGENT_SSH_PUBKEY=<your_public_key>\" \\\njenkins/ssh-agent:alpine-jdk21\n\n* Remember to replace the tag <your_public_key> for your own SSH *public* key.\n* Your public key value in this example could be found by issuing : `cat ~/.ssh/jenkins_agent_key.pub` on the machine your created it. Do not add the square brackets `[]` around the key va"
  },
  "5311": {
    "source_file": "using-agents.txt",
    "text": "e could be found by issuing : `cat ~/.ssh/jenkins_agent_key.pub` on the machine your created it. Do not add the square brackets `[]` around the key value\n* The value of [your-public-key] MUST include the full contents of your .pub file, including the `ssh-XXXX` prefix.\n** Ex: `ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAAAQQCo9+BpMRYQ/dL3DS2CyJxRF+j6ctbT3/Qp84+KeFhnii7NT7fELilKUSnxS30WAvQCCo2yU1orfgqr41mM70"
  },
  "5312": {
    "source_file": "using-agents.txt",
    "text": " `ssh-XXXX` prefix.\n** Ex: `ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAAAQQCo9+BpMRYQ/dL3DS2CyJxRF+j6ctbT3/Qp84+KeFhnii7NT7fELilKUSnxS30WAvQCCo2yU1orfgqr41mM70MB`\n* [[ssh-anchor]] If your machine already has a ssh server running on the `22` port (if you logged onto this machine thanks to the `ssh` command, that's the case), you should use another port for the `docker` command, such as `-p 4444:22`\n\n2. Now "
  },
  "5313": {
    "source_file": "using-agents.txt",
    "text": "d onto this machine thanks to the `ssh` command, that's the case), you should use another port for the `docker` command, such as `-p 4444:22`\n\n2. Now the container `agent1` is running. +\nHint: the command `docker ps` can be used to check if the container is running as expected.\n\nHere we will use the  to create the agent containers.\n\n1. run the command to start your first agent:\ndocker run -d --rm "
  },
  "5314": {
    "source_file": "using-agents.txt",
    "text": "iner is running as expected.\n\nHere we will use the  to create the agent containers.\n\n1. run the command to start your first agent:\ndocker run -d --rm --name=agent1 --network jenkins -p 22:22 `\n  -e \"JENKINS_AGENT_SSH_PUBKEY=<your_public_key>\" `\n  jenkins/ssh-agent:jdk21\n\n* Remember to replace the tag <your_public_key> for your own SSH *public* key.\n* Your public key in this example is: `Get-Conten"
  },
  "5315": {
    "source_file": "using-agents.txt",
    "text": "kins/ssh-agent:jdk21\n\n* Remember to replace the tag <your_public_key> for your own SSH *public* key.\n* Your public key in this example is: `Get-Content $Env:USERPROFILE\\.ssh\\jenkins_agent_key.pub`\n\n2. Now the container `agent1` is running. +\nHint: the command `docker ps` can be used to check if the container is running as expected.\nAdditionally, the command `docker container inspect agent1 | Selec"
  },
  "5316": {
    "source_file": "using-agents.txt",
    "text": "e command `docker ps` can be used to check if the container is running as expected.\nAdditionally, the command `docker container inspect agent1 | Select-String -Pattern '\"IPAddress\": \"\\d+\\.\\d+\\.\\d+\\.\\d+\"'` can be used to see the *Host* to be set in Jenkins for the agent.\n\nFrom your Jenkins dashboard, navigate to *Manage Jenkins*.\nSelect *Nodes*.\nSelect *New Node* to create your agent.\nEnter your No"
  },
  "5317": {
    "source_file": "using-agents.txt",
    "text": "nkins for the agent.\n\nFrom your Jenkins dashboard, navigate to *Manage Jenkins*.\nSelect *Nodes*.\nSelect *New Node* to create your agent.\nEnter your Node name, select the Permanent Agent option, and select *Create*.\nOn the agent creation page fill in the fields:\n* Remote root directory\n* Labels\n* Usage\n* Launch method\n** Host\n** Credentials\n** Host Key verification Strategy\nSelect *Save* and `agent"
  },
  "5318": {
    "source_file": "using-agents.txt",
    "text": "the fields:\n* Remote root directory\n* Labels\n* Usage\n* Launch method\n** Host\n** Credentials\n** Host Key verification Strategy\nSelect *Save* and `agent1` will be registered, but offline for the time being.\nSelect the `agent1` node to view its status.\n\nThe status page should show the message: `This node is being launched.`\nIf that's not the case, select *Relaunch agent* and wait a few seconds.\n\nAfte"
  },
  "5319": {
    "source_file": "using-agents.txt",
    "text": "\nThe status page should show the message: `This node is being launched.`\nIf that's not the case, select *Relaunch agent* and wait a few seconds.\n\nAfter waiting, select the `Log` option to view the logs.\nAt the bottom of the log, you should receive the message: `Agent successfully connected and online`.\n\nIf your Jenkins controller does not start the agent via ssh, please check the port you <<ssh-an"
  },
  "5320": {
    "source_file": "using-agents.txt",
    "text": "e message: `Agent successfully connected and online`.\n\nIf your Jenkins controller does not start the agent via ssh, please check the port you <<ssh-anchor,configured>> on your agent.\nCopy the port number and then select *Advanced*.\nUnder *Advanced*, you can paste the port number into the *Port* field.\n\nFrom your Jenkins dashboard select *New Item*.\nEnter a name, for example, `First job on agent1`."
  },
  "5321": {
    "source_file": "using-agents.txt",
    "text": "you can paste the port number into the *Port* field.\n\nFrom your Jenkins dashboard select *New Item*.\nEnter a name, for example, `First job on agent1`.\nSelect *Freestyle project* and select OK to create the job.\nSelect the option *Restrict where this project can be run*.\nEnter the node label (`agent1`) in the *Label Expression* field.\nBe careful with white spaces before or after the label.\n\nSelect "
  },
  "5322": {
    "source_file": "using-agents.txt",
    "text": "project can be run*.\nEnter the node label (`agent1`) in the *Label Expression* field.\nBe careful with white spaces before or after the label.\n\nSelect the *Execute shell* option from the *Build Steps* dropdown;\nAdd the command: `echo $NODE_NAME` in the *Command* field and the name of the agent will be printed inside the log when this job is run.\nSelect *Save* and then select *Build Now*.\nWait a few"
  },
  "5323": {
    "source_file": "using-agents.txt",
    "text": "e *Command* field and the name of the agent will be printed inside the log when this job is run.\nSelect *Save* and then select *Build Now*.\nWait a few seconds, and then go to *Console Output* page.\nYou should receive output similar to:\nThis video provides instructions on how to restart a Jenkins agent using various methods.\n\nvideo::MTLgbp0GH8w[youtube,width=800,height=420]"
  },
  "5324": {
    "source_file": "using-agents.txt",
    "text": "vides instructions on how to restart a Jenkins agent using various methods.\n\nvideo::MTLgbp0GH8w[youtube,width=800,height=420]"
  },
  "5325": {
    "source_file": "using-credentials.txt",
    "text": "layout: section\ntitle: Using credentials\n\n\nThere are numerous 3rd-party sites and applications that can interact with\nJenkins, for example, artifact repositories, cloud-based storage systems and\nservices, and so on.\n\nA systems administrator of such an application can configure credentials in the\napplication for dedicated use by Jenkins. This would typically be done to \"lock\ndown\" areas of the appl"
  },
  "5326": {
    "source_file": "using-credentials.txt",
    "text": "n application can configure credentials in the\napplication for dedicated use by Jenkins. This would typically be done to \"lock\ndown\" areas of the application's functionality available to Jenkins, usually by\napplying access controls to these credentials. Once a Jenkins manager (i.e. a\nJenkins user who administers a Jenkins site) adds/configures these credentials\nin Jenkins, the credentials can be u"
  },
  "5327": {
    "source_file": "using-credentials.txt",
    "text": "ls. Once a Jenkins manager (i.e. a\nJenkins user who administers a Jenkins site) adds/configures these credentials\nin Jenkins, the credentials can be used by Pipeline projects to interact with\nthese 3rd party applications.\n\n*Note:* The Jenkins credentials functionality described on this and related\npages is provided by the plugin:credentials-binding[Credentials Binding plugin].\n\n.The correct way to"
  },
  "5328": {
    "source_file": "using-credentials.txt",
    "text": "ials functionality described on this and related\npages is provided by the plugin:credentials-binding[Credentials Binding plugin].\n\n.The correct way to handle credentials in Jenkins\nvideo::yfjtMIDgmfs[youtube,width=800,height=420]\n\nCredentials stored in Jenkins can be used:\n\n* anywhere applicable throughout Jenkins (global credentials),\n  [[types-of-credentials]]\n* by a specific Pipeline project/it"
  },
  "5329": {
    "source_file": "using-credentials.txt",
    "text": "in Jenkins can be used:\n\n* anywhere applicable throughout Jenkins (global credentials),\n  [[types-of-credentials]]\n* by a specific Pipeline project/item (read more about this in the\n\n  section of ),\n* by a specific Jenkins user (as is the case for\n  ).\n\nJenkins can store the following types of credentials:\n\n* *Secret text* - a token such as an API token or GitHub personal access\n  token,\n* *Userna"
  },
  "5330": {
    "source_file": "using-credentials.txt",
    "text": ").\n\nJenkins can store the following types of credentials:\n\n* *Secret text* - a token such as an API token or GitHub personal access\n  token,\n* *Username and password* - which could be handled as separate components or as\n  a colon separated string in the format `username:password` (read more about\n  this in\n  ),\n* *Secret file* - which is essentially secret content in a file,\n* *SSH Username with "
  },
  "5331": {
    "source_file": "using-credentials.txt",
    "text": " the format `username:password` (read more about\n  this in\n  ),\n* *Secret file* - which is essentially secret content in a file,\n* *SSH Username with private key* - an\n  ,\n* *Certificate* - a  and optional password, or\n* *Docker Host Certificate Authentication* credentials.\n\nTo maximize security, credentials configured in Jenkins are stored in an\nencrypted form on the controller Jenkins controller"
  },
  "5332": {
    "source_file": "using-credentials.txt",
    "text": "entication* credentials.\n\nTo maximize security, credentials configured in Jenkins are stored in an\nencrypted form on the controller Jenkins controller (encrypted by the Jenkins\ncontroller ID) and are only handled in Pipeline projects via their credential IDs.\n\nThis minimizes the chances of exposing the actual credentials themselves to\nJenkins users and hinders the ability to copy functional creden"
  },
  "5333": {
    "source_file": "using-credentials.txt",
    "text": "tial IDs.\n\nThis minimizes the chances of exposing the actual credentials themselves to\nJenkins users and hinders the ability to copy functional credentials from one\nJenkins controller to another.\n\nThis section describes procedures for configuring credentials in Jenkins.\n\nCredentials can be added to Jenkins by any Jenkins user who has the *Credentials\n> Create* permission (set through *Matrix-based"
  },
  "5334": {
    "source_file": "using-credentials.txt",
    "text": "dentials in Jenkins.\n\nCredentials can be added to Jenkins by any Jenkins user who has the *Credentials\n> Create* permission (set through *Matrix-based security*). These permissions\ncan be configured by a Jenkins user with the *Administer* permission. Read more\nabout this in the\n section of\nOtherwise, any Jenkins user can add and configure credentials if the\n*Authorization* settings of your Jenkins"
  },
  "5335": {
    "source_file": "using-credentials.txt",
    "text": " Read more\nabout this in the\n section of\nOtherwise, any Jenkins user can add and configure credentials if the\n*Authorization* settings of your Jenkins controller's *Security*\nsettings page is set to the default *Logged-in users can do anything* setting or\n*Anyone can do anything* setting.\n\nTo add new global credentials to your Jenkins controller:\n\nIf required, ensure you are logged in to Jenkins ("
  },
  "5336": {
    "source_file": "using-credentials.txt",
    "text": "ng or\n*Anyone can do anything* setting.\n\nTo add new global credentials to your Jenkins controller:\n\nIf required, ensure you are logged in to Jenkins (as a user with the\n  *Credentials > Create* permission).\nFrom the Jenkins Dashboard, navigate to *Manage Jenkins > Credentials*.\nUnder *Stores scoped to Jenkins*, select *System*.\nUnder *System*, select the *Global credentials (unrestricted)* link to"
  },
  "5337": {
    "source_file": "using-credentials.txt",
    "text": "nage Jenkins > Credentials*.\nUnder *Stores scoped to Jenkins*, select *System*.\nUnder *System*, select the *Global credentials (unrestricted)* link to access\n  this default domain.\nSelect *Add Credentials* on the left. +\n  *Note:* If there are no credentials in this default domain, you could also\n  select the *add some credentials* link (which is the same as selecting the *Add\n  Credentials* link)"
  },
  "5338": {
    "source_file": "using-credentials.txt",
    "text": "dentials in this default domain, you could also\n  select the *add some credentials* link (which is the same as selecting the *Add\n  Credentials* link).\nFrom the *Kind* field, choose the\n   to add.\nFrom the *Scope* field, choose either:\n  * *Global* - if the credential/s to be added is/are for a Pipeline\n    project/item. Choosing this option applies the scope of the credential/s to\n    the Pipelin"
  },
  "5339": {
    "source_file": "using-credentials.txt",
    "text": " if the credential/s to be added is/are for a Pipeline\n    project/item. Choosing this option applies the scope of the credential/s to\n    the Pipeline project/item \"object\" and all its descendant objects.\n  * *System* - if the credential/s to be added is/are for the Jenkins controller\n    itself to interact with system administration functions, such as email\n    authentication, agent connection, "
  },
  "5340": {
    "source_file": "using-credentials.txt",
    "text": "ed is/are for the Jenkins controller\n    itself to interact with system administration functions, such as email\n    authentication, agent connection, etc. Choosing this option applies the\n    scope of the credential/s to a single object only.\nAdd the credentials themselves into the appropriate fields for your chosen\n  credential type:\n  * *Secret text* - copy the secret text and paste it into the "
  },
  "5341": {
    "source_file": "using-credentials.txt",
    "text": " credentials themselves into the appropriate fields for your chosen\n  credential type:\n  * *Secret text* - copy the secret text and paste it into the *Secret* field.\n  * *Username and password* - specify the credential's *Username* and *Password*\n    in their respective fields.\n  * *Secret file* - select the *Choose file* option next to the *File* field to\n    select the secret file to upload to J"
  },
  "5342": {
    "source_file": "using-credentials.txt",
    "text": " in their respective fields.\n  * *Secret file* - select the *Choose file* option next to the *File* field to\n    select the secret file to upload to Jenkins.\n  * *SSH Username with private key* - specify the credentials *Username*,\n    *Private Key* and optional *Passphrase* into their respective fields. +\n    *Note:* Choosing *Enter directly* allows you to copy the private key's text\n    and past"
  },
  "5343": {
    "source_file": "using-credentials.txt",
    "text": "and optional *Passphrase* into their respective fields. +\n    *Note:* Choosing *Enter directly* allows you to copy the private key's text\n    and paste it into the resulting *Key* text box.\n  * *Certificate* - specify the *Certificate* and optional *Password*. Choosing\n    *Upload PKCS#12 certificate* allows you to upload the certificate as a file\n    via the resulting *Upload certificate* button."
  },
  "5344": {
    "source_file": "using-credentials.txt",
    "text": "Password*. Choosing\n    *Upload PKCS#12 certificate* allows you to upload the certificate as a file\n    via the resulting *Upload certificate* button.\n  * *Docker Host Certificate Authentication* - copy and paste the appropriate\n    details into the *Client Key*, *Client Certificate* and *Server CA\n    Certificate* fields.\nIn the *ID* field, specify a meaningful credential ID value - for example,\n"
  },
  "5345": {
    "source_file": "using-credentials.txt",
    "text": "*Client Key*, *Client Certificate* and *Server CA\n    Certificate* fields.\nIn the *ID* field, specify a meaningful credential ID value - for example,\n  `jenkins-user-for-xyz-artifact-repository`. The inbuilt (default) credentials provider\n  can use uppercase or lowercase letters for the credential ID, as well as any valid separator character,\n  other credential providers may apply further restrict"
  },
  "5346": {
    "source_file": "using-credentials.txt",
    "text": "ppercase or lowercase letters for the credential ID, as well as any valid separator character,\n  other credential providers may apply further restrictions on allowed characters or lengths.\n  However, for the benefit of all users on your Jenkins controller, it is best to\n  use a single and consistent convention for specifying credential IDs. +\n  *Note:* This field is optional. If you do not specify"
  },
  "5347": {
    "source_file": "using-credentials.txt",
    "text": "oller, it is best to\n  use a single and consistent convention for specifying credential IDs. +\n  *Note:* This field is optional. If you do not specify its value, Jenkins\n  assigns a globally unique ID (GUID) value for the credential ID. Bear in mind\n  that once a credential ID is set, it can no longer be changed.\nSpecify an optional *Description* for the credential/s.\nSelect *OK* to save the crede"
  },
  "5348": {
    "source_file": "using-credentials.txt",
    "text": "  that once a credential ID is set, it can no longer be changed.\nSpecify an optional *Description* for the credential/s.\nSelect *OK* to save the credentials."
  },
  "5349": {
    "source_file": "using-jenkins-to-build-a-java-application-with-maven.txt",
    "text": "layout: redirect\nredirect_url: ../build-a-java-app-with-maven"
  },
  "5350": {
    "source_file": "using-jenkins-to-build-a-java-maven-project.txt",
    "text": "layout: redirect\nredirect_url: ../build-a-java-app-with-maven"
  },
  "5351": {
    "source_file": "using-jenkins-to-build-a-node-js-and-react-application-with-npm.txt",
    "text": "layout: redirect\nredirect_url: ../build-a-node-js-and-react-app-with-npm"
  },
  "5352": {
    "source_file": "using-jenkins-to-build-a-node-js-react-project.txt",
    "text": "layout: redirect\nredirect_url: ../build-a-node-js-and-react-app-with-npm"
  },
  "5353": {
    "source_file": "using-jenkinsfile-runner-github-action-to-build-jenkins-pipeline.txt",
    "text": "layout: documentation\ntitle: Build a Jenkins pipeline by using Jenkinsfile Runner GitHub Actions\nsection: doc\n\n\nThis tutorial shows you how to use  in the  context.\n\nClassical Jenkins controllers bind physically with the permanently running servers.\n packages the Jenkins core and other necessary items, and serves as an entry point to your pipeline job.\nAt a high level, Jenkinsfile Runner GitHub Ac"
  },
  "5354": {
    "source_file": "using-jenkinsfile-runner-github-action-to-build-jenkins-pipeline.txt",
    "text": " packages the Jenkins core and other necessary items, and serves as an entry point to your pipeline job.\nAt a high level, Jenkinsfile Runner GitHub Actions wrap around the Jenkinsfile Runner and other necessary modules for the user.\nOnce the user commits the changes to the remote GitHub repository, the GitHub Actions will run the pipeline as defined by the Jenkinsfile.\nAfter the pipeline ends, the"
  },
  "5355": {
    "source_file": "using-jenkinsfile-runner-github-action-to-build-jenkins-pipeline.txt",
    "text": "mits the changes to the remote GitHub repository, the GitHub Actions will run the pipeline as defined by the Jenkinsfile.\nAfter the pipeline ends, the user can view the pipeline log in the GitHub Action page.\nFurthermore, the user can integrate the GitHub Actions in the marketplace with the Jenkinsfile Runner GitHub Actions.\n\nFor this tutorial, you will need:\n\n* A GitHub account\n* A GitHub reposit"
  },
  "5356": {
    "source_file": "using-jenkinsfile-runner-github-action-to-build-jenkins-pipeline.txt",
    "text": "itHub Actions in the marketplace with the Jenkinsfile Runner GitHub Actions.\n\nFor this tutorial, you will need:\n\n* A GitHub account\n* A GitHub repository\n* Git installed locally\n* Fundamental knowledge .\n* If you want to integrate Jenkins plugins, you also need to know what  is.\nThis tutorial reviews some basic concepts of JCasC.\n\nWe recommend users refer to  as a starter.\n\n* In the upper-right co"
  },
  "5357": {
    "source_file": "using-jenkinsfile-runner-github-action-to-build-jenkins-pipeline.txt",
    "text": "u also need to know what  is.\nThis tutorial reviews some basic concepts of JCasC.\n\nWe recommend users refer to  as a starter.\n\n* In the upper-right corner of GitHub, use the \u201c+\u201d drop-down menu, then select *New repository*.\n* Provide a memorable name for your repository such as \"hello-world\".\n* Optionally, add a description of your repository.\nFor example, \"My first repository on GitHub\".\n* Choose"
  },
  "5358": {
    "source_file": "using-jenkinsfile-runner-github-action-to-build-jenkins-pipeline.txt",
    "text": " for your repository such as \"hello-world\".\n* Optionally, add a description of your repository.\nFor example, \"My first repository on GitHub\".\n* Choose a repository visibility.\n\nGitHub Actions are free for standard GitHub-hosted runners in public repositories and self-hosted runners.\nIf you make the repository private, each GitHub account receives a predetermined amount of free minutes and storage "
  },
  "5359": {
    "source_file": "using-jenkinsfile-runner-github-action-to-build-jenkins-pipeline.txt",
    "text": "sitories and self-hosted runners.\nIf you make the repository private, each GitHub account receives a predetermined amount of free minutes and storage for use with GitHub-hosted runners.\nPlease refer to  for more information.\n\nIn this section you will create a Jenkinsfile, which defines how to run the Jenkins pipeline.\nRefer to the  for more details about the workflow definitions.\nThe following is "
  },
  "5360": {
    "source_file": "using-jenkinsfile-runner-github-action-to-build-jenkins-pipeline.txt",
    "text": " create a Jenkinsfile, which defines how to run the Jenkins pipeline.\nRefer to the  for more details about the workflow definitions.\nThe following is an example Jenkinsfile, where the name of this Jenkinsfile is `Jenkinsfile`:\n\npipeline {\n    agent any\n    stages {\n        stage('hello') {\n            steps {\n                sh 'echo Hello Jenkins!'\n            }\n        }\n    }\n}\n\nIn this section"
  },
  "5361": {
    "source_file": "using-jenkinsfile-runner-github-action-to-build-jenkins-pipeline.txt",
    "text": "ny\n    stages {\n        stage('hello') {\n            steps {\n                sh 'echo Hello Jenkins!'\n            }\n        }\n    }\n}\n\nIn this section, you will create a plugin list file, which specifies the plugins you will need to install in the ephemeral Jenkins controller.\nPlease refer to .\n\nThe following example plugin list file will install all the specified latest plugins.\n\ngit\ndocker\njunit"
  },
  "5362": {
    "source_file": "using-jenkinsfile-runner-github-action-to-build-jenkins-pipeline.txt",
    "text": "hemeral Jenkins controller.\nPlease refer to .\n\nThe following example plugin list file will install all the specified latest plugins.\n\ngit\ndocker\njunit\ncredentials\nblueocean\n\nIn our example, we don\u2019t have to install any extra plugins, so you can create an empty plugin list file called \u201cplugins.txt\u201d.\n\nIn this section, you\u2019ll learn how to create a workflow definition so you can run Jenkins pipeline w"
  },
  "5363": {
    "source_file": "using-jenkinsfile-runner-github-action-to-build-jenkins-pipeline.txt",
    "text": "e an empty plugin list file called \u201cplugins.txt\u201d.\n\nIn this section, you\u2019ll learn how to create a workflow definition so you can run Jenkins pipeline with GitHub Actions.\nThe following steps are required to create the definition.\n\nIn your local GitHub repository prepare a workflow definition YAML file with a name, such as  `ci.yml`, in the \u201c.github/workflows\u201d directory.\nCreate the name of your work"
  },
  "5364": {
    "source_file": "using-jenkinsfile-runner-github-action-to-build-jenkins-pipeline.txt",
    "text": " repository prepare a workflow definition YAML file with a name, such as  `ci.yml`, in the \u201c.github/workflows\u201d directory.\nCreate the name of your workflow and event that triggers your workflow.\nRefer to  that trigger workflows.\nIn our example, the `push` event triggers the workflow when a commit or tag is pushed.\nname: Java CI\non: [push]\n\nUse an Ubuntu runner for the job.\njobs:\n  job-name:\n    run"
  },
  "5365": {
    "source_file": "using-jenkinsfile-runner-github-action-to-build-jenkins-pipeline.txt",
    "text": "ush` event triggers the workflow when a commit or tag is pushed.\nname: Java CI\non: [push]\n\nUse an Ubuntu runner for the job.\njobs:\n  job-name:\n    runs-on: ubuntu-latest\n\n(Optional) If you want to use `jfr-container-action` later, you need to declare this using the `ghcr.io/jenkinsci/jenkinsfile-runner:master` or any image extending it.\nIf you choose to use `jfr-static-image-action`, you can skip "
  },
  "5366": {
    "source_file": "using-jenkinsfile-runner-github-action-to-build-jenkins-pipeline.txt",
    "text": " this using the `ghcr.io/jenkinsci/jenkinsfile-runner:master` or any image extending it.\nIf you choose to use `jfr-static-image-action`, you can skip this step.\njobs:\n  job-name:\n    runs-on: ubuntu-latest\n    container:\n      image: ghcr.io/jenkinsci/jenkinsfile-runner:master\n\nCall the `actions/checkout@v2` to pull your codes into the runner.\n** \u201cCall\u201d means \u201cuses\u201d in the workflow definition spec"
  },
  "5367": {
    "source_file": "using-jenkinsfile-runner-github-action-to-build-jenkins-pipeline.txt",
    "text": "i/jenkinsfile-runner:master\n\nCall the `actions/checkout@v2` to pull your codes into the runner.\n** \u201cCall\u201d means \u201cuses\u201d in the workflow definition specifically.\nYou can check the details about the \u201cuses\u201d keyword.\n- uses: actions/checkout@v2\n\nCall the Jenkinsfile-runner actions.\n** If you use `jfr-container-action`, you need to call `jenkinsci/jfr-container-action@master` and provide the necessary i"
  },
  "5368": {
    "source_file": "using-jenkinsfile-runner-github-action-to-build-jenkins-pipeline.txt",
    "text": "Jenkinsfile-runner actions.\n** If you use `jfr-container-action`, you need to call `jenkinsci/jfr-container-action@master` and provide the necessary inputs.\nuses:\n  jenkinsci/jfr-container-action@master\nwith:\n  command: run\n  jenkinsfile: Jenkinsfile\n  pluginstxt: plugins.txt\n\n** If you use `jfr-static-image-action`, you need to call `jenkinsci/jfr-static-image-action@master` and provide the neces"
  },
  "5369": {
    "source_file": "using-jenkinsfile-runner-github-action-to-build-jenkins-pipeline.txt",
    "text": "\n  pluginstxt: plugins.txt\n\n** If you use `jfr-static-image-action`, you need to call `jenkinsci/jfr-static-image-action@master` and provide the necessary inputs.\nuses:\n  jenkinsci/jfr-static-image-action@master\nwith:\n  command: run\n  jenkinsfile: Jenkinsfile\n  pluginstxt: plugins.txt\n\nIf you use `jfr-container-action`, you can verify your work by checking the following complete example.\n\nname: Ja"
  },
  "5370": {
    "source_file": "using-jenkinsfile-runner-github-action-to-build-jenkins-pipeline.txt",
    "text": "nkinsfile\n  pluginstxt: plugins.txt\n\nIf you use `jfr-container-action`, you can verify your work by checking the following complete example.\n\nname: Java CI\non: [push]\njobs:\n  jenkins-container-pipeline:\n    runs-on: ubuntu-latest\n    container:\n      image: ghcr.io/jenkinsci/jenkinsfile-runner:master\n    steps:\n      - uses: actions/checkout@v2\n      - uses:\n          jenkinsci/jfr-container-actio"
  },
  "5371": {
    "source_file": "using-jenkinsfile-runner-github-action-to-build-jenkins-pipeline.txt",
    "text": " image: ghcr.io/jenkinsci/jenkinsfile-runner:master\n    steps:\n      - uses: actions/checkout@v2\n      - uses:\n          jenkinsci/jfr-container-action@master\n        with:\n          command: run\n          jenkinsfile: Jenkinsfile\n          pluginstxt: plugins.txt\n          jcasc: jcasc.yml\n\nIf you use `jfr-static-image-action`, you can verify your work by checking the following complete example.\n"
  },
  "5372": {
    "source_file": "using-jenkinsfile-runner-github-action-to-build-jenkins-pipeline.txt",
    "text": "t: plugins.txt\n          jcasc: jcasc.yml\n\nIf you use `jfr-static-image-action`, you can verify your work by checking the following complete example.\n\nname: Java CI\non: [push]\njobs:\n  jenkins-static-image-pipeline:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v2\n      - uses:\n          jenkinsci/jfr-static-image-action@master\n        with:\n          command: run\n          j"
  },
  "5373": {
    "source_file": "using-jenkinsfile-runner-github-action-to-build-jenkins-pipeline.txt",
    "text": "s:\n      - uses: actions/checkout@v2\n      - uses:\n          jenkinsci/jfr-static-image-action@master\n        with:\n          command: run\n          jenkinsfile: Jenkinsfile\n          pluginstxt: plugins.txt\n          jcasc: jcasc.yml\n\nThere is another powerful GitHub Action list called Jenkinsfile Runner Runtime Actions.\nFor these GitHub Actions, you can run them in any runners, which are Windows"
  },
  "5374": {
    "source_file": "using-jenkinsfile-runner-github-action-to-build-jenkins-pipeline.txt",
    "text": "er powerful GitHub Action list called Jenkinsfile Runner Runtime Actions.\nFor these GitHub Actions, you can run them in any runners, which are Windows, Linux and macOS.\nYou can check their step by step usage .\n\nOnce you create your workflow definition, you can commit all the local changes to the remote repository.\nPushing your commits will trigger and execute your workflow.\nAfter this workflow has"
  },
  "5375": {
    "source_file": "using-jenkinsfile-runner-github-action-to-build-jenkins-pipeline.txt",
    "text": "n, you can commit all the local changes to the remote repository.\nPushing your commits will trigger and execute your workflow.\nAfter this workflow has started, you can see the visualization graph of the run's progress and view each step's activity on GitHub.\nIf you want to learn more about viewing your workflow details, refer to .\n[.boxshadow]\n\nTypically, we need to access the web UI to set up Jen"
  },
  "5376": {
    "source_file": "using-jenkinsfile-runner-github-action-to-build-jenkins-pipeline.txt",
    "text": " GitHub.\nIf you want to learn more about viewing your workflow details, refer to .\n[.boxshadow]\n\nTypically, we need to access the web UI to set up Jenkins.\nHowever, we\u2019re unable to access the web UI under the circumstances of running Jenkins pipeline in the GitHub Actions, since the Jenkins controller is ephemeral.\nThe JCasC () plugin can configure this ephemeral Jenkins controller, by providing t"
  },
  "5377": {
    "source_file": "using-jenkinsfile-runner-github-action-to-build-jenkins-pipeline.txt",
    "text": " in the GitHub Actions, since the Jenkins controller is ephemeral.\nThe JCasC () plugin can configure this ephemeral Jenkins controller, by providing the human-readable declarative configuration files.\n\nIn this example, we review how to set up the environment variables by JCasC and access them in the Jenkinsfile.\n\nCreate a JCasC YAML file called `jcasc.yml` and declare the environment variables:\nje"
  },
  "5378": {
    "source_file": "using-jenkinsfile-runner-github-action-to-build-jenkins-pipeline.txt",
    "text": "ironment variables by JCasC and access them in the Jenkinsfile.\n\nCreate a JCasC YAML file called `jcasc.yml` and declare the environment variables:\njenkins:\n  globalNodeProperties:\n    - envVars:\n        env:\n          - key: hello\n            value: world\n\nCreate a Jenkinsfile:\npipeline {\n    agent any\n    stages {\n        stage('test casc env') {\n            steps {\n                echo \"JCasC e"
  },
  "5379": {
    "source_file": "using-jenkinsfile-runner-github-action-to-build-jenkins-pipeline.txt",
    "text": " world\n\nCreate a Jenkinsfile:\npipeline {\n    agent any\n    stages {\n        stage('test casc env') {\n            steps {\n                echo \"JCasC env.hello: ${env.hello}\"\n            }\n        }\n    }\n}\n\nSpecify the `jcasc.yml` in the GitHub Actions input:\nuses:\n  jenkinsci/jfr-container-action@master\nwith:\n  command: run\n  jenkinsfile: Jenkinsfile\n  pluginstxt: plugins.txt\n  jcasc: jcasc.yml\n\n"
  },
  "5380": {
    "source_file": "using-jenkinsfile-runner-github-action-to-build-jenkins-pipeline.txt",
    "text": "ns input:\nuses:\n  jenkinsci/jfr-container-action@master\nwith:\n  command: run\n  jenkinsfile: Jenkinsfile\n  pluginstxt: plugins.txt\n  jcasc: jcasc.yml\n\nFor additional information, refer to the  provided by the plugin:configuration-as-code[Configuration as Code] plugin, and learn how to configure the Jenkins controller without using the UI page.\nSome plugins do not have concrete examples, but you can"
  },
  "5381": {
    "source_file": "using-jenkinsfile-runner-github-action-to-build-jenkins-pipeline.txt",
    "text": " as Code] plugin, and learn how to configure the Jenkins controller without using the UI page.\nSome plugins do not have concrete examples, but you can debug and find their JCasC in the UI page.\nYou can check the configuration in *Manage Jenkins* -> *Configuration as Code* -> *View Configuration*.\nThen, you can copy the parts you need to the JCasC file.\n\nThere are many powerful plugins that can be "
  },
  "5382": {
    "source_file": "using-jenkinsfile-runner-github-action-to-build-jenkins-pipeline.txt",
    "text": "Configuration as Code* -> *View Configuration*.\nThen, you can copy the parts you need to the JCasC file.\n\nThere are many powerful plugins that can be part of your Jenkins controller.\nYou can add the plugins in the plugin list file, and configure the plugins in the JCasC YAML file as needed.\n\nIn this example, we review how to install JDK21 in the ephemeral Jenkins controller.\n\nSpecify `adoptopenjdk"
  },
  "5383": {
    "source_file": "using-jenkinsfile-runner-github-action-to-build-jenkins-pipeline.txt",
    "text": "plugins in the JCasC YAML file as needed.\n\nIn this example, we review how to install JDK21 in the ephemeral Jenkins controller.\n\nSpecify `adoptopenjdk` plugin in the plugins.txt file.\nAs the version is not specified, the latest version will be installed.\nadoptopenjdk\n\nCreate a JCasC Yaml file named `jcasc.yml` and specify which JDK version to install.\ntool:\n  jdk:\n    installations:\n      - name: "
  },
  "5384": {
    "source_file": "using-jenkinsfile-runner-github-action-to-build-jenkins-pipeline.txt",
    "text": "led.\nadoptopenjdk\n\nCreate a JCasC Yaml file named `jcasc.yml` and specify which JDK version to install.\ntool:\n  jdk:\n    installations:\n      - name: jdk21\n        home: \"~/jdk21\"\n        properties:\n          - installSource:\n              installers:\n                - adoptOpenJdkInstaller:\n                    id: \"jdk-21.0.7+6\"\n\nCreate a Jenkinsfile. Remember to set up JDK21 as a tool.\npipeline"
  },
  "5385": {
    "source_file": "using-jenkinsfile-runner-github-action-to-build-jenkins-pipeline.txt",
    "text": "s:\n                - adoptOpenJdkInstaller:\n                    id: \"jdk-21.0.7+6\"\n\nCreate a Jenkinsfile. Remember to set up JDK21 as a tool.\npipeline {\n    agent any\n    tools {\n        maven 'maven'\n        jdk 'jdk21'\n    }\n    stages {\n        stage('env') {\n            steps {\n                sh 'mvn --version'\n            }\n        }\n        stage('build') {\n            steps {\n             "
  },
  "5386": {
    "source_file": "using-jenkinsfile-runner-github-action-to-build-jenkins-pipeline.txt",
    "text": "age('env') {\n            steps {\n                sh 'mvn --version'\n            }\n        }\n        stage('build') {\n            steps {\n                sh 'mvn clean install -B --no-transfer-progress'\n            }\n        }\n    }\n}\n\nSpecify the `jcasc.yml` in the GitHub Actions input.\nuses:\n  jenkinsci/jfr-container-action@master\nwith:\n  command: run\n  jenkinsfile: Jenkinsfile\n  pluginstxt: plug"
  },
  "5387": {
    "source_file": "using-jenkinsfile-runner-github-action-to-build-jenkins-pipeline.txt",
    "text": "asc.yml` in the GitHub Actions input.\nuses:\n  jenkinsci/jfr-container-action@master\nwith:\n  command: run\n  jenkinsfile: Jenkinsfile\n  pluginstxt: plugins.txt\n  jcasc: jcasc.yml\n\nSometimes, JCasC might not be able to provide the configurations you need.\nIn this case, refer to  to set up the ephemeral Jenkins controller.\nThese Groovy scripts will have full access to the ephemeral Jenkins server and "
  },
  "5388": {
    "source_file": "using-jenkinsfile-runner-github-action-to-build-jenkins-pipeline.txt",
    "text": "d.\nIn this case, refer to  to set up the ephemeral Jenkins controller.\nThese Groovy scripts will have full access to the ephemeral Jenkins server and will be executed right after Jenkins starts up.\n\nNOTE: This option and its core are still in progress, so it\u2019s not mentioned in the Jenkinsfile Runner GitHub Actions official guide.\nHowever, it does work and can be used at this time.\n\nIn this example"
  },
  "5389": {
    "source_file": "using-jenkinsfile-runner-github-action-to-build-jenkins-pipeline.txt",
    "text": "s, so it\u2019s not mentioned in the Jenkinsfile Runner GitHub Actions official guide.\nHowever, it does work and can be used at this time.\n\nIn this example, we review how to use Groovy scripts to set up the Jenkins controller:\n\nCreate a directory, for example `groovy.init.d`, to store all your Groovy setup scripts.\nCreate a Groovy file called `test.groovy`.\n* Do not name it `init.groovy` because this n"
  },
  "5390": {
    "source_file": "using-jenkinsfile-runner-github-action-to-build-jenkins-pipeline.txt",
    "text": "mple `groovy.init.d`, to store all your Groovy setup scripts.\nCreate a Groovy file called `test.groovy`.\n* Do not name it `init.groovy` because this name is already occupied.\nAdd the debug output:\nprintln 'Hello Groovy Hooks!'\n\nSpecify the `groovy.init.d` directory in the GitHub Actions input.\nuses:\n  jenkinsci/jfr-container-action@master\nwith:\n  command: run\n  jenkinsfile: Jenkinsfile\n  pluginstx"
  },
  "5391": {
    "source_file": "using-jenkinsfile-runner-github-action-to-build-jenkins-pipeline.txt",
    "text": "it.d` directory in the GitHub Actions input.\nuses:\n  jenkinsci/jfr-container-action@master\nwith:\n  command: run\n  jenkinsfile: Jenkinsfile\n  pluginstxt: plugins.txt\n  jcasc: jcasc.yml\n  initHook: groovy.init.d\n\nCheck the GitHub Actions log and verify that the groovy script is executed right after Jenkins starts up, before the actual pipeline is run.\n\nYou can integrate this process with other GitHu"
  },
  "5392": {
    "source_file": "using-jenkinsfile-runner-github-action-to-build-jenkins-pipeline.txt",
    "text": " that the groovy script is executed right after Jenkins starts up, before the actual pipeline is run.\n\nYou can integrate this process with other GitHub Actions in the marketplace, via Jenkinsfile Runner GitHub Actions.\nHowever, if the starting time of the Jenkins container is different in these GitHub Actions, some GitHub Actions cannot be used.\nIn other words, `jfr-static-image-action` cannot be "
  },
  "5393": {
    "source_file": "using-jenkinsfile-runner-github-action-to-build-jenkins-pipeline.txt",
    "text": "f the Jenkins container is different in these GitHub Actions, some GitHub Actions cannot be used.\nIn other words, `jfr-static-image-action` cannot be integrated with other GitHub Actions _except_ `actions/checkout`.\nHowever, you can integrate other GitHub Actions with `jfr-container-action` and `jfr-runtime-action`.\nRefer to their differences in .\n\nIn this example, we review how to integrate the \""
  },
  "5394": {
    "source_file": "using-jenkinsfile-runner-github-action-to-build-jenkins-pipeline.txt",
    "text": "itHub Actions with `jfr-container-action` and `jfr-runtime-action`.\nRefer to their differences in .\n\nIn this example, we review how to integrate the \"actions/setup-node\" GitHub Action with `jfr-runtime-action` to compile a JavaScript project:\n\nUse an Ubuntu runner for the job.\njobs:\n  job-name:\n    runs-on: ubuntu-latest\n\nCall the `actions/checkout@v2` to pull your codes into the runner.\n- uses: a"
  },
  "5395": {
    "source_file": "using-jenkinsfile-runner-github-action-to-build-jenkins-pipeline.txt",
    "text": " Ubuntu runner for the job.\njobs:\n  job-name:\n    runs-on: ubuntu-latest\n\nCall the `actions/checkout@v2` to pull your codes into the runner.\n- uses: actions/checkout@v2\n\nCall the `actions/setup-node@v3` to set up node 18.\n- uses: actions/setup-node@v3\n  with:\n    node-version: 18\n\nCall the `jenkinsci/jfr-setup-action@master` to set up Jenkins.\n- uses: jenkinsci/jfr-setup-action@master\n\nCall the `j"
  },
  "5396": {
    "source_file": "using-jenkinsfile-runner-github-action-to-build-jenkins-pipeline.txt",
    "text": "3\n  with:\n    node-version: 18\n\nCall the `jenkinsci/jfr-setup-action@master` to set up Jenkins.\n- uses: jenkinsci/jfr-setup-action@master\n\nCall the `jenkinsci/jfr-plugin-installation-action@master` to install additional plugins.\n- uses: jenkinsci/jfr-plugin-installation-action@master\n  with:\n      pluginstxt: plugins.txt\n\nCall the `jenkinsci/jfr-runtime-action@master` to run the Jenkins pipeline.\n"
  },
  "5397": {
    "source_file": "using-jenkinsfile-runner-github-action-to-build-jenkins-pipeline.txt",
    "text": "-plugin-installation-action@master\n  with:\n      pluginstxt: plugins.txt\n\nCall the `jenkinsci/jfr-runtime-action@master` to run the Jenkins pipeline.\n- uses: jenkinsci/jfr-runtime-action@master\n  with:\n    command: run\n    jenkinsfile: Jenkinsfile\n\nRefer to the  for the full example.\n\nWell done!\nYou have now built your project by using Jenkinsfile Runner GitHub Actions!\n\nWhen you want to make your"
  },
  "5398": {
    "source_file": "using-jenkinsfile-runner-github-action-to-build-jenkins-pipeline.txt",
    "text": "efer to the  for the full example.\n\nWell done!\nYou have now built your project by using Jenkinsfile Runner GitHub Actions!\n\nWhen you want to make your ephemeral Jenkins controllers in the GitHub Actions more extensible, you can refer to the  for more details.\nThe official guide shows the parameters of these GitHub Actions, their comparisons, and other advanced functionality.\nYou can also find addi"
  },
  "5399": {
    "source_file": "using-jenkinsfile-runner-github-action-to-build-jenkins-pipeline.txt",
    "text": " details.\nThe official guide shows the parameters of these GitHub Actions, their comparisons, and other advanced functionality.\nYou can also find additional examples in the .\n\nTo learn more about the contributions of Jenkinsfile Runner GitHub Actions, refer to:\n\n*\n*"
  },
  "5400": {
    "source_file": "using-jenkinsfile-runner-github-action-to-build-jenkins-pipeline.txt",
    "text": ", refer to:\n\n*\n*"
  },
  "5401": {
    "source_file": "using-jmeter-with-jenkins.txt",
    "text": "layout: section\ntitle: Using JMeter with Jenkins\n\n\nifdef::env-github[:imagesdir: ../resources]\nifndef::env-github[:imagesdir: ../../resources]\n\nThere are several advantages to using JMeter and Jenkins together.\nContinuous integration and test automation have become standards in the DevOps world, but the performance levels and system complexity are constantly increasing.\n\nWith Jenkins, you can inte"
  },
  "5402": {
    "source_file": "using-jmeter-with-jenkins.txt",
    "text": "ion have become standards in the DevOps world, but the performance levels and system complexity are constantly increasing.\n\nWith Jenkins, you can integrate all JMeter tests in your pipeline process, and better understand the details of your applications.\n\nSome of the main benefits of using JMeter with Jenkins are:\n\n* Unattended test execution for each system.\n* Build failure logs and recovery step"
  },
  "5403": {
    "source_file": "using-jmeter-with-jenkins.txt",
    "text": "ons.\n\nSome of the main benefits of using JMeter with Jenkins are:\n\n* Unattended test execution for each system.\n* Build failure logs and recovery steps.\n* Secure and easy access to test reports of each build.\n* Automation of routine work.\n\nNOTE: This page outlines how to use Apache JMeter with Jenkins.\nThe instructions are intentionally performed by running Apache JMeter on the Jenkins controller."
  },
  "5404": {
    "source_file": "using-jmeter-with-jenkins.txt",
    "text": " page outlines how to use Apache JMeter with Jenkins.\nThe instructions are intentionally performed by running Apache JMeter on the Jenkins controller.\nApache JMeter in a Jenkins production environment should be run on a Jenkins agent, not on the Jenkins controller.\nTo learn more about Jenkins agents, refer to the  page.\n\n may be used to test the performance of static sites, dynamic sites, and comp"
  },
  "5405": {
    "source_file": "using-jmeter-with-jenkins.txt",
    "text": "ins controller.\nTo learn more about Jenkins agents, refer to the  page.\n\n may be used to test the performance of static sites, dynamic sites, and complete web applications.\nIt can also be used to simulate a heavy load on a server, group of servers, network, or object, allowing for strength testing or overall performance analyzation under different load types.\n\nThe Jenkins docs has a page to help w"
  },
  "5406": {
    "source_file": "using-jmeter-with-jenkins.txt",
    "text": "etwork, or object, allowing for strength testing or overall performance analyzation under different load types.\n\nThe Jenkins docs has a page to help with the .\nThis guide uses the .jar installation.\nRefer to the  if you want to use .jar as well.\nBoth installation methods produce the same results.\n\nTo integrate JMeter with Jenkins, we will use the plugin:performance[Performance plugin].\n\nFollow the"
  },
  "5407": {
    "source_file": "using-jmeter-with-jenkins.txt",
    "text": " installation methods produce the same results.\n\nTo integrate JMeter with Jenkins, we will use the plugin:performance[Performance plugin].\n\nFollow these steps to install it:\n\nFrom your Jenkins dashboard page, go to: *Manage Jenkins*.\nGo to the *Plugins* page.\nSelect *Available*, and enter 'performance' in the search field.\nMark the installation checkbox, and select *Install without restart*.\nIf ev"
  },
  "5408": {
    "source_file": "using-jmeter-with-jenkins.txt",
    "text": "ns* page.\nSelect *Available*, and enter 'performance' in the search field.\nMark the installation checkbox, and select *Install without restart*.\nIf everything is successful, you will receive this confirmation screen:\n\nTo install JMeter, follow these steps:\n\nRefer to the .\nSelect your download option based on your system: .zip for Windows or .tgz for Linux.\nThis tutorial is done on Linux, so the .t"
  },
  "5409": {
    "source_file": "using-jmeter-with-jenkins.txt",
    "text": "steps:\n\nRefer to the .\nSelect your download option based on your system: .zip for Windows or .tgz for Linux.\nThis tutorial is done on Linux, so the .tgz option is displayed.\nExtract the downloaded file in your preferred location, for example `/usr/jmeter`.\nEdit the file: `<YOUR-JMETER-PATH>>/bin/user.properties`.\nFor example, usr/jmeter/bin is the file path used here.\nAdd this command to the last "
  },
  "5410": {
    "source_file": "using-jmeter-with-jenkins.txt",
    "text": "eter`.\nEdit the file: `<YOUR-JMETER-PATH>>/bin/user.properties`.\nFor example, usr/jmeter/bin is the file path used here.\nAdd this command to the last line of the file: `jmeter.save.saveservice.output_format=xml`.\nSave and close the file to ensure the changes are made.\nThis command integrates the output from JMeter into Jenkins.\nNow let's create our JMeter test plan.\n\nJMeter uses test plans to orga"
  },
  "5411": {
    "source_file": "using-jmeter-with-jenkins.txt",
    "text": " changes are made.\nThis command integrates the output from JMeter into Jenkins.\nNow let's create our JMeter test plan.\n\nJMeter uses test plans to organize each test.\nOnce configured, Jenkins calls all test plans defined in a pipeline, and then shows the results in the build reports.\nThis means all test plans must be configured on JMeter first.\nAfter this is complete, enter the info in Jenkins so i"
  },
  "5412": {
    "source_file": "using-jmeter-with-jenkins.txt",
    "text": "the results in the build reports.\nThis means all test plans must be configured on JMeter first.\nAfter this is complete, enter the info in Jenkins so it knows which tests needs to call.\n\nFollow these steps to create a test plan:\n\nRun the file: `<YOUR-JMETER-PATH>>/bin/jmeter.sh` to open the JMeter GUI. For example, /usr/jmeter/bin/jmeter.sh would be used in this example.\nIn a definitive installatio"
  },
  "5413": {
    "source_file": "using-jmeter-with-jenkins.txt",
    "text": "JMETER-PATH>>/bin/jmeter.sh` to open the JMeter GUI. For example, /usr/jmeter/bin/jmeter.sh would be used in this example.\nIn a definitive installation, you can set these commands to your path system or system variables.\nNOTE: For Windows users the file will be `jmeter.bat`.\n\nFrom the JMeter GUI, go to *File*, and then select *New*.\nEnter a name for your test plan.\nOn the left side of the screen, "
  },
  "5414": {
    "source_file": "using-jmeter-with-jenkins.txt",
    "text": "ile will be `jmeter.bat`.\n\nFrom the JMeter GUI, go to *File*, and then select *New*.\nEnter a name for your test plan.\nOn the left side of the screen, using the right or secondary select with your mouse, select your test plan.\nFollow this path: *Add > Thread(Users) > Thread Group*, and select it.\nIn Thread Group, increase the *Number of Threads (users)* to five and the *Loop Count* to two.\nOn the l"
  },
  "5415": {
    "source_file": "using-jmeter-with-jenkins.txt",
    "text": " Thread(Users) > Thread Group*, and select it.\nIn Thread Group, increase the *Number of Threads (users)* to five and the *Loop Count* to two.\nOn the left side of the screen, right or secondary select *Thread Group* with your mouse, then follow this path: *Add > Sampler > HTTP Request*, and select the HTTP Request option.\nIn HTTP Request, enter the *Name* of your test, the *Server Name or IP*, and "
  },
  "5416": {
    "source_file": "using-jmeter-with-jenkins.txt",
    "text": "ath: *Add > Sampler > HTTP Request*, and select the HTTP Request option.\nIn HTTP Request, enter the *Name* of your test, the *Server Name or IP*, and the *Path* context. For example, here we would use `Installing`, `www.jenkins.io`, and `/doc/book/installing/`.\nRepeat steps six and seven two more times to different context/pages. For example, we will use www.jenkins.io/node.\nNow our plan has three"
  },
  "5417": {
    "source_file": "using-jmeter-with-jenkins.txt",
    "text": "stalling/`.\nRepeat steps six and seven two more times to different context/pages. For example, we will use www.jenkins.io/node.\nNow our plan has three things to test.\nTo add a visual report, right or secondary select your Thread Group, then follow the path: *Add > Listener > View results in table*.\nSelect the *View Results in Table* option.\nTo save the test plan, select the Save (disk) icon in the"
  },
  "5418": {
    "source_file": "using-jmeter-with-jenkins.txt",
    "text": "e path: *Add > Listener > View results in table*.\nSelect the *View Results in Table* option.\nTo save the test plan, select the Save (disk) icon in the upper left side of the screen or go to *File > Save*, and enter a name for the test plan with a .jmx extension.\nFor example: `jenkins.io.jml`.\n\nRun the test and view the table results.\n\nOur test is working well in the graphical user interface, but t"
  },
  "5419": {
    "source_file": "using-jmeter-with-jenkins.txt",
    "text": "x extension.\nFor example: `jenkins.io.jml`.\n\nRun the test and view the table results.\n\nOur test is working well in the graphical user interface, but to integrate it with Jenkins, it needs to be run from the command line.\n\nTo run the test plan using the command line, follow these steps:\n\nFrom the terminal, run the following command:\nset OUT=jmeter.save.saveservice.output_format\nset JMX=/usr/jmeter/"
  },
  "5420": {
    "source_file": "using-jmeter-with-jenkins.txt",
    "text": "he command line, follow these steps:\n\nFrom the terminal, run the following command:\nset OUT=jmeter.save.saveservice.output_format\nset JMX=/usr/jmeter/bin/jenkins.io.jmx\nset JTL=/usr/jmeter/reports/jenkins.io.report.jtl\n/usr/jmeter/bin/jmeter -j %OUT%=xml -n -t %JMX% -l %JTL%\n\nIf everything works properly, the report file is created at the indicated location by the `-l` parameter.\nAfter running Jme"
  },
  "5421": {
    "source_file": "using-jmeter-with-jenkins.txt",
    "text": "=xml -n -t %JMX% -l %JTL%\n\nIf everything works properly, the report file is created at the indicated location by the `-l` parameter.\nAfter running Jmeter from the command line, we now have everything needed to execute JMeter from Jenkins.\n\nTo execute Jmeter from Jenkins, follow these steps:\n\nFrom the Jenkins dashboard, select *New Item*.\nEnter the item name, for example `JmeterTest`, select freest"
  },
  "5422": {
    "source_file": "using-jmeter-with-jenkins.txt",
    "text": " Jmeter from Jenkins, follow these steps:\n\nFrom the Jenkins dashboard, select *New Item*.\nEnter the item name, for example `JmeterTest`, select freestyle project, and then select *OK*.\nGo to the *Build Environment* tab, select *Add build step*, and select the option *Execute Windows batch command*.\nEnter the same code we used to run JMeter in the previous section:\nGo to the *Post-build Action* tab"
  },
  "5423": {
    "source_file": "using-jmeter-with-jenkins.txt",
    "text": "elect the option *Execute Windows batch command*.\nEnter the same code we used to run JMeter in the previous section:\nGo to the *Post-build Action* tab and select *Add post-build action*, then select *Publish Performance test result report*.\nNOTE: This option comes from the performance plugin.\nIf it is not available, check the previous section and make sure you have installed the plugin.\n\nFill in t"
  },
  "5424": {
    "source_file": "using-jmeter-with-jenkins.txt",
    "text": "s option comes from the performance plugin.\nIf it is not available, check the previous section and make sure you have installed the plugin.\n\nFill in the source for these reports:\nSave the project, and then select *Build Now* from the JmeterTest page.\nAfter the job finishes, navigate to the *Console Output* view the execution details.\nFrom the *Console Output* view, you can access the *Performance "
  },
  "5425": {
    "source_file": "using-jmeter-with-jenkins.txt",
    "text": "\nAfter the job finishes, navigate to the *Console Output* view the execution details.\nFrom the *Console Output* view, you can access the *Performance Report*, and can view the JMeter report data.\nYou now have JMeter running within Jenkins, and can use the data provided."
  },
  "5426": {
    "source_file": "using-jmeter-with-jenkins.txt",
    "text": "e the data provided."
  },
  "5427": {
    "source_file": "using-local-language.txt",
    "text": "layout: section\ntitle: Using local language\n\n\nifdef::env-github[:imagesdir: ../resources]\nifndef::env-github[:imagesdir: ../../resources]\n\nJenkins displays text depending on the language of the browser.\nIt detects the language of your internet browser.\n\nNote that, depending on the browser and on the language, you might need to download addons.\n\nYou can additionally change the system language (used"
  },
  "5428": {
    "source_file": "using-local-language.txt",
    "text": "r.\n\nNote that, depending on the browser and on the language, you might need to download addons.\n\nYou can additionally change the system language (used when builds are executing), as well as the user interface language for all users by using the plugin:locale[Locale Plugin]."
  },
  "5429": {
    "source_file": "using-local-language.txt",
    "text": "n:locale[Locale Plugin]."
  },
  "5430": {
    "source_file": "viewing-logs.txt",
    "text": "layout: section\n\n\nifndef::env-github[:imagesdir: ../../resources/managing]\n\nWhen running `jenkins.war` manually with `java -jar jenkins.war`, all logging information by default is output to standard out.\nMany Jenkins native packages modify this behavior to ensure logging information is output in a more conventional location for the platform.\n\nBy default logs can be viewed by running `journalctl -u"
  },
  "5431": {
    "source_file": "viewing-logs.txt",
    "text": "ior to ensure logging information is output in a more conventional location for the platform.\n\nBy default logs can be viewed by running `journalctl -u jenkins.service`.\n\nTo customize the log location, run `systemctl edit jenkins` and add the following:\n\n[Service]\nEnvironment=\"JENKINS_LOG=%L/jenkins/jenkins.log\"\n\nBy default, logs should be at `%JENKINS_HOME%/jenkins.out` and `%JENKINS_HOME%/jenkins"
  },
  "5432": {
    "source_file": "viewing-logs.txt",
    "text": "g:\n\n[Service]\nEnvironment=\"JENKINS_LOG=%L/jenkins/jenkins.log\"\n\nBy default, logs should be at `%JENKINS_HOME%/jenkins.out` and `%JENKINS_HOME%/jenkins.err`, unless customized in `%JENKINS_HOME%/jenkins.xml`.\n\nLog files should be at `+/var/log/jenkins/jenkins.log+`, unless customized in `org.jenkins-ci.plist`.\n\nWhen Jenkins is started from a command line with `+java -jar jenkins.war+`, the log file"
  },
  "5433": {
    "source_file": "viewing-logs.txt",
    "text": "/jenkins.log+`, unless customized in `org.jenkins-ci.plist`.\n\nWhen Jenkins is started from a command line with `+java -jar jenkins.war+`, the log file will be written to the `+JENKINS_HOME+` directory.\nIf no value is assigned to the `+JENKINS_HOME+` environment variable, the log file will be written to the `+.jenkins/log+` directory.\n\nIf you run Jenkins inside Docker as a detached container, you c"
  },
  "5434": {
    "source_file": "viewing-logs.txt",
    "text": "environment variable, the log file will be written to the `+.jenkins/log+` directory.\n\nIf you run Jenkins inside Docker as a detached container, you can use `docker logs <containerId>` to view the Jenkins logs.\n\nJenkins uses `java.util.logging` for logging.\nThe `java.util.logging` system by default sends every log above `INFO` to stdout.\n\nJenkins is equipped with a GUI for configuring/collecting/r"
  },
  "5435": {
    "source_file": "viewing-logs.txt",
    "text": "ogging.\nThe `java.util.logging` system by default sends every log above `INFO` to stdout.\n\nJenkins is equipped with a GUI for configuring/collecting/reporting log records of your choosing.\nThis page shows you how to do this.\n\nFirst, select the \"System Log\" from the \"Manage Jenkins\" page:\n\nFrom there, you can create a custom log recorder, which helps you group relevant logs together while filtering"
  },
  "5436": {
    "source_file": "viewing-logs.txt",
    "text": "m Log\" from the \"Manage Jenkins\" page:\n\nFrom there, you can create a custom log recorder, which helps you group relevant logs together while filtering out the noise.\n\nChoose a name that makes sense to you.\n\nYou'll be then asked to configure loggers and their levels whose output you'd like to collect.\nDepending on which part of Jenkins you monitor, you'll need to specify different loggers.\nTell us "
  },
  "5437": {
    "source_file": "viewing-logs.txt",
    "text": "nd their levels whose output you'd like to collect.\nDepending on which part of Jenkins you monitor, you'll need to specify different loggers.\nTell us the symptom of your problem in the users list and we should be able to tell you where you need to look.\nAlso, this is really just a wrapper around the java.util.logging package, so if you program in Java, you might be able to guess where to look.\n\nOn"
  },
  "5438": {
    "source_file": "viewing-logs.txt",
    "text": "ok.\nAlso, this is really just a wrapper around the java.util.logging package, so if you program in Java, you might be able to guess where to look.\n\nOnce the set up is complete, Jenkins will start collecting data.\nThe collected logs are available from the web UI.\n\nThe simplest solution is to install the , which causes custom logs to be written to disk automatically.\n\n1. Create a file `logging.prope"
  },
  "5439": {
    "source_file": "viewing-logs.txt",
    "text": " the web UI.\n\nThe simplest solution is to install the , which causes custom logs to be written to disk automatically.\n\n1. Create a file `logging.properties`\n2. Define the logging levels and a `ConsoleHandler`\n3. Pass this file to the JVM by adding the system property `-Djava.util.logging.config.file=<pathTo>/logging.properties`.\n\nAn example *logging.properties* is included below.\n\nNOTE: For a norm"
  },
  "5440": {
    "source_file": "viewing-logs.txt",
    "text": "e system property `-Djava.util.logging.config.file=<pathTo>/logging.properties`.\n\nAn example *logging.properties* is included below.\n\nNOTE: For a normal production environment the default level is INFO, it is not advised to have debug log in production.\n\nhandlers = java.util.logging.ConsoleHandler\n\n# see https://docs.oracle.com/en/java/javase/17/docs/api/java.logging/java/util/logging/SimpleFormat"
  },
  "5441": {
    "source_file": "viewing-logs.txt",
    "text": "on.\n\nhandlers = java.util.logging.ConsoleHandler\n\n# see https://docs.oracle.com/en/java/javase/17/docs/api/java.logging/java/util/logging/SimpleFormatter.html\njava.util.logging.SimpleFormatter.format = [%1$tF %1$tT][%4$-6s][%2$s] %5$s %6$s %n\n\n# Keep this level to ALL or FINEST or it will be filtered before applying other levels\njava.util.logging.ConsoleHandler.level = ALL\n\n# Default level\n.level="
  },
  "5442": {
    "source_file": "viewing-logs.txt",
    "text": " this level to ALL or FINEST or it will be filtered before applying other levels\njava.util.logging.ConsoleHandler.level = ALL\n\n# Default level\n.level= INFO\n\n# High verbosity for a dedicated package com.myplugin.*\ncom.myplugin.level = ALL"
  },
  "5443": {
    "source_file": "war-file.txt",
    "text": "layout: section\ntitle: WAR file\n\n\nifdef::env-github[:imagesdir: ../resources]\nifndef::env-github[:imagesdir: ../../resources]\n\nThe Jenkins Web application ARchive (WAR) file bundles ,\na  servlet container wrapper,\nand can be started on any operating system or platform with a version of Java supported by Jenkins.\nSee the  page for details.\n\nThe Jenkins Web application ARchive (WAR) file can be star"
  },
  "5444": {
    "source_file": "war-file.txt",
    "text": "system or platform with a version of Java supported by Jenkins.\nSee the  page for details.\n\nThe Jenkins Web application ARchive (WAR) file can be started from the command line like this:\n\nDownload the  to an appropriate directory on your machine\nOpen up a terminal/command prompt window to the download directory\nRun the command `java -jar jenkins.war`\nBrowse to `http://localhost:8080` and wait unti"
  },
  "5445": {
    "source_file": "war-file.txt",
    "text": " up a terminal/command prompt window to the download directory\nRun the command `java -jar jenkins.war`\nBrowse to `http://localhost:8080` and wait until the *Unlock Jenkins* page appears\nContinue on with the <<setup-wizard,Post-installation setup wizard>> below\n\n*Notes:*\n\n* This process does not automatically install any specific plugins.\n  They need to installed separately via the\n   >\n   page in "
  },
  "5446": {
    "source_file": "war-file.txt",
    "text": "rd>> below\n\n*Notes:*\n\n* This process does not automatically install any specific plugins.\n  They need to installed separately via the\n   >\n   page in Jenkins.\n* You can change the port by specifying the `--httpPort` option when you run the\n  `java -jar jenkins.war` command. For example, to make Jenkins accessible\n  through port 9090, then run Jenkins using the command: +\n  `java -jar jenkins.war -"
  },
  "5447": {
    "source_file": "war-file.txt",
    "text": "ar jenkins.war` command. For example, to make Jenkins accessible\n  through port 9090, then run Jenkins using the command: +\n  `java -jar jenkins.war --httpPort=9090`\n* You can change the directory where Jenkins stores its configuration with the `JENKINS_HOME` environment variable.\n  For example, to place the Jenkins configuration files in a subdirectory named `my-jenkins-config`, define `JENKINS_H"
  },
  "5448": {
    "source_file": "war-file.txt",
    "text": "INS_HOME` environment variable.\n  For example, to place the Jenkins configuration files in a subdirectory named `my-jenkins-config`, define `JENKINS_HOME=my-jenkins-config` before running the `java -jar jenkins.war` command.\n  Use the Windows commands:\n.Windows\n\nC:\\Temp > set JENKINS_HOME=my-jenkins-config\nC:\\Temp > java -jar jenkins.war\n\nor the Unix command:\n.Unix\n\nJENKINS_HOME=my-jenkins-config "
  },
  "5449": {
    "source_file": "war-file.txt",
    "text": "s:\n.Windows\n\nC:\\Temp > set JENKINS_HOME=my-jenkins-config\nC:\\Temp > java -jar jenkins.war\n\nor the Unix command:\n.Unix\n\nJENKINS_HOME=my-jenkins-config java -jar jenkins.war\n\nFor more details of command line arguments that can adjust Jenkins startup, use the command: +\n`java -jar jenkins.war --help`"
  },
  "5450": {
    "source_file": "war-file.txt",
    "text": "se the command: +\n`java -jar jenkins.war --help`"
  },
  "5451": {
    "source_file": "web-browsers.txt",
    "text": "layout: redirect\nredirect_url: /doc/book/platform-information/support-policy-web-browsers/"
  },
  "5452": {
    "source_file": "web.txt",
    "text": "title: Web Framework\nlayout: developer\nsummary: How Jenkins uses the Stapler framework\n\n\nJenkins classes are bound to URLs by using https://github.com/stapler[Stapler].\nThe singleton `jenkinsdoc:Jenkins[]` instance is bound to the context root (most of the time \"/\") URL, and the rest of the objects are bound according to their reachability from this root object.\nStapler uses reflection to recursiv"
  },
  "5453": {
    "source_file": "web.txt",
    "text": "of the time \"/\") URL, and the rest of the objects are bound according to their reachability from this root object.\nStapler uses reflection to recursively determine how to process any given URL.\nA few examples of how the URL `/foo/bar` could be processed:\n\n* A `getFoo(String)` is defined on the `Jenkins` object, and Stapler passes `bar` as a parameter.\n  The object returned has a method called `doI"
  },
  "5454": {
    "source_file": "web.txt",
    "text": "sed:\n\n* A `getFoo(String)` is defined on the `Jenkins` object, and Stapler passes `bar` as a parameter.\n  The object returned has a method called `doIndex(\u2026)` that gets called and renders the response.\n* `getFoo()` is defined and returns an object that has a `getBar` or `doBar` method.\n  The object returned from that has an associated `index.jelly` or `index.groovy` view.\n* `getFoo()` is defined a"
  },
  "5455": {
    "source_file": "web.txt",
    "text": "at has a `getBar` or `doBar` method.\n  The object returned from that has an associated `index.jelly` or `index.groovy` view.\n* `getFoo()` is defined and the returned object has a view named `bar.jelly` or `bar.groovy` defined.\n* `doFoo()` is defined.\n\nA number of additional ways to handle requests exist, but these are the most common.\n\nJenkins' model objects have multiple _views_ that are used to "
  },
  "5456": {
    "source_file": "web.txt",
    "text": "\n\nA number of additional ways to handle requests exist, but these are the most common.\n\nJenkins' model objects have multiple _views_ that are used to render HTML pages about each object.\nViews are written in https://jakarta.apache.org/commons/jelly/[Jelly] or http://groovy-lang.org/[Groovy] and can be composed of a number of different partial views (or view fragments)."
  },
  "5457": {
    "source_file": "web.txt",
    "text": "Jelly] or http://groovy-lang.org/[Groovy] and can be composed of a number of different partial views (or view fragments)."
  },
  "5458": {
    "source_file": "wiki-page.txt",
    "text": "title: Plugin Wiki Pages\nlayout: developersection\nreferences:\n- url: ../documentation/\n  title: Plugin documentation\n- url: https://reports.jenkins.io/jenkins-plugin-migration.html\n  title: Plugin migration progress report\n\n\nWARNING: The Jenkins wiki was made 'read-only' in .\nIn September 2021,  and as a result, the impacted server was permanently disabled and the site was rendered static.\nPlugin "
  },
  "5459": {
    "source_file": "wiki-page.txt",
    "text": " was made 'read-only' in .\nIn September 2021,  and as a result, the impacted server was permanently disabled and the site was rendered static.\nPlugin documentation is now maintained in the GitHub repository of the plugin.\nSee the  for details.\n\nPlugin documentation is available from the  so that potential users can learn about the plugin without installing it.\n\nAll plugin documentation has been co"
  },
  "5460": {
    "source_file": "wiki-page.txt",
    "text": "n documentation is available from the  so that potential users can learn about the plugin without installing it.\n\nAll plugin documentation has been converted to markdown and is stored in the  repository.\nThis guide will walk you through the process of migrating plugin documentation from the plugins-wiki-docs repository to the plugin repository, so that it is sourced from the README file inside the"
  },
  "5461": {
    "source_file": "wiki-page.txt",
    "text": "f migrating plugin documentation from the plugins-wiki-docs repository to the plugin repository, so that it is sourced from the README file inside the repository's root.\n\nNOTE: If there is no ticket for the documentation migration created by the current plugin maintainers,\nmake sure to create one and then discuss with the plugin maintainers.\nSimilarly, Asciidoc/Markdown preferences should be also "
  },
  "5462": {
    "source_file": "wiki-page.txt",
    "text": "ent plugin maintainers,\nmake sure to create one and then discuss with the plugin maintainers.\nSimilarly, Asciidoc/Markdown preferences should be also discussed with maintainers.\n\nThe following list provides the migration steps:\n\nSearch for the plugin to update in the .\n** If the status of the plugin is _TODO_ move on to step two, else retry step one with a different plugin.\nFork the plugin reposit"
  },
  "5463": {
    "source_file": "wiki-page.txt",
    "text": " to update in the .\n** If the status of the plugin is _TODO_ move on to step two, else retry step one with a different plugin.\nFork the plugin repository in GitHub and clone it to your local machine.\nSearch for and open the plugin page in the  repository.\nCopy the README.md file and all docs/images to the plugin repository.\n** You can merge the copied file with the existing README file or create a"
  },
  "5464": {
    "source_file": "wiki-page.txt",
    "text": "tory.\nCopy the README.md file and all docs/images to the plugin repository.\n** You can merge the copied file with the existing README file or create a new one.\nCopy-edit the documentation as described <<copy-edit-documentation, below>>.\nModify the URL documentation page reference in the project file so that it points to GitHub ().\nCommit changes, push them to your fork, and create a pull request a"
  },
  "5465": {
    "source_file": "wiki-page.txt",
    "text": "L documentation page reference in the project file so that it points to GitHub ().\nCommit changes, push them to your fork, and create a pull request against the repository.\nConfigure a redirect from the out-of-date wiki page to the migrated content.\n\nNOTE: After migration, the continued existence of out-of-date wiki pages causes several problems, such as duplication, confusion, and unclear migrati"
  },
  "5466": {
    "source_file": "wiki-page.txt",
    "text": "\nNOTE: After migration, the continued existence of out-of-date wiki pages causes several problems, such as duplication, confusion, and unclear migration progress.\nThis persistence makes it harder to identify which pages have migrated and those waiting for migration.\nIf you cannot identify migrated pages, this creates a major technical obstacle in content migration from the wiki.\n\n[[copy-edit-docum"
  },
  "5467": {
    "source_file": "wiki-page.txt",
    "text": "g for migration.\nIf you cannot identify migrated pages, this creates a major technical obstacle in content migration from the wiki.\n\n[[copy-edit-documentation]]\n\nReview/edit the migrated file formatting.\n** If the document includes \"Table of contents\", remove this section in Markdown\n   or replace it using the `:toc:` macros in Asciidoc ().\n** If the source Wiki page includes code blocks, they wil"
  },
  "5468": {
    "source_file": "wiki-page.txt",
    "text": "\", remove this section in Markdown\n   or replace it using the `:toc:` macros in Asciidoc ().\n** If the source Wiki page includes code blocks, they will need to be manually converted.\n   Pandoc exports them as tables.\nExtract changelogs to a separate file or create GitHub releases for past versions.\n** If you create a changelog file, extract the changelogs to a separate `CHANGELOG.md` file in the r"
  },
  "5469": {
    "source_file": "wiki-page.txt",
    "text": "file or create GitHub releases for past versions.\n** If you create a changelog file, extract the changelogs to a separate `CHANGELOG.md` file in the repository root.\n   It allows tools like Dependabot to read changelog summaries.\n** Use versions as headers.\n   Changelogs in Wiki often include release dates, but it is better to keep them in the text below the header.\n** Examples: ,\nReview the text."
  },
  "5470": {
    "source_file": "wiki-page.txt",
    "text": "eaders.\n   Changelogs in Wiki often include release dates, but it is better to keep them in the text below the header.\n** Examples: ,\nReview the text.\n** Verify formatting and spelling.\n** Wiki pages are often outdated, and it is nice to review them before submitting\n   (e.g. rename \"slave\" to \"agent\", \"workflow\" to \"pipeline\", \"Hudson\" to \"Jenkins\", etc.).\nCheck that the images are not outdated.\n"
  },
  "5471": {
    "source_file": "wiki-page.txt",
    "text": "before submitting\n   (e.g. rename \"slave\" to \"agent\", \"workflow\" to \"pipeline\", \"Hudson\" to \"Jenkins\", etc.).\nCheck that the images are not outdated.\n** A lot of UI changes have occurred, and wiki pages often contain out-of-date images (images that contain keywords like Hudson will need to be replaced).\nCommit changes, push them to your fork and create a pull request against the plugin repository."
  },
  "5472": {
    "source_file": "wiki-page.txt",
    "text": "ontain keywords like Hudson will need to be replaced).\nCommit changes, push them to your fork and create a pull request against the plugin repository.\nOnce the pull request is merged, create an `INFRA` Jenkins JIRA ticket to replace the content on Wiki by a link to the new jenkins.io locations."
  },
  "5473": {
    "source_file": "wiki-page.txt",
    "text": "ki by a link to the new jenkins.io locations."
  },
  "5474": {
    "source_file": "windows.txt",
    "text": "layout: documentation\ntitle:  Upgrading Windows masters and agents\nnotitle: true\n\n\nThe following features can be enabled after upgrading Jenkins to 2.60.1:\n\n* Automatic upgrade of  library (`slave.jar`) on agents\n* Automatic termination of runaway agent processes on agents\n* Automatic termination of Jenkins controller processes\n\nNOTE: The described features and guidelines apply to classic JNLP age"
  },
  "5475": {
    "source_file": "windows.txt",
    "text": "ent processes on agents\n* Automatic termination of Jenkins controller processes\n\nNOTE: The described features and guidelines apply to classic JNLP agents installed as services.\nPlugins like plugin:windows-slaves[Windows Agents Plugin] do not offer all features so far, see .\n\nThe upgrade steps are described in the https://github.com/jenkinsci/windows-slave-installer-module#upgrading-old-agents[Agen"
  },
  "5476": {
    "source_file": "windows.txt",
    "text": "l features so far, see .\n\nThe upgrade steps are described in the https://github.com/jenkinsci/windows-slave-installer-module#upgrading-old-agents[Agent Upgrade Guide] (Windows Agent Installer Module Docs).\n\nThe only non-trivial action is a XML configuration change.\nDuring the 2.60.1 upgrade it is recommended to perform the following steps:\n\n1. Add the  extension.\n ** See the example in the templat"
  },
  "5477": {
    "source_file": "windows.txt",
    "text": "uration change.\nDuring the 2.60.1 upgrade it is recommended to perform the following steps:\n\n1. Add the  extension.\n ** See the example in the template referenced below.\n2. Enable automatic download of the `slave.jar` file\n ** Example: `<download from=\"JENKINS_URL/jnlpJars/slave.jar\" to=\"%BASE%\\slave.jar\"/>` (replace `JENKINS_URL` by the actual URL)\n\nNOTE: If you use Jenkins with HTTP over insecur"
  },
  "5478": {
    "source_file": "windows.txt",
    "text": "m=\"JENKINS_URL/jnlpJars/slave.jar\" to=\"%BASE%\\slave.jar\"/>` (replace `JENKINS_URL` by the actual URL)\n\nNOTE: If you use Jenkins with HTTP over insecure network, be aware of the risk of MITM attacks.\nBy default new agents have auto-update enabled for HTTPS only.\n\nWhen updating the `jenkins-slave.xml` configuration file, you can use\n\nas a template for the new configuration.\n\nJenkins controller execu"
  },
  "5479": {
    "source_file": "windows.txt",
    "text": "HTTPS only.\n\nWhen updating the `jenkins-slave.xml` configuration file, you can use\n\nas a template for the new configuration.\n\nJenkins controller executables may run away in some rare cases, hence it is recommended to enable the  for them.\n\nIn order to upgrade the master and enable this feature, perform the following steps:\n\n1. Update Jenkins to 2.60.1 and start the instance. It will automatically "
  },
  "5480": {
    "source_file": "windows.txt",
    "text": "o upgrade the master and enable this feature, perform the following steps:\n\n1. Update Jenkins to 2.60.1 and start the instance. It will automatically upgrade the `jenkins.exe` file.\n2. Stop the Jenkins service\n3. Modify `jenkins.xml` in the Jenkins home directory\n** To enable Runaway Process Killer, add  to `jenkins.xml`\n4. Start Jenkins again\n\nTo verify the upgrade correctness, check the `jenkins"
  },
  "5481": {
    "source_file": "windows.txt",
    "text": "ome directory\n** To enable Runaway Process Killer, add  to `jenkins.xml`\n4. Start Jenkins again\n\nTo verify the upgrade correctness, check the `jenkins.wrapper.log` output.\nIt should contain log entries related Runaway Process Killer after the successful startup.\n\nWinSW offers many advanced features you may want to enable.\nFor more details see these documents:\n\n*"
  },
  "5482": {
    "source_file": "windows.txt",
    "text": "ful startup.\n\nWinSW offers many advanced features you may want to enable.\nFor more details see these documents:\n\n*"
  },
  "5483": {
    "source_file": "with-chef.txt",
    "text": "layout: section\nwip: true"
  },
  "5484": {
    "source_file": "with-puppet.txt",
    "text": "layout: section\nwip: true"
  },
  "5485": {
    "source_file": "working-with-projects.txt",
    "text": "layout: section\ntitle: Working with projects\n\n\nJenkins uses projects (also known as \"jobs\") to perform its work.\nProjects are defined and run by Jenkins users.\nJenkins offers several different types of projects, including:\n\n*\n*\n*\n* Freestyle\n* plugin:matrix-project[Multi-configuration (matrix)]\n* plugin:maven-plugin[Maven]\n* plugin:external-monitor-job[External job]\n\nDarin Pope provides a summary "
  },
  "5486": {
    "source_file": "working-with-projects.txt",
    "text": ":matrix-project[Multi-configuration (matrix)]\n* plugin:maven-plugin[Maven]\n* plugin:external-monitor-job[External job]\n\nDarin Pope provides a summary of the differences between Pipeline projects and freestyle projects in this video.\n\n.Comparing Pipeline and freestyle projects\nvideo::IOUm1lw7F58[youtube,width=800,height=420]\n\nCopy an existing project by clicking the \"New Item\" link on the side pane"
  },
  "5487": {
    "source_file": "working-with-projects.txt",
    "text": "ine and freestyle projects\nvideo::IOUm1lw7F58[youtube,width=800,height=420]\n\nCopy an existing project by clicking the \"New Item\" link on the side panel.\nEnter the name of the destination project in the  \"Item name\" field.\nInsert the name of the source project into the \"Copy from\" field.\nThe existing project will be copied to a new project with the name that was entered in the \"Item name\" field.\n\n."
  },
  "5488": {
    "source_file": "working-with-projects.txt",
    "text": "e project into the \"Copy from\" field.\nThe existing project will be copied to a new project with the name that was entered in the \"Item name\" field.\n\n.Copy a project\nvideo::MNzNPCJJqaI[youtube,width=800,height=420]\n\nRename an existing project by clicking the \"Rename\" action on the project page.\nWhen a job is renamed, other jobs that refer to the job by name must be updated to match the new name.\n\n."
  },
  "5489": {
    "source_file": "working-with-projects.txt",
    "text": "ing the \"Rename\" action on the project page.\nWhen a job is renamed, other jobs that refer to the job by name must be updated to match the new name.\n\n.Rename a project\nvideo::zO3xnCwbv_c[youtube,width=800,height=420]\n\nMove an existing project to another folder by clicking the \"Move\" action on the project page.\nWhen a job is moved, other jobs that refer to the job by name must be updated to match th"
  },
  "5490": {
    "source_file": "working-with-projects.txt",
    "text": "er folder by clicking the \"Move\" action on the project page.\nWhen a job is moved, other jobs that refer to the job by name must be updated to match the new name.\n\n.Move a project\nvideo::Mof_YRGZLd8[youtube,width=800,height=420]"
  },
  "5491": {
    "source_file": "writing-an-scm-plugin.txt",
    "text": "title: Writing an SCM Plugin\nlayout: developer\nreferences:\n- url: https://github.com/jenkinsci/scm-api-plugin/blob/master/docs/consumer.adoc\n  title: SCM API Consumer Guide\n- url: https://github.com/jenkinsci/scm-api-plugin/blob/master/docs/implementation.adoc\n  title: SCM API Implementation Guide\n- url: https://wiki.jenkins.io/display/JENKINS/SCM+plugin+architecture\n  title: >\n    Part 1: SCM plu"
  },
  "5492": {
    "source_file": "writing-an-scm-plugin.txt",
    "text": "ation.adoc\n  title: SCM API Implementation Guide\n- url: https://wiki.jenkins.io/display/JENKINS/SCM+plugin+architecture\n  title: >\n    Part 1: SCM plugin architecture\n- url: https://wiki.jenkins.io/display/JENKINS/Remoting\n  title: >\n    Part 2: Remoting\n- url: https://wiki.jenkins.io/display/JENKINS/Polling+for+changes\n  title: >\n    Part 3: Polling for changes\n- url: https://wiki.jenkins.io/disp"
  },
  "5493": {
    "source_file": "writing-an-scm-plugin.txt",
    "text": "ting\n- url: https://wiki.jenkins.io/display/JENKINS/Polling+for+changes\n  title: >\n    Part 3: Polling for changes\n- url: https://wiki.jenkins.io/display/JENKINS/Checking+out+files\n  title: >\n    Part 4: Checking out files\n- url: https://wiki.jenkins.io/display/JENKINS/Change+log\n  title: >\n    Part 5: Change log\n- url: https://wiki.jenkins.io/display/JENKINS/Repository+browser\n  title: >\n    Part"
  },
  "5494": {
    "source_file": "writing-an-scm-plugin.txt",
    "text": ".io/display/JENKINS/Change+log\n  title: >\n    Part 5: Change log\n- url: https://wiki.jenkins.io/display/JENKINS/Repository+browser\n  title: >\n    Part 6: Repository browser\n- url: https://github.com/martinda/simple-scm-plugin # TODO move into jenkinsci org\n  title: simple-scm-plugin\n  description: A simple SCM skeleton plugin you can build with Gradle or Maven. No real functionality, just a minima"
  },
  "5495": {
    "source_file": "writing-an-scm-plugin.txt",
    "text": "ci org\n  title: simple-scm-plugin\n  description: A simple SCM skeleton plugin you can build with Gradle or Maven. No real functionality, just a minimalistic skeleton.\n\n\nThis document is a how-to on writing an SCM plugin for Jenkins.\nIt is based on my experiences writing the .\n\nFor the rest of this how-to, it is assumed that the plugin development environment has been set up according to the .\n\nFir"
  },
  "5496": {
    "source_file": "writing-an-scm-plugin.txt",
    "text": " experiences writing the .\n\nFor the rest of this how-to, it is assumed that the plugin development environment has been set up according to the .\n\nFirst you should investigate on what configuration parameters that the SCM should have and should not have.\nIt is advisable to keep the number of configuration points as low as possible to be in line with the easiness as the rest of Jenkins.\nFor the Tea"
  },
  "5497": {
    "source_file": "writing-an-scm-plugin.txt",
    "text": "ave.\nIt is advisable to keep the number of configuration points as low as possible to be in line with the easiness as the rest of Jenkins.\nFor the Team Foundation Server I have determined that the following configuration parameters are needed:\n\n* the server name/url\n* the name of the project\n* if the server is secured, credentials such as username, password and domain\n* cleanCopy, if the workspace"
  },
  "5498": {
    "source_file": "writing-an-scm-plugin.txt",
    "text": " server name/url\n* the name of the project\n* if the server is secured, credentials such as username, password and domain\n* cleanCopy, if the workspace should be emptied before every build\n* the name of the workspace\n\nThe global configuration page should configure:\n\n* a command line tool, that is used instead of TFS library.\nThe command line tool field will have validation logic to make sure that H"
  },
  "5499": {
    "source_file": "writing-an-scm-plugin.txt",
    "text": "uld configure:\n\n* a command line tool, that is used instead of TFS library.\nThe command line tool field will have validation logic to make sure that Hudson can find it.\n\nSecondly, you should determine what data you would like to store in the change log for each build.\nThe change log should contain information such as the author, date, message.\nTeam Foundation Server change sets contains the follow"
  },
  "5500": {
    "source_file": "writing-an-scm-plugin.txt",
    "text": "og for each build.\nThe change log should contain information such as the author, date, message.\nTeam Foundation Server change sets contains the following information:\n\n* Revision\n* Author\n* Date and time\n* Comment\n* A list of files\n* Action (added, deleted, changed)\n* File name\n* Version\n\n* The  section covers how to create the base classes and jelly files that a SCM implementation requires.\n* The"
  },
  "5501": {
    "source_file": "writing-an-scm-plugin.txt",
    "text": "eleted, changed)\n* File name\n* Version\n\n* The  section covers how to create the base classes and jelly files that a SCM implementation requires.\n* The  section covers how the plugin should interact with the SCM server,\neither through a command line tool or an API, so it can be distributed to agents.\n* The  section covers how a plugin can poll for changes and what methods that should be implemented"
  },
  "5502": {
    "source_file": "writing-an-scm-plugin.txt",
    "text": "ool or an API, so it can be distributed to agents.\n* The  section covers how a plugin can poll for changes and what methods that should be implemented.\n* The  section covers what a plugin needs to do when checking out files at the beginning of a build.\n* The  section covers how the change log for a build should be handled so it can be displayed in the Changes page.\n* The  section covers how to sup"
  },
  "5503": {
    "source_file": "writing-an-scm-plugin.txt",
    "text": "d.\n* The  section covers how the change log for a build should be handled so it can be displayed in the Changes page.\n* The  section covers how to support web based repository browsers in a plugin.\n* The  section covers how to tag a build using tag/label features in the SCM.\n\n* https://github.com/martinda/simple-scm-plugin[simple-scm-plugin]:\nA simple SCM skeleton plugin you can build with Gradle "
  },
  "5504": {
    "source_file": "writing-an-scm-plugin.txt",
    "text": "abel features in the SCM.\n\n* https://github.com/martinda/simple-scm-plugin[simple-scm-plugin]:\nA simple SCM skeleton plugin you can build with Gradle or Maven.\nNo real functionality, just a minimalistic skeleton."
  },
  "5505": {
    "source_file": "writing-cli-commands.txt",
    "text": "title: Writing CLI commands\nlayout: developer\n\n\nPlugins can contribute additional commands to .\n\nThis is useful for:\n\n* exposing administrative commands to admins, so that they can script some of the Jenkins babysitting work,\n* exposing data and operations to builds executing inside Jenkins, so that they can interact with Jenkins in a richer way.\n\nWriting commands can be done in two ways.\n\n## Anno"
  },
  "5506": {
    "source_file": "writing-cli-commands.txt",
    "text": "ations to builds executing inside Jenkins, so that they can interact with Jenkins in a richer way.\n\nWriting commands can be done in two ways.\n\n## Annotating a method with CLIMethod\n\nIf you are exposing behaviors of your model objects as CLI commands, the easiest way to achieve it is to put jenkinsdoc:CLIMethod[@CLIMethod] on a method of your model object. See jenkinsdoc:hudson.model.Queue#clear()["
  },
  "5507": {
    "source_file": "writing-cli-commands.txt",
    "text": " the easiest way to achieve it is to put jenkinsdoc:CLIMethod[@CLIMethod] on a method of your model object. See jenkinsdoc:hudson.model.Queue#clear()[Queue.clear()] as an example.\nIn addition to the command name as specified in the annotation, you also need to define \"CLI.command-name.shortDescription\" as a message resource, which captures one line human-readable explanation of the command (see je"
  },
  "5508": {
    "source_file": "writing-cli-commands.txt",
    "text": "so need to define \"CLI.command-name.shortDescription\" as a message resource, which captures one line human-readable explanation of the command (see jenkinsdoc:hudson.cli.CLICommand#getShortDescription()[CLICommand.getShortDescription()]).\n\npublic class AbstractItem {\n    @CLIMethod(name=\"delete-job\")\n    public synchronized void delete() throws IOException, InterruptedException {\n        performDe"
  },
  "5509": {
    "source_file": "writing-cli-commands.txt",
    "text": "ss AbstractItem {\n    @CLIMethod(name=\"delete-job\")\n    public synchronized void delete() throws IOException, InterruptedException {\n        performDelete();\n\n        if (this instanceof TopLevelItem) {\n            Jenkins.get().deleteJob((TopLevelItem)this);\n        }\n        Jenkins.get().rebuildDependencyGraph();\n    }\n    ...\n}\n\nNotice that the method is an instance method. So when the delete-"
  },
  "5510": {
    "source_file": "writing-cli-commands.txt",
    "text": "em)this);\n        }\n        Jenkins.get().rebuildDependencyGraph();\n    }\n    ...\n}\n\nNotice that the method is an instance method. So when the delete-job command is executed, which job is deleted?\nTo resolve this, you also need to define a `CLI resolver`, which uses a portion of arguments and options to determine the instance object that receives a method call.\n\n@CLIResolver\npublic static Abstract"
  },
  "5511": {
    "source_file": "writing-cli-commands.txt",
    "text": "ver`, which uses a portion of arguments and options to determine the instance object that receives a method call.\n\n@CLIResolver\npublic static AbstractItem resolveForCLI(\n        @Argument(required=true,metaVar=\"NAME\",usage=\"Job name\") String name) throws CmdLineException {\n    AbstractItem item = Jenkins.get().getItemByFullName(name, AbstractItem.class);\n    if (item==null)\n        throw new CmdLi"
  },
  "5512": {
    "source_file": "writing-cli-commands.txt",
    "text": "rows CmdLineException {\n    AbstractItem item = Jenkins.get().getItemByFullName(name, AbstractItem.class);\n    if (item==null)\n        throw new CmdLineException(null,\"No such job exists:\"+name);\n    return item;\n}\n\nOf all the resolver methods that are discovered, Jenkins picks the one that returns the best return type.\nIt doesn't matter where the resolver method is defined, or how it's named.\n\nBo"
  },
  "5513": {
    "source_file": "writing-cli-commands.txt",
    "text": "re discovered, Jenkins picks the one that returns the best return type.\nIt doesn't matter where the resolver method is defined, or how it's named.\n\nBoth resolver methods and CLI methods can have any number of  annotations, which causes the parameters and arguments to be injected upon a method invocation.\nAll the other unannotated parameters receive null.\nCombined with the stapler method binding, t"
  },
  "5514": {
    "source_file": "writing-cli-commands.txt",
    "text": " and arguments to be injected upon a method invocation.\nAll the other unannotated parameters receive null.\nCombined with the stapler method binding, this enables you to make your method invocable from both CLI and HTTP.\n\n## Extending CLICommand\n\nYou can also implement a CLI command as a subtype of jenkinsdoc:CLICommand[], and put jenkinsdoc:hudson.Extension[Extension].\nYou can use existing impleme"
  },
  "5515": {
    "source_file": "writing-cli-commands.txt",
    "text": "can also implement a CLI command as a subtype of jenkinsdoc:CLICommand[], and put jenkinsdoc:hudson.Extension[Extension].\nYou can use existing implementations in the core, such as jenkinsdoc:GroovyCommand[], as a starting point. `CLICommand` exposes a lower-level control of the CLI set up (such as a jenkinsdoc:component:remoting:hudson.remoting.Channel[Channel].)\n\nThis approach is suitable for the"
  },
  "5516": {
    "source_file": "writing-cli-commands.txt",
    "text": "a lower-level control of the CLI set up (such as a jenkinsdoc:component:remoting:hudson.remoting.Channel[Channel].)\n\nThis approach is suitable for the commands that require more serious terminal interaction and remote code execution.\n\nSee the jenkinsdoc:CLICommand[javadoc of CLICommand] for more details."
  },
  "5517": {
    "source_file": "writing-cli-commands.txt",
    "text": "doc:CLICommand[javadoc of CLICommand] for more details."
  },
  "5518": {
    "source_file": "xss-prevention.txt",
    "text": "title: Preventing Cross-Site Scripting in Jelly views\nlayout: developer\n\n\n// Adapted from https://wiki.jenkins.io/display/JENKINS/Jelly+and+XSS+prevention\n\nCross-Site Scripting (XSS) is a web application vulnerability that allows users with the ability to control what gets shown to other users on a web page to run scripts in their browser.\n\nJenkins displays content written by users with different "
  },
  "5519": {
    "source_file": "xss-prevention.txt",
    "text": "ty to control what gets shown to other users on a web page to run scripts in their browser.\n\nJenkins displays content written by users with different levels of access in many different areas, and the Jelly files typically contain placeholders like this:\n\n<h1>Project ${it.name}</h1>\n\nIf `it.name` evaluates to a string containing HTML tags, those will be placed verbatim into the output, for example:"
  },
  "5520": {
    "source_file": "xss-prevention.txt",
    "text": "is:\n\n<h1>Project ${it.name}</h1>\n\nIf `it.name` evaluates to a string containing HTML tags, those will be placed verbatim into the output, for example:\n\n<h1>Project <script src=\"https://evil.com/exploit-jenkins.js\"></script>my java build</h1>\n\n Keep Your Your Toolchain Updated\n\nSince plugin POM 1.596, Jelly files are required to escape variables by default, and the build fails if such problems are "
  },
  "5521": {
    "source_file": "xss-prevention.txt",
    "text": "our Your Toolchain Updated\n\nSince plugin POM 1.596, Jelly files are required to escape variables by default, and the build fails if such problems are found.\nTherefore it is strongly recommended to use at least that version of the plugin parent POM to prevent accidental XSS vulnerabilities.\n\nIt's recommended to always use the newest available 2.x or newer plugin parent POM.\n\nLocalized expressions o"
  },
  "5522": {
    "source_file": "xss-prevention.txt",
    "text": " prevent accidental XSS vulnerabilities.\n\nIt's recommended to always use the newest available 2.x or newer plugin parent POM.\n\nLocalized expressions of the form `+${%expression}+` are also affected by the above in the following ways:\n\n1. The localized expression (read from a resource file) is not escaped, and allows inline HTML.\n2. Any arguments to the expression are escaped.\n\nThis means the follo"
  },
  "5523": {
    "source_file": "xss-prevention.txt",
    "text": "d expression (read from a resource file) is not escaped, and allows inline HTML.\n2. Any arguments to the expression are escaped.\n\nThis means the following works as expected (rendering the `a` tag), and still prevents XSS problems in the user-specified name:\n\n.index.jelly\n\n<?jelly escape-by-default='true'?>\n<p>${%blurb(it.displayName)}</p>\n\n.index.properties\n\nblurb=<a href=\"https://jenkins.io/\">{0}"
  },
  "5524": {
    "source_file": "xss-prevention.txt",
    "text": "d name:\n\n.index.jelly\n\n<?jelly escape-by-default='true'?>\n<p>${%blurb(it.displayName)}</p>\n\n.index.properties\n\nblurb=<a href=\"https://jenkins.io/\">{0}</a>\n\nIn rare cases, it might be necessary to render content that has previously been escaped or otherwise processed, without further escaping.\nA common reason to do this is to support formatting using the jenkinsdoc:MarkupFormatter[markup formatter "
  },
  "5525": {
    "source_file": "xss-prevention.txt",
    "text": "erwise processed, without further escaping.\nA common reason to do this is to support formatting using the jenkinsdoc:MarkupFormatter[markup formatter configured for the current Jenkins controller], with might support a plugin:antisamy-markup-formatter[safe subset of HTML], or other markup languages, like plugin:pegdown-formatter[Markdown].\nIn those cases, the security is controlled by the markup f"
  },
  "5526": {
    "source_file": "xss-prevention.txt",
    "text": "r[safe subset of HTML], or other markup languages, like plugin:pegdown-formatter[Markdown].\nIn those cases, the security is controlled by the markup formatter.\n\nTo do that, use the `<j:out>` Jelly tag:\n\n<?jelly escape-by-default='true'?>\n<j:jelly xmlns:j=\"jelly:core\">\n  <j:out value=\"${app.markupFormatter.translate(it.description)}\"/>\n</j:jelly>\n\nTo pass arguments to localized expressions without "
  },
  "5527": {
    "source_file": "xss-prevention.txt",
    "text": "ns:j=\"jelly:core\">\n  <j:out value=\"${app.markupFormatter.translate(it.description)}\"/>\n</j:jelly>\n\nTo pass arguments to localized expressions without escaping them in escaped-by-default Jelly files, wrap them in a call to `Functions#rawHtml`:\n\n<?jelly escape-by-default='true'?>\n<j:jelly xmlns:j=\"jelly:core\">\n  <h1>${%welcomeMessage(h.rawHtml(it.markupFormattedName)}</h1>\n</j:jelly>\n\n[WARNING]\nIf t"
  },
  "5528": {
    "source_file": "xss-prevention.txt",
    "text": "y escape-by-default='true'?>\n<j:jelly xmlns:j=\"jelly:core\">\n  <h1>${%welcomeMessage(h.rawHtml(it.markupFormattedName)}</h1>\n</j:jelly>\n\n[WARNING]\nIf the source of the argument to `j:out` or `Functions#rawHtml` isn't completely trusted, these might result in an XSS vulnerability.\n\nIn a situation where you need to pass information to JavaScript, you might inject the value directly inside the script "
  },
  "5529": {
    "source_file": "xss-prevention.txt",
    "text": "sult in an XSS vulnerability.\n\nIn a situation where you need to pass information to JavaScript, you might inject the value directly inside the script like in the following snippet.\n\n<?jelly escape-by-default='true'?>\n<j:jelly xmlns:j=\"jelly:core\">\n  <h1>Random title</h1>\n  <div id=\"target-div\"></div>\n\n  <script>\n     var textToInsert = \"${variableFromJava}\";\n     document.querySelector('#target-di"
  },
  "5530": {
    "source_file": "xss-prevention.txt",
    "text": "<h1>Random title</h1>\n  <div id=\"target-div\"></div>\n\n  <script>\n     var textToInsert = \"${variableFromJava}\";\n     document.querySelector('#target-div').innerText = textToInsert;\n  </script>\n</j:jelly>\n\nIn this case, if the `variableFromJava` comes from an unsafe source, it could be used to create a cross-site scripting (XSS) attack.\nFor example the following code will be executed: `\";alert(123);"
  },
  "5531": {
    "source_file": "xss-prevention.txt",
    "text": "from an unsafe source, it could be used to create a cross-site scripting (XSS) attack.\nFor example the following code will be executed: `\";alert(123);\"`.\nThe JavaScript sent to the client will be:\n\nvar textToInsert = \"\";alert(123);\"\";\n\n The good way\n\nIf you need to pass a variable to your JavaScript, we strongly recommend to use this approach instead:\n\n<?jelly escape-by-default='true'?>\n<j:jelly x"
  },
  "5532": {
    "source_file": "xss-prevention.txt",
    "text": "\nIf you need to pass a variable to your JavaScript, we strongly recommend to use this approach instead:\n\n<?jelly escape-by-default='true'?>\n<j:jelly xmlns:j=\"jelly:core\">\n  <h1>Random title</h1>\n  <div id=\"target-div\" data-inserted-from-java=\"${variableFromJava}\"></div>\n\n  <script>\n     var targetDiv = document.querySelector('#target-div');\n     var textToInsert = targetDiv.getAttribute('data-inse"
  },
  "5533": {
    "source_file": "xss-prevention.txt",
    "text": "bleFromJava}\"></div>\n\n  <script>\n     var targetDiv = document.querySelector('#target-div');\n     var textToInsert = targetDiv.getAttribute('data-inserted-from-java');\n     // equivalent of: targetDiv.dataset.insertedFromJava\n     targetDiv.innerText = textToInsert;\n  </script>\n</j:jelly>\n\n// .\n\nIn this case you are taking advantage of the Jelly escape mechanism to ensure that the result is just a"
  },
  "5534": {
    "source_file": "xss-prevention.txt",
    "text": " = textToInsert;\n  </script>\n</j:jelly>\n\n// .\n\nIn this case you are taking advantage of the Jelly escape mechanism to ensure that the result is just a String.\nIf we try to inject a `\"`, it will be automatically converted to `&amp;quot;`.\n\nIn the previous (vulnerable) example, the injected code was inside a context of \"code to be interpreted\"."
  },
  "5535": {
    "source_file": "xss-prevention.txt",
    "text": "ious (vulnerable) example, the injected code was inside a context of \"code to be interpreted\"."
  },
  "5536": {
    "source_file": "_blue-ocean-status.txt",
    "text": "Blue Ocean will not receive further functionality updates.\nBlue Ocean will continue to provide easy-to-use Pipeline visualization, but it will not be enhanced further.\nIt will only receive selective updates for significant security issues or functional defects.\n\nAlternative options for Pipeline visualization, such as the  and  plugins, are available and offer some of the same functionality.\nWhile "
  },
  "5537": {
    "source_file": "_blue-ocean-status.txt",
    "text": "al defects.\n\nAlternative options for Pipeline visualization, such as the  and  plugins, are available and offer some of the same functionality.\nWhile not complete replacements for Blue Ocean, contributions are encouraged from the community for continued development of these plugins.\n\nThe  assists users as they define Pipeline steps with their arguments.\nIt is the preferred tool for Jenkins Pipelin"
  },
  "5538": {
    "source_file": "_blue-ocean-status.txt",
    "text": "ued development of these plugins.\n\nThe  assists users as they define Pipeline steps with their arguments.\nIt is the preferred tool for Jenkins Pipeline creation, as it provides online help for the Pipeline steps available in your Jenkins controller.\nIt uses the plugins installed on your Jenkins controller to generate the Pipeline syntax.\nRefer to the  page for information on all available Pipeline"
  },
  "5539": {
    "source_file": "_blue-ocean-status.txt",
    "text": "It uses the plugins installed on your Jenkins controller to generate the Pipeline syntax.\nRefer to the  page for information on all available Pipeline steps."
  },
  "5540": {
    "source_file": "_built-in-node-migration.txt",
    "text": "// Included in other files because we need it in multiple locations\n\nAs part of the , the built-in node was renamed from \"master node\" to \"built-in node\" in Jenkins 2.307 and in Jenkins 2.319.1.\nThis is not just a change affecting the UI and documentation:\nThe node name affects the implicitly assigned label of the node (and consequently the `NODE_LABELS` environment variable), as well as the `NODE"
  },
  "5541": {
    "source_file": "_built-in-node-migration.txt",
    "text": "ation:\nThe node name affects the implicitly assigned label of the node (and consequently the `NODE_LABELS` environment variable), as well as the `NODE_NAME` environment variable.\n\nNOTE: The `NODE_NAME` environment variable in Pipelines is set by the plugin:workflow-durable-task-step[Pipeline: Nodes and Processes] plugin.\nIn plugin version 2.39 and earlier, this value is always `master`. Update to "
  },
  "5542": {
    "source_file": "_built-in-node-migration.txt",
    "text": "plugin:workflow-durable-task-step[Pipeline: Nodes and Processes] plugin.\nIn plugin version 2.39 and earlier, this value is always `master`. Update to version 2.40 or newer to get consistent behavior between job types.\n\nJenkins features using node labels are therefore potentially impacted by any such changes.\nThese features include:\n\n* Label assignments of various project types, both on the top lev"
  },
  "5543": {
    "source_file": "_built-in-node-migration.txt",
    "text": "els are therefore potentially impacted by any such changes.\nThese features include:\n\n* Label assignments of various project types, both on the top level (e.g. Freestyle jobs) and within jobs (e.g. `node` statements in Scripted Pipeline, `label` parameters to `agent` sections in Declarative Pipeline, or plugin:matrix-project[Matrix Project] axes).\n* Label assignments of features like custom tool au"
  },
  "5544": {
    "source_file": "_built-in-node-migration.txt",
    "text": "eters to `agent` sections in Declarative Pipeline, or plugin:matrix-project[Matrix Project] axes).\n* Label assignments of features like custom tool auto-installers, typically used to distinguish OS platforms.\n* Any custom build scripts whose behavior is different based on the `NODE_NAME` or `NODE_LABELS` environment variables\n(or their `env` global variable equivalent in Pipeline).\n* Any similar f"
  },
  "5545": {
    "source_file": "_built-in-node-migration.txt",
    "text": " is different based on the `NODE_NAME` or `NODE_LABELS` environment variables\n(or their `env` global variable equivalent in Pipeline).\n* Any similar features in plugins.\n\nDue to the potential impact to build behavior, deployments upgrading Jenkins to version 2.307 or newer do not automatically get these behavior changes applied.\nInstead, an administrative monitor informs administrators about this "
  },
  "5546": {
    "source_file": "_built-in-node-migration.txt",
    "text": " version 2.307 or newer do not automatically get these behavior changes applied.\nInstead, an administrative monitor informs administrators about this change and allows them to apply it.\n\n// Screenshot here? Is this useful?\n\nBefore applying the built-in node name and label migration, administrators are advised to review their configuration and build scripts to assess the impact to their controller "
  },
  "5547": {
    "source_file": "_built-in-node-migration.txt",
    "text": "in node name and label migration, administrators are advised to review their configuration and build scripts to assess the impact to their controller and jobs.\n\nMost problems with label assignments can likely be worked around by manually assigning the label `master` to the built-in node and then migrating affected configuration incrementally to not need this workaround.\n\n* plugin:workflow-durable-"
  },
  "5548": {
    "source_file": "_built-in-node-migration.txt",
    "text": "e label `master` to the built-in node and then migrating affected configuration incrementally to not need this workaround.\n\n* plugin:workflow-durable-task-step[Pipeline: Nodes and Processes] always sets the `NODE_NAME` to `master` in Pipelines before .\n* plugin:nodelabelparameter[Node and Label Parameter plugin] displays the controller node as `master` in releases before .\n\nUse https://issues.jenk"
  },
  "5549": {
    "source_file": "_built-in-node-migration.txt",
    "text": " .\n* plugin:nodelabelparameter[Node and Label Parameter plugin] displays the controller node as `master` in releases before .\n\nUse https://issues.jenkins.io/issues/?jql=labels%3Dbuilt-in-node-migration-regression[this Jira query] to find compatibility issues tracked in the Jenkins Jira.\n\nUse https://github.com/search?q=%22https%3A%2F%2Fgithub.com%2Fjenkinsci%2Fjenkins%2Fpull%2F5425%22+-repo%3Ajenk"
  },
  "5550": {
    "source_file": "_built-in-node-migration.txt",
    "text": "y issues tracked in the Jenkins Jira.\n\nUse https://github.com/search?q=%22https%3A%2F%2Fgithub.com%2Fjenkinsci%2Fjenkins%2Fpull%2F5425%22+-repo%3Ajenkinsci%2Fjenkins&type=Issues&ref=advsearch&l=&l=[this GitHub query] to find compatibility issues tracked on GitHub.\n\nPlease report problems in the respective plugin's issue tracker.\n\nIf the affected plugin uses the Jenkins Jira to track issues, please"
  },
  "5551": {
    "source_file": "_built-in-node-migration.txt",
    "text": "ked on GitHub.\n\nPlease report problems in the respective plugin's issue tracker.\n\nIf the affected plugin uses the Jenkins Jira to track issues, please add the label `built-in-node-migration-regression`.\n\nIf the affected plugin tracks issues on GitHub, please make sure to mention the https://github.com/jenkinsci/jenkins/pull/5425[Jenkins pull request] that implemented the change in your issue."
  },
  "5552": {
    "source_file": "_built-in-node-migration.txt",
    "text": ", please make sure to mention the https://github.com/jenkinsci/jenkins/pull/5425[Jenkins pull request] that implemented the change in your issue."
  },
  "5553": {
    "source_file": "_compile-the-plugin.txt",
    "text": "Use Apache Maven to compile the plugin and run its automated tests with the command:\n\nmvn clean verify"
  },
  "5554": {
    "source_file": "_context_path.txt",
    "text": "[#context-path]\n\nThe context path is the prefix of a URL path.\nThe Jenkins controller and the reverse proxy *must use the same context path*.\nFor example, if the Jenkins controller URL is https://www.example.com/jenkins/ then the `--prefix=/jenkins` argument must be included in the Jenkins controller command line arguments.\n\nSet the context path when using the Linux packages by running `systemctl "
  },
  "5555": {
    "source_file": "_context_path.txt",
    "text": "argument must be included in the Jenkins controller command line arguments.\n\nSet the context path when using the Linux packages by running `systemctl edit jenkins` and adding the following:\n\n[Service]\nEnvironment=\"JENKINS_PREFIX=/jenkins\"\n\nSet the context path on Windows controllers by including the `--prefix` command line argument in the `jenkins.xml` file in the installation directory.\n\nEnsure t"
  },
  "5556": {
    "source_file": "_context_path.txt",
    "text": "ntext path on Windows controllers by including the `--prefix` command line argument in the `jenkins.xml` file in the installation directory.\n\nEnsure that Jenkins is running at the context path where your reverse proxy is serving Jenkins.\nYou will have the least pain if you keep to this principle.\n\nThe `--prefix` command line argument is not needed if the context path is empty.\nFor example, the URL"
  },
  "5557": {
    "source_file": "_context_path.txt",
    "text": "e the least pain if you keep to this principle.\n\nThe `--prefix` command line argument is not needed if the context path is empty.\nFor example, the URL https://jenkins.example.com/ has an empty context path."
  },
  "5558": {
    "source_file": "_create-a-branch.txt",
    "text": "In a local copy of your  of the plugin repository create a  for your work with the command:\n\ngit checkout -b {task-identifier} master"
  },
  "5559": {
    "source_file": "_create-a-pull-request.txt",
    "text": "Commit that change:\n\ngit add {modified-files}\ngit commit -m \"{task-description}\"\n\nPush the change to GitHub:\n\ngit push origin --set-upstream {task-identifier}\n\nTotal 0 (delta 0), reused 0 (delta 0), pack-reused 0\nremote:\nremote: Create a pull request for '{task-identifier}' on GitHub by visiting:\nremote: https://github.com/user/your-plugin/pull/new/{task-identifier}\nremote:\nTo github.com:user/your"
  },
  "5560": {
    "source_file": "_create-a-pull-request.txt",
    "text": " for '{task-identifier}' on GitHub by visiting:\nremote: https://github.com/user/your-plugin/pull/new/{task-identifier}\nremote:\nTo github.com:user/your-plugin.git\n * [new branch]      {task-identifier} -> {task-identifier}\nBranch '{task-identifier}' tracking remote branch '{task-identifier}'.\n\nNotice that the output of the command includes the URL, which can be used to open a pull request.\nCopy tha"
  },
  "5561": {
    "source_file": "_create-a-pull-request.txt",
    "text": "racking remote branch '{task-identifier}'.\n\nNotice that the output of the command includes the URL, which can be used to open a pull request.\nCopy that URL in your web browser and submit a pull request."
  },
  "5562": {
    "source_file": "_docker-for-tutorials.txt",
    "text": "Open up a terminal window.\nCreate a  in\n  Docker using the following\n\n  command:\ndocker network create jenkins\n\nIn order to execute Docker commands inside Jenkins nodes, download and run\n  the `docker:dind` Docker image using the following\n\n  command:\ndocker run \\\n  --name jenkins-docker \\# <1> --rm \\# <2> --detach \\# <3> --privileged \\# <4> --network jenkins \\# <5> --network-alias docker \\# <6> -"
  },
  "5563": {
    "source_file": "_docker-for-tutorials.txt",
    "text": ":\ndocker run \\\n  --name jenkins-docker \\# <1> --rm \\# <2> --detach \\# <3> --privileged \\# <4> --network jenkins \\# <5> --network-alias docker \\# <6> --env DOCKER_TLS_CERTDIR=/certs \\# <7> --volume jenkins-docker-certs:/certs/client \\# <8> --volume jenkins-data:/var/jenkins_home \\# <9> --publish 2376:2376 \\# <10> --publish 3000:3000 --publish 5000:5000 \\# <11> docker:dind \\# <12> --storage-driver o"
  },
  "5564": {
    "source_file": "_docker-for-tutorials.txt",
    "text": "nkins-data:/var/jenkins_home \\# <9> --publish 2376:2376 \\# <10> --publish 3000:3000 --publish 5000:5000 \\# <11> docker:dind \\# <12> --storage-driver overlay2 # <13> <1> ( _Optional_ ) Specifies the Docker container name to use for running the\nimage. By default, Docker will generate a unique name for the container.\n<2> ( _Optional_ ) Automatically removes the Docker container (the instance of\nthe D"
  },
  "5565": {
    "source_file": "_docker-for-tutorials.txt",
    "text": "By default, Docker will generate a unique name for the container.\n<2> ( _Optional_ ) Automatically removes the Docker container (the instance of\nthe Docker image) when it is shut down.\n<3> ( _Optional_ ) Runs the Docker container in the background. This instance\ncan be stopped later by running `docker stop jenkins-docker`.\n<4> Running Docker in Docker currently requires privileged access to functi"
  },
  "5566": {
    "source_file": "_docker-for-tutorials.txt",
    "text": "his instance\ncan be stopped later by running `docker stop jenkins-docker`.\n<4> Running Docker in Docker currently requires privileged access to function\nproperly. This requirement may be relaxed with newer Linux kernel versions.\n// TODO: what versions of Linux?\n<5> This corresponds with the network created in the earlier step.\n<6> Makes the Docker in Docker container available as the hostname `doc"
  },
  "5567": {
    "source_file": "_docker-for-tutorials.txt",
    "text": "s of Linux?\n<5> This corresponds with the network created in the earlier step.\n<6> Makes the Docker in Docker container available as the hostname `docker`\nwithin the `jenkins` network.\n<7> Enables the use of TLS in the Docker server. Due to the use\nof a privileged container, this is recommended, though it requires the use of\nthe shared volume described below. This environment variable controls the"
  },
  "5568": {
    "source_file": "_docker-for-tutorials.txt",
    "text": "f a privileged container, this is recommended, though it requires the use of\nthe shared volume described below. This environment variable controls the root\ndirectory where Docker TLS certificates are managed.\n<8> Maps the `/certs/client` directory inside the container to\na Docker volume named `jenkins-docker-certs` as created above.\n<9> Maps the `/var/jenkins_home` directory inside the container t"
  },
  "5569": {
    "source_file": "_docker-for-tutorials.txt",
    "text": "side the container to\na Docker volume named `jenkins-docker-certs` as created above.\n<9> Maps the `/var/jenkins_home` directory inside the container to the Docker\nvolume named `jenkins-data`. This will allow for other Docker\ncontainers controlled by this Docker container's Docker daemon to mount data\nfrom Jenkins.\n<10> ( _Optional_ ) Exposes the Docker daemon port on the host machine. This is\nusef"
  },
  "5570": {
    "source_file": "_docker-for-tutorials.txt",
    "text": "this Docker container's Docker daemon to mount data\nfrom Jenkins.\n<10> ( _Optional_ ) Exposes the Docker daemon port on the host machine. This is\nuseful for executing `docker` commands on the host machine to control this\ninner Docker daemon.\n<11> Exposes ports 3000 and 5000 from the docker in docker container, used by some of the tutorials.\n<12> The `docker:dind` image itself. This image can be do"
  },
  "5571": {
    "source_file": "_docker-for-tutorials.txt",
    "text": "oses ports 3000 and 5000 from the docker in docker container, used by some of the tutorials.\n<12> The `docker:dind` image itself. This image can be downloaded before running\nby using the command: `docker image pull docker:dind`.\n<13> The storage driver for the Docker volume. See\n for supported\noptions.\n*Note:* If copying and pasting the command snippet above does not work, try\ncopying and pasting "
  },
  "5572": {
    "source_file": "_docker-for-tutorials.txt",
    "text": "er for the Docker volume. See\n for supported\noptions.\n*Note:* If copying and pasting the command snippet above does not work, try\ncopying and pasting this annotation-free version here:\ndocker run --name jenkins-docker --rm --detach \\\n  --privileged --network jenkins --network-alias docker \\\n  --env DOCKER_TLS_CERTDIR=/certs \\\n  --volume jenkins-docker-certs:/certs/client \\\n  --volume jenkins-data:"
  },
  "5573": {
    "source_file": "_docker-for-tutorials.txt",
    "text": "-network jenkins --network-alias docker \\\n  --env DOCKER_TLS_CERTDIR=/certs \\\n  --volume jenkins-docker-certs:/certs/client \\\n  --volume jenkins-data:/var/jenkins_home \\\n  --publish 3000:3000 --publish 5000:5000 --publish 2376:2376 \\\n  docker:dind --storage-driver overlay2\n\nCustomise official Jenkins Docker image, by executing below two steps:\n.. Create Dockerfile with the following content:\nFROM "
  },
  "5574": {
    "source_file": "_docker-for-tutorials.txt",
    "text": "storage-driver overlay2\n\nCustomise official Jenkins Docker image, by executing below two steps:\n.. Create Dockerfile with the following content:\nFROM jenkins/jenkins:{jenkins-stable}-jdk21\nUSER root\nRUN apt-get update && apt-get install -y lsb-release ca-certificates curl && \\\n    install -m 0755 -d /etc/apt/keyrings && \\\n    curl -fsSL https://download.docker.com/linux/debian/gpg -o /etc/apt/keyr"
  },
  "5575": {
    "source_file": "_docker-for-tutorials.txt",
    "text": "e ca-certificates curl && \\\n    install -m 0755 -d /etc/apt/keyrings && \\\n    curl -fsSL https://download.docker.com/linux/debian/gpg -o /etc/apt/keyrings/docker.asc && \\\n    chmod a+r /etc/apt/keyrings/docker.asc && \\\n    echo \"deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.asc] \\\n    https://download.docker.com/linux/debian $(. /etc/os-release && echo \\\"$VERSION_CODENA"
  },
  "5576": {
    "source_file": "_docker-for-tutorials.txt",
    "text": "int-architecture) signed-by=/etc/apt/keyrings/docker.asc] \\\n    https://download.docker.com/linux/debian $(. /etc/os-release && echo \\\"$VERSION_CODENAME\\\") stable\" \\\n    | tee /etc/apt/sources.list.d/docker.list > /dev/null && \\\n    apt-get update && apt-get install -y docker-ce-cli && \\\n    apt-get clean && rm -rf /var/lib/apt/lists/*\nUSER jenkins\nRUN jenkins-plugin-cli --plugins \"blueocean:1.27."
  },
  "5577": {
    "source_file": "_docker-for-tutorials.txt",
    "text": " apt-get install -y docker-ce-cli && \\\n    apt-get clean && rm -rf /var/lib/apt/lists/*\nUSER jenkins\nRUN jenkins-plugin-cli --plugins \"blueocean:1.27.24 docker-workflow:634.vedc7242b_eda_7 json-path-api\"\n\n.. Build a new docker image from this Dockerfile and assign the image a meaningful name, e.g. \"myjenkins-blueocean:{jenkins-stable}-1\":\ndocker build -t myjenkins-blueocean:{jenkins-stable}-1 .\n\nK"
  },
  "5578": {
    "source_file": "_docker-for-tutorials.txt",
    "text": "ile and assign the image a meaningful name, e.g. \"myjenkins-blueocean:{jenkins-stable}-1\":\ndocker build -t myjenkins-blueocean:{jenkins-stable}-1 .\n\nKeep in mind that the process described above will automatically download the official Jenkins Docker image\nif this hasn't been done before.\n\nRun your own `myjenkins-blueocean:{jenkins-stable}-1` image as a container in Docker using the\n  following\n\n "
  },
  "5579": {
    "source_file": "_docker-for-tutorials.txt",
    "text": " image\nif this hasn't been done before.\n\nRun your own `myjenkins-blueocean:{jenkins-stable}-1` image as a container in Docker using the\n  following\n\n  command:\ndocker run \\\n  --name jenkins-blueocean \\# <1> --detach \\# <2> --network jenkins \\# <3> --env DOCKER_HOST=tcp://docker:2376 \\# <4> --env DOCKER_CERT_PATH=/certs/client \\\n  --env DOCKER_TLS_VERIFY=1 \\\n  --publish 8080:8080 \\# <5> --publish 5"
  },
  "5580": {
    "source_file": "_docker-for-tutorials.txt",
    "text": "env DOCKER_HOST=tcp://docker:2376 \\# <4> --env DOCKER_CERT_PATH=/certs/client \\\n  --env DOCKER_TLS_VERIFY=1 \\\n  --publish 8080:8080 \\# <5> --publish 50000:50000 \\# <6> --volume jenkins-data:/var/jenkins_home \\# <7> --volume jenkins-docker-certs:/certs/client:ro \\# <8> --volume \"$HOME\":/home \\# <9> --restart=on-failure \\# <10> --env JAVA_OPTS=\"-Dhudson.plugins.git.GitSCM.ALLOW_LOCAL_CHECKOUT=true\" "
  },
  "5581": {
    "source_file": "_docker-for-tutorials.txt",
    "text": "s/client:ro \\# <8> --volume \"$HOME\":/home \\# <9> --restart=on-failure \\# <10> --env JAVA_OPTS=\"-Dhudson.plugins.git.GitSCM.ALLOW_LOCAL_CHECKOUT=true\" \\# <11> myjenkins-blueocean:{jenkins-stable}-1 # <12> <1> ( _Optional_ ) Specifies the Docker container name for this instance of\nthe Docker image.\n<2> ( _Optional_ ) Runs the current container in the background\n(i.e. \"detached\" mode) and outputs the"
  },
  "5582": {
    "source_file": "_docker-for-tutorials.txt",
    "text": "ner name for this instance of\nthe Docker image.\n<2> ( _Optional_ ) Runs the current container in the background\n(i.e. \"detached\" mode) and outputs the container ID. If you do not specify this\noption, then the running Docker log for this container is output in the terminal\nwindow.\n<3> Connects this container to the `jenkins` network defined in the earlier\nstep. This makes the Docker daemon from the"
  },
  "5583": {
    "source_file": "_docker-for-tutorials.txt",
    "text": "output in the terminal\nwindow.\n<3> Connects this container to the `jenkins` network defined in the earlier\nstep. This makes the Docker daemon from the previous step available to this\nJenkins container through the hostname `docker`.\n<4> Specifies the environment variables used by `docker`, `docker-compose`, and\nother Docker tools to connect to the Docker daemon from the previous step.\n<5> Maps (i.e"
  },
  "5584": {
    "source_file": "_docker-for-tutorials.txt",
    "text": "environment variables used by `docker`, `docker-compose`, and\nother Docker tools to connect to the Docker daemon from the previous step.\n<5> Maps (i.e. \"publishes\") port 8080 of the current container to\nport 8080 on the host machine. The first number represents the port on the host\nwhile the last represents the container's port. Therefore, if you specified `-p\n49000:8080` for this option, you woul"
  },
  "5585": {
    "source_file": "_docker-for-tutorials.txt",
    "text": " represents the port on the host\nwhile the last represents the container's port. Therefore, if you specified `-p\n49000:8080` for this option, you would be accessing Jenkins on your host machine\nthrough port 49000.\n<6> ( _Optional_ ) Maps port 50000 of the current container to\nport 50000 on the host machine. This is only necessary if you have set up one or\nmore inbound Jenkins agents on other machi"
  },
  "5586": {
    "source_file": "_docker-for-tutorials.txt",
    "text": "f the current container to\nport 50000 on the host machine. This is only necessary if you have set up one or\nmore inbound Jenkins agents on other machines, which in turn interact with\nyour `jenkins-blueocean` container (the Jenkins \"controller\").\nInbound Jenkins agents communicate with the Jenkins\ncontroller through TCP port 50000 by default. You can change this port number on\nyour Jenkins controll"
  },
  "5587": {
    "source_file": "_docker-for-tutorials.txt",
    "text": "und Jenkins agents communicate with the Jenkins\ncontroller through TCP port 50000 by default. You can change this port number on\nyour Jenkins controller through the\npage. If you were to change the *TCP port for inbound Jenkins agents* of your Jenkins controller\nto 51000 (for example), then you would need to re-run Jenkins (via this\n`docker run ...` command) and specify this \"publish\" option with s"
  },
  "5588": {
    "source_file": "_docker-for-tutorials.txt",
    "text": " controller\nto 51000 (for example), then you would need to re-run Jenkins (via this\n`docker run ...` command) and specify this \"publish\" option with something like\n`--publish 52000:51000`, where the last value matches this changed value on the\nJenkins controller and the first value is the port number on the machine hosting\nthe Jenkins controller. Inbound Jenkins agents communicate with the\nJenkins"
  },
  "5589": {
    "source_file": "_docker-for-tutorials.txt",
    "text": "s controller and the first value is the port number on the machine hosting\nthe Jenkins controller. Inbound Jenkins agents communicate with the\nJenkins controller on that port (52000 in this example).\nNote that  do not need this configuration.\n<7> Maps the `/var/jenkins_home` directory in the container to the Docker\n with the name\n`jenkins-data`. Instead of mapping the `/var/jenkins_home` directory"
  },
  "5590": {
    "source_file": "_docker-for-tutorials.txt",
    "text": "s the `/var/jenkins_home` directory in the container to the Docker\n with the name\n`jenkins-data`. Instead of mapping the `/var/jenkins_home` directory to a Docker\nvolume, you could also map this directory to one on your machine's local file\nsystem. For example, specifying the option +\n`--volume $HOME/jenkins:/var/jenkins_home` would map the container's\n`/var/jenkins_home` directory to the `jenkins"
  },
  "5591": {
    "source_file": "_docker-for-tutorials.txt",
    "text": "or example, specifying the option +\n`--volume $HOME/jenkins:/var/jenkins_home` would map the container's\n`/var/jenkins_home` directory to the `jenkins` subdirectory within the `$HOME`\ndirectory on your local machine, which would typically be\n`/Users/<your-username>/jenkins` or `/home/<your-username>/jenkins`.\nNote that if you change the source volume or directory for this, the volume\nfrom the `doc"
  },
  "5592": {
    "source_file": "_docker-for-tutorials.txt",
    "text": "<your-username>/jenkins` or `/home/<your-username>/jenkins`.\nNote that if you change the source volume or directory for this, the volume\nfrom the `docker:dind` container above needs to be updated to match this.\n<8> Maps the `/certs/client` directory to the previously created\n`jenkins-docker-certs` volume. This makes the client TLS certificates needed\nto connect to the Docker daemon available in th"
  },
  "5593": {
    "source_file": "_docker-for-tutorials.txt",
    "text": "to the previously created\n`jenkins-docker-certs` volume. This makes the client TLS certificates needed\nto connect to the Docker daemon available in the path specified by the\n`DOCKER_CERT_PATH` environment variable.\n<9> Maps the `$HOME` directory on the host (i.e. your local) machine (usually\nthe `/Users/<your-username>` directory) to the `/home` directory in the\ncontainer. Used to access local cha"
  },
  "5594": {
    "source_file": "_docker-for-tutorials.txt",
    "text": "he host (i.e. your local) machine (usually\nthe `/Users/<your-username>` directory) to the `/home` directory in the\ncontainer. Used to access local changes to the tutorial repository.\n<10> Configure the Docker container restart policy to restart on failure as described in the .\n<11> Allow local checkout for the tutorial.\nSee  for the reasons why this argument should not be used on a production inst"
  },
  "5595": {
    "source_file": "_docker-for-tutorials.txt",
    "text": "ilure as described in the .\n<11> Allow local checkout for the tutorial.\nSee  for the reasons why this argument should not be used on a production installation.\n<12> The name of the Docker image, which you built in the previous step.\n*Note:* If copying and pasting the command snippet above does not work, try\ncopying and pasting this annotation-free version here:\ndocker run --name jenkins-blueocean "
  },
  "5596": {
    "source_file": "_docker-for-tutorials.txt",
    "text": "g and pasting the command snippet above does not work, try\ncopying and pasting this annotation-free version here:\ndocker run --name jenkins-blueocean --detach \\\n  --network jenkins --env DOCKER_HOST=tcp://docker:2376 \\\n  --env DOCKER_CERT_PATH=/certs/client --env DOCKER_TLS_VERIFY=1 \\\n  --publish 8080:8080 --publish 50000:50000 \\\n  --volume jenkins-data:/var/jenkins_home \\\n  --volume jenkins-docke"
  },
  "5597": {
    "source_file": "_docker-for-tutorials.txt",
    "text": "/client --env DOCKER_TLS_VERIFY=1 \\\n  --publish 8080:8080 --publish 50000:50000 \\\n  --volume jenkins-data:/var/jenkins_home \\\n  --volume jenkins-docker-certs:/certs/client:ro \\\n  --volume \"$HOME\":/home \\\n  --restart=on-failure \\\n  --env JAVA_OPTS=\"-Dhudson.plugins.git.GitSCM.ALLOW_LOCAL_CHECKOUT=true\" \\\n  myjenkins-blueocean:{jenkins-stable}-1\n\nProceed to the <<setup-wizard,Post-installation setup"
  },
  "5598": {
    "source_file": "_docker-for-tutorials.txt",
    "text": "hudson.plugins.git.GitSCM.ALLOW_LOCAL_CHECKOUT=true\" \\\n  myjenkins-blueocean:{jenkins-stable}-1\n\nProceed to the <<setup-wizard,Post-installation setup wizard>>.\n\nThe Jenkins project provides a Linux container image, not a Windows container image.\nBe sure that your Docker for Windows installation is configured to run `Linux Containers` rather than `Windows Containers`.\nSee the Docker documentation "
  },
  "5599": {
    "source_file": "_docker-for-tutorials.txt",
    "text": "sure that your Docker for Windows installation is configured to run `Linux Containers` rather than `Windows Containers`.\nSee the Docker documentation for instructions to .\nOnce configured to run `Linux Containers`, the steps are:\n\nOpen up a command prompt window and similar to the <<on-macos-and-linux,macOS and Linux>> instructions above do the following:\nCreate a bridge network in Docker\ndocker n"
  },
  "5600": {
    "source_file": "_docker-for-tutorials.txt",
    "text": "rompt window and similar to the <<on-macos-and-linux,macOS and Linux>> instructions above do the following:\nCreate a bridge network in Docker\ndocker network create jenkins\n\nRun a docker:dind Docker image\ndocker run --name jenkins-docker --detach ^\n  --privileged --network jenkins --network-alias docker ^\n  --env DOCKER_TLS_CERTDIR=/certs ^\n  --volume jenkins-docker-certs:/certs/client ^\n  --volume"
  },
  "5601": {
    "source_file": "_docker-for-tutorials.txt",
    "text": "--privileged --network jenkins --network-alias docker ^\n  --env DOCKER_TLS_CERTDIR=/certs ^\n  --volume jenkins-docker-certs:/certs/client ^\n  --volume jenkins-data:/var/jenkins_home ^\n  --publish 3000:3000 --publish 5000:5000 --publish 2376:2376 ^\n  docker:dind\n\nCustomise official Jenkins Docker image, by executing below two steps:\n.. Create Dockerfile with the following content:\nFROM jenkins/jenk"
  },
  "5602": {
    "source_file": "_docker-for-tutorials.txt",
    "text": "docker:dind\n\nCustomise official Jenkins Docker image, by executing below two steps:\n.. Create Dockerfile with the following content:\nFROM jenkins/jenkins:{jenkins-stable}-jdk21\nUSER root\nRUN apt-get update && apt-get install -y lsb-release\nRUN curl -fsSLo /usr/share/keyrings/docker-archive-keyring.asc \\\n  https://download.docker.com/linux/debian/gpg\nRUN echo \"deb [arch=$(dpkg --print-architecture)"
  },
  "5603": {
    "source_file": "_docker-for-tutorials.txt",
    "text": "fsSLo /usr/share/keyrings/docker-archive-keyring.asc \\\n  https://download.docker.com/linux/debian/gpg\nRUN echo \"deb [arch=$(dpkg --print-architecture) \\\n  signed-by=/usr/share/keyrings/docker-archive-keyring.asc] \\\n  https://download.docker.com/linux/debian \\\n  $(lsb_release -cs) stable\" > /etc/apt/sources.list.d/docker.list\nRUN apt-get update && apt-get install -y docker-ce-cli\nUSER jenkins\nRUN j"
  },
  "5604": {
    "source_file": "_docker-for-tutorials.txt",
    "text": "/debian \\\n  $(lsb_release -cs) stable\" > /etc/apt/sources.list.d/docker.list\nRUN apt-get update && apt-get install -y docker-ce-cli\nUSER jenkins\nRUN jenkins-plugin-cli --plugins \"blueocean:1.27.24 docker-workflow:634.vedc7242b_eda_7 json-path-api\"\n\n.. Build a new docker image from this Dockerfile and assign the image a meaningful name, e.g. \"myjenkins-blueocean:{jenkins-stable}-1\":\ndocker build -t"
  },
  "5605": {
    "source_file": "_docker-for-tutorials.txt",
    "text": ". Build a new docker image from this Dockerfile and assign the image a meaningful name, e.g. \"myjenkins-blueocean:{jenkins-stable}-1\":\ndocker build -t myjenkins-blueocean:{jenkins-stable}-1 .\n\nKeep in mind that the process described above will automatically download the official Jenkins Docker image\nif this hasn't been done before.\n\nRun your own `myjenkins-blueocean:{jenkins-stable}-1` image as a "
  },
  "5606": {
    "source_file": "_docker-for-tutorials.txt",
    "text": "tically download the official Jenkins Docker image\nif this hasn't been done before.\n\nRun your own `myjenkins-blueocean:{jenkins-stable}-1` image as a container in Docker using the following\n\n  command:\ndocker run --name jenkins-blueocean --detach ^\n  --network jenkins --env DOCKER_HOST=tcp://docker:2376 ^\n  --env DOCKER_CERT_PATH=/certs/client --env DOCKER_TLS_VERIFY=1 ^\n  --volume jenkins-data:/v"
  },
  "5607": {
    "source_file": "_docker-for-tutorials.txt",
    "text": " --network jenkins --env DOCKER_HOST=tcp://docker:2376 ^\n  --env DOCKER_CERT_PATH=/certs/client --env DOCKER_TLS_VERIFY=1 ^\n  --volume jenkins-data:/var/jenkins_home ^\n  --volume jenkins-docker-certs:/certs/client:ro ^\n  --volume \"%HOMEDRIVE%%HOMEPATH%\":/home ^\n  --restart=on-failure ^\n  --env JAVA_OPTS=\"-Dhudson.plugins.git.GitSCM.ALLOW_LOCAL_CHECKOUT=true\" ^\n  --publish 8080:8080 --publish 50000"
  },
  "5608": {
    "source_file": "_docker-for-tutorials.txt",
    "text": "H%\":/home ^\n  --restart=on-failure ^\n  --env JAVA_OPTS=\"-Dhudson.plugins.git.GitSCM.ALLOW_LOCAL_CHECKOUT=true\" ^\n  --publish 8080:8080 --publish 50000:50000 myjenkins-blueocean:{jenkins-stable}-1\n\nProceed to the <<setup-wizard,Setup wizard>>.\n\n[[accessing-the-jenkins-blue-ocean-docker-container]]\n\nIf you have some experience with Docker and you wish or need to access your\nDocker container through "
  },
  "5609": {
    "source_file": "_docker-for-tutorials.txt",
    "text": "ssing-the-jenkins-blue-ocean-docker-container]]\n\nIf you have some experience with Docker and you wish or need to access your\nDocker container through a terminal/command prompt using the\n\ncommand, you can add an option like `--name jenkins-tutorial` to the `docker exec` command.\nThat will access the Jenkins Docker container named \"jenkins-tutorial\".\n\nThis means you could access your docker containe"
  },
  "5610": {
    "source_file": "_docker-for-tutorials.txt",
    "text": "o the `docker exec` command.\nThat will access the Jenkins Docker container named \"jenkins-tutorial\".\n\nThis means you could access your docker container (through a separate\nterminal/command prompt window) with a `docker exec` command like:\n\n`docker exec -it jenkins-blueocean bash`\n\n[[accessing-the-jenkins-console-log-through-docker-logs]]\n\nThere is a possibility you may need to access the Jenkins c"
  },
  "5611": {
    "source_file": "_docker-for-tutorials.txt",
    "text": "ec -it jenkins-blueocean bash`\n\n[[accessing-the-jenkins-console-log-through-docker-logs]]\n\nThere is a possibility you may need to access the Jenkins console log, for\ninstance, when <<unlocking-jenkins,Unlocking Jenkins>> as part of the\n<<setup-wizard,Post-installation setup wizard>>.\n\nThe Jenkins console log is easily accessible through the terminal/command\nprompt window from which you executed th"
  },
  "5612": {
    "source_file": "_docker-for-tutorials.txt",
    "text": ",Post-installation setup wizard>>.\n\nThe Jenkins console log is easily accessible through the terminal/command\nprompt window from which you executed the `docker run ...` command.\nIn case if needed you can also access the Jenkins console log through the\n of\nyour container using the following command:\n\n`docker logs <docker-container-name>`\n\nYour `<docker-container-name>` can be obtained using the `do"
  },
  "5613": {
    "source_file": "_docker-for-tutorials.txt",
    "text": "e\n of\nyour container using the following command:\n\n`docker logs <docker-container-name>`\n\nYour `<docker-container-name>` can be obtained using the `docker ps` command.\n\nThere is a possibility you may need to access the Jenkins home directory, for\ninstance, to check the details of a Jenkins build in the `workspace`\nsubdirectory.\n\nIf you mapped the Jenkins home directory (`/var/jenkins_home`) to one"
  },
  "5614": {
    "source_file": "_docker-for-tutorials.txt",
    "text": "tance, to check the details of a Jenkins build in the `workspace`\nsubdirectory.\n\nIf you mapped the Jenkins home directory (`/var/jenkins_home`) to one on your\nmachine's local file system (i.e. in the `docker run ...` command\n<<downloading-and-running-jenkins-in-docker,above>>), then you can access the\ncontents of this directory through your machine's usual terminal/command prompt.\n\nOtherwise, if y"
  },
  "5615": {
    "source_file": "_docker-for-tutorials.txt",
    "text": "-jenkins-in-docker,above>>), then you can access the\ncontents of this directory through your machine's usual terminal/command prompt.\n\nOtherwise, if you specified the `--volume jenkins-data:/var/jenkins_home` option in\nthe `docker run ...` command, you can access the contents of the Jenkins home\ndirectory through your container's terminal/command prompt using the\n\ncommand:\n\n`docker container exec "
  },
  "5616": {
    "source_file": "_docker-for-tutorials.txt",
    "text": "ou can access the contents of the Jenkins home\ndirectory through your container's terminal/command prompt using the\n\ncommand:\n\n`docker container exec -it <docker-container-name> bash`\n\nAs mentioned <<accessing-the-jenkins-console-log-through-docker-logs,above>>,\nyour `<docker-container-name>` can be obtained using the\n\ncommand. If you specified the +\n`--name jenkins-blueocean` option in the `docke"
  },
  "5617": {
    "source_file": "_docker-for-tutorials.txt",
    "text": "ogs,above>>,\nyour `<docker-container-name>` can be obtained using the\n\ncommand. If you specified the +\n`--name jenkins-blueocean` option in the `docker container run ...`\ncommand above (see also\n<<accessing-the-jenkins-blue-ocean-docker-container,Accessing the Jenkins/Blue\nOcean Docker container>>), you can simply use the `docker container exec` command:\n\n`docker container exec -it jenkins-blueoce"
  },
  "5618": {
    "source_file": "_docker-for-tutorials.txt",
    "text": "essing the Jenkins/Blue\nOcean Docker container>>), you can simply use the `docker container exec` command:\n\n`docker container exec -it jenkins-blueocean bash`"
  },
  "5619": {
    "source_file": "_docker.txt",
    "text": "Open up a terminal window.\nCreate a  in Docker using the following  command:\ndocker network create jenkins\n\nIn order to execute Docker commands inside Jenkins nodes, download and run the `docker:dind` Docker image using the following  command:\ndocker run \\\n  --name jenkins-docker \\# <1> --rm \\# <2> --detach \\# <3> --privileged \\# <4> --network jenkins \\# <5> --network-alias docker \\# <6> --env DOC"
  },
  "5620": {
    "source_file": "_docker.txt",
    "text": " run \\\n  --name jenkins-docker \\# <1> --rm \\# <2> --detach \\# <3> --privileged \\# <4> --network jenkins \\# <5> --network-alias docker \\# <6> --env DOCKER_TLS_CERTDIR=/certs \\# <7> --volume jenkins-docker-certs:/certs/client \\# <8> --volume jenkins-data:/var/jenkins_home \\# <9> --publish 2376:2376 \\# <10> docker:dind \\# <11> --storage-driver overlay2# <12> <1> ( _Optional_ ) Specifies the Docker co"
  },
  "5621": {
    "source_file": "_docker.txt",
    "text": "ta:/var/jenkins_home \\# <9> --publish 2376:2376 \\# <10> docker:dind \\# <11> --storage-driver overlay2# <12> <1> ( _Optional_ ) Specifies the Docker container name to use for running the image.\nBy default, Docker generates a unique name for the container.\n<2> ( _Optional_ ) Automatically removes the Docker container (the replica of the Docker image) when it is shut down.\n<3> ( _Optional_ ) Runs the"
  },
  "5622": {
    "source_file": "_docker.txt",
    "text": "ner.\n<2> ( _Optional_ ) Automatically removes the Docker container (the replica of the Docker image) when it is shut down.\n<3> ( _Optional_ ) Runs the Docker container in the background.\nYou can stop this process by running `docker stop jenkins-docker`.\n<4> Running Docker in Docker currently requires privileged access to function properly.\nThis requirement may be relaxed with newer Linux kernel ve"
  },
  "5623": {
    "source_file": "_docker.txt",
    "text": "r`.\n<4> Running Docker in Docker currently requires privileged access to function properly.\nThis requirement may be relaxed with newer Linux kernel versions.\n// TODO: what versions of Linux?\n<5> This corresponds with the network created in the earlier step.\n<6> Makes the Docker in Docker container available as the hostname `docker` within the `jenkins` network.\n<7> Enables the use of TLS in the Do"
  },
  "5624": {
    "source_file": "_docker.txt",
    "text": "r step.\n<6> Makes the Docker in Docker container available as the hostname `docker` within the `jenkins` network.\n<7> Enables the use of TLS in the Docker server.\nDue to the use of a privileged container, this is recommended, though it requires the use of the shared volume described below.\nThis environment variable controls the root directory where Docker TLS certificates are managed.\n<8> Maps the"
  },
  "5625": {
    "source_file": "_docker.txt",
    "text": "se of the shared volume described below.\nThis environment variable controls the root directory where Docker TLS certificates are managed.\n<8> Maps the `/certs/client` directory inside the container to a Docker volume named `jenkins-docker-certs` as created above.\n<9> Maps the `/var/jenkins_home` directory inside the container to the Docker volume named `jenkins-data`.\nThis allows for other Docker "
  },
  "5626": {
    "source_file": "_docker.txt",
    "text": "reated above.\n<9> Maps the `/var/jenkins_home` directory inside the container to the Docker volume named `jenkins-data`.\nThis allows for other Docker containers controlled by this Docker container's Docker daemon to mount data from Jenkins.\n<10> ( _Optional_ ) Exposes the Docker daemon port on the host machine.\nThis is useful for executing `docker` commands on the host machine to control this inne"
  },
  "5627": {
    "source_file": "_docker.txt",
    "text": "ptional_ ) Exposes the Docker daemon port on the host machine.\nThis is useful for executing `docker` commands on the host machine to control this inner Docker daemon.\n<11> The `docker:dind` image itself.\nDownload this image before running, by using the command: `docker image pull docker:dind`.\n<12> The storage driver for the Docker volume.\nRefer to the  documentation for supported options.\n\nNOTE: "
  },
  "5628": {
    "source_file": "_docker.txt",
    "text": "he command: `docker image pull docker:dind`.\n<12> The storage driver for the Docker volume.\nRefer to the  documentation for supported options.\n\nNOTE: If you have problems copying and pasting the above command snippet, use the annotation-free version below:\ndocker run --name jenkins-docker --rm --detach \\\n  --privileged --network jenkins --network-alias docker \\\n  --env DOCKER_TLS_CERTDIR=/certs \\\n"
  },
  "5629": {
    "source_file": "_docker.txt",
    "text": "below:\ndocker run --name jenkins-docker --rm --detach \\\n  --privileged --network jenkins --network-alias docker \\\n  --env DOCKER_TLS_CERTDIR=/certs \\\n  --volume jenkins-docker-certs:/certs/client \\\n  --volume jenkins-data:/var/jenkins_home \\\n  --publish 2376:2376 \\\n  docker:dind --storage-driver overlay2\n\nCustomize the official Jenkins Docker image, by executing the following two steps:\n.. Create "
  },
  "5630": {
    "source_file": "_docker.txt",
    "text": "ish 2376:2376 \\\n  docker:dind --storage-driver overlay2\n\nCustomize the official Jenkins Docker image, by executing the following two steps:\n.. Create a Dockerfile with the following content:\nFROM jenkins/jenkins:{jenkins-stable}-jdk21\nUSER root\nRUN apt-get update && apt-get install -y lsb-release ca-certificates curl && \\\n    install -m 0755 -d /etc/apt/keyrings && \\\n    curl -fsSL https://downloa"
  },
  "5631": {
    "source_file": "_docker.txt",
    "text": "pt-get update && apt-get install -y lsb-release ca-certificates curl && \\\n    install -m 0755 -d /etc/apt/keyrings && \\\n    curl -fsSL https://download.docker.com/linux/debian/gpg -o /etc/apt/keyrings/docker.asc && \\\n    chmod a+r /etc/apt/keyrings/docker.asc && \\\n    echo \"deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.asc] \\\n    https://download.docker.com/linux/debian"
  },
  "5632": {
    "source_file": "_docker.txt",
    "text": "ocker.asc && \\\n    echo \"deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.asc] \\\n    https://download.docker.com/linux/debian $(. /etc/os-release && echo \\\"$VERSION_CODENAME\\\") stable\" \\\n    | tee /etc/apt/sources.list.d/docker.list > /dev/null && \\\n    apt-get update && apt-get install -y docker-ce-cli && \\\n    apt-get clean && rm -rf /var/lib/apt/lists/*\nUSER jenkins\nRUN"
  },
  "5633": {
    "source_file": "_docker.txt",
    "text": "er.list > /dev/null && \\\n    apt-get update && apt-get install -y docker-ce-cli && \\\n    apt-get clean && rm -rf /var/lib/apt/lists/*\nUSER jenkins\nRUN jenkins-plugin-cli --plugins \"blueocean docker-workflow json-path-api\"\n\n.. Build a new docker image from this Dockerfile, and assign the image a meaningful name, such as \"myjenkins-blueocean:{jenkins-stable}-1\":\ndocker build -t myjenkins-blueocean:{"
  },
  "5634": {
    "source_file": "_docker.txt",
    "text": " from this Dockerfile, and assign the image a meaningful name, such as \"myjenkins-blueocean:{jenkins-stable}-1\":\ndocker build -t myjenkins-blueocean:{jenkins-stable}-1 .\n\nIf you have not yet downloaded the official Jenkins Docker image, the above process automatically downloads it for you.\n\nRun your own `myjenkins-blueocean:{jenkins-stable}-1` image as a container in Docker using the following  co"
  },
  "5635": {
    "source_file": "_docker.txt",
    "text": "cess automatically downloads it for you.\n\nRun your own `myjenkins-blueocean:{jenkins-stable}-1` image as a container in Docker using the following  command:\ndocker run \\\n  --name jenkins-blueocean \\# <1> --restart=on-failure \\# <2> --detach \\# <3> --network jenkins \\# <4> --env DOCKER_HOST=tcp://docker:2376 \\# <5> --env DOCKER_CERT_PATH=/certs/client \\\n  --env DOCKER_TLS_VERIFY=1 \\\n  --publish 808"
  },
  "5636": {
    "source_file": "_docker.txt",
    "text": "network jenkins \\# <4> --env DOCKER_HOST=tcp://docker:2376 \\# <5> --env DOCKER_CERT_PATH=/certs/client \\\n  --env DOCKER_TLS_VERIFY=1 \\\n  --publish 8080:8080 \\# <6> --publish 50000:50000 \\# <7> --volume jenkins-data:/var/jenkins_home \\# <8> --volume jenkins-docker-certs:/certs/client:ro \\# <9> myjenkins-blueocean:{jenkins-stable}-1 # <10> <1> ( _Optional_ ) Specifies the Docker container name for t"
  },
  "5637": {
    "source_file": "_docker.txt",
    "text": "enkins-docker-certs:/certs/client:ro \\# <9> myjenkins-blueocean:{jenkins-stable}-1 # <10> <1> ( _Optional_ ) Specifies the Docker container name for this instance of the Docker image.\n<2> Always restart the container if it stops.\nIf it is manually stopped, it is restarted only when Docker daemon restarts or the container itself is manually restarted.\n<3> ( _Optional_ ) Runs the current container i"
  },
  "5638": {
    "source_file": "_docker.txt",
    "text": "opped, it is restarted only when Docker daemon restarts or the container itself is manually restarted.\n<3> ( _Optional_ ) Runs the current container in the background, known as \"detached\" mode, and outputs the container ID.\nIf you do not specify this option, then the running Docker log for this container is displayed in the terminal window.\n<4> Connects this container to the `jenkins` network prev"
  },
  "5639": {
    "source_file": "_docker.txt",
    "text": " option, then the running Docker log for this container is displayed in the terminal window.\n<4> Connects this container to the `jenkins` network previously defined.\nThe Docker daemon is now available to this Jenkins container through the hostname `docker`.\n<5> Specifies the environment variables used by `docker`, `docker-compose`, and other Docker tools to connect to the Docker daemon from the pr"
  },
  "5640": {
    "source_file": "_docker.txt",
    "text": "ocker`.\n<5> Specifies the environment variables used by `docker`, `docker-compose`, and other Docker tools to connect to the Docker daemon from the previous step.\n<6> Maps, or publishes, port 8080 of the current container to port 8080 on the host machine.\nThe first number represents the port on the host, while the last represents the container's port.\nFor example, to access Jenkins on your host ma"
  },
  "5641": {
    "source_file": "_docker.txt",
    "text": "hine.\nThe first number represents the port on the host, while the last represents the container's port.\nFor example, to access Jenkins on your host machine through port 49000, enter `-p 49000:8080` for this option.\n<7> ( _Optional_ ) Maps port 50000 of the current container to port 50000 on the host machine.\nThis is only necessary if you have set up one or more inbound Jenkins agents on other mach"
  },
  "5642": {
    "source_file": "_docker.txt",
    "text": "of the current container to port 50000 on the host machine.\nThis is only necessary if you have set up one or more inbound Jenkins agents on other machines, which in turn interact with your `jenkins-blueocean` container, known as the Jenkins \"controller\".\nInbound Jenkins agents communicate with the Jenkins controller through TCP port 50000 by default.\nYou can change this port number on your Jenkins"
  },
  "5643": {
    "source_file": "_docker.txt",
    "text": "er\".\nInbound Jenkins agents communicate with the Jenkins controller through TCP port 50000 by default.\nYou can change this port number on your Jenkins controller through the  page.\nFor example, if you update the *TCP port for inbound Jenkins agents* of your Jenkins controller to 51000, you need to re-run Jenkins via the `docker run ...` command.\nSpecify the \"publish\" option as follows: the first v"
  },
  "5644": {
    "source_file": "_docker.txt",
    "text": "of your Jenkins controller to 51000, you need to re-run Jenkins via the `docker run ...` command.\nSpecify the \"publish\" option as follows: the first value is the port number on the machine hosting the Jenkins controller, and the last value matches the changed value on the Jenkins controller, for example,`--publish 52000:51000`.\nInbound Jenkins agents communicate with the Jenkins controller on that"
  },
  "5645": {
    "source_file": "_docker.txt",
    "text": "e changed value on the Jenkins controller, for example,`--publish 52000:51000`.\nInbound Jenkins agents communicate with the Jenkins controller on that port (52000 in this example).\nNote that  do not need this configuration.\n<8> Maps the `/var/jenkins_home` directory in the container to the Docker  with the name `jenkins-data`.\nInstead of mapping the `/var/jenkins_home` directory to a Docker volume"
  },
  "5646": {
    "source_file": "_docker.txt",
    "text": "_home` directory in the container to the Docker  with the name `jenkins-data`.\nInstead of mapping the `/var/jenkins_home` directory to a Docker volume, you can also map this directory to one on your machine's local file system.\nFor example, specify the option `--volume $HOME/jenkins:/var/jenkins_home` to map the container's `/var/jenkins_home` directory to the `jenkins` subdirectory within the `$H"
  },
  "5647": {
    "source_file": "_docker.txt",
    "text": "he option `--volume $HOME/jenkins:/var/jenkins_home` to map the container's `/var/jenkins_home` directory to the `jenkins` subdirectory within the `$HOME` directory on your local machine -- typically `/Users/<your-username>/jenkins` or `/home/<your-username>/jenkins`.\nNOTE: If you change the source volume or directory for this, the volume from the `docker:dind` container above needs to be updated "
  },
  "5648": {
    "source_file": "_docker.txt",
    "text": "sername>/jenkins`.\nNOTE: If you change the source volume or directory for this, the volume from the `docker:dind` container above needs to be updated to match this.\n<9> Maps the `/certs/client` directory to the previously created `jenkins-docker-certs` volume.\nThe client TLS certificates required to connect to the Docker daemon are now available in the path specified by the `DOCKER_CERT_PATH` envi"
  },
  "5649": {
    "source_file": "_docker.txt",
    "text": "s` volume.\nThe client TLS certificates required to connect to the Docker daemon are now available in the path specified by the `DOCKER_CERT_PATH` environment variable.\n<10> The name of the Docker image, which you built in the previous step.\n\nNOTE: If you have problems copying and pasting the command snippet, use the annotation-free version below:\ndocker run --name jenkins-blueocean --restart=on-fa"
  },
  "5650": {
    "source_file": "_docker.txt",
    "text": " you have problems copying and pasting the command snippet, use the annotation-free version below:\ndocker run --name jenkins-blueocean --restart=on-failure --detach \\\n  --network jenkins --env DOCKER_HOST=tcp://docker:2376 \\\n  --env DOCKER_CERT_PATH=/certs/client --env DOCKER_TLS_VERIFY=1 \\\n  --publish 8080:8080 --publish 50000:50000 \\\n  --volume jenkins-data:/var/jenkins_home \\\n  --volume jenkins"
  },
  "5651": {
    "source_file": "_docker.txt",
    "text": "/certs/client --env DOCKER_TLS_VERIFY=1 \\\n  --publish 8080:8080 --publish 50000:50000 \\\n  --volume jenkins-data:/var/jenkins_home \\\n  --volume jenkins-docker-certs:/certs/client:ro \\\n  myjenkins-blueocean:{jenkins-stable}-1\n\nProceed to the <<setup-wizard,Post-installation setup wizard>>.\n\nThe Jenkins project provides a Linux container image, not a Windows container image.\nBe sure that your Docker "
  },
  "5652": {
    "source_file": "_docker.txt",
    "text": "zard,Post-installation setup wizard>>.\n\nThe Jenkins project provides a Linux container image, not a Windows container image.\nBe sure that your Docker for Windows installation is configured to run `Linux Containers` rather than `Windows Containers`.\nRefer to the Docker documentation for instructions to .\nOnce configured to run `Linux Containers`, the steps are:\n\nOpen up a command prompt window and "
  },
  "5653": {
    "source_file": "_docker.txt",
    "text": "efer to the Docker documentation for instructions to .\nOnce configured to run `Linux Containers`, the steps are:\n\nOpen up a command prompt window and similar to the <<on-macos-and-linux,macOS and Linux>> instructions above do the following:\nCreate a bridge network in Docker\ndocker network create jenkins\n\nRun a docker:dind Docker image\ndocker run --name jenkins-docker --rm --detach ^\n  --privileged"
  },
  "5654": {
    "source_file": "_docker.txt",
    "text": "bridge network in Docker\ndocker network create jenkins\n\nRun a docker:dind Docker image\ndocker run --name jenkins-docker --rm --detach ^\n  --privileged --network jenkins --network-alias docker ^\n  --env DOCKER_TLS_CERTDIR=/certs ^\n  --volume jenkins-docker-certs:/certs/client ^\n  --volume jenkins-data:/var/jenkins_home ^\n  --publish 2376:2376 ^\n  docker:dind\n\nCustomize the official Jenkins Docker i"
  },
  "5655": {
    "source_file": "_docker.txt",
    "text": "ocker-certs:/certs/client ^\n  --volume jenkins-data:/var/jenkins_home ^\n  --publish 2376:2376 ^\n  docker:dind\n\nCustomize the official Jenkins Docker image, by executing the following two steps:\n.. Create a Dockerfile with the following content:\nFROM jenkins/jenkins:{jenkins-stable}-jdk21\nUSER root\nRUN apt-get update && apt-get install -y lsb-release\nRUN curl -fsSLo /usr/share/keyrings/docker-archi"
  },
  "5656": {
    "source_file": "_docker.txt",
    "text": "jenkins/jenkins:{jenkins-stable}-jdk21\nUSER root\nRUN apt-get update && apt-get install -y lsb-release\nRUN curl -fsSLo /usr/share/keyrings/docker-archive-keyring.asc \\\n  https://download.docker.com/linux/debian/gpg\nRUN echo \"deb [arch=$(dpkg --print-architecture) \\\n  signed-by=/usr/share/keyrings/docker-archive-keyring.asc] \\\n  https://download.docker.com/linux/debian \\\n  $(lsb_release -cs) stable\""
  },
  "5657": {
    "source_file": "_docker.txt",
    "text": "rchitecture) \\\n  signed-by=/usr/share/keyrings/docker-archive-keyring.asc] \\\n  https://download.docker.com/linux/debian \\\n  $(lsb_release -cs) stable\" > /etc/apt/sources.list.d/docker.list\nRUN apt-get update && apt-get install -y docker-ce-cli\nUSER jenkins\nRUN jenkins-plugin-cli --plugins \"blueocean docker-workflow json-path-api\"\n\n.. Build a new docker image from this Dockerfile and assign the ima"
  },
  "5658": {
    "source_file": "_docker.txt",
    "text": "enkins\nRUN jenkins-plugin-cli --plugins \"blueocean docker-workflow json-path-api\"\n\n.. Build a new docker image from this Dockerfile and assign the image a meaningful name, e.g. \"myjenkins-blueocean:{jenkins-stable}-1\":\ndocker build -t myjenkins-blueocean:{jenkins-stable}-1 .\n\nIf you have not yet downloaded the official Jenkins Docker image, the above process automatically downloads it for you.\n\nRu"
  },
  "5659": {
    "source_file": "_docker.txt",
    "text": "cean:{jenkins-stable}-1 .\n\nIf you have not yet downloaded the official Jenkins Docker image, the above process automatically downloads it for you.\n\nRun your own `myjenkins-blueocean:{jenkins-stable}-1` image as a container in Docker using the following  command:\ndocker run --name jenkins-blueocean --restart=on-failure --detach ^\n  --network jenkins --env DOCKER_HOST=tcp://docker:2376 ^\n  --env DOC"
  },
  "5660": {
    "source_file": "_docker.txt",
    "text": "ng  command:\ndocker run --name jenkins-blueocean --restart=on-failure --detach ^\n  --network jenkins --env DOCKER_HOST=tcp://docker:2376 ^\n  --env DOCKER_CERT_PATH=/certs/client --env DOCKER_TLS_VERIFY=1 ^\n  --volume jenkins-data:/var/jenkins_home ^\n  --volume jenkins-docker-certs:/certs/client:ro ^\n  --publish 8080:8080 --publish 50000:50000 myjenkins-blueocean:{jenkins-stable}-1\n\nProceed to the "
  },
  "5661": {
    "source_file": "_docker.txt",
    "text": "  --volume jenkins-docker-certs:/certs/client:ro ^\n  --publish 8080:8080 --publish 50000:50000 myjenkins-blueocean:{jenkins-stable}-1\n\nProceed to the <<setup-wizard,Setup wizard>>.\n\n[[accessing-the-jenkins-blue-ocean-docker-container]]\n\nIf you want to access your Docker container through a terminal/command prompt using the  command, add an option like `--name jenkins-tutorial` to the `docker exec`"
  },
  "5662": {
    "source_file": "_docker.txt",
    "text": "o access your Docker container through a terminal/command prompt using the  command, add an option like `--name jenkins-tutorial` to the `docker exec` command.\nThat will access the Jenkins Docker container named \"jenkins-tutorial\".\n\nYou can access your docker container (through a separate terminal/command prompt window) with a `docker exec` command such as:\n\n`docker exec -it jenkins-blueocean bash"
  },
  "5663": {
    "source_file": "_docker.txt",
    "text": "ur docker container (through a separate terminal/command prompt window) with a `docker exec` command such as:\n\n`docker exec -it jenkins-blueocean bash`\n\n[[accessing-the-jenkins-console-log-through-docker-logs]]\n\nYou may want to access the Jenkins console log, for instance, when <<unlocking-jenkins,Unlocking Jenkins>> as part of the <<setup-wizard,Post-installation setup wizard>>.\n\nAccess the Jenki"
  },
  "5664": {
    "source_file": "_docker.txt",
    "text": "sole log, for instance, when <<unlocking-jenkins,Unlocking Jenkins>> as part of the <<setup-wizard,Post-installation setup wizard>>.\n\nAccess the Jenkins console log through the terminal/command prompt window from which you executed the `docker run ...` command.\nAlternatively, you can also access the Jenkins console log through the  of your container using the following command:\n\n`docker logs <dock"
  },
  "5665": {
    "source_file": "_docker.txt",
    "text": ".` command.\nAlternatively, you can also access the Jenkins console log through the  of your container using the following command:\n\n`docker logs <docker-container-name>`\n\nYour `<docker-container-name>` can be obtained using the `docker ps` command.\n\nYou can access the Jenkins home directory, to check the details of a Jenkins build in the `workspace` subdirectory, for example.\n\nIf you mapped the Je"
  },
  "5666": {
    "source_file": "_docker.txt",
    "text": "You can access the Jenkins home directory, to check the details of a Jenkins build in the `workspace` subdirectory, for example.\n\nIf you mapped the Jenkins home directory (`/var/jenkins_home`) to one on your machine's local file system, for example, in the `docker run ...` command <<downloading-and-running-jenkins-in-docker,above>>, access the directory contents through your machine's usual termin"
  },
  "5667": {
    "source_file": "_docker.txt",
    "text": "in the `docker run ...` command <<downloading-and-running-jenkins-in-docker,above>>, access the directory contents through your machine's usual terminal/command prompt.\n\nIf you specified the `--volume jenkins-data:/var/jenkins_home` option in the `docker run ...` command, access the contents of the Jenkins home directory through your container's terminal/command prompt using the  command:\n\n`docker"
  },
  "5668": {
    "source_file": "_docker.txt",
    "text": "cker run ...` command, access the contents of the Jenkins home directory through your container's terminal/command prompt using the  command:\n\n`docker container exec -it <docker-container-name> bash`\n\nAs per <<accessing-the-jenkins-console-log-through-docker-logs,the previous section>>, get your `<docker-container-name>` using the  command.\nIf you specified the `--name jenkins-blueocean` option in"
  },
  "5669": {
    "source_file": "_docker.txt",
    "text": "h-docker-logs,the previous section>>, get your `<docker-container-name>` using the  command.\nIf you specified the `--name jenkins-blueocean` option in the `docker container run ...`  command above (refer to <<accessing-the-jenkins-blue-ocean-docker-container,Accessing the Jenkins/Blue Ocean Docker container>> if needed), use the `docker container exec` command:\n\n`docker container exec -it jenkins-"
  },
  "5670": {
    "source_file": "_docker.txt",
    "text": "ontainer,Accessing the Jenkins/Blue Ocean Docker container>> if needed), use the `docker container exec` command:\n\n`docker container exec -it jenkins-blueocean bash`"
  },
  "5671": {
    "source_file": "_install-apache-maven.txt",
    "text": "Jenkins plugins are built with Apache Maven.\n\nDownload Maven from the .\nMake sure to download one of the binary archives (with `bin` in their name).\n\nNOTE: Many Linux distributions provide packages for Maven for an easier install and upgrade experience.\nConsult your distribution's documentation for details.\nOn macOS, the  package manager offers Maven packages.\nMake sure a recent version of Maven 3"
  },
  "5672": {
    "source_file": "_install-apache-maven.txt",
    "text": "ce.\nConsult your distribution's documentation for details.\nOn macOS, the  package manager offers Maven packages.\nMake sure a recent version of Maven 3, ideally 3.9.6 or newer, is provided if you decide to go this route.\nOlder versions can cause an error \"Unknown packaging: hpi\".\n\nNext, you will need to extract Maven and take note of its location.\nWhen you extract the Maven files, make sure you ext"
  },
  "5673": {
    "source_file": "_install-apache-maven.txt",
    "text": "ror \"Unknown packaging: hpi\".\n\nNext, you will need to extract Maven and take note of its location.\nWhen you extract the Maven files, make sure you extract them directly into the target directory.\nFor example, extract the files straight into C:\\Program Files (x86)\\Maven; do not extract the files to a different location and then copy the files.\n\nThen, add the full path of the `bin/` subdirectory ext"
  },
  "5674": {
    "source_file": "_install-apache-maven.txt",
    "text": "m Files (x86)\\Maven; do not extract the files to a different location and then copy the files.\n\nThen, add the full path of the `bin/` subdirectory extracted (for example, `~/Applications/apache-maven/bin` or `C:\\Program files\\Maven\\bin`) to the `PATH` variable in your OS.\nThis will let you invoke Maven using `mvn`.\n\nThe rest of the tutorial assumes that Maven is on your `PATH` environment variable"
  },
  "5675": {
    "source_file": "_install-apache-maven.txt",
    "text": "` variable in your OS.\nThis will let you invoke Maven using `mvn`.\n\nThe rest of the tutorial assumes that Maven is on your `PATH` environment variable.\n\nApache Maven needs to be configured for Jenkins plugin development.\nThe  for Apache Maven requires some additional global configurations to function correctly with older Jenkins plugin environments.\n\nImproper configuration settings can cause Maven"
  },
  "5676": {
    "source_file": "_install-apache-maven.txt",
    "text": "s some additional global configurations to function correctly with older Jenkins plugin environments.\n\nImproper configuration settings can cause Maven to report errors or warnings, including failure to download artifacts during the update process.\nTo avoid issues, include the following content in the `settings.xml` file in your `~/.m2` directory (Windows users will find them in `%USERPROFILE%\\.m2\\"
  },
  "5677": {
    "source_file": "_install-apache-maven.txt",
    "text": " avoid issues, include the following content in the `settings.xml` file in your `~/.m2` directory (Windows users will find them in `%USERPROFILE%\\.m2\\settings.xml`):\n\n<settings xmlns=\"http://maven.apache.org/SETTINGS/1.0.0\"\n          xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n          xsi:schemaLocation=\"http://maven.apache.org/SETTINGS/1.0.0\n                              http://maven."
  },
  "5678": {
    "source_file": "_install-apache-maven.txt",
    "text": "//www.w3.org/2001/XMLSchema-instance\"\n          xsi:schemaLocation=\"http://maven.apache.org/SETTINGS/1.0.0\n                              http://maven.apache.org/xsd/settings-1.0.0.xsd\">\n  <pluginGroups>\n    <pluginGroup>org.jenkins-ci.tools</pluginGroup>\n  </pluginGroups>\n  <profiles>\n    <profile>\n      <id>jenkins</id>\n      <activation>\n        <activeByDefault>true</activeByDefault>\n      </ac"
  },
  "5679": {
    "source_file": "_install-apache-maven.txt",
    "text": "oup>\n  </pluginGroups>\n  <profiles>\n    <profile>\n      <id>jenkins</id>\n      <activation>\n        <activeByDefault>true</activeByDefault>\n      </activation>\n      <repositories>\n        <repository>\n          <id>repo.jenkins-ci.org</id>\n          <url>https://repo.jenkins-ci.org/public/</url>\n        </repository>\n      </repositories>\n      <pluginRepositories>\n        <pluginRepository>\n    "
  },
  "5680": {
    "source_file": "_install-apache-maven.txt",
    "text": " <url>https://repo.jenkins-ci.org/public/</url>\n        </repository>\n      </repositories>\n      <pluginRepositories>\n        <pluginRepository>\n          <id>repo.jenkins-ci.org</id>\n          <url>https://repo.jenkins-ci.org/public/</url>\n        </pluginRepository>\n      </pluginRepositories>\n    </profile>\n  </profiles>\n</settings>"
  },
  "5681": {
    "source_file": "_install-apache-maven.txt",
    "text": "</pluginRepository>\n      </pluginRepositories>\n    </profile>\n  </profiles>\n</settings>"
  },
  "5682": {
    "source_file": "_installation_requirements.txt",
    "text": "Minimum hardware requirements:\n\n* 256 MB of RAM\n* 1 GB of drive space (although 10 GB is a recommended minimum if running\n  Jenkins as a Docker container)\n\nRecommended hardware configuration for a small team:\n\n* 4 GB+ of RAM\n* 50 GB+ of drive space\n\nComprehensive hardware recommendations:\n\n* Hardware: see the  page\n\nSoftware requirements:\n\n* Java: see the  page\n* Web browser: see the  page\n* For W"
  },
  "5683": {
    "source_file": "_installation_requirements.txt",
    "text": "Comprehensive hardware recommendations:\n\n* Hardware: see the  page\n\nSoftware requirements:\n\n* Java: see the  page\n* Web browser: see the  page\n* For Windows operating system:\n* For Linux operating system:\n* For servlet containers:"
  },
  "5684": {
    "source_file": "_jenkins-command-parameters.txt",
    "text": "Jenkins networking configuration is generally controlled by command line arguments.\nThe networking configuration arguments are:\n\n.Jenkins Networking Command Line Parameters\n[cols=\",\",options=\"header\",]\n|===\n|Command Line Parameter\n|Description\n\n|`--httpPort=$HTTP_PORT`\n|Runs Jenkins listener on port $HTTP_PORT using standard _http_ protocol.\nThe default is port 8080.\nTo disable (because you're usi"
  },
  "5685": {
    "source_file": "_jenkins-command-parameters.txt",
    "text": "ttpPort=$HTTP_PORT`\n|Runs Jenkins listener on port $HTTP_PORT using standard _http_ protocol.\nThe default is port 8080.\nTo disable (because you're using _https_), use port `+-1+`.\nThis option does not impact the root URL being generated within Jenkins logic (UI, inbound agent files, etc.).\nIt is defined by the Jenkins URL specified in the global configuration.\n\n|`--httpListenAddress=$HTTP_HOST`\n|B"
  },
  "5686": {
    "source_file": "_jenkins-command-parameters.txt",
    "text": "s logic (UI, inbound agent files, etc.).\nIt is defined by the Jenkins URL specified in the global configuration.\n\n|`--httpListenAddress=$HTTP_HOST`\n|Binds Jenkins to the IP address represented by $HTTP_HOST.\nThe default is 0.0.0.0 \u2014 i.e. listening on all available interfaces.\nFor example, to only listen for requests from localhost, you could use:\n`--httpListenAddress=127.0.0.1`\n\n|`--httpsPort=$HTT"
  },
  "5687": {
    "source_file": "_jenkins-command-parameters.txt",
    "text": " all available interfaces.\nFor example, to only listen for requests from localhost, you could use:\n`--httpListenAddress=127.0.0.1`\n\n|`--httpsPort=$HTTPS_PORT`\n|Uses HTTPS protocol on port $HTTPS_PORT.\nThis option does not impact the root URL being generated within Jenkins logic (UI, inbound agent files, etc.).\nIt is defined by the Jenkins URL specified in the global configuration.\n\n|`--httpsListen"
  },
  "5688": {
    "source_file": "_jenkins-command-parameters.txt",
    "text": "nerated within Jenkins logic (UI, inbound agent files, etc.).\nIt is defined by the Jenkins URL specified in the global configuration.\n\n|`--httpsListenAddress=$HTTPS_HOST`\n|Binds Jenkins to listen for HTTPS requests on the IP address represented by $HTTPS_HOST.\n\n|`--http2Port=$HTTP_PORT`\n|Uses HTTP/2 protocol on port $HTTP_PORT.\nThis option does not impact the root URL being generated within Jenkin"
  },
  "5689": {
    "source_file": "_jenkins-command-parameters.txt",
    "text": "TTPS_HOST.\n\n|`--http2Port=$HTTP_PORT`\n|Uses HTTP/2 protocol on port $HTTP_PORT.\nThis option does not impact the root URL being generated within Jenkins logic (UI, inbound agent files, etc.).\nIt is defined by the Jenkins URL specified in the global configuration.\n\n|`--http2ListenAddress=$HTTPS_HOST`\n|Binds Jenkins to listen for HTTP/2 requests on the IP address represented by $HTTPS_HOST.\n\n|`--pref"
  },
  "5690": {
    "source_file": "_jenkins-command-parameters.txt",
    "text": "nfiguration.\n\n|`--http2ListenAddress=$HTTPS_HOST`\n|Binds Jenkins to listen for HTTP/2 requests on the IP address represented by $HTTPS_HOST.\n\n|`--prefix=$PREFIX`\n|Runs Jenkins to include the $PREFIX at the end of the URL.\nFor example, set _--prefix=/jenkins_ to make Jenkins accessible at _http://myServer:8080/jenkins_\n\n|`--sessionTimeout=$TIMEOUT`\n|Sets the http session timeout value\nto $SESSION_T"
  },
  "5691": {
    "source_file": "_jenkins-command-parameters.txt",
    "text": "jenkins_ to make Jenkins accessible at _http://myServer:8080/jenkins_\n\n|`--sessionTimeout=$TIMEOUT`\n|Sets the http session timeout value\nto $SESSION_TIMEOUT minutes. Default to what webapp specifies, and then\nto 60 minutes\n|===\n\nOther Jenkins initialization options are also controlled by command line arguments.\nThe miscellaneous configuration arguments are:\n\n.Jenkins Miscellaneous Command Line Par"
  },
  "5692": {
    "source_file": "_jenkins-command-parameters.txt",
    "text": "ization options are also controlled by command line arguments.\nThe miscellaneous configuration arguments are:\n\n.Jenkins Miscellaneous Command Line Parameters\n[cols=\",\",options=\"header\",]\n|===\n|Command Line Parameter\n|Description\n\n|`--argumentsRealm.passwd.$USER=$PASS`\n|Assigns the password for user $USER.\nIf Jenkins security is enabled, you must log in as a user who has an _admin_ role to configur"
  },
  "5693": {
    "source_file": "_jenkins-command-parameters.txt",
    "text": "asswd.$USER=$PASS`\n|Assigns the password for user $USER.\nIf Jenkins security is enabled, you must log in as a user who has an _admin_ role to configure Jenkins.\n\n|`--argumentsRealm.roles.$USER=admin`\n|Assigns user $USER the admin  role.\nThe user can configure Jenkins even if security is enabled in Jenkins.\nRefer to  for more information.\n\n|`--paramsFromStdIn`\n|Reads parameters from standard input "
  },
  "5694": {
    "source_file": "_jenkins-command-parameters.txt",
    "text": "configure Jenkins even if security is enabled in Jenkins.\nRefer to  for more information.\n\n|`--paramsFromStdIn`\n|Reads parameters from standard input (stdin).\nWhen parameters are passed via the command line, they can be viewed using `ps(1)` in Unix or Process Explorer in Windows as long as the process keeps running.\nThis is undesirable when passing sensitive parameters like `--httpsKeyStorePasswor"
  },
  "5695": {
    "source_file": "_jenkins-command-parameters.txt",
    "text": "r Process Explorer in Windows as long as the process keeps running.\nThis is undesirable when passing sensitive parameters like `--httpsKeyStorePassword`.\nWith the `--paramsFromStdIn` parameter you can replace e.g. +\n`java -jar jenkins.war --httpPort=-1 --httpsPort=443 --httpsKeyStore=path/to/keystore --httpsKeyStorePassword=keystorePassword` +\nwith +\n`echo '--httpPort=-1 --httpsPort=443 --httpsKey"
  },
  "5696": {
    "source_file": "_jenkins-command-parameters.txt",
    "text": "-1 --httpsPort=443 --httpsKeyStore=path/to/keystore --httpsKeyStorePassword=keystorePassword` +\nwith +\n`echo '--httpPort=-1 --httpsPort=443 --httpsKeyStore=path/to/keystore --httpsKeyStorePassword=keystorePassword' \\| java -jar jenkins.war --paramsFromStdIn`.\n\n|`--useJmx`\n|Enable\n|===\n\nJenkins passes all command line parameters to the Winstone servlet container.\nMore information about Jenkins Wins"
  },
  "5697": {
    "source_file": "_jenkins-command-parameters.txt",
    "text": "omStdIn`.\n\n|`--useJmx`\n|Enable\n|===\n\nJenkins passes all command line parameters to the Winstone servlet container.\nMore information about Jenkins Winstone command line parameters is available from the\nCAUTION: *Be Careful with Command Line Parameters* +\nJenkins ignores command line parameters it doesn't understand instead of producing an error.\nBe careful when using command line parameters and mak"
  },
  "5698": {
    "source_file": "_jenkins-command-parameters.txt",
    "text": "* +\nJenkins ignores command line parameters it doesn't understand instead of producing an error.\nBe careful when using command line parameters and make sure you have the correct spelling.\nFor example, the parameter needed for defining the Jenkins administrative user is `--argument**s**Realm` and not `--argumentRealm`.\n\nSome Jenkins behaviors are configured with Java properties.\nJava properties are"
  },
  "5699": {
    "source_file": "_jenkins-command-parameters.txt",
    "text": "inistrative user is `--argument**s**Realm` and not `--argumentRealm`.\n\nSome Jenkins behaviors are configured with Java properties.\nJava properties are set from the command line that started Jenkins.\nProperty assignments use the form `-DsomeName=someValue` to assign the value `someValue` to the property named `someName`.\nFor example, to assign the value `true` to a property `testName`, the command "
  },
  "5700": {
    "source_file": "_jenkins-command-parameters.txt",
    "text": "alue` to assign the value `someValue` to the property named `someName`.\nFor example, to assign the value `true` to a property `testName`, the command line argument would be `-DtestName=true`.\n\nRefer to the detailed list of  for more information.\n\nIf you're setting up Jenkins using the built-in Winstone server and want to use an existing certificate for HTTPS:\n\n--httpPort=-1 \\\n--httpsPort=443 \\\n--h"
  },
  "5701": {
    "source_file": "_jenkins-command-parameters.txt",
    "text": "you're setting up Jenkins using the built-in Winstone server and want to use an existing certificate for HTTPS:\n\n--httpPort=-1 \\\n--httpsPort=443 \\\n--httpsKeyStore=path/to/keystore \\\n--httpsKeyStorePassword=keystorePassword\n\nThe  allows web servers to reduce latency over encrypted connections by pipelining requests, multiplexing requests, and allowing servers to push, in some cases, before receivin"
  },
  "5702": {
    "source_file": "_jenkins-command-parameters.txt",
    "text": " reduce latency over encrypted connections by pipelining requests, multiplexing requests, and allowing servers to push, in some cases, before receiving a client request for the data.\nThe Jetty server used by Jenkins supports HTTP/2 with the addition of the Application-Layer Protocol Negotiation (ALPN) TLS extension.\n\nNOTE: Enabling HTTP/2 implicitly enables TLS even if no HTTPS port is set, and as"
  },
  "5703": {
    "source_file": "_jenkins-command-parameters.txt",
    "text": "of the Application-Layer Protocol Negotiation (ALPN) TLS extension.\n\nNOTE: Enabling HTTP/2 implicitly enables TLS even if no HTTPS port is set, and as of Jenkins 2.339, which uses Winstone 5.23, you have to also specify an HTTPS key store file.\n\n--httpPort=-1 \\\n--http2Port=9090 \\\n--httpsKeyStore=path/to/keystore \\\n--httpsKeyStorePassword=keystorePassword\n\nThese instructions use a stock Jenkins ins"
  },
  "5704": {
    "source_file": "_jenkins-command-parameters.txt",
    "text": "tpPort=-1 \\\n--http2Port=9090 \\\n--httpsKeyStore=path/to/keystore \\\n--httpsKeyStorePassword=keystorePassword\n\nThese instructions use a stock Jenkins installation on Windows Server.\nThe instructions assume a certificate signed by a Certificate Authority such as Digicert.\nIf you are making your own certificate skip steps 3, 4, and 5.\n\nThis process utilizes Java's keytool.\nUse the Java `keytool` includ"
  },
  "5705": {
    "source_file": "_jenkins-command-parameters.txt",
    "text": " such as Digicert.\nIf you are making your own certificate skip steps 3, 4, and 5.\n\nThis process utilizes Java's keytool.\nUse the Java `keytool` included with your Java installation.\n\n*Step 1*: Create a new keystore on your server.\nThis will place a 'keystore' file in your current directory.\n\nC:\\>keytool -genkeypair -keysize 2048 -keyalg RSA -alias jenkins -keystore keystore\nEnter keystore password"
  },
  "5706": {
    "source_file": "_jenkins-command-parameters.txt",
    "text": "keystore' file in your current directory.\n\nC:\\>keytool -genkeypair -keysize 2048 -keyalg RSA -alias jenkins -keystore keystore\nEnter keystore password:\nRe-enter new password:\nWhat is your first and last name?\n[Unknown]: server.example.com\nWhat is the name of your organizational unit?\n[Unknown]: A Unit\nWhat is the name of your organization?\n[Unknown]: A Company\nWhat is the name of your City or Loca"
  },
  "5707": {
    "source_file": "_jenkins-command-parameters.txt",
    "text": " name of your organizational unit?\n[Unknown]: A Unit\nWhat is the name of your organization?\n[Unknown]: A Company\nWhat is the name of your City or Locality?\n[Unknown]: A City\nWhat is the name of your State or Province?\n[Unknown]: A State\nWhat is the two-letter country code for this unit?\n[Unknown]: US\nIs CN=server.example.com, OU=A Unit, O=A Company, L=A City, ST=A State, C=US correct?\n[no]: yes\n\nE"
  },
  "5708": {
    "source_file": "_jenkins-command-parameters.txt",
    "text": "wo-letter country code for this unit?\n[Unknown]: US\nIs CN=server.example.com, OU=A Unit, O=A Company, L=A City, ST=A State, C=US correct?\n[no]: yes\n\nEnter key password for <jenkins>\n(RETURN if same as keystore password):\n\n*Step 2*: Verify the keystore was created (your fingerprint will vary).\n\nC:\\>keytool -list -keystore keystore\nEnter keystore password:\n\nKeystore type: JKS\nKeystore provider: SUN\n"
  },
  "5709": {
    "source_file": "_jenkins-command-parameters.txt",
    "text": "e was created (your fingerprint will vary).\n\nC:\\>keytool -list -keystore keystore\nEnter keystore password:\n\nKeystore type: JKS\nKeystore provider: SUN\n\nYour keystore contains 1 entry\n\njenkins, May 6, 2015, PrivateKeyEntry,\nCertificate fingerprint (SHA1): AA:AA:AA:AA:AA:AA:AA:AA:AA:AA ...\n\n*Step 3*: Create the certificate request.  This will create a\n'certreq.csr' file in your current directory.\n\nC:"
  },
  "5710": {
    "source_file": "_jenkins-command-parameters.txt",
    "text": "1): AA:AA:AA:AA:AA:AA:AA:AA:AA:AA ...\n\n*Step 3*: Create the certificate request.  This will create a\n'certreq.csr' file in your current directory.\n\nC:\\>keytool -certreq -alias jenkins -keyalg RSA ^\n-file certreq.csr ^\n-ext SAN=dns:server-name,dns:server-name.your.company.com ^\n-keystore keystore\nEnter keystore password:\n\n*Step 4*: Use the contents of the `+certreq.csr+` file to generate a certific"
  },
  "5711": {
    "source_file": "_jenkins-command-parameters.txt",
    "text": "ver-name.your.company.com ^\n-keystore keystore\nEnter keystore password:\n\n*Step 4*: Use the contents of the `+certreq.csr+` file to generate a certificate from your certificate provider.\nRequest a SHA-1 certificate (SHA-2 is untested but will likely work).\nIf using DigiCert, download the resulting certificate as Other format  \"a .p7b bundle of all the certs in a .p7b file\".\n\n*Step 5*: Add the resul"
  },
  "5712": {
    "source_file": "_jenkins-command-parameters.txt",
    "text": "ork).\nIf using DigiCert, download the resulting certificate as Other format  \"a .p7b bundle of all the certs in a .p7b file\".\n\n*Step 5*: Add the resulting .p7b into the keystore you created above.\n\nC:\\>keytool -import ^\n-alias jenkins ^\n-trustcacerts ^\n-file response_from_digicert.p7b ^\n-keystore keystore\nEnter keystore password:\nCertificate reply was installed in keystore\n\n*Step 6*: Copy the 'key"
  },
  "5713": {
    "source_file": "_jenkins-command-parameters.txt",
    "text": " ^\n-file response_from_digicert.p7b ^\n-keystore keystore\nEnter keystore password:\nCertificate reply was installed in keystore\n\n*Step 6*: Copy the 'keystore' file to your Jenkins secrets directory.\nOn a stock installation, this will be at\n\nC:\\Program Files (x86)\\Jenkins\\secrets\n\n*Step 7*: Modify the <arguments> section of your\n`+C:\\Program Files (x86)\\Jenkins\\jenkins.xml+` file to reflect the new\nc"
  },
  "5714": {
    "source_file": "_jenkins-command-parameters.txt",
    "text": "Files (x86)\\Jenkins\\secrets\n\n*Step 7*: Modify the <arguments> section of your\n`+C:\\Program Files (x86)\\Jenkins\\jenkins.xml+` file to reflect the new\ncertificate.\nNOTE: This example disables http via `+--httpPort=-1+` and places the server on `+8443+` via `+--httpsPort=8443+`.\n\n<arguments>\n  -Xrs\n  -Xmx256m\n  -Dhudson.lifecycle=hudson.lifecycle.WindowsServiceLifecycle\n  -jar \"%BASE%\\jenkins.war\"\n  "
  },
  "5715": {
    "source_file": "_jenkins-command-parameters.txt",
    "text": " via `+--httpsPort=8443+`.\n\n<arguments>\n  -Xrs\n  -Xmx256m\n  -Dhudson.lifecycle=hudson.lifecycle.WindowsServiceLifecycle\n  -jar \"%BASE%\\jenkins.war\"\n  --httpPort=-1\n  --httpsPort=8443\n  --httpsKeyStore=\"%BASE%\\secrets\\keystore\"\n  --httpsKeyStorePassword=your.password.here\n</arguments>\n\n*Step 8*: Restart the jenkins service to initialize the new configuration.\n\nnet stop jenkins\nnet start jenkins\n\n*S"
  },
  "5716": {
    "source_file": "_jenkins-command-parameters.txt",
    "text": "rd=your.password.here\n</arguments>\n\n*Step 8*: Restart the jenkins service to initialize the new configuration.\n\nnet stop jenkins\nnet start jenkins\n\n*Step 9*: After 30-60 seconds, Jenkins will have completed the startup process and you should be able to access the website at _https://server.example.com:8443_.\nVerify the certificate looks good via your browser's tools.\nIf the service terminates imme"
  },
  "5717": {
    "source_file": "_jenkins-command-parameters.txt",
    "text": "to access the website at _https://server.example.com:8443_.\nVerify the certificate looks good via your browser's tools.\nIf the service terminates immediately, there's an error somewhere in your configuration.\nUseful error information can be found in:\n\nC:\\Program Files (x86)\\Jenkins\\jenkins.err.log\nC:\\Program Files (x86)\\Jenkins\\jenkins.out.log"
  },
  "5718": {
    "source_file": "_jenkins-command-parameters.txt",
    "text": "\n\nC:\\Program Files (x86)\\Jenkins\\jenkins.err.log\nC:\\Program Files (x86)\\Jenkins\\jenkins.out.log"
  },
  "5719": {
    "source_file": "_kubernetes.txt",
    "text": "A typical Jenkins deployment consists of a controller node and, optionally, one or more agents. To simplify the deployment of Jenkins, we\u2019ll use  to deploy Jenkins.\nHelm is a package manager for Kubernetes and its package format is called a chart.\nMany community-developed charts are available on .\n\nHelm Charts provide \u201cpush button\u201d deployment and deletion of apps, making adoption and development o"
  },
  "5720": {
    "source_file": "_kubernetes.txt",
    "text": "ny community-developed charts are available on .\n\nHelm Charts provide \u201cpush button\u201d deployment and deletion of apps, making adoption and development of Kubernetes apps easier for those with little container or microservices experience.\n\nHelm command line interface::\nIf you don't have Helm command line interface installed and configured locally, see the sections below to <<Install Helm>> and <<Conf"
  },
  "5721": {
    "source_file": "_kubernetes.txt",
    "text": "line interface::\nIf you don't have Helm command line interface installed and configured locally, see the sections below to <<Install Helm>> and <<Configure Helm>>.\n\nTo install Helm CLI, follow the instructions from the  page.\n\nOnce Helm is installed and set up properly, add the Jenkins repo as follows:\n\nhelm repo add jenkinsci https://charts.jenkins.io\nhelm repo update\n\nThe helm charts in the Jenk"
  },
  "5722": {
    "source_file": "_kubernetes.txt",
    "text": "and set up properly, add the Jenkins repo as follows:\n\nhelm repo add jenkinsci https://charts.jenkins.io\nhelm repo update\n\nThe helm charts in the Jenkins repo can be listed with the command:\n\nhelm search repo jenkinsci\n\nWe want to create a  for our Jenkins controller pod.\nThis will prevent us from losing our whole configuration of the Jenkins controller and our jobs when we reboot our minikube.\nTh"
  },
  "5723": {
    "source_file": "_kubernetes.txt",
    "text": "enkins controller pod.\nThis will prevent us from losing our whole configuration of the Jenkins controller and our jobs when we reboot our minikube.\nThis  explains which directories we can use to mount or data.\nIn a multi-node Kubernetes cluster, you\u2019ll need some solution like NFS to make the mount directory available in the whole cluster.\nBut because we use minikube which is a one-node cluster we "
  },
  "5724": {
    "source_file": "_kubernetes.txt",
    "text": "ll need some solution like NFS to make the mount directory available in the whole cluster.\nBut because we use minikube which is a one-node cluster we don\u2019t have to bother about it.\n\nWe choose to use the `/data` directory. This directory will contain our Jenkins controller configuration.\n\n*We will create a volume which is called jenkins-pv:*\n\nPaste the content from the  into a YAML formatted file c"
  },
  "5725": {
    "source_file": "_kubernetes.txt",
    "text": "our Jenkins controller configuration.\n\n*We will create a volume which is called jenkins-pv:*\n\nPaste the content from the  into a YAML formatted file called `jenkins-01-volume.yaml`.\nRun the following command to apply the spec:\nkubectl apply -f jenkins-01-volume.yaml\n\nNOTE: It\u2019s worth noting that, in the above spec, hostPath uses the /data/jenkins-volume/ of your node to emulate network-attached st"
  },
  "5726": {
    "source_file": "_kubernetes.txt",
    "text": "s-01-volume.yaml\n\nNOTE: It\u2019s worth noting that, in the above spec, hostPath uses the /data/jenkins-volume/ of your node to emulate network-attached storage.\nThis approach is only suited for development and testing purposes.\nFor production, you should provide a network resource like a Google Compute Engine persistent disk, or an Amazon Elastic Block Store volume.\n\nMinikube configured for hostPath s"
  },
  "5727": {
    "source_file": "_kubernetes.txt",
    "text": " provide a network resource like a Google Compute Engine persistent disk, or an Amazon Elastic Block Store volume.\n\nMinikube configured for hostPath sets the permissions on /data to the root account only. Once the volume is created you will need to manually change the permissions to allow the jenkins account to write its data.\n\nminikube ssh\nsudo chown -R 1000:1000 /data/jenkins-volume\n\nIn Kubernet"
  },
  "5728": {
    "source_file": "_kubernetes.txt",
    "text": "anually change the permissions to allow the jenkins account to write its data.\n\nminikube ssh\nsudo chown -R 1000:1000 /data/jenkins-volume\n\nIn Kubernetes, service accounts are used to provide an identity for pods.\nPods that want to interact with the API server will authenticate with a\nparticular service account.\nBy default, applications will authenticate as the `default` service account in\nthe name"
  },
  "5729": {
    "source_file": "_kubernetes.txt",
    "text": "PI server will authenticate with a\nparticular service account.\nBy default, applications will authenticate as the `default` service account in\nthe namespace they are running in.\nThis means, for example, that an application running in the `test` namespace\nwill use the default service account of the `test` namespace.\n\n*We will create a service account called jenkins:*\n\nA ClusterRole is a set of permi"
  },
  "5730": {
    "source_file": "_kubernetes.txt",
    "text": "ace\nwill use the default service account of the `test` namespace.\n\n*We will create a service account called jenkins:*\n\nA ClusterRole is a set of permissions that can be assigned to resources within a given cluster.\nKubernetes APIs are categorized into API groups, based on the API objects that they relate to.\nWhile creating a ClusterRole, you can specify the operations that can be performed by the "
  },
  "5731": {
    "source_file": "_kubernetes.txt",
    "text": "o API groups, based on the API objects that they relate to.\nWhile creating a ClusterRole, you can specify the operations that can be performed by the ClusterRole on one or more API objects in one or more API groups, just as we have done above.\nClusterRoles have several uses. You can use a ClusterRole to:\n\n* define permissions on namespaced resources and be granted within individual namespace(s)\n* "
  },
  "5732": {
    "source_file": "_kubernetes.txt",
    "text": "rRoles have several uses. You can use a ClusterRole to:\n\n* define permissions on namespaced resources and be granted within individual namespace(s)\n* define permissions on namespaced resources and be granted across all namespaces\n* define permissions on cluster-scoped resources\n\nIf you want to define a role cluster-wide, use a ClusterRole;\nif you want to define a role within a namespace, use a Rol"
  },
  "5733": {
    "source_file": "_kubernetes.txt",
    "text": " on cluster-scoped resources\n\nIf you want to define a role cluster-wide, use a ClusterRole;\nif you want to define a role within a namespace, use a Role.\n\nA role binding grants the permissions defined in a role to a user or set of users.\nIt holds a list of subjects (users, groups, or service accounts), and a reference to the role being granted.\n\nA RoleBinding may reference any Role in the same name"
  },
  "5734": {
    "source_file": "_kubernetes.txt",
    "text": "st of subjects (users, groups, or service accounts), and a reference to the role being granted.\n\nA RoleBinding may reference any Role in the same namespace.\nAlternatively, a RoleBinding can reference a ClusterRole and bind that ClusterRole to the namespace of the RoleBinding.\nTo bind a ClusterRole to all the namespaces in our cluster, we use a ClusterRoleBinding.\n\nPaste the content from the  into "
  },
  "5735": {
    "source_file": "_kubernetes.txt",
    "text": "espace of the RoleBinding.\nTo bind a ClusterRole to all the namespaces in our cluster, we use a ClusterRoleBinding.\n\nPaste the content from the  into a YAML formatted file called\n`jenkins-02-sa.yaml`.\nRun the following command to apply the spec:\nkubectl apply -f jenkins-02-sa.yaml\n\nWe will deploy Jenkins including the Jenkins Kubernetes plugin.\nSee the https://github.com/jenkinsci/helm-charts/tree"
  },
  "5736": {
    "source_file": "_kubernetes.txt",
    "text": "ctl apply -f jenkins-02-sa.yaml\n\nWe will deploy Jenkins including the Jenkins Kubernetes plugin.\nSee the https://github.com/jenkinsci/helm-charts/tree/main/charts/jenkins[official chart] for more details.\n\nTo enable persistence, we will create an override file and pass it as an argument to the\n  Helm CLI.\n   Paste the content from https://raw.githubusercontent.com/jenkinsci/helm-charts/main/charts"
  },
  "5737": {
    "source_file": "_kubernetes.txt",
    "text": "rride file and pass it as an argument to the\n  Helm CLI.\n   Paste the content from https://raw.githubusercontent.com/jenkinsci/helm-charts/main/charts/jenkins/values.yaml into a YAML formatted file called `jenkins-values.yaml`.\nThe `jenkins-values.yaml` is used as a template to provide values that are necessary for setup.\n\nOpen the `jenkins-values.yaml` file in your favorite text editor and modify"
  },
  "5738": {
    "source_file": "_kubernetes.txt",
    "text": "ml` is used as a template to provide values that are necessary for setup.\n\nOpen the `jenkins-values.yaml` file in your favorite text editor and modify the following:\n\n  * nodePort: Because we are using minikube we need to use NodePort as service type. Only cloud providers offer load balancers. We define port 32000 as port.\n\n    * storageClass:\nstorageClass: jenkins-pv\n\n    * serviceAccount: the se"
  },
  "5739": {
    "source_file": "_kubernetes.txt",
    "text": ". Only cloud providers offer load balancers. We define port 32000 as port.\n\n    * storageClass:\nstorageClass: jenkins-pv\n\n    * serviceAccount: the serviceAccount section of the `jenkins-values.yaml` file should look like this:\nserviceAccount:\n  create: false\n# Service account name is autogenerated by default\nname: jenkins\nannotations: {}\n\n    Where `name: jenkins` refers to the serviceAccount cre"
  },
  "5740": {
    "source_file": "_kubernetes.txt",
    "text": "te: false\n# Service account name is autogenerated by default\nname: jenkins\nannotations: {}\n\n    Where `name: jenkins` refers to the serviceAccount created for jenkins.\n\n    * We can also define which plugins we want to install on our Jenkins.\n      We use some default plugins like git and the pipeline plugin.\n\nNow you can install Jenkins by running the `helm install` command and passing it the\n  f"
  },
  "5741": {
    "source_file": "_kubernetes.txt",
    "text": "e use some default plugins like git and the pipeline plugin.\n\nNow you can install Jenkins by running the `helm install` command and passing it the\n  following arguments:\n\n  * The name of the release `jenkins`\n  * The -f flag with the YAML file with overrides `jenkins-values.yaml`\n  * The name of the chart `jenkinsci/jenkins`\n  * The `-n` flag with the name of your namespace `jenkins`\nchart=jenkins"
  },
  "5742": {
    "source_file": "_kubernetes.txt",
    "text": "verrides `jenkins-values.yaml`\n  * The name of the chart `jenkinsci/jenkins`\n  * The `-n` flag with the name of your namespace `jenkins`\nchart=jenkinsci/jenkins\nhelm install jenkins -n jenkins -f jenkins-values.yaml $chart\n\nThis outputs something similar to the following:\nNAME: jenkins\nLAST DEPLOYED: Wed Sep 16 11:13:10 2020\nNAMESPACE: jenkins\nSTATUS: deployed\nREVISION: 1\n\n\ud83d\udc46\ud83c\udffbNote that your passwor"
  },
  "5743": {
    "source_file": "_kubernetes.txt",
    "text": "ilar to the following:\nNAME: jenkins\nLAST DEPLOYED: Wed Sep 16 11:13:10 2020\nNAMESPACE: jenkins\nSTATUS: deployed\nREVISION: 1\n\n\ud83d\udc46\ud83c\udffbNote that your password will be different.\n\n*Option 2*\nRun the following command:\njsonpath=\"{.data.jenkins-admin-password}\"\nkubectl get secret -n jenkins jenkins -o jsonpath=$jsonpath\n\nThe output should be a **base64 encoded string** like this:\nWkIwRkdnbDZYZg==\n\nDecode th"
  },
  "5744": {
    "source_file": "_kubernetes.txt",
    "text": "\"\nkubectl get secret -n jenkins jenkins -o jsonpath=$jsonpath\n\nThe output should be a **base64 encoded string** like this:\nWkIwRkdnbDZYZg==\n\nDecode the base64 string and you have your password. You can use  to decode your output.\n\nGet the name of the Pod running that is running Jenkins using the following command:\nkubectl get pods -n jenkins\n\nUse the kubectl command to set up port forwarding:\nkube"
  },
  "5745": {
    "source_file": "_kubernetes.txt",
    "text": " Pod running that is running Jenkins using the following command:\nkubectl get pods -n jenkins\n\nUse the kubectl command to set up port forwarding:\nkubectl -n jenkins port-forward <pod_name> 8080:8080\nForwarding from 127.0.0.1:8080 -> 8080\nForwarding from [::1]:8080 -> 8080\n\nVisit http://127.0.0.1:8080/ and log in using `admin` as the username and the password you retrieved earlier.\n\nThis section de"
  },
  "5746": {
    "source_file": "_kubernetes.txt",
    "text": "rom [::1]:8080 -> 8080\n\nVisit http://127.0.0.1:8080/ and log in using `admin` as the username and the password you retrieved earlier.\n\nThis section describes how to use a set of YAML (Yet Another Markup Language) files to install Jenkins on a Kubernetes cluster.\nThe YAML files are easily tracked, edited, and can be reused indefinitely.\n\nCopy the contents from  into your preferred text editor and c"
  },
  "5747": {
    "source_file": "_kubernetes.txt",
    "text": "tes cluster.\nThe YAML files are easily tracked, edited, and can be reused indefinitely.\n\nCopy the contents from  into your preferred text editor and create a jenkins-03-deployment.yaml file in the \u201cjenkins\u201d namespace we created in the .\n\n* This  is defining a Deployment as indicated by the `kind` field.\n* The Deployment specifies a single replica. This ensures one and only one instance\nwill be mai"
  },
  "5748": {
    "source_file": "_kubernetes.txt",
    "text": "efining a Deployment as indicated by the `kind` field.\n* The Deployment specifies a single replica. This ensures one and only one instance\nwill be maintained by the Replication Controller in the event of failure.\n* The container image name is `jenkins` and version is a floating tag `lts-jdk21`\n(for determinism, you may want a specific version tag like `2.32.2` instead -- but\nthen you would have to"
  },
  "5749": {
    "source_file": "_kubernetes.txt",
    "text": "s` and version is a floating tag `lts-jdk21`\n(for determinism, you may want a specific version tag like `2.32.2` instead -- but\nthen you would have to update and re-apply it with iterations of this file).\nNote you may have to set up an `imagePullPolicy: Always` to pull new images according\nto changes of the floating tag (e.g. when new LTS is released).\n* The list of ports specified within the spec"
  },
  "5750": {
    "source_file": "_kubernetes.txt",
    "text": "cy: Always` to pull new images according\nto changes of the floating tag (e.g. when new LTS is released).\n* The list of ports specified within the spec are a list of ports to expose from\nthe container on the Pods IP address.\n** Jenkins running on (http) port 8080.\n** The Pod exposes the port 8080 of the jenkins container.\n* The volumeMounts section of the file creates a Persistent Volume.\nThis volu"
  },
  "5751": {
    "source_file": "_kubernetes.txt",
    "text": "p) port 8080.\n** The Pod exposes the port 8080 of the jenkins container.\n* The volumeMounts section of the file creates a Persistent Volume.\nThis volume is mounted within the container at the path /var/jenkins_home and\nso modifications to data within /var/jenkins_home are written to the volume.\nThe role of a persistent volume is to store basic Jenkins data and preserve it\nbeyond the lifetime of a "
  },
  "5752": {
    "source_file": "_kubernetes.txt",
    "text": " /var/jenkins_home are written to the volume.\nThe role of a persistent volume is to store basic Jenkins data and preserve it\nbeyond the lifetime of a pod.\n\nExit and save the changes once you add the content to the Jenkins deployment file.\n\nTo create the deployment execute:\n\nkubectl create -f jenkins-03-deployment.yaml -n jenkins\n\nThe command also instructs the system to install Jenkins within the "
  },
  "5753": {
    "source_file": "_kubernetes.txt",
    "text": "the deployment execute:\n\nkubectl create -f jenkins-03-deployment.yaml -n jenkins\n\nThe command also instructs the system to install Jenkins within the jenkins namespace.\n\nTo validate that creating the deployment was successful you can invoke:\n\nkubectl get deployments -n jenkins\n\nWe have a Jenkins controller deployed but it is still not accessible.\nThe Jenkins Pod has been assigned an IP address tha"
  },
  "5754": {
    "source_file": "_kubernetes.txt",
    "text": " get deployments -n jenkins\n\nWe have a Jenkins controller deployed but it is still not accessible.\nThe Jenkins Pod has been assigned an IP address that is internal to the Kubernetes cluster.\nIt\u2019s possible to log into the Kubernetes Node and access Jenkins from there but that\u2019s not a very useful way to access the service.\n\nTo make Jenkins accessible outside the Kubernetes cluster the Pod needs to b"
  },
  "5755": {
    "source_file": "_kubernetes.txt",
    "text": "nkins from there but that\u2019s not a very useful way to access the service.\n\nTo make Jenkins accessible outside the Kubernetes cluster the Pod needs to be exposed as a Service.\nA Service is an abstraction that exposes Jenkins to the wider network.\nIt allows us to maintain a persistent connection to the pod regardless of the changes in the cluster.\nWith a local deployment, this means creating a NodePo"
  },
  "5756": {
    "source_file": "_kubernetes.txt",
    "text": "lows us to maintain a persistent connection to the pod regardless of the changes in the cluster.\nWith a local deployment, this means creating a NodePort service type.\nA NodePort service type exposes a service on a port on each node in the cluster.\nThe service is accessed through the Node IP address and the service nodePort.\nA simple service is defined :\n\n* This  is defining a Service as\nindicated "
  },
  "5757": {
    "source_file": "_kubernetes.txt",
    "text": "e service is accessed through the Node IP address and the service nodePort.\nA simple service is defined :\n\n* This  is defining a Service as\nindicated by the `kind` field.\n* The Service is of type NodePort. Other options are ClusterIP (only accessible within the cluster) and LoadBalancer (IP address assigned by a cloud provider e.g. AWS Elastic IP).\n* The list of ports specified within the spec is "
  },
  "5758": {
    "source_file": "_kubernetes.txt",
    "text": " within the cluster) and LoadBalancer (IP address assigned by a cloud provider e.g. AWS Elastic IP).\n* The list of ports specified within the spec is a list of ports exposed by this service.\n** The port is the port that will be exposed by the service.\n** The target port is the port to access the Pods targeted by this service. A port name may also be specified.\n* The selector specifies the selectio"
  },
  "5759": {
    "source_file": "_kubernetes.txt",
    "text": ".\n** The target port is the port to access the Pods targeted by this service. A port name may also be specified.\n* The selector specifies the selection criteria for the Pods targeted by this service.\n\nTo create the service execute:\n\nkubectl create -f jenkins-04-service.yaml -n jenkins\n\nTo validate that creating the service was successful you can run:\n\nkubectl get services -n jenkins\nNAME       TYP"
  },
  "5760": {
    "source_file": "_kubernetes.txt",
    "text": " jenkins-04-service.yaml -n jenkins\n\nTo validate that creating the service was successful you can run:\n\nkubectl get services -n jenkins\nNAME       TYPE        CLUSTER-IP       EXTERNAL-IP    PORT(S)           AGE\njenkins    NodePort    10.103.31.217    <none>         8080:32664/TCP    59s\n\nSo now we have created a deployment and service, how do we access Jenkins?\n\nFrom the output above we can see "
  },
  "5761": {
    "source_file": "_kubernetes.txt",
    "text": "   <none>         8080:32664/TCP    59s\n\nSo now we have created a deployment and service, how do we access Jenkins?\n\nFrom the output above we can see that the service has been exposed on port 32664.\nWe also know that because the service is of type NodeType the service will route\nrequests made to any node on this port to the Jenkins pod.\nAll that\u2019s left for us is to determine the IP address of the "
  },
  "5762": {
    "source_file": "_kubernetes.txt",
    "text": "deType the service will route\nrequests made to any node on this port to the Jenkins pod.\nAll that\u2019s left for us is to determine the IP address of the minikube VM.\nMinikube have made this really simple by including a specific command that outputs\nthe IP address of the running cluster:\n\nminikube ip\n192.168.99.100\n\nNow we can access the Jenkins controller at http://192.168.99.100:32664/\n\nTo access Je"
  },
  "5763": {
    "source_file": "_kubernetes.txt",
    "text": "IP address of the running cluster:\n\nminikube ip\n192.168.99.100\n\nNow we can access the Jenkins controller at http://192.168.99.100:32664/\n\nTo access Jenkins, you initially need to enter your credentials.\nThe default username for new installations is admin.\nThe password can be obtained in several ways.\nThis example uses the Jenkins deployment pod name.\n\nTo find the name of the pod, enter the followi"
  },
  "5764": {
    "source_file": "_kubernetes.txt",
    "text": "dmin.\nThe password can be obtained in several ways.\nThis example uses the Jenkins deployment pod name.\n\nTo find the name of the pod, enter the following command:\n\nkubectl get pods -n jenkins\n\nOnce you locate the name of the pod, use it to access the pod\u2019s logs.\n\nkubectl logs <pod_name> -n jenkins\n\nThe password is at the end of the log formatted as a long alphanumeric string:\n\n\n\n\n\nJenkins initial s"
  },
  "5765": {
    "source_file": "_kubernetes.txt",
    "text": "pod\u2019s logs.\n\nkubectl logs <pod_name> -n jenkins\n\nThe password is at the end of the log formatted as a long alphanumeric string:\n\n\n\n\n\nJenkins initial setup is required.\nAn admin user has been created and a password generated.\nPlease use the following password to proceed to installation:\n\n94b73ef6578c4b4692a157f768b2cfef\n\nThis may also be found at:\n/var/jenkins_home/secrets/initialAdminPassword\n\n\n\n\n"
  },
  "5766": {
    "source_file": "_kubernetes.txt",
    "text": "password to proceed to installation:\n\n94b73ef6578c4b4692a157f768b2cfef\n\nThis may also be found at:\n/var/jenkins_home/secrets/initialAdminPassword\n\n\n\n\n\nYou have successfully installed Jenkins on your Kubernetes cluster and can use it to create new and efficient development pipelines.\n\nThe  is a Kubernetes native Operator which manages operations\nfor Jenkins on Kubernetes.\n\nIt was built with immutab"
  },
  "5767": {
    "source_file": "_kubernetes.txt",
    "text": " efficient development pipelines.\n\nThe  is a Kubernetes native Operator which manages operations\nfor Jenkins on Kubernetes.\n\nIt was built with immutability and declarative configuration as code in mind, to automate many of the manual tasks required\nto deploy and run Jenkins on Kubernetes.\n\nJenkins Operator is easy to install with applying just a few yaml manifests or with the use of Helm.\n\nFor ins"
  },
  "5768": {
    "source_file": "_kubernetes.txt",
    "text": "o deploy and run Jenkins on Kubernetes.\n\nJenkins Operator is easy to install with applying just a few yaml manifests or with the use of Helm.\n\nFor instructions on installing Jenkins Operator on your Kubernetes cluster and deploying and configuring Jenkins there,\nsee ."
  },
  "5769": {
    "source_file": "_kubernetes.txt",
    "text": "nkins there,\nsee ."
  },
  "5770": {
    "source_file": "_new_prerequisites.txt",
    "text": "For this tutorial, you will require:\n\n* A macOS, Linux, Windows, or Chromebook (with Linux) machine with:\n** 2 GB of RAM\n** 2 GB of drive space for Jenkins\n* The following software installed:\n** https://www.docker.com/[Docker]\n** https://docs.docker.com/compose/install/[Docker Compose]"
  },
  "5771": {
    "source_file": "_new_prerequisites.txt",
    "text": "com/compose/install/[Docker Compose]"
  },
  "5772": {
    "source_file": "_prerequisites.txt",
    "text": "For this tutorial, you will require:\n\n* A macOS, Linux or Windows machine with:\n** 256 MB of RAM, although more than 2 GB is recommended.\n** 10 GB of drive space for Jenkins and your Docker images and containers.\n* The following software installed:\n** https://www.docker.com/[Docker] - Read more about installing Docker in the\n    section of\n   the  page. +\n   *Note:* If you use Linux, this tutorial"
  },
  "5773": {
    "source_file": "_prerequisites.txt",
    "text": "* https://www.docker.com/[Docker] - Read more about installing Docker in the\n    section of\n   the  page. +\n   *Note:* If you use Linux, this tutorial assumes that you are not running\n   Docker commands as the root user, but instead with a single user account that\n   also has access to the other tools used throughout this tutorial."
  },
  "5774": {
    "source_file": "_prerequisites.txt",
    "text": "r account that\n   also has access to the other tools used throughout this tutorial."
  },
  "5775": {
    "source_file": "_run-jenkins-in-docker.txt",
    "text": "In this tutorial, you'll be running Jenkins as a Docker container from the\n Docker\nimage.\n\nTo run Jenkins in Docker, follow the relevant instructions below for either\n<<on-macos-and-linux,macOS and Linux>> or <<on-windows,Windows>>.\n\nYou can read more about Docker container and image concepts in the\n\nsection of the  page."
  },
  "5776": {
    "source_file": "_run-jenkins-in-docker.txt",
    "text": "e about Docker container and image concepts in the\n\nsection of the  page."
  },
  "5777": {
    "source_file": "_setup-wizard-for-tutorials.txt",
    "text": "[[setup-wizard]]\n\nBefore you can access Jenkins, there are a few quick \"one-off\" steps you'll need\nto perform.\n\nWhen you first access a new Jenkins controller, you are asked to unlock it using\nan automatically-generated password.\n\nAfter the 2 sets of asterisks appear in the terminal/command prompt window,\n  browse to `http://localhost:8080` and wait until the *Unlock Jenkins* page\n  appears.\n[.box"
  },
  "5778": {
    "source_file": "_setup-wizard-for-tutorials.txt",
    "text": " asterisks appear in the terminal/command prompt window,\n  browse to `http://localhost:8080` and wait until the *Unlock Jenkins* page\n  appears.\n[.boxshadow]\n\nDisplay the Jenkins console log with the command:\ndocker logs jenkins-blueocean\n\nFrom your terminal/command prompt window again, copy the\n  automatically-generated alphanumeric password (between the 2 sets of\n  asterisks).\n[.boxshadow]\n\nOn t"
  },
  "5779": {
    "source_file": "_setup-wizard-for-tutorials.txt",
    "text": "terminal/command prompt window again, copy the\n  automatically-generated alphanumeric password (between the 2 sets of\n  asterisks).\n[.boxshadow]\n\nOn the *Unlock Jenkins* page, paste this password into the *Administrator\n  password* field and click *Continue*.\n\nAfter <<unlocking-jenkins,unlocking Jenkins>>, the *Customize Jenkins* page\nappears.\n\nOn this page, click *Install suggested plugins*.\n\nThe"
  },
  "5780": {
    "source_file": "_setup-wizard-for-tutorials.txt",
    "text": "ontinue*.\n\nAfter <<unlocking-jenkins,unlocking Jenkins>>, the *Customize Jenkins* page\nappears.\n\nOn this page, click *Install suggested plugins*.\n\nThe setup wizard shows the progression of Jenkins being configured and the\nsuggested plugins being installed. This process may take a few minutes.\n\nFinally, Jenkins asks you to create your first administrator user.\n\nWhen the *Create First Admin User* pa"
  },
  "5781": {
    "source_file": "_setup-wizard-for-tutorials.txt",
    "text": "alled. This process may take a few minutes.\n\nFinally, Jenkins asks you to create your first administrator user.\n\nWhen the *Create First Admin User* page appears, specify your details in the\n  respective fields and click *Save and Finish*.\nWhen the *Jenkins is ready* page appears, click *Start using Jenkins*. +\n  *Notes:*\n* This page may indicate *Jenkins is almost ready!* instead and if so, click\n"
  },
  "5782": {
    "source_file": "_setup-wizard-for-tutorials.txt",
    "text": "enkins is ready* page appears, click *Start using Jenkins*. +\n  *Notes:*\n* This page may indicate *Jenkins is almost ready!* instead and if so, click\n  *Restart*.\n* If the page doesn't automatically refresh after a minute, use your web browser\n  to refresh the page manually.\nIf required, log in to Jenkins with the credentials of the user you just\n  created and you're ready to start using Jenkins!\n"
  },
  "5783": {
    "source_file": "_setup-wizard-for-tutorials.txt",
    "text": "efresh the page manually.\nIf required, log in to Jenkins with the credentials of the user you just\n  created and you're ready to start using Jenkins!\n\nThroughout the remainder of this tutorial, you can stop your\nDocker container by running:\n\ndocker stop jenkins-blueocean jenkins-docker\n\nTo restart your Docker container:\n\nRun the same `docker run ...` commands you ran for <<on-macos-and-linux,macOS"
  },
  "5784": {
    "source_file": "_setup-wizard-for-tutorials.txt",
    "text": "top jenkins-blueocean jenkins-docker\n\nTo restart your Docker container:\n\nRun the same `docker run ...` commands you ran for <<on-macos-and-linux,macOS, Linux>> or\n  <<on-windows,Windows>> above. +\nBrowse to `http://localhost:8080`.\nWait until the log in page appears and log in."
  },
  "5785": {
    "source_file": "_setup-wizard-for-tutorials.txt",
    "text": " in page appears and log in."
  },
  "5786": {
    "source_file": "_setup-wizard.txt",
    "text": "[[setup-wizard]]\n\nAfter downloading, installing and running Jenkins using one of the procedures\nabove (except for installation with Jenkins Operator), the post-installation setup wizard begins.\n\nThis setup wizard takes you through a few quick \"one-off\" steps to unlock\nJenkins, customize it with plugins and create the first administrator user\nthrough which you can continue accessing Jenkins.\n\nWhen "
  },
  "5787": {
    "source_file": "_setup-wizard.txt",
    "text": "f\" steps to unlock\nJenkins, customize it with plugins and create the first administrator user\nthrough which you can continue accessing Jenkins.\n\nWhen you first access a new Jenkins controller, you are asked to unlock it using\nan automatically-generated password.\n\nBrowse to `http://localhost:8080` (or whichever port you configured for\n  Jenkins when installing it) and wait until the *Unlock Jenkins"
  },
  "5788": {
    "source_file": "_setup-wizard.txt",
    "text": "ed password.\n\nBrowse to `http://localhost:8080` (or whichever port you configured for\n  Jenkins when installing it) and wait until the *Unlock Jenkins* page appears.\n[.boxshadow]\n\nFrom the Jenkins console log output, copy the automatically-generated\n  alphanumeric password (between the 2 sets of asterisks).\n[.boxshadow]\n\n  *Note:*\n* The command: `sudo cat /var/lib/jenkins/secrets/initialAdminPassw"
  },
  "5789": {
    "source_file": "_setup-wizard.txt",
    "text": "  alphanumeric password (between the 2 sets of asterisks).\n[.boxshadow]\n\n  *Note:*\n* The command: `sudo cat /var/lib/jenkins/secrets/initialAdminPassword` will print the password at console. +\n* If you are running Jenkins in Docker using the official `jenkins/jenkins` image you can use `sudo docker exec ${CONTAINER_ID or CONTAINER_NAME} cat /var/jenkins_home/secrets/initialAdminPassword` to print "
  },
  "5790": {
    "source_file": "_setup-wizard.txt",
    "text": " `jenkins/jenkins` image you can use `sudo docker exec ${CONTAINER_ID or CONTAINER_NAME} cat /var/jenkins_home/secrets/initialAdminPassword` to print the password in the console without having to exec into the container. +\nOn the *Unlock Jenkins* page, paste this password into the *Administrator\n  password* field and click *Continue*. +\n  *Note:*\n* The Jenkins console log indicates the location (i"
  },
  "5791": {
    "source_file": "_setup-wizard.txt",
    "text": "e, paste this password into the *Administrator\n  password* field and click *Continue*. +\n  *Note:*\n* The Jenkins console log indicates the location (in the Jenkins home directory)\n  where this password can also be obtained. This password must be entered in the\n  setup wizard on new Jenkins installations before you can access Jenkins's main\n  UI. This password also serves as the default administrat"
  },
  "5792": {
    "source_file": "_setup-wizard.txt",
    "text": "red in the\n  setup wizard on new Jenkins installations before you can access Jenkins's main\n  UI. This password also serves as the default administrator account's password\n  (with username \"admin\") if you happen to skip the subsequent user-creation\n  step in the setup wizard.\n\nAfter <<unlocking-jenkins,unlocking Jenkins>>, the *Customize Jenkins* page\nappears. Here you can install any number of us"
  },
  "5793": {
    "source_file": "_setup-wizard.txt",
    "text": " step in the setup wizard.\n\nAfter <<unlocking-jenkins,unlocking Jenkins>>, the *Customize Jenkins* page\nappears. Here you can install any number of useful plugins as part of your\ninitial setup.\n\nClick one of the two options shown:\n\n* *Install suggested plugins* - to install the recommended set of plugins, which\n   are based on most common use cases.\n* *Select plugins to install* - to choose which "
  },
  "5794": {
    "source_file": "_setup-wizard.txt",
    "text": "ed plugins* - to install the recommended set of plugins, which\n   are based on most common use cases.\n* *Select plugins to install* - to choose which set of plugins to initially\n   install. When you first access the plugin selection page, the suggested\n   plugins are selected by default.\n\nNOTE: If you are not sure what plugins you need, choose **Install suggested\nplugins**.\nYou can install (or rem"
  },
  "5795": {
    "source_file": "_setup-wizard.txt",
    "text": "ed\n   plugins are selected by default.\n\nNOTE: If you are not sure what plugins you need, choose **Install suggested\nplugins**.\nYou can install (or remove) additional Jenkins plugins at a later point in time\nvia the\n >\n page in Jenkins.\n\nThe setup wizard shows the progression of Jenkins being configured and your\nchosen set of Jenkins plugins being installed. This process may take a few\nminutes.\n\nFi"
  },
  "5796": {
    "source_file": "_setup-wizard.txt",
    "text": "ard shows the progression of Jenkins being configured and your\nchosen set of Jenkins plugins being installed. This process may take a few\nminutes.\n\nFinally, after <<customizing-jenkins-with-plugins,customizing Jenkins with\nplugins>>, Jenkins asks you to create your first administrator user.\n\nWhen the *Create First Admin User* page appears, specify the details for your\n  administrator user in the r"
  },
  "5797": {
    "source_file": "_setup-wizard.txt",
    "text": " to create your first administrator user.\n\nWhen the *Create First Admin User* page appears, specify the details for your\n  administrator user in the respective fields and click *Save and Finish*.\nWhen the *Jenkins is ready* page appears, click *Start using Jenkins*. +\n  *Notes:*\n* This page may indicate *Jenkins is almost ready!* instead and if so, click\n  *Restart*.\n* If the page does not automat"
  },
  "5798": {
    "source_file": "_setup-wizard.txt",
    "text": " using Jenkins*. +\n  *Notes:*\n* This page may indicate *Jenkins is almost ready!* instead and if so, click\n  *Restart*.\n* If the page does not automatically refresh after a minute, use your web\n  browser to refresh the page manually.\nIf required, log in to Jenkins with the credentials of the user you just\n  created and you are ready to start using Jenkins!"
  },
  "5799": {
    "source_file": "_setup-wizard.txt",
    "text": " in to Jenkins with the credentials of the user you just\n  created and you are ready to start using Jenkins!"
  }
}